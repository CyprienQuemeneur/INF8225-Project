{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "abstract-tomato",
      "metadata": {
        "id": "abstract-tomato"
      },
      "source": [
        "\n",
        "$\\color{red}{\\text{WARNING}}$\n",
        "\n",
        "**Opening the file directly into GitHub will display the entire content of the cells, as they are extremely lengthy this will severely complexify the reading of the notebook. We strongly encourage you to download this file locally and open it with jupyter before attempting to examine it.**\n",
        "\n",
        "# ResNet meets Split-Attention: replication, ablation and analysis of ResNeSt\n",
        "# Transfer learning subsection\n",
        "\n",
        "*Authors: Emilie OURAOU, Cyprien QUEMENEUR, Hugo RODET*\n",
        "\n",
        "\n",
        "<img src=\"https://pytorch.org/assets/images/resnest.jpg\" alt=\"alt\" width=\"50%\"/>\n",
        "\n",
        "### Overview\n",
        "ResNeSt is an architecture of neural networks, applied to computer vision, proposing a mix between a modern convolutive neural network (CNN), the ResNet, as well as the attention mechanism. For our final project we propose a study of the article which introduced the ResNeSts and conduct some additional analyses and ablations. This work indirectly follows our article presentation which focused on vision transformers (ViTs).\n",
        "\n",
        "ResNeSts can be trained as a general model on image classification then fine-tuned on more downstream tasks (aka transfer learning). This notebook reproduces the experiments on semantic segmentation, instance segmentation and object detection, using the pretrained models made available by the authors of the original article (all rights reserved).\n",
        "\n",
        "### Disclaimer\n",
        "This notebook includes several pieces of analyses along with the experiments. However it does not substitute the final report, which is written under an article format.\n",
        "\n",
        "### Relevant references for this subsection\n",
        "\n",
        "Reference to the main article:\n",
        "* [ResNeSt: Split-Attention Networks](https://arxiv.org/abs/2004.08955)\n",
        "\n",
        "References to the repositories:\n",
        "* [ResNeSt main repository](https://github.com/zhanghang1989/ResNeSt)\n",
        "* [Detectron2](https://github.com/facebookresearch/detectron2)\n",
        "* [PyTorch-Encoding](https://github.com/zhanghang1989/PyTorch-Encoding)\n",
        "\n",
        "References to the datasets:\n",
        "* [ADE20k](https://groups.csail.mit.edu/vision/datasets/ADE20K/)\n",
        "* [COCO](https://cocodataset.org/#home)\n",
        "* [CityScapes](https://www.cityscapes-dataset.com/)\n",
        "\n",
        "Other references:\n",
        "* [PyTorch-Encoding for semantic segmentation](https://hangzhang.org/PyTorch-Encoding/model_zoo/segmentation.html)\n",
        "* [GluonCV toolkit for segmentation](https://cv.gluon.ai/model_zoo/segmentation.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semantic segmentation on ADE20k"
      ],
      "metadata": {
        "id": "ApeHVSAySAeM"
      },
      "id": "ApeHVSAySAeM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A simple example"
      ],
      "metadata": {
        "id": "sBOpM9q89-8M"
      },
      "id": "sBOpM9q89-8M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The links to download the pretrained ResNeSt models for semantic segmentation are available on:\n",
        "\n",
        "- Gluon (https://cv.gluon.ai/model_zoo/segmentation.html)\n",
        "- The first author's personal website (https://hangzhang.org/PyTorch-Encoding/model_zoo/segmentation.html)\n",
        "\n",
        "We first test the pretrained model on a single image."
      ],
      "metadata": {
        "id": "99uzcBkoTOag"
      },
      "id": "99uzcBkoTOag"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import encoding"
      ],
      "metadata": {
        "id": "HkAYdfFrgUlu"
      },
      "id": "HkAYdfFrgUlu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/zhanghang1989/PyTorch-Encoding/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8PsGCGA6FK7",
        "outputId": "10efac5a-e9e8-4bad-bc7e-0c20e97fa37b"
      },
      "id": "C8PsGCGA6FK7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/zhanghang1989/PyTorch-Encoding/\n",
            "  Cloning https://github.com/zhanghang1989/PyTorch-Encoding/ to /tmp/pip-req-build-l4kp7bi2\n",
            "  Running command git clone -q https://github.com/zhanghang1989/PyTorch-Encoding/ /tmp/pip-req-build-l4kp7bi2\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20220417) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20220417) (4.64.0)\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20220417) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20220417) (0.11.1+cu111)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20220417) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20220417) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20220417) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->torch-encoding==1.2.2b20220417) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20220417) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20220417) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20220417) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20220417) (1.24.3)\n",
            "Building wheels for collected packages: torch-encoding\n",
            "  Building wheel for torch-encoding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-encoding: filename=torch_encoding-1.2.2b20220417-cp37-cp37m-linux_x86_64.whl size=9153068 sha256=1f64cddd24e8c0ca370aff102c57a3512c148517b86ff0399c2c05ef6243d508\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dqwic_uh/wheels/d4/83/00/5a9524a23f206528125bf76110b7304681afa76adbba084b5c\n",
            "Successfully built torch-encoding\n",
            "Installing collected packages: portalocker, nose, torch-encoding\n",
            "Successfully installed nose-1.3.7 portalocker-2.4.0 torch-encoding-1.2.2b20220417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the pretrained model ResNeSt50 from the net and load the image."
      ],
      "metadata": {
        "id": "gn9V0DMTTaWe"
      },
      "id": "gn9V0DMTTaWe"
    },
    {
      "cell_type": "code",
      "source": [
        "model = encoding.models.get_model('DeepLab_ResNeSt50_PContext', pretrained=True).cuda()\n",
        "model.eval()\n",
        "\n",
        "url = 'https://github.com/zhanghang1989/image-data/blob/master/' + \\\n",
        "      'encoding/segmentation/pcontext/2010_001829_org.jpg?raw=true'\n",
        "filename = 'example.jpg'\n",
        "img = encoding.utils.load_image(\n",
        "    encoding.utils.download(url, filename)).cuda().unsqueeze(0)"
      ],
      "metadata": {
        "id": "3fp4JqIUgYyf"
      },
      "id": "3fp4JqIUgYyf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting the result and visualising it. The image is stored on the drive."
      ],
      "metadata": {
        "id": "qnPCnFy7Tlne"
      },
      "id": "qnPCnFy7Tlne"
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.evaluate(img)\n",
        "predict = torch.max(output, 1)[1].cpu().numpy() + 1\n",
        "\n",
        "mask = encoding.utils.get_mask_pallete(predict, 'pascal_voc')\n",
        "mask.save('output.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tfXgafm51HR",
        "outputId": "bf6e61a0-f760-48a0-ab3a-ba09e83c7577"
      },
      "id": "5tfXgafm51HR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model file /root/.encoding/models/resnest50-fb9de5b3.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/resnest50-fb9de5b3.zip from https://s3.us-west-1.wasabisys.com/encoding/models/resnest50-fb9de5b3.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 107689/107689 [00:07<00:00, 13739.36KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model file /root/.encoding/models/deeplab_resnest50_pcontext-08dccbc4.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/deeplab_resnest50_pcontext-08dccbc4.zip from https://s3.us-west-1.wasabisys.com/encoding/models/deeplab_resnest50_pcontext-08dccbc4.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "172046KB [00:07, 21675.93KB/s]                            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conducting the experiments"
      ],
      "metadata": {
        "id": "38rHRo9D-Cvs"
      },
      "id": "38rHRo9D-Cvs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now replicate the results of the paper for the pretrained models fine-tuned for semantic segmentation. The dataset used is ADE20K. \n",
        "\n",
        "The original paper also includes experiments on CityScapes, but contrary to what is announced we could not find the pretrained models for this dataset.\n",
        "\n",
        "For more information on these two datasets see:\n",
        "* https://groups.csail.mit.edu/vision/datasets/ADE20K/\n",
        "* https://www.cityscapes-dataset.com/\n",
        "\n",
        "We will access the necessary files from the drive and run the experiments with Colab. For this to work you will need to download the PyTorch-Encoding repository and add it to your drive (all rights reserved). The link to the repository is the following: \n",
        "* https://github.com/zhanghang1989/PyTorch-Encoding"
      ],
      "metadata": {
        "id": "yQeBmPJqTtfx"
      },
      "id": "yQeBmPJqTtfx"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kos0q-2pkHe6",
        "outputId": "1227bdb7-6802-4d85-d4a0-9ae08d0cd0e2"
      },
      "id": "kos0q-2pkHe6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZb2hN0ikmPT",
        "outputId": "8493dbb2-ee8a-4162-8c1c-c258a8b3231c"
      },
      "id": "RZb2hN0ikmPT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may need to update the path according to your drive's files organisation."
      ],
      "metadata": {
        "id": "Z2Hs5R6Xcwy8"
      },
      "id": "Z2Hs5R6Xcwy8"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/PyTorch-Encoding && python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGBTpUKVkOaX",
        "outputId": "34fb2b18-0d37-4197-a62d-714aa39acbe5"
      },
      "id": "iGBTpUKVkOaX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Building version 1.2.2b20220417\n",
            "c++:  ['/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.cpp', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/syncbn_cpu.cpp', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/encoding_cpu.cpp', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/rectify_cpu.cpp', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/operator.cpp', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp']\n",
            "cuda:  ['/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/operator.cpp', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/encoding_kernel.cu', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/lib_ssd.cu', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/roi_align_kernel.cu', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.cu', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/rectify_cuda.cu', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/syncbn_kernel.cu', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/activation_kernel.cu']\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing torch_encoding.egg-info/PKG-INFO\n",
            "writing dependency_links to torch_encoding.egg-info/dependency_links.txt\n",
            "writing requirements to torch_encoding.egg-info/requires.txt\n",
            "writing top-level names to torch_encoding.egg-info/top_level.txt\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:381: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'torch_encoding.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/encoding\n",
            "copying encoding/__init__.py -> build/lib.linux-x86_64-3.7/encoding\n",
            "copying encoding/parallel.py -> build/lib.linux-x86_64-3.7/encoding\n",
            "copying encoding/version.py -> build/lib.linux-x86_64-3.7/encoding\n",
            "creating build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/pcontext.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/cityscapescoarse.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/ade20k.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/pascal_aug.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/imagenet.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/pascal_voc.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/__init__.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/minc.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/cityscapes.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/base.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/hpw18.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/coco.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/folder.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "creating build/lib.linux-x86_64-3.7/encoding/functions\n",
            "copying encoding/functions/rectify.py -> build/lib.linux-x86_64-3.7/encoding/functions\n",
            "copying encoding/functions/customize.py -> build/lib.linux-x86_64-3.7/encoding/functions\n",
            "copying encoding/functions/dist_syncbn.py -> build/lib.linux-x86_64-3.7/encoding/functions\n",
            "copying encoding/functions/__init__.py -> build/lib.linux-x86_64-3.7/encoding/functions\n",
            "copying encoding/functions/encoding.py -> build/lib.linux-x86_64-3.7/encoding/functions\n",
            "copying encoding/functions/syncbn.py -> build/lib.linux-x86_64-3.7/encoding/functions\n",
            "creating build/lib.linux-x86_64-3.7/encoding/models\n",
            "copying encoding/models/model_zoo.py -> build/lib.linux-x86_64-3.7/encoding/models\n",
            "copying encoding/models/__init__.py -> build/lib.linux-x86_64-3.7/encoding/models\n",
            "copying encoding/models/model_store.py -> build/lib.linux-x86_64-3.7/encoding/models\n",
            "copying encoding/models/deepten.py -> build/lib.linux-x86_64-3.7/encoding/models\n",
            "creating build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/lr_scheduler.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/__init__.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/files.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/dist_helper.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/metrics.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/presets.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/pallete.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/precise_bn.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/misc.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/train_helper.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "creating build/lib.linux-x86_64-3.7/encoding/transforms\n",
            "copying encoding/transforms/autoaug.py -> build/lib.linux-x86_64-3.7/encoding/transforms\n",
            "copying encoding/transforms/__init__.py -> build/lib.linux-x86_64-3.7/encoding/transforms\n",
            "copying encoding/transforms/get_transform.py -> build/lib.linux-x86_64-3.7/encoding/transforms\n",
            "copying encoding/transforms/transforms.py -> build/lib.linux-x86_64-3.7/encoding/transforms\n",
            "creating build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/attention.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/customize.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/syncbn.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/encoding.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/__init__.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/splat.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/rectify.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/dropblock.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/loss.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "creating build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "copying encoding/models/backbone/resnest.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "copying encoding/models/backbone/wideresnet.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "copying encoding/models/backbone/resnet_variants.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "copying encoding/models/backbone/xception.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "copying encoding/models/backbone/resnext.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "copying encoding/models/backbone/resnet.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "copying encoding/models/backbone/__init__.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "creating build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/psp.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/atten.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/deeplab.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/upernet.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/fcfpn.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/__init__.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/encnet.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/base.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/fcn.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "creating build/lib.linux-x86_64-3.7/encoding/lib\n",
            "creating build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "copying encoding/lib/cpu/operator.h -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "copying encoding/lib/cpu/roi_align_cpu.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "copying encoding/lib/cpu/syncbn_cpu.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "copying encoding/lib/cpu/encoding_cpu.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "copying encoding/lib/cpu/rectify_cpu.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "copying encoding/lib/cpu/operator.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "copying encoding/lib/cpu/nms_cpu.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "creating build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/common.h -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/device_tensor.h -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/operator.h -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/operator.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/encoding_kernel.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/lib_ssd.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/roi_align_kernel.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/nms_kernel.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/rectify_cuda.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/syncbn_kernel.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/activation_kernel.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "running build_ext\n",
            "building 'encoding.cpu' extension\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/content\n",
            "creating build/temp.linux-x86_64-3.7/content/drive\n",
            "creating build/temp.linux-x86_64-3.7/content/drive/MyDrive\n",
            "creating build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks\n",
            "creating build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding\n",
            "creating build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding\n",
            "creating build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib\n",
            "creating build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.cpp -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.cpp:183:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n",
            " #pragma omp parallel for private(c) \\\n",
            " \n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/syncbn_cpu.cpp -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/syncbn_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/encoding_cpu.cpp -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/encoding_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/rectify_cpu.cpp -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/rectify_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/operator.cpp -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/operator.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/operator.cpp:1:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/operator.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kpybind11::array_t<float> apply_transform(int, int, int, pybind11::array_t<float>, pybind11::array_t<float>)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/operator.h:96:29:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Knarrowing conversion of ‘\u001b[01m\u001b[K(long unsigned int)img_buf.pybind11::buffer_info::size\u001b[m\u001b[K’ from ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’ to ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ inside { } [\u001b[01;35m\u001b[K-Wnarrowing\u001b[m\u001b[K]\n",
            "   py::array_t<float> result{\u001b[01;35m\u001b[K(unsigned long)img_buf.size\u001b[m\u001b[K};\n",
            "                             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:61:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n",
            " #pragma omp parallel for\n",
            " \n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:83:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n",
            " #pragma omp parallel for\n",
            " \n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<at::Tensor> Non_Max_Suppression_CPU(const at::Tensor&, const at::Tensor&, double)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:35:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_ASSERT(input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == at::kFloat || input.type().scalarType() == at::kDouble);\n",
            "                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:241:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            " #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:261:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            " #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:313:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                         \\\n",
            "       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:585:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(__VA_ARGS__)); \\\n",
            "                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:35:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_ASSERT(input.type().scalarType() == at::kFloat || input.type().scalarType() == at::kDouble);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:35:67:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_ASSERT(input.type().scalarType() == at::kFloat || input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == at::kDouble);\n",
            "                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:241:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            " #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:261:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            " #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:313:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                         \\\n",
            "       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:585:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(__VA_ARGS__)); \\\n",
            "                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:35:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_ASSERT(input.type().scalarType() == at::kFloat || input.type().scalarType() == at::kDouble);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:36:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_ASSERT(scores.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == at::kFloat || scores.type().scalarType() == at::kDouble);\n",
            "                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:241:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            " #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:261:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            " #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:313:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                         \\\n",
            "       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:585:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(__VA_ARGS__)); \\\n",
            "                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:36:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_ASSERT(scores.type().scalarType() == at::kFloat || scores.type().scalarType() == at::kDouble);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:36:69:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_ASSERT(scores.type().scalarType() == at::kFloat || scores.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == at::kDouble);\n",
            "                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:241:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            " #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:261:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            " #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:313:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                         \\\n",
            "       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:585:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(__VA_ARGS__)); \\\n",
            "                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:36:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_ASSERT(scores.type().scalarType() == at::kFloat || scores.type().scalarType() == at::kDouble);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:46:64:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto mask = torch::zeros({batch_size, num_boxes}, input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.toScalarType(at::kByte));\n",
            "                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:49:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = unsigned char]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto *rawMask = mask.data<unsigned char>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:216:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:50:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto *rawIdx = sorted_inds.data<int64_t>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:216:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:52:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   if (input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == at::kFloat)\n",
            "                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:54:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     auto *rawInput = input.data<float>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:216:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:77:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     auto *rawInput = input.data<double>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:216:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/syncbn_cpu.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/encoding_cpu.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/rectify_cpu.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/operator.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/encoding/cpu.cpython-37m-x86_64-linux-gnu.so\n",
            "building 'encoding.gpu' extension\n",
            "creating build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/operator.cpp -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/operator.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/encoding_kernel.cu -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/encoding_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/lib_ssd.cu -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/lib_ssd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/roi_align_kernel.cu -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/roi_align_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.cu -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<at::Tensor> Non_Max_Suppression_CUDA(const at::Tensor&, const at::Tensor&, double)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.cu:80:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto mask = torch::zeros({batch_size, num_boxes}, input.typ\u001b[01;35m\u001b[Ke\u001b[m\u001b[K().toScalarType(at::kByte));\n",
            "                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/rectify_cuda.cu -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/rectify_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/syncbn_kernel.cu -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/syncbn_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/activation_kernel.cu -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/activation_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/operator.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/encoding_kernel.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/lib_ssd.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/roi_align_kernel.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/rectify_cuda.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/syncbn_kernel.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/activation_kernel.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/encoding/gpu.cpython-37m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/encoding\n",
            "copying build/lib.linux-x86_64-3.7/encoding/__init__.py -> build/bdist.linux-x86_64/egg/encoding\n",
            "copying build/lib.linux-x86_64-3.7/encoding/parallel.py -> build/bdist.linux-x86_64/egg/encoding\n",
            "copying build/lib.linux-x86_64-3.7/encoding/version.py -> build/bdist.linux-x86_64/egg/encoding\n",
            "creating build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/pcontext.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/cityscapescoarse.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/ade20k.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/pascal_aug.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/imagenet.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/pascal_voc.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/__init__.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/minc.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/cityscapes.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/base.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/hpw18.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/coco.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/folder.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "creating build/bdist.linux-x86_64/egg/encoding/functions\n",
            "copying build/lib.linux-x86_64-3.7/encoding/functions/rectify.py -> build/bdist.linux-x86_64/egg/encoding/functions\n",
            "copying build/lib.linux-x86_64-3.7/encoding/functions/customize.py -> build/bdist.linux-x86_64/egg/encoding/functions\n",
            "copying build/lib.linux-x86_64-3.7/encoding/functions/dist_syncbn.py -> build/bdist.linux-x86_64/egg/encoding/functions\n",
            "copying build/lib.linux-x86_64-3.7/encoding/functions/__init__.py -> build/bdist.linux-x86_64/egg/encoding/functions\n",
            "copying build/lib.linux-x86_64-3.7/encoding/functions/encoding.py -> build/bdist.linux-x86_64/egg/encoding/functions\n",
            "copying build/lib.linux-x86_64-3.7/encoding/functions/syncbn.py -> build/bdist.linux-x86_64/egg/encoding/functions\n",
            "creating build/bdist.linux-x86_64/egg/encoding/models\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/model_zoo.py -> build/bdist.linux-x86_64/egg/encoding/models\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/__init__.py -> build/bdist.linux-x86_64/egg/encoding/models\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/model_store.py -> build/bdist.linux-x86_64/egg/encoding/models\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/deepten.py -> build/bdist.linux-x86_64/egg/encoding/models\n",
            "creating build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/backbone/resnest.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/backbone/wideresnet.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/backbone/resnet_variants.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/backbone/xception.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/backbone/resnext.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/backbone/resnet.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/backbone/__init__.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "creating build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/psp.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/atten.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/deeplab.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/upernet.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/fcfpn.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/__init__.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/encnet.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/base.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/fcn.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "creating build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/lr_scheduler.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/__init__.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/files.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/dist_helper.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/metrics.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/presets.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/pallete.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/precise_bn.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/misc.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/train_helper.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "creating build/bdist.linux-x86_64/egg/encoding/transforms\n",
            "copying build/lib.linux-x86_64-3.7/encoding/transforms/autoaug.py -> build/bdist.linux-x86_64/egg/encoding/transforms\n",
            "copying build/lib.linux-x86_64-3.7/encoding/transforms/__init__.py -> build/bdist.linux-x86_64/egg/encoding/transforms\n",
            "copying build/lib.linux-x86_64-3.7/encoding/transforms/get_transform.py -> build/bdist.linux-x86_64/egg/encoding/transforms\n",
            "copying build/lib.linux-x86_64-3.7/encoding/transforms/transforms.py -> build/bdist.linux-x86_64/egg/encoding/transforms\n",
            "creating build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/attention.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/customize.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/syncbn.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/encoding.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/__init__.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/splat.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/rectify.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/dropblock.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/loss.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "creating build/bdist.linux-x86_64/egg/encoding/lib\n",
            "creating build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/operator.h -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/roi_align_cpu.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/syncbn_cpu.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/encoding_cpu.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/rectify_cpu.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/operator.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/nms_cpu.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "creating build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/common.h -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/device_tensor.h -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/operator.h -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/operator.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/encoding_kernel.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/lib_ssd.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/roi_align_kernel.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/nms_kernel.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/rectify_cuda.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/syncbn_kernel.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/activation_kernel.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/cpu.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/encoding\n",
            "copying build/lib.linux-x86_64-3.7/encoding/gpu.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/encoding\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/parallel.py to parallel.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/version.py to version.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/pcontext.py to pcontext.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/cityscapescoarse.py to cityscapescoarse.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/ade20k.py to ade20k.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/pascal_aug.py to pascal_aug.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/imagenet.py to imagenet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/pascal_voc.py to pascal_voc.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/minc.py to minc.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/cityscapes.py to cityscapes.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/base.py to base.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/hpw18.py to hpw18.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/coco.py to coco.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/folder.py to folder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/rectify.py to rectify.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/customize.py to customize.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/dist_syncbn.py to dist_syncbn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/encoding.py to encoding.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/syncbn.py to syncbn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/model_zoo.py to model_zoo.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/model_store.py to model_store.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/deepten.py to deepten.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/resnest.py to resnest.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/wideresnet.py to wideresnet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/resnet_variants.py to resnet_variants.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/xception.py to xception.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/resnext.py to resnext.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/resnet.py to resnet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/psp.py to psp.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/atten.py to atten.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/deeplab.py to deeplab.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/upernet.py to upernet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/fcfpn.py to fcfpn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/encnet.py to encnet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/base.py to base.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/fcn.py to fcn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/lr_scheduler.py to lr_scheduler.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/files.py to files.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/dist_helper.py to dist_helper.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/metrics.py to metrics.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/presets.py to presets.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/pallete.py to pallete.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/precise_bn.py to precise_bn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/misc.py to misc.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/train_helper.py to train_helper.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/transforms/autoaug.py to autoaug.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/transforms/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/transforms/get_transform.py to get_transform.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/transforms/transforms.py to transforms.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/attention.py to attention.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/customize.py to customize.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/syncbn.py to syncbn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/encoding.py to encoding.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/splat.py to splat.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/rectify.py to rectify.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/dropblock.py to dropblock.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/loss.py to loss.cpython-37.pyc\n",
            "creating stub loader for encoding/cpu.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for encoding/gpu.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/cpu.py to cpu.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/gpu.py to gpu.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torch_encoding.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torch_encoding.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torch_encoding.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torch_encoding.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torch_encoding.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "encoding.__pycache__.cpu.cpython-37: module references __file__\n",
            "encoding.__pycache__.gpu.cpython-37: module references __file__\n",
            "creating dist\n",
            "creating 'dist/torch_encoding-1.2.2b20220417-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing torch_encoding-1.2.2b20220417-py3.7-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/torch_encoding-1.2.2b20220417-py3.7-linux-x86_64.egg\n",
            "Extracting torch_encoding-1.2.2b20220417-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding torch-encoding 1.2.2b20220417 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/torch_encoding-1.2.2b20220417-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for torch-encoding==1.2.2b20220417\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Pillow==7.1.2\n",
            "Best match: Pillow 7.1.2\n",
            "Adding Pillow 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torchvision==0.11.1+cu111\n",
            "Best match: torchvision 0.11.1+cu111\n",
            "Adding torchvision 0.11.1+cu111 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torch==1.10.0+cu111\n",
            "Best match: torch 1.10.0+cu111\n",
            "Adding torch 1.10.0+cu111 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for portalocker==2.4.0\n",
            "Best match: portalocker 2.4.0\n",
            "Adding portalocker 2.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for nose==1.3.7\n",
            "Best match: nose 1.3.7\n",
            "Adding nose 1.3.7 to easy-install.pth file\n",
            "Installing nosetests script to /usr/local/bin\n",
            "Installing nosetests-3.4 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.64.0\n",
            "Best match: tqdm 4.64.0\n",
            "Adding tqdm 4.64.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.5\n",
            "Best match: numpy 1.21.5\n",
            "Adding numpy 1.21.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2021.10.8\n",
            "Best match: certifi 2021.10.8\n",
            "Adding certifi 2021.10.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.1.1\n",
            "Best match: typing-extensions 4.1.1\n",
            "Adding typing-extensions 4.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for torch-encoding==1.2.2b20220417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading and preparing the dataset ADE20k"
      ],
      "metadata": {
        "id": "JBDBUCF7SH8d"
      },
      "id": "JBDBUCF7SH8d"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/PyTorch-Encoding && python scripts/prepare_ade20k.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hqg3sOhm4Hm",
        "outputId": "2695de0c-8077-460e-b76e-946a3dfcaef3"
      },
      "id": "5Hqg3sOhm4Hm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.encoding/data/downloads/ADEChallengeData2016.zip from http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip...\n",
            "944710KB [00:12, 72823.05KB/s]                \n",
            "Downloading /root/.encoding/data/downloads/release_test.zip from http://data.csail.mit.edu/places/ADEchallenge/release_test.zip...\n",
            "100% 206856/206856 [00:03<00:00, 67270.39KB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and evaluating ResNeST50 on the validation set."
      ],
      "metadata": {
        "id": "IlJAjz1aSOSD"
      },
      "id": "IlJAjz1aSOSD"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/PyTorch-Encoding/experiments/segmentation/ && python test.py --dataset ADE20K --model-zoo DeepLab_ResNeSt50_ADE --eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wdgxdkokROF",
        "outputId": "768e65f1-c7d1-4b97-f57a-235dd1b85799"
      },
      "id": "5wdgxdkokROF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(acc_bn=False, aux=False, backbone='resnet50', base_size=520, batch_size=16, crop_size=480, cuda=True, dataset='ADE20K', eval=True, export=None, model='encnet', model_zoo='DeepLab_ResNeSt50_ADE', no_cuda=False, no_val=False, resume=None, se_loss=False, se_weight=0.2, seed=1, test_batch_size=16, test_folder=None, test_val=False, train_split='train', verify=None, workers=16)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Model file /root/.encoding/models/resnest50-fb9de5b3.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/resnest50-fb9de5b3.zip from https://s3.us-west-1.wasabisys.com/encoding/models/resnest50-fb9de5b3.zip...\n",
            "100% 107689/107689 [00:08<00:00, 12596.27KB/s]\n",
            "Model file /root/.encoding/models/deeplab_resnest50_ade-2225f09d.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/deeplab_resnest50_ade-2225f09d.zip from https://s3.us-west-1.wasabisys.com/encoding/models/deeplab_resnest50_ade-2225f09d.zip...\n",
            "172229KB [00:09, 18697.87KB/s]                \n",
            "DeepLabV3(\n",
            "  (pretrained): ResNet(\n",
            "    (conv1): Sequential(\n",
            "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): GlobalAvgPool2d()\n",
            "    (fc): None\n",
            "  )\n",
            "  (head): DeepLabV3Head(\n",
            "    (aspp): ASPP_Module(\n",
            "      (b0): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b1): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b2): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b3): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b4): AsppPooling(\n",
            "        (gap): Sequential(\n",
            "          (0): AdaptiveAvgPool2d(output_size=1)\n",
            "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (3): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (project): Sequential(\n",
            "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Dropout2d(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (auxlayer): FCNHead(\n",
            "    (conv5): Sequential(\n",
            "      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "MultiEvalModule: base_size 520, crop_size 480\n",
            "pixAcc: 0.8117, mIoU: 0.4512: 100% 2000/2000 [1:26:53<00:00,  2.61s/it]\n",
            "pixAcc: 0.8117, mIoU: 0.4512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation results for ResNeSt50 on ADE20k validation set:\n",
        "* pixAcc: 0.8117\n",
        "* mIoU: 0.4512"
      ],
      "metadata": {
        "id": "980tAdNk8BXF"
      },
      "id": "980tAdNk8BXF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and evaluating ResNeST101 on the validation set."
      ],
      "metadata": {
        "id": "3r_WKhdeSWiG"
      },
      "id": "3r_WKhdeSWiG"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/PyTorch-Encoding/experiments/segmentation/ && python test.py --dataset ADE20K --model-zoo DeepLab_ResNeSt101_ADE --eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQsOdDnT8JIR",
        "outputId": "6d68d2c0-c45d-4992-b06b-5022e9aa5b49"
      },
      "id": "jQsOdDnT8JIR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(acc_bn=False, aux=False, backbone='resnet50', base_size=520, batch_size=16, crop_size=480, cuda=True, dataset='ADE20K', eval=True, export=None, model='encnet', model_zoo='DeepLab_ResNeSt101_ADE', no_cuda=False, no_val=False, resume=None, se_loss=False, se_weight=0.2, seed=1, test_batch_size=16, test_folder=None, test_val=False, train_split='train', verify=None, workers=16)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Model file /root/.encoding/models/resnest101-966fb78c.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/resnest101-966fb78c.zip from https://s3.us-west-1.wasabisys.com/encoding/models/resnest101-966fb78c.zip...\n",
            "189242KB [00:09, 19363.69KB/s]                \n",
            "Model file /root/.encoding/models/deeplab_resnest101_ade-06ca799c.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/deeplab_resnest101_ade-06ca799c.zip from https://s3.us-west-1.wasabisys.com/encoding/models/deeplab_resnest101_ade-06ca799c.zip...\n",
            "100% 253789/253789 [00:12<00:00, 21111.08KB/s]\n",
            "DeepLabV3(\n",
            "  (pretrained): ResNet(\n",
            "    (conv1): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (6): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (7): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (8): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (9): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (10): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (11): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (12): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (13): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (14): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (15): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (16): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (17): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (18): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (19): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (20): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (21): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (22): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): GlobalAvgPool2d()\n",
            "    (fc): None\n",
            "  )\n",
            "  (head): DeepLabV3Head(\n",
            "    (aspp): ASPP_Module(\n",
            "      (b0): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b1): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b2): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b3): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b4): AsppPooling(\n",
            "        (gap): Sequential(\n",
            "          (0): AdaptiveAvgPool2d(output_size=1)\n",
            "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (3): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (project): Sequential(\n",
            "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Dropout2d(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (auxlayer): FCNHead(\n",
            "    (conv5): Sequential(\n",
            "      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "MultiEvalModule: base_size 520, crop_size 480\n",
            "pixAcc: 0.8207, mIoU: 0.4691: 100% 2000/2000 [2:09:42<00:00,  3.89s/it]\n",
            "pixAcc: 0.8207, mIoU: 0.4691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation results for ResNeSt101 on ADE20k validation set:\n",
        "* pixAcc: 0.8207\n",
        "* mIoU: 0.4691"
      ],
      "metadata": {
        "id": "hO8f9IygaM4H"
      },
      "id": "hO8f9IygaM4H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and evaluating ResNeST200 on the validation set."
      ],
      "metadata": {
        "id": "tfLX5LlqSdK-"
      },
      "id": "tfLX5LlqSdK-"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/PyTorch-Encoding/experiments/segmentation/ && python test.py --dataset ADE20K --model-zoo DeepLab_ResNeSt200_ADE --eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U77b134jaRFw",
        "outputId": "73e70b1e-6d3a-46e6-8218-4b372141864c"
      },
      "id": "U77b134jaRFw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(acc_bn=False, aux=False, backbone='resnet50', base_size=520, batch_size=16, crop_size=480, cuda=True, dataset='ADE20K', eval=True, export=None, model='encnet', model_zoo='DeepLab_ResNeSt200_ADE', no_cuda=False, no_val=False, resume=None, se_loss=False, se_weight=0.2, seed=1, test_batch_size=16, test_folder=None, test_val=False, train_split='train', verify=None, workers=16)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Model file /root/.encoding/models/resnest200-d7fd712f.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/resnest200-d7fd712f.zip from https://s3.us-west-1.wasabisys.com/encoding/models/resnest200-d7fd712f.zip...\n",
            "100% 275389/275389 [00:12<00:00, 21324.48KB/s]\n",
            "Model file /root/.encoding/models/deeplab_resnest200_ade-7b9e7d3e.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/deeplab_resnest200_ade-7b9e7d3e.zip from https://s3.us-west-1.wasabisys.com/encoding/models/deeplab_resnest200_ade-7b9e7d3e.zip...\n",
            "100% 339949/339949 [00:13<00:00, 24641.55KB/s]\n",
            "DeepLabV3(\n",
            "  (pretrained): ResNet(\n",
            "    (conv1): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (6): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (7): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (8): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (9): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (10): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (11): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (12): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (13): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (14): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (15): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (16): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (17): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (18): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (19): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (20): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (21): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (22): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (23): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (6): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (7): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (8): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (9): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (10): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (11): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (12): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (13): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (14): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (15): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (16): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (17): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (18): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (19): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (20): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (21): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (22): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (23): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (24): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (25): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (26): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (27): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (28): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (29): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (30): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (31): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (32): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (33): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (34): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (35): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): GlobalAvgPool2d()\n",
            "    (fc): None\n",
            "  )\n",
            "  (head): DeepLabV3Head(\n",
            "    (aspp): ASPP_Module(\n",
            "      (b0): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b1): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b2): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b3): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b4): AsppPooling(\n",
            "        (gap): Sequential(\n",
            "          (0): AdaptiveAvgPool2d(output_size=1)\n",
            "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (3): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (project): Sequential(\n",
            "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Dropout2d(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (auxlayer): FCNHead(\n",
            "    (conv5): Sequential(\n",
            "      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "MultiEvalModule: base_size 520, crop_size 480\n",
            "pixAcc: 0.8245, mIoU: 0.4836: 100% 2000/2000 [2:59:07<00:00,  5.37s/it]\n",
            "pixAcc: 0.8245, mIoU: 0.4836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation results for ResNeSt200 on ADE20k validation set:\n",
        "* pixAcc: 0.8245\n",
        "* mIoU: 0.4836\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UOZ8t5dEFbiP"
      },
      "id": "UOZ8t5dEFbiP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final results match those found in the original paper, the pretrained models thus perform as expected.\n",
        "\n",
        "model\\metrics  | pixAcc | mIoU |\n",
        "------------------|------------------|------------------|\n",
        "**ResNeSt50**    | 0.8117 | 0.4512 | \n",
        "**ResNeSt101**   | 0.8207 | 0.4691 | \n",
        "**ResNeSt200**   | 0.8245 | 0.4836 | \n",
        "\n",
        "Please consult the final report for additional comments."
      ],
      "metadata": {
        "id": "GSloc6OaVGy0"
      },
      "id": "GSloc6OaVGy0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instance segmentation"
      ],
      "metadata": {
        "id": "9Gw7TkmtU_4r"
      },
      "id": "9Gw7TkmtU_4r"
    },
    {
      "cell_type": "markdown",
      "source": [
        "For conducting the experiments for instance segmentation and object detection we will need to load and prepare the dataset COCO. The pretrained models use a Detectron2 wrapper to function so we will also need to install this library.\n",
        "\n",
        "We will access the necessary files from the drive and run the experiments with Colab. For this to work you will need to download the ResNeSt repository and add it to your drive (all rights reserved).\n",
        "\n",
        "Link to the ReSNeSt repository:\n",
        "* https://github.com/zhanghang1989/ResNeSt\n",
        "\n",
        "Most of the documentation needed here is available in the detectron2 wrapper subsection as well as in the detectron2 repository.  \n",
        "* https://github.com/zhanghang1989/ResNeSt/tree/master/d2  \n",
        "* https://github.com/facebookresearch/detectron2/blob/main/GETTING_STARTED.md\n",
        "\n",
        "In the wrapper subsection you will find both the configuration files as well as the weights, saved under the .pth format. The weights need to be downloaded manually and added to the repository, the path should be the following:\n",
        "* ResNeSt-master/d2/checkpoints/COCO-InstanceSegmentation/someweights.pth\n",
        "\n",
        "The configuration files are available by default when cloning the repository, it is not needed to download them."
      ],
      "metadata": {
        "id": "5mIkh6MDVtml"
      },
      "id": "5mIkh6MDVtml"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "8RUg-2g86DjS"
      },
      "id": "8RUg-2g86DjS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_tEl7ai6BCK",
        "outputId": "4b4cdc1c-5933-4fac-c395-f32eefb95eec"
      },
      "id": "z_tEl7ai6BCK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You main need to update the path according to your drive's files organisation."
      ],
      "metadata": {
        "id": "z1ilxob_XPmm"
      },
      "id": "z1ilxob_XPmm"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master && python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IhfuLPD6Jrn",
        "outputId": "a1a9918f-8a52-4b13-e658-ab558398ad26"
      },
      "id": "8IhfuLPD6Jrn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Building version 0.0.6b20220430\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing resnest.egg-info/PKG-INFO\n",
            "writing dependency_links to resnest.egg-info/dependency_links.txt\n",
            "writing requirements to resnest.egg-info/requires.txt\n",
            "writing top-level names to resnest.egg-info/top_level.txt\n",
            "reading manifest file 'resnest.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'resnest.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "copying resnest/version.py -> build/lib/resnest\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/resnest\n",
            "copying build/lib/resnest/__init__.py -> build/bdist.linux-x86_64/egg/resnest\n",
            "copying build/lib/resnest/utils.py -> build/bdist.linux-x86_64/egg/resnest\n",
            "creating build/bdist.linux-x86_64/egg/resnest/d2\n",
            "copying build/lib/resnest/d2/config.py -> build/bdist.linux-x86_64/egg/resnest/d2\n",
            "copying build/lib/resnest/d2/__init__.py -> build/bdist.linux-x86_64/egg/resnest/d2\n",
            "copying build/lib/resnest/d2/splat.py -> build/bdist.linux-x86_64/egg/resnest/d2\n",
            "copying build/lib/resnest/d2/resnest.py -> build/bdist.linux-x86_64/egg/resnest/d2\n",
            "creating build/bdist.linux-x86_64/egg/resnest/torch\n",
            "copying build/lib/resnest/torch/config.py -> build/bdist.linux-x86_64/egg/resnest/torch\n",
            "copying build/lib/resnest/torch/utils.py -> build/bdist.linux-x86_64/egg/resnest/torch\n",
            "copying build/lib/resnest/torch/loss.py -> build/bdist.linux-x86_64/egg/resnest/torch\n",
            "copying build/lib/resnest/torch/__init__.py -> build/bdist.linux-x86_64/egg/resnest/torch\n",
            "creating build/bdist.linux-x86_64/egg/resnest/torch/datasets\n",
            "copying build/lib/resnest/torch/datasets/__init__.py -> build/bdist.linux-x86_64/egg/resnest/torch/datasets\n",
            "copying build/lib/resnest/torch/datasets/imagenet.py -> build/bdist.linux-x86_64/egg/resnest/torch/datasets\n",
            "copying build/lib/resnest/torch/datasets/build.py -> build/bdist.linux-x86_64/egg/resnest/torch/datasets\n",
            "creating build/bdist.linux-x86_64/egg/resnest/torch/models\n",
            "copying build/lib/resnest/torch/models/splat.py -> build/bdist.linux-x86_64/egg/resnest/torch/models\n",
            "copying build/lib/resnest/torch/models/resnest.py -> build/bdist.linux-x86_64/egg/resnest/torch/models\n",
            "copying build/lib/resnest/torch/models/__init__.py -> build/bdist.linux-x86_64/egg/resnest/torch/models\n",
            "copying build/lib/resnest/torch/models/ablation.py -> build/bdist.linux-x86_64/egg/resnest/torch/models\n",
            "copying build/lib/resnest/torch/models/build.py -> build/bdist.linux-x86_64/egg/resnest/torch/models\n",
            "copying build/lib/resnest/torch/models/resnet.py -> build/bdist.linux-x86_64/egg/resnest/torch/models\n",
            "creating build/bdist.linux-x86_64/egg/resnest/torch/transforms\n",
            "copying build/lib/resnest/torch/transforms/__init__.py -> build/bdist.linux-x86_64/egg/resnest/torch/transforms\n",
            "copying build/lib/resnest/torch/transforms/build.py -> build/bdist.linux-x86_64/egg/resnest/torch/transforms\n",
            "copying build/lib/resnest/torch/transforms/transforms.py -> build/bdist.linux-x86_64/egg/resnest/torch/transforms\n",
            "copying build/lib/resnest/torch/transforms/autoaug.py -> build/bdist.linux-x86_64/egg/resnest/torch/transforms\n",
            "creating build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/dropblock.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/splat.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/resnet.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/transforms.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/data_utils.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/__init__.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/model_zoo.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/ablation.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/resnest.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/model_store.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/version.py -> build/bdist.linux-x86_64/egg/resnest\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/d2/config.py to config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/d2/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/d2/splat.py to splat.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/d2/resnest.py to resnest.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/config.py to config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/loss.py to loss.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/datasets/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/datasets/imagenet.py to imagenet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/datasets/build.py to build.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/models/splat.py to splat.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/models/resnest.py to resnest.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/models/ablation.py to ablation.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/models/build.py to build.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/models/resnet.py to resnet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/transforms/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/transforms/build.py to build.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/transforms/transforms.py to transforms.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/transforms/autoaug.py to autoaug.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/dropblock.py to dropblock.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/splat.py to splat.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/resnet.py to resnet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/transforms.py to transforms.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/data_utils.py to data_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/model_zoo.py to model_zoo.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/ablation.py to ablation.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/resnest.py to resnest.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/model_store.py to model_store.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/version.py to version.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resnest.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resnest.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resnest.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resnest.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resnest.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/resnest-0.0.6b20220430-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing resnest-0.0.6b20220430-py3.7.egg\n",
            "Copying resnest-0.0.6b20220430-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding resnest 0.0.6b20220430 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/resnest-0.0.6b20220430-py3.7.egg\n",
            "Processing dependencies for resnest==0.0.6b20220430\n",
            "Searching for fvcore\n",
            "Reading https://pypi.org/simple/fvcore/\n",
            "Downloading https://files.pythonhosted.org/packages/f7/07/daa016cd34f7ba8a439983236f67345d4c32ae56a607eec1cf2440c3e4a6/fvcore-0.1.5.post20220414.tar.gz#sha256=3b95983a799047661422c01671da2fa4749f60fa947e2b0ad0520f1ebc11be43\n",
            "Best match: fvcore 0.1.5.post20220414\n",
            "Processing fvcore-0.1.5.post20220414.tar.gz\n",
            "Writing /tmp/easy_install-p60avdnh/fvcore-0.1.5.post20220414/setup.cfg\n",
            "Running fvcore-0.1.5.post20220414/setup.py -q bdist_egg --dist-dir /tmp/easy_install-p60avdnh/fvcore-0.1.5.post20220414/egg-dist-tmp-olz12_z0\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Moving fvcore-0.1.5.post20220414-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding fvcore 0.1.5.post20220414 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/fvcore-0.1.5.post20220414-py3.7.egg\n",
            "Searching for iopath\n",
            "Reading https://pypi.org/simple/iopath/\n",
            "Downloading https://files.pythonhosted.org/packages/af/20/65dd9bd25a1eb7fa35b5ae38d289126af065f8a0c1f6a90564f4bff0f89d/iopath-0.1.9-py3-none-any.whl#sha256=9058ac24f0328decdf8dbe209b33074b8702a3c4d9ba2f7801d46cb61a880b6e\n",
            "Best match: iopath 0.1.9\n",
            "Processing iopath-0.1.9-py3-none-any.whl\n",
            "Installing iopath-0.1.9-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding iopath 0.1.9 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/iopath-0.1.9-py3.7.egg\n",
            "Searching for nose\n",
            "Reading https://pypi.org/simple/nose/\n",
            "Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl#sha256=9ff7c6cc443f8c51994b34a667bbcf45afd6d945be7477b52e97516fd17c53ac\n",
            "Best match: nose 1.3.7\n",
            "Processing nose-1.3.7-py3-none-any.whl\n",
            "Installing nose-1.3.7-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding nose 1.3.7 to easy-install.pth file\n",
            "Installing nosetests script to /usr/local/bin\n",
            "Installing nosetests-3.4 script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/nose-1.3.7-py3.7.egg\n",
            "Searching for pyyaml>=5.1\n",
            "Reading https://pypi.org/simple/pyyaml/\n",
            "Downloading https://files.pythonhosted.org/packages/eb/5f/6e6fe6904e1a9c67bc2ca5629a69e7a5a0b17f079da838bab98a1e548b25/PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl#sha256=231710d57adfd809ef5d34183b8ed1eeae3f76459c18fb4a0b373ad56bedcdd9\n",
            "Best match: PyYAML 6.0\n",
            "Processing PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
            "Installing PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding PyYAML 6.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/PyYAML-6.0-py3.7-linux-x86_64.egg\n",
            "Searching for yacs>=0.1.6\n",
            "Reading https://pypi.org/simple/yacs/\n",
            "Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl#sha256=99f893e30497a4b66842821bac316386f7bd5c4f47ad35c9073ef089aa33af32\n",
            "Best match: yacs 0.1.8\n",
            "Processing yacs-0.1.8-py3-none-any.whl\n",
            "Installing yacs-0.1.8-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding yacs 0.1.8 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/yacs-0.1.8-py3.7.egg\n",
            "Searching for portalocker\n",
            "Reading https://pypi.org/simple/portalocker/\n",
            "Downloading https://files.pythonhosted.org/packages/f1/4e/1030afbf2e64e676e968bbbc82014ce4ddf1cc1ed0b492585958768cf79a/portalocker-2.4.0-py2.py3-none-any.whl#sha256=b092f48e1e30a234ab3dd1cfd44f2f235e8a41f4e310e463fc8d6798d1c3c235\n",
            "Best match: portalocker 2.4.0\n",
            "Processing portalocker-2.4.0-py2.py3-none-any.whl\n",
            "Installing portalocker-2.4.0-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding portalocker 2.4.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/portalocker-2.4.0-py3.7.egg\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Pillow==7.1.2\n",
            "Best match: Pillow 7.1.2\n",
            "Adding Pillow 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torch==1.11.0+cu113\n",
            "Best match: torch 1.11.0+cu113\n",
            "Adding torch 1.11.0+cu113 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.64.0\n",
            "Best match: tqdm 4.64.0\n",
            "Adding tqdm 4.64.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tabulate==0.8.9\n",
            "Best match: tabulate 0.8.9\n",
            "Adding tabulate 0.8.9 to easy-install.pth file\n",
            "Installing tabulate script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2021.10.8\n",
            "Best match: certifi 2021.10.8\n",
            "Adding certifi 2021.10.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.2.0\n",
            "Best match: typing-extensions 4.2.0\n",
            "Adding typing-extensions 4.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for resnest==0.0.6b20220430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation of detectron2. For an example on how to use detectron2 in colab see:\n",
        "* https://colab.research.google.com/drive/1uK6zkmNEbdRcSv1gL2GFG8rk24T9IMtZ"
      ],
      "metadata": {
        "id": "vDxPZvVuVfDw"
      },
      "id": "vDxPZvVuVfDw"
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvdYLy-66Uiu",
        "outputId": "c2135c61-e74b-45d5-e20a-a2836f191fef"
      },
      "id": "IvdYLy-66Uiu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-_q0x50c6\n",
            "  Running command git clone -q https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-_q0x50c6\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (3.2.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.0.4)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.1.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.7/dist-packages/yacs-0.1.8-py3.7.egg (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.8.9)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (4.64.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.8.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.7/dist-packages/fvcore-0.1.5.post20220414-py3.7.egg (from detectron2==0.6) (0.1.5.post20220414)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.7/dist-packages/iopath-0.1.9-py3.7.egg (from detectron2==0.6) (0.1.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.16.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n",
            "Collecting omegaconf>=2.1\n",
            "  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.1.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 17.2 MB/s \n",
            "\u001b[?25hCollecting black==21.4b2\n",
            "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 67.1 MB/s \n",
            "\u001b[?25hCollecting scipy>1.5.1\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting regex>=2020.1.8\n",
            "  Downloading regex-2022.4.24-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 62.0 MB/s \n",
            "\u001b[?25hCollecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (4.2.0)\n",
            "Collecting pathspec<1,>=0.8.1\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (7.1.2)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 61.5 MB/s \n",
            "\u001b[?25hCollecting toml>=0.10.1\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.21.6)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 57.0 MB/s \n",
            "\u001b[?25hCollecting importlib-resources<5.3\n",
            "  Downloading importlib_resources-5.2.3-py3-none-any.whl (27 kB)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 73.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources<5.3->hydra-core>=1.1->detectron2==0.6) (3.8.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages/portalocker-2.4.0-py3.7.egg (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (3.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (1.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2==0.6) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.44.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.3.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.6) (4.11.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.2.0)\n",
            "Building wheels for collected packages: detectron2, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp37-cp37m-linux_x86_64.whl size=5286162 sha256=26defbfbcd1682b97fc83f3ab10cbfdf09636db8a5704b211be65dfdeb1dbe4f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0z3dmo1q/wheels/07/dc/32/0322cb484dbefab8b9366bfedbaff5060ac7d149d69c27ca5d\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=ed2c27780663546344789b0d7d39b002a883ff7e9d3622dc0a8db207ede400f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built detectron2 antlr4-python3-runtime\n",
            "Installing collected packages: pyyaml, antlr4-python3-runtime, typed-ast, toml, regex, pathspec, omegaconf, mypy-extensions, importlib-resources, scipy, hydra-core, black, detectron2\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 5.7.1\n",
            "    Uninstalling importlib-resources-5.7.1:\n",
            "      Successfully uninstalled importlib-resources-5.7.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed antlr4-python3-runtime-4.8 black-21.4b2 detectron2-0.6 hydra-core-1.1.2 importlib-resources-5.2.3 mypy-extensions-0.4.3 omegaconf-2.1.2 pathspec-0.9.0 pyyaml-6.0 regex-2022.4.24 scipy-1.7.3 toml-0.10.2 typed-ast-1.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading and preparing the dataset COCO. For more information on this dataset see: https://cocodataset.org/#home."
      ],
      "metadata": {
        "id": "Bx6KiQmXViyS"
      },
      "id": "Bx6KiQmXViyS"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2/datasets && python prepare_coco.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dvGLpMLeOGR",
        "outputId": "87323be6-30a0-4c96-c9d4-282750ad12f7"
      },
      "id": "6dvGLpMLeOGR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18883655KB [07:23, 42600.08KB/s]                  \n",
            "796471KB [00:21, 37923.51KB/s]                \n",
            "246981KB [00:06, 39193.58KB/s]                \n",
            "100% 432/432 [00:00<00:00, 4898.18KB/s]\n",
            "19KB [00:00, 992.67KB/s]  \n",
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 12.85 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating pycocotools.egg-info\n",
            "writing pycocotools.egg-info/PKG-INFO\n",
            "writing dependency_links to pycocotools.egg-info/dependency_links.txt\n",
            "writing requirements to pycocotools.egg-info/requires.txt\n",
            "writing top-level names to pycocotools.egg-info/top_level.txt\n",
            "writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
            "writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/pycocotools\n",
            "copying pycocotools/__init__.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
            "copying pycocotools/coco.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
            "copying pycocotools/cocoeval.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
            "copying pycocotools/mask.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
            "running build_ext\n",
            "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/MyDrive/Colab Notebooks/ResNeSt-master/d2/datasets/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/__init__.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/coco.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/cocoeval.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/mask.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/coco.py to coco.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/cocoeval.py to cocoeval.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/mask.py to mask.cpython-37.pyc\n",
            "creating stub loader for pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/_mask.py to _mask.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "pycocotools.__pycache__._mask.cpython-37: module references __file__\n",
            "creating dist\n",
            "creating 'dist/pycocotools-2.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing pycocotools-2.0-py3.7-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/pycocotools-2.0-py3.7-linux-x86_64.egg\n",
            "Extracting pycocotools-2.0-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding pycocotools 2.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/pycocotools-2.0-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for pycocotools==2.0\n",
            "Searching for matplotlib==3.2.2\n",
            "Best match: matplotlib 3.2.2\n",
            "Adding matplotlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Cython==0.29.28\n",
            "Best match: Cython 0.29.28\n",
            "Adding Cython 0.29.28 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for setuptools==57.4.0\n",
            "Best match: setuptools 57.4.0\n",
            "Adding setuptools 57.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cycler==0.11.0\n",
            "Best match: cycler 0.11.0\n",
            "Adding cycler 0.11.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyparsing==3.0.8\n",
            "Best match: pyparsing 3.0.8\n",
            "Adding pyparsing 3.0.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for kiwisolver==1.4.2\n",
            "Best match: kiwisolver 1.4.2\n",
            "Adding kiwisolver 1.4.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.2.0\n",
            "Best match: typing-extensions 4.2.0\n",
            "Adding typing-extensions 4.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for pycocotools==2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cd into the dataset. We need the training set, the validation set and the annotations set to perform the experiments."
      ],
      "metadata": {
        "id": "Cd6vLRrIXkaY"
      },
      "id": "Cd6vLRrIXkaY"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2/datasets/coco && ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xhc0t3AWVv7o",
        "outputId": "c9f03d9c-97a6-4ae0-f362-b609469feda7"
      },
      "id": "Xhc0t3AWVv7o",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "annotations\t\t      train2017      val2017\n",
            "annotations_trainval2017.zip  train2017.zip  val2017.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x-c58bd325.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pmYW7my6iEb",
        "outputId": "fdd8f061-332c-4507-a4dc-daa52aaa8017"
      },
      "id": "9pmYW7my6iEb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command Line Args: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x-c58bd325.pth'], resume=False)\n",
            "\u001b[32m[04/30 13:31:58 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[04/30 13:31:59 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ----------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "numpy                   1.21.6\n",
            "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.5\n",
            "CUDA compiler           CUDA 11.1\n",
            "detectron2 arch flags   7.5\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.11.0+cu113 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           Yes\n",
            "GPU 0                   Tesla T4 (arch=7.5)\n",
            "Driver version          460.32.03\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.12.0+cu113 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
            "fvcore                  0.1.5.post20220414\n",
            "iopath                  0.1.9\n",
            "cv2                     4.1.2\n",
            "----------------------  ----------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.3\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.2\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "\u001b[32m[04/30 13:31:59 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x-c58bd325.pth'], resume=False)\n",
            "\u001b[32m[04/30 13:31:59 detectron2]: \u001b[0mContents of args.config_file=./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml:\n",
            "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186m../ResNest-Base-RCNN-FPN.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mhttps://s3.us-west-1.wasabisys.com/resnest/detectron/resnest50_detectron-255b5649.pth\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mFastRCNNConvFCHead\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m123.68\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m116.779\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m103.939\u001b[39m]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m58.393\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.12\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.375\u001b[39m]\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\u001b[38;5;15m    \u001b[39m\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mRGB\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\n",
            "\u001b[32m[04/30 13:31:59 detectron2]: \u001b[0mRunning with full config:\n",
            "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRGB\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mpolygon\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m672\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m704\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m736\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m768\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mchoice\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnest_fpn_backbone\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGeneralizedRCNN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.68\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.779\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.939\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m58.393\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.12\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.375\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRPN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVG_DOWN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOTTLENECK_WIDTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEEP_STEM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_NUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFastRCNNConvFCHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_FED_LOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_SIGMOID_CE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x-c58bd325.pth\n",
            "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./output\n",
            "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR_END\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m90000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m60000\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m80000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\n",
            "\u001b[32m[04/30 13:32:00 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[04/30 13:32:00 d2.utils.env]: \u001b[0mUsing a generated random seed 363649\n",
            "\u001b[32m[04/30 13:32:10 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(\n",
            "      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output2): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral3): Conv2d(\n",
            "      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output3): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral4): Conv2d(\n",
            "      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output4): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral5): Conv2d(\n",
            "      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output5): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNeSt(\n",
            "      (stem): BasicStem(\n",
            "        (conv1_1): Conv2d(\n",
            "          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "        )\n",
            "        (conv1_2): Conv2d(\n",
            "          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "        )\n",
            "        (conv1_3): Conv2d(\n",
            "          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): CascadeROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): ModuleList(\n",
            "      (0): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (1): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (2): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): ModuleList(\n",
            "      (0): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (1): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (2): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/30 13:32:11 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from ./checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x-c58bd325.pth ...\n",
            "\u001b[32m[04/30 13:32:19 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
            "| Names in Model                                  | Names in Checkpoint                                                                                                           | Shapes                                             |\n",
            "|:------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------|\n",
            "| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,1,1)                |\n",
            "| backbone.bottom_up.res2.0.conv2.bn0.*           | backbone.bottom_up.res2.0.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.0.conv2.bn1.*           | backbone.bottom_up.res2.0.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.0.conv2.conv.weight     | backbone.bottom_up.res2.0.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.0.conv2.fc1.*           | backbone.bottom_up.res2.0.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.0.conv2.fc2.*           | backbone.bottom_up.res2.0.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.1.conv2.bn0.*           | backbone.bottom_up.res2.1.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.1.conv2.bn1.*           | backbone.bottom_up.res2.1.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.1.conv2.conv.weight     | backbone.bottom_up.res2.1.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.1.conv2.fc1.*           | backbone.bottom_up.res2.1.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.1.conv2.fc2.*           | backbone.bottom_up.res2.1.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.2.conv2.bn0.*           | backbone.bottom_up.res2.2.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.2.conv2.bn1.*           | backbone.bottom_up.res2.2.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.2.conv2.conv.weight     | backbone.bottom_up.res2.2.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.2.conv2.fc1.*           | backbone.bottom_up.res2.2.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.2.conv2.fc2.*           | backbone.bottom_up.res2.2.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv2.bn0.*           | backbone.bottom_up.res3.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.0.conv2.bn1.*           | backbone.bottom_up.res3.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.0.conv2.conv.weight     | backbone.bottom_up.res3.0.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.0.conv2.fc1.*           | backbone.bottom_up.res3.0.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.0.conv2.fc2.*           | backbone.bottom_up.res3.0.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv2.bn0.*           | backbone.bottom_up.res3.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.1.conv2.bn1.*           | backbone.bottom_up.res3.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.1.conv2.conv.weight     | backbone.bottom_up.res3.1.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.1.conv2.fc1.*           | backbone.bottom_up.res3.1.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.1.conv2.fc2.*           | backbone.bottom_up.res3.1.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv2.bn0.*           | backbone.bottom_up.res3.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.2.conv2.bn1.*           | backbone.bottom_up.res3.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.2.conv2.conv.weight     | backbone.bottom_up.res3.2.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.2.conv2.fc1.*           | backbone.bottom_up.res3.2.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.2.conv2.fc2.*           | backbone.bottom_up.res3.2.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv2.bn0.*           | backbone.bottom_up.res3.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.3.conv2.bn1.*           | backbone.bottom_up.res3.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.3.conv2.conv.weight     | backbone.bottom_up.res3.3.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.3.conv2.fc1.*           | backbone.bottom_up.res3.3.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.3.conv2.fc2.*           | backbone.bottom_up.res3.3.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv2.bn0.*           | backbone.bottom_up.res4.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.bn1.*           | backbone.bottom_up.res4.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.conv.weight     | backbone.bottom_up.res4.0.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.0.conv2.fc1.*           | backbone.bottom_up.res4.0.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv2.fc2.*           | backbone.bottom_up.res4.0.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.1.conv2.bn0.*           | backbone.bottom_up.res4.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.bn1.*           | backbone.bottom_up.res4.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.conv.weight     | backbone.bottom_up.res4.1.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.1.conv2.fc1.*           | backbone.bottom_up.res4.1.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv2.fc2.*           | backbone.bottom_up.res4.1.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.2.conv2.bn0.*           | backbone.bottom_up.res4.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.bn1.*           | backbone.bottom_up.res4.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.conv.weight     | backbone.bottom_up.res4.2.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.2.conv2.fc1.*           | backbone.bottom_up.res4.2.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv2.fc2.*           | backbone.bottom_up.res4.2.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.3.conv2.bn0.*           | backbone.bottom_up.res4.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.bn1.*           | backbone.bottom_up.res4.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.conv.weight     | backbone.bottom_up.res4.3.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.3.conv2.fc1.*           | backbone.bottom_up.res4.3.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv2.fc2.*           | backbone.bottom_up.res4.3.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.4.conv2.bn0.*           | backbone.bottom_up.res4.4.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.bn1.*           | backbone.bottom_up.res4.4.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.conv.weight     | backbone.bottom_up.res4.4.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.4.conv2.fc1.*           | backbone.bottom_up.res4.4.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv2.fc2.*           | backbone.bottom_up.res4.4.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.5.conv2.bn0.*           | backbone.bottom_up.res4.5.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.bn1.*           | backbone.bottom_up.res4.5.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.conv.weight     | backbone.bottom_up.res4.5.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.5.conv2.fc1.*           | backbone.bottom_up.res4.5.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv2.fc2.*           | backbone.bottom_up.res4.5.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| backbone.bottom_up.res5.0.conv2.bn0.*           | backbone.bottom_up.res5.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.0.conv2.bn1.*           | backbone.bottom_up.res5.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.0.conv2.conv.weight     | backbone.bottom_up.res5.0.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.0.conv2.fc1.*           | backbone.bottom_up.res5.0.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.0.conv2.fc2.*           | backbone.bottom_up.res5.0.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.1.conv2.bn0.*           | backbone.bottom_up.res5.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.1.conv2.bn1.*           | backbone.bottom_up.res5.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.1.conv2.conv.weight     | backbone.bottom_up.res5.1.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.1.conv2.fc1.*           | backbone.bottom_up.res5.1.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.1.conv2.fc2.*           | backbone.bottom_up.res5.1.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.2.conv2.bn0.*           | backbone.bottom_up.res5.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.2.conv2.bn1.*           | backbone.bottom_up.res5.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.2.conv2.conv.weight     | backbone.bottom_up.res5.2.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.2.conv2.fc1.*           | backbone.bottom_up.res5.2.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.2.conv2.fc2.*           | backbone.bottom_up.res5.2.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.stem.conv1_1.*               | backbone.bottom_up.stem.conv1_1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (32,) (32,) (32,) (32,) (32,3,3,3)                 |\n",
            "| backbone.bottom_up.stem.conv1_2.*               | backbone.bottom_up.stem.conv1_2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (32,) (32,) (32,) (32,) (32,32,3,3)                |\n",
            "| backbone.bottom_up.stem.conv1_3.*               | backbone.bottom_up.stem.conv1_3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,32,3,3)                |\n",
            "| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,2048,1,1)      |\n",
            "| backbone.fpn_output2.*                          | backbone.fpn_output2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output3.*                          | backbone.fpn_output3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output4.*                          | backbone.fpn_output4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output5.*                          | backbone.fpn_output5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                                                       | (12,) (12,256,1,1)                                 |\n",
            "| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                                                | (256,) (256,256,3,3)                               |\n",
            "| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                                                   | (3,) (3,256,1,1)                                   |\n",
            "| roi_heads.box_head.0.conv1.*                    | roi_heads.box_head.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv2.*                    | roi_heads.box_head.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv3.*                    | roi_heads.box_head.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv4.*                    | roi_heads.box_head.0.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.fc1.*                      | roi_heads.box_head.0.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_head.1.conv1.*                    | roi_heads.box_head.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv2.*                    | roi_heads.box_head.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv3.*                    | roi_heads.box_head.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv4.*                    | roi_heads.box_head.1.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.fc1.*                      | roi_heads.box_head.1.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_head.2.conv1.*                    | roi_heads.box_head.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv2.*                    | roi_heads.box_head.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv3.*                    | roi_heads.box_head.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv4.*                    | roi_heads.box_head.2.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.fc1.*                      | roi_heads.box_head.2.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_predictor.0.bbox_pred.*           | roi_heads.box_predictor.0.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.0.cls_score.*           | roi_heads.box_predictor.0.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.box_predictor.1.bbox_pred.*           | roi_heads.box_predictor.1.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.1.cls_score.*           | roi_heads.box_predictor.1.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.box_predictor.2.bbox_pred.*           | roi_heads.box_predictor.2.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.2.cls_score.*           | roi_heads.box_predictor.2.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.mask_head.deconv.*                    | roi_heads.mask_head.deconv.{bias,weight}                                                                                      | (256,) (256,256,2,2)                               |\n",
            "| roi_heads.mask_head.mask_fcn1.*                 | roi_heads.mask_head.mask_fcn1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.mask_fcn2.*                 | roi_heads.mask_head.mask_fcn2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.mask_fcn3.*                 | roi_heads.mask_head.mask_fcn3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.mask_fcn4.*                 | roi_heads.mask_head.mask_fcn4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.predictor.*                 | roi_heads.mask_head.predictor.{bias,weight}                                                                                   | (80,) (80,256,1,1)                                 |\n",
            "\u001b[32m[04/30 13:32:20 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json\n",
            "\u001b[32m[04/30 13:32:21 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n",
            "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
            "|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\n",
            "|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\n",
            "|     train     | 190          |    truck     | 414          |     boat      | 424          |\n",
            "| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\n",
            "| parking meter | 60           |    bench     | 411          |     bird      | 427          |\n",
            "|      cat      | 202          |     dog      | 218          |     horse     | 272          |\n",
            "|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\n",
            "|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\n",
            "|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\n",
            "|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\n",
            "|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\n",
            "|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\n",
            "|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\n",
            "|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\n",
            "|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\n",
            "|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\n",
            "|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\n",
            "|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\n",
            "|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\n",
            "|     couch     | 261          | potted plant | 342          |      bed      | 163          |\n",
            "| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\n",
            "|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\n",
            "|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\n",
            "|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\n",
            "| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\n",
            "|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\n",
            "|  hair drier   | 11           |  toothbrush  | 57           |               |              |\n",
            "|     total     | 36335        |              |              |               |              |\u001b[0m\n",
            "\u001b[32m[04/30 13:32:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/30 13:32:21 d2.data.common]: \u001b[0mSerializing 5000 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/30 13:32:21 d2.data.common]: \u001b[0mSerialized dataset takes 19.10 MiB\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[32m[04/30 13:32:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 5000 batches\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m[04/30 13:32:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/5000. Dataloading: 0.0012 s/iter. Inference: 0.3588 s/iter. Eval: 0.0187 s/iter. Total: 0.3787 s/iter. ETA=0:31:29\n",
            "\u001b[32m[04/30 13:32:32 d2.evaluation.evaluator]: \u001b[0mInference done 25/5000. Dataloading: 0.0018 s/iter. Inference: 0.3572 s/iter. Eval: 0.0175 s/iter. Total: 0.3767 s/iter. ETA=0:31:13\n",
            "\u001b[32m[04/30 13:32:37 d2.evaluation.evaluator]: \u001b[0mInference done 38/5000. Dataloading: 0.0019 s/iter. Inference: 0.3611 s/iter. Eval: 0.0195 s/iter. Total: 0.3825 s/iter. ETA=0:31:38\n",
            "\u001b[32m[04/30 13:32:42 d2.evaluation.evaluator]: \u001b[0mInference done 51/5000. Dataloading: 0.0019 s/iter. Inference: 0.3627 s/iter. Eval: 0.0201 s/iter. Total: 0.3849 s/iter. ETA=0:31:44\n",
            "\u001b[32m[04/30 13:32:48 d2.evaluation.evaluator]: \u001b[0mInference done 65/5000. Dataloading: 0.0019 s/iter. Inference: 0.3640 s/iter. Eval: 0.0183 s/iter. Total: 0.3844 s/iter. ETA=0:31:36\n",
            "\u001b[32m[04/30 13:32:53 d2.evaluation.evaluator]: \u001b[0mInference done 79/5000. Dataloading: 0.0019 s/iter. Inference: 0.3644 s/iter. Eval: 0.0181 s/iter. Total: 0.3846 s/iter. ETA=0:31:32\n",
            "\u001b[32m[04/30 13:32:58 d2.evaluation.evaluator]: \u001b[0mInference done 92/5000. Dataloading: 0.0019 s/iter. Inference: 0.3642 s/iter. Eval: 0.0187 s/iter. Total: 0.3850 s/iter. ETA=0:31:29\n",
            "\u001b[32m[04/30 13:33:03 d2.evaluation.evaluator]: \u001b[0mInference done 105/5000. Dataloading: 0.0020 s/iter. Inference: 0.3649 s/iter. Eval: 0.0203 s/iter. Total: 0.3873 s/iter. ETA=0:31:35\n",
            "\u001b[32m[04/30 13:33:09 d2.evaluation.evaluator]: \u001b[0mInference done 119/5000. Dataloading: 0.0020 s/iter. Inference: 0.3655 s/iter. Eval: 0.0197 s/iter. Total: 0.3872 s/iter. ETA=0:31:29\n",
            "\u001b[32m[04/30 13:33:14 d2.evaluation.evaluator]: \u001b[0mInference done 132/5000. Dataloading: 0.0020 s/iter. Inference: 0.3663 s/iter. Eval: 0.0197 s/iter. Total: 0.3882 s/iter. ETA=0:31:29\n",
            "\u001b[32m[04/30 13:33:19 d2.evaluation.evaluator]: \u001b[0mInference done 145/5000. Dataloading: 0.0020 s/iter. Inference: 0.3675 s/iter. Eval: 0.0203 s/iter. Total: 0.3899 s/iter. ETA=0:31:32\n",
            "\u001b[32m[04/30 13:33:24 d2.evaluation.evaluator]: \u001b[0mInference done 158/5000. Dataloading: 0.0020 s/iter. Inference: 0.3682 s/iter. Eval: 0.0201 s/iter. Total: 0.3904 s/iter. ETA=0:31:30\n",
            "\u001b[32m[04/30 13:33:29 d2.evaluation.evaluator]: \u001b[0mInference done 171/5000. Dataloading: 0.0020 s/iter. Inference: 0.3684 s/iter. Eval: 0.0198 s/iter. Total: 0.3903 s/iter. ETA=0:31:24\n",
            "\u001b[32m[04/30 13:33:35 d2.evaluation.evaluator]: \u001b[0mInference done 184/5000. Dataloading: 0.0020 s/iter. Inference: 0.3690 s/iter. Eval: 0.0205 s/iter. Total: 0.3916 s/iter. ETA=0:31:25\n",
            "\u001b[32m[04/30 13:33:40 d2.evaluation.evaluator]: \u001b[0mInference done 197/5000. Dataloading: 0.0020 s/iter. Inference: 0.3696 s/iter. Eval: 0.0201 s/iter. Total: 0.3918 s/iter. ETA=0:31:21\n",
            "\u001b[32m[04/30 13:33:45 d2.evaluation.evaluator]: \u001b[0mInference done 210/5000. Dataloading: 0.0020 s/iter. Inference: 0.3702 s/iter. Eval: 0.0197 s/iter. Total: 0.3919 s/iter. ETA=0:31:17\n",
            "\u001b[32m[04/30 13:33:50 d2.evaluation.evaluator]: \u001b[0mInference done 224/5000. Dataloading: 0.0020 s/iter. Inference: 0.3703 s/iter. Eval: 0.0191 s/iter. Total: 0.3915 s/iter. ETA=0:31:09\n",
            "\u001b[32m[04/30 13:33:56 d2.evaluation.evaluator]: \u001b[0mInference done 237/5000. Dataloading: 0.0020 s/iter. Inference: 0.3712 s/iter. Eval: 0.0192 s/iter. Total: 0.3924 s/iter. ETA=0:31:08\n",
            "\u001b[32m[04/30 13:34:01 d2.evaluation.evaluator]: \u001b[0mInference done 250/5000. Dataloading: 0.0020 s/iter. Inference: 0.3718 s/iter. Eval: 0.0194 s/iter. Total: 0.3932 s/iter. ETA=0:31:07\n",
            "\u001b[32m[04/30 13:34:06 d2.evaluation.evaluator]: \u001b[0mInference done 262/5000. Dataloading: 0.0020 s/iter. Inference: 0.3726 s/iter. Eval: 0.0197 s/iter. Total: 0.3944 s/iter. ETA=0:31:08\n",
            "\u001b[32m[04/30 13:34:11 d2.evaluation.evaluator]: \u001b[0mInference done 275/5000. Dataloading: 0.0020 s/iter. Inference: 0.3727 s/iter. Eval: 0.0194 s/iter. Total: 0.3941 s/iter. ETA=0:31:02\n",
            "\u001b[32m[04/30 13:34:16 d2.evaluation.evaluator]: \u001b[0mInference done 288/5000. Dataloading: 0.0020 s/iter. Inference: 0.3733 s/iter. Eval: 0.0194 s/iter. Total: 0.3947 s/iter. ETA=0:30:59\n",
            "\u001b[32m[04/30 13:34:22 d2.evaluation.evaluator]: \u001b[0mInference done 301/5000. Dataloading: 0.0020 s/iter. Inference: 0.3739 s/iter. Eval: 0.0195 s/iter. Total: 0.3955 s/iter. ETA=0:30:58\n",
            "\u001b[32m[04/30 13:34:27 d2.evaluation.evaluator]: \u001b[0mInference done 314/5000. Dataloading: 0.0020 s/iter. Inference: 0.3744 s/iter. Eval: 0.0196 s/iter. Total: 0.3960 s/iter. ETA=0:30:55\n",
            "\u001b[32m[04/30 13:34:32 d2.evaluation.evaluator]: \u001b[0mInference done 327/5000. Dataloading: 0.0020 s/iter. Inference: 0.3750 s/iter. Eval: 0.0195 s/iter. Total: 0.3966 s/iter. ETA=0:30:53\n",
            "\u001b[32m[04/30 13:34:37 d2.evaluation.evaluator]: \u001b[0mInference done 339/5000. Dataloading: 0.0020 s/iter. Inference: 0.3756 s/iter. Eval: 0.0197 s/iter. Total: 0.3974 s/iter. ETA=0:30:52\n",
            "\u001b[32m[04/30 13:34:43 d2.evaluation.evaluator]: \u001b[0mInference done 352/5000. Dataloading: 0.0020 s/iter. Inference: 0.3762 s/iter. Eval: 0.0196 s/iter. Total: 0.3979 s/iter. ETA=0:30:49\n",
            "\u001b[32m[04/30 13:34:48 d2.evaluation.evaluator]: \u001b[0mInference done 365/5000. Dataloading: 0.0020 s/iter. Inference: 0.3766 s/iter. Eval: 0.0197 s/iter. Total: 0.3984 s/iter. ETA=0:30:46\n",
            "\u001b[32m[04/30 13:34:53 d2.evaluation.evaluator]: \u001b[0mInference done 377/5000. Dataloading: 0.0020 s/iter. Inference: 0.3771 s/iter. Eval: 0.0199 s/iter. Total: 0.3991 s/iter. ETA=0:30:44\n",
            "\u001b[32m[04/30 13:34:58 d2.evaluation.evaluator]: \u001b[0mInference done 390/5000. Dataloading: 0.0020 s/iter. Inference: 0.3773 s/iter. Eval: 0.0196 s/iter. Total: 0.3990 s/iter. ETA=0:30:39\n",
            "\u001b[32m[04/30 13:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 403/5000. Dataloading: 0.0019 s/iter. Inference: 0.3778 s/iter. Eval: 0.0196 s/iter. Total: 0.3995 s/iter. ETA=0:30:36\n",
            "\u001b[32m[04/30 13:35:09 d2.evaluation.evaluator]: \u001b[0mInference done 416/5000. Dataloading: 0.0019 s/iter. Inference: 0.3783 s/iter. Eval: 0.0195 s/iter. Total: 0.3999 s/iter. ETA=0:30:32\n",
            "\u001b[32m[04/30 13:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 429/5000. Dataloading: 0.0019 s/iter. Inference: 0.3786 s/iter. Eval: 0.0194 s/iter. Total: 0.4001 s/iter. ETA=0:30:28\n",
            "\u001b[32m[04/30 13:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 441/5000. Dataloading: 0.0019 s/iter. Inference: 0.3792 s/iter. Eval: 0.0194 s/iter. Total: 0.4006 s/iter. ETA=0:30:26\n",
            "\u001b[32m[04/30 13:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 454/5000. Dataloading: 0.0019 s/iter. Inference: 0.3794 s/iter. Eval: 0.0192 s/iter. Total: 0.4007 s/iter. ETA=0:30:21\n",
            "\u001b[32m[04/30 13:35:30 d2.evaluation.evaluator]: \u001b[0mInference done 467/5000. Dataloading: 0.0019 s/iter. Inference: 0.3799 s/iter. Eval: 0.0191 s/iter. Total: 0.4011 s/iter. ETA=0:30:17\n",
            "\u001b[32m[04/30 13:35:35 d2.evaluation.evaluator]: \u001b[0mInference done 480/5000. Dataloading: 0.0019 s/iter. Inference: 0.3804 s/iter. Eval: 0.0189 s/iter. Total: 0.4013 s/iter. ETA=0:30:13\n",
            "\u001b[32m[04/30 13:35:40 d2.evaluation.evaluator]: \u001b[0mInference done 492/5000. Dataloading: 0.0019 s/iter. Inference: 0.3809 s/iter. Eval: 0.0191 s/iter. Total: 0.4020 s/iter. ETA=0:30:12\n",
            "\u001b[32m[04/30 13:35:46 d2.evaluation.evaluator]: \u001b[0mInference done 505/5000. Dataloading: 0.0020 s/iter. Inference: 0.3811 s/iter. Eval: 0.0191 s/iter. Total: 0.4022 s/iter. ETA=0:30:08\n",
            "\u001b[32m[04/30 13:35:51 d2.evaluation.evaluator]: \u001b[0mInference done 518/5000. Dataloading: 0.0019 s/iter. Inference: 0.3814 s/iter. Eval: 0.0191 s/iter. Total: 0.4025 s/iter. ETA=0:30:04\n",
            "\u001b[32m[04/30 13:35:56 d2.evaluation.evaluator]: \u001b[0mInference done 530/5000. Dataloading: 0.0019 s/iter. Inference: 0.3818 s/iter. Eval: 0.0192 s/iter. Total: 0.4031 s/iter. ETA=0:30:01\n",
            "\u001b[32m[04/30 13:36:02 d2.evaluation.evaluator]: \u001b[0mInference done 542/5000. Dataloading: 0.0019 s/iter. Inference: 0.3823 s/iter. Eval: 0.0195 s/iter. Total: 0.4038 s/iter. ETA=0:29:59\n",
            "\u001b[32m[04/30 13:36:07 d2.evaluation.evaluator]: \u001b[0mInference done 554/5000. Dataloading: 0.0019 s/iter. Inference: 0.3826 s/iter. Eval: 0.0195 s/iter. Total: 0.4041 s/iter. ETA=0:29:56\n",
            "\u001b[32m[04/30 13:36:12 d2.evaluation.evaluator]: \u001b[0mInference done 567/5000. Dataloading: 0.0019 s/iter. Inference: 0.3829 s/iter. Eval: 0.0194 s/iter. Total: 0.4044 s/iter. ETA=0:29:52\n",
            "\u001b[32m[04/30 13:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 579/5000. Dataloading: 0.0019 s/iter. Inference: 0.3833 s/iter. Eval: 0.0195 s/iter. Total: 0.4049 s/iter. ETA=0:29:50\n",
            "\u001b[32m[04/30 13:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 591/5000. Dataloading: 0.0019 s/iter. Inference: 0.3836 s/iter. Eval: 0.0196 s/iter. Total: 0.4053 s/iter. ETA=0:29:46\n",
            "\u001b[32m[04/30 13:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 604/5000. Dataloading: 0.0019 s/iter. Inference: 0.3839 s/iter. Eval: 0.0195 s/iter. Total: 0.4054 s/iter. ETA=0:29:42\n",
            "\u001b[32m[04/30 13:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 616/5000. Dataloading: 0.0019 s/iter. Inference: 0.3843 s/iter. Eval: 0.0195 s/iter. Total: 0.4058 s/iter. ETA=0:29:39\n",
            "\u001b[32m[04/30 13:36:38 d2.evaluation.evaluator]: \u001b[0mInference done 628/5000. Dataloading: 0.0019 s/iter. Inference: 0.3846 s/iter. Eval: 0.0195 s/iter. Total: 0.4061 s/iter. ETA=0:29:35\n",
            "\u001b[32m[04/30 13:36:43 d2.evaluation.evaluator]: \u001b[0mInference done 640/5000. Dataloading: 0.0019 s/iter. Inference: 0.3849 s/iter. Eval: 0.0197 s/iter. Total: 0.4066 s/iter. ETA=0:29:32\n",
            "\u001b[32m[04/30 13:36:48 d2.evaluation.evaluator]: \u001b[0mInference done 652/5000. Dataloading: 0.0019 s/iter. Inference: 0.3852 s/iter. Eval: 0.0198 s/iter. Total: 0.4070 s/iter. ETA=0:29:29\n",
            "\u001b[32m[04/30 13:36:53 d2.evaluation.evaluator]: \u001b[0mInference done 664/5000. Dataloading: 0.0019 s/iter. Inference: 0.3855 s/iter. Eval: 0.0199 s/iter. Total: 0.4074 s/iter. ETA=0:29:26\n",
            "\u001b[32m[04/30 13:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 677/5000. Dataloading: 0.0019 s/iter. Inference: 0.3858 s/iter. Eval: 0.0197 s/iter. Total: 0.4075 s/iter. ETA=0:29:21\n",
            "\u001b[32m[04/30 13:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 689/5000. Dataloading: 0.0019 s/iter. Inference: 0.3861 s/iter. Eval: 0.0197 s/iter. Total: 0.4078 s/iter. ETA=0:29:18\n",
            "\u001b[32m[04/30 13:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 701/5000. Dataloading: 0.0019 s/iter. Inference: 0.3863 s/iter. Eval: 0.0197 s/iter. Total: 0.4080 s/iter. ETA=0:29:14\n",
            "\u001b[32m[04/30 13:37:14 d2.evaluation.evaluator]: \u001b[0mInference done 713/5000. Dataloading: 0.0019 s/iter. Inference: 0.3867 s/iter. Eval: 0.0197 s/iter. Total: 0.4084 s/iter. ETA=0:29:10\n",
            "\u001b[32m[04/30 13:37:19 d2.evaluation.evaluator]: \u001b[0mInference done 725/5000. Dataloading: 0.0019 s/iter. Inference: 0.3870 s/iter. Eval: 0.0199 s/iter. Total: 0.4089 s/iter. ETA=0:29:08\n",
            "\u001b[32m[04/30 13:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 737/5000. Dataloading: 0.0019 s/iter. Inference: 0.3872 s/iter. Eval: 0.0199 s/iter. Total: 0.4092 s/iter. ETA=0:29:04\n",
            "\u001b[32m[04/30 13:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 749/5000. Dataloading: 0.0019 s/iter. Inference: 0.3875 s/iter. Eval: 0.0200 s/iter. Total: 0.4095 s/iter. ETA=0:29:00\n",
            "\u001b[32m[04/30 13:37:35 d2.evaluation.evaluator]: \u001b[0mInference done 762/5000. Dataloading: 0.0019 s/iter. Inference: 0.3877 s/iter. Eval: 0.0198 s/iter. Total: 0.4096 s/iter. ETA=0:28:55\n",
            "\u001b[32m[04/30 13:37:40 d2.evaluation.evaluator]: \u001b[0mInference done 774/5000. Dataloading: 0.0019 s/iter. Inference: 0.3880 s/iter. Eval: 0.0198 s/iter. Total: 0.4098 s/iter. ETA=0:28:51\n",
            "\u001b[32m[04/30 13:37:45 d2.evaluation.evaluator]: \u001b[0mInference done 786/5000. Dataloading: 0.0019 s/iter. Inference: 0.3882 s/iter. Eval: 0.0198 s/iter. Total: 0.4101 s/iter. ETA=0:28:48\n",
            "\u001b[32m[04/30 13:37:50 d2.evaluation.evaluator]: \u001b[0mInference done 798/5000. Dataloading: 0.0020 s/iter. Inference: 0.3885 s/iter. Eval: 0.0199 s/iter. Total: 0.4104 s/iter. ETA=0:28:44\n",
            "\u001b[32m[04/30 13:37:55 d2.evaluation.evaluator]: \u001b[0mInference done 810/5000. Dataloading: 0.0019 s/iter. Inference: 0.3887 s/iter. Eval: 0.0199 s/iter. Total: 0.4106 s/iter. ETA=0:28:40\n",
            "\u001b[32m[04/30 13:38:00 d2.evaluation.evaluator]: \u001b[0mInference done 822/5000. Dataloading: 0.0019 s/iter. Inference: 0.3890 s/iter. Eval: 0.0197 s/iter. Total: 0.4107 s/iter. ETA=0:28:36\n",
            "\u001b[32m[04/30 13:38:05 d2.evaluation.evaluator]: \u001b[0mInference done 834/5000. Dataloading: 0.0019 s/iter. Inference: 0.3891 s/iter. Eval: 0.0197 s/iter. Total: 0.4109 s/iter. ETA=0:28:31\n",
            "\u001b[32m[04/30 13:38:10 d2.evaluation.evaluator]: \u001b[0mInference done 846/5000. Dataloading: 0.0020 s/iter. Inference: 0.3893 s/iter. Eval: 0.0198 s/iter. Total: 0.4111 s/iter. ETA=0:28:27\n",
            "\u001b[32m[04/30 13:38:15 d2.evaluation.evaluator]: \u001b[0mInference done 858/5000. Dataloading: 0.0019 s/iter. Inference: 0.3895 s/iter. Eval: 0.0197 s/iter. Total: 0.4112 s/iter. ETA=0:28:23\n",
            "\u001b[32m[04/30 13:38:20 d2.evaluation.evaluator]: \u001b[0mInference done 870/5000. Dataloading: 0.0020 s/iter. Inference: 0.3897 s/iter. Eval: 0.0196 s/iter. Total: 0.4113 s/iter. ETA=0:28:18\n",
            "\u001b[32m[04/30 13:38:26 d2.evaluation.evaluator]: \u001b[0mInference done 882/5000. Dataloading: 0.0019 s/iter. Inference: 0.3899 s/iter. Eval: 0.0195 s/iter. Total: 0.4114 s/iter. ETA=0:28:14\n",
            "\u001b[32m[04/30 13:38:31 d2.evaluation.evaluator]: \u001b[0mInference done 894/5000. Dataloading: 0.0019 s/iter. Inference: 0.3901 s/iter. Eval: 0.0195 s/iter. Total: 0.4116 s/iter. ETA=0:28:10\n",
            "\u001b[32m[04/30 13:38:36 d2.evaluation.evaluator]: \u001b[0mInference done 906/5000. Dataloading: 0.0020 s/iter. Inference: 0.3902 s/iter. Eval: 0.0195 s/iter. Total: 0.4118 s/iter. ETA=0:28:05\n",
            "\u001b[32m[04/30 13:38:41 d2.evaluation.evaluator]: \u001b[0mInference done 918/5000. Dataloading: 0.0020 s/iter. Inference: 0.3904 s/iter. Eval: 0.0195 s/iter. Total: 0.4119 s/iter. ETA=0:28:01\n",
            "\u001b[32m[04/30 13:38:46 d2.evaluation.evaluator]: \u001b[0mInference done 930/5000. Dataloading: 0.0019 s/iter. Inference: 0.3905 s/iter. Eval: 0.0195 s/iter. Total: 0.4120 s/iter. ETA=0:27:57\n",
            "\u001b[32m[04/30 13:38:51 d2.evaluation.evaluator]: \u001b[0mInference done 942/5000. Dataloading: 0.0019 s/iter. Inference: 0.3907 s/iter. Eval: 0.0194 s/iter. Total: 0.4121 s/iter. ETA=0:27:52\n",
            "\u001b[32m[04/30 13:38:56 d2.evaluation.evaluator]: \u001b[0mInference done 954/5000. Dataloading: 0.0019 s/iter. Inference: 0.3909 s/iter. Eval: 0.0193 s/iter. Total: 0.4123 s/iter. ETA=0:27:48\n",
            "\u001b[32m[04/30 13:39:01 d2.evaluation.evaluator]: \u001b[0mInference done 966/5000. Dataloading: 0.0019 s/iter. Inference: 0.3911 s/iter. Eval: 0.0193 s/iter. Total: 0.4125 s/iter. ETA=0:27:43\n",
            "\u001b[32m[04/30 13:39:06 d2.evaluation.evaluator]: \u001b[0mInference done 978/5000. Dataloading: 0.0019 s/iter. Inference: 0.3912 s/iter. Eval: 0.0194 s/iter. Total: 0.4127 s/iter. ETA=0:27:39\n",
            "\u001b[32m[04/30 13:39:11 d2.evaluation.evaluator]: \u001b[0mInference done 990/5000. Dataloading: 0.0019 s/iter. Inference: 0.3914 s/iter. Eval: 0.0194 s/iter. Total: 0.4129 s/iter. ETA=0:27:35\n",
            "\u001b[32m[04/30 13:39:17 d2.evaluation.evaluator]: \u001b[0mInference done 1003/5000. Dataloading: 0.0019 s/iter. Inference: 0.3916 s/iter. Eval: 0.0193 s/iter. Total: 0.4129 s/iter. ETA=0:27:30\n",
            "\u001b[32m[04/30 13:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 1015/5000. Dataloading: 0.0019 s/iter. Inference: 0.3917 s/iter. Eval: 0.0192 s/iter. Total: 0.4130 s/iter. ETA=0:27:25\n",
            "\u001b[32m[04/30 13:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 1027/5000. Dataloading: 0.0019 s/iter. Inference: 0.3919 s/iter. Eval: 0.0194 s/iter. Total: 0.4133 s/iter. ETA=0:27:22\n",
            "\u001b[32m[04/30 13:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 1039/5000. Dataloading: 0.0020 s/iter. Inference: 0.3920 s/iter. Eval: 0.0194 s/iter. Total: 0.4135 s/iter. ETA=0:27:17\n",
            "\u001b[32m[04/30 13:39:37 d2.evaluation.evaluator]: \u001b[0mInference done 1051/5000. Dataloading: 0.0020 s/iter. Inference: 0.3922 s/iter. Eval: 0.0194 s/iter. Total: 0.4136 s/iter. ETA=0:27:13\n",
            "\u001b[32m[04/30 13:39:43 d2.evaluation.evaluator]: \u001b[0mInference done 1063/5000. Dataloading: 0.0020 s/iter. Inference: 0.3924 s/iter. Eval: 0.0194 s/iter. Total: 0.4138 s/iter. ETA=0:27:09\n",
            "\u001b[32m[04/30 13:39:48 d2.evaluation.evaluator]: \u001b[0mInference done 1075/5000. Dataloading: 0.0020 s/iter. Inference: 0.3926 s/iter. Eval: 0.0194 s/iter. Total: 0.4140 s/iter. ETA=0:27:05\n",
            "\u001b[32m[04/30 13:39:53 d2.evaluation.evaluator]: \u001b[0mInference done 1087/5000. Dataloading: 0.0020 s/iter. Inference: 0.3927 s/iter. Eval: 0.0194 s/iter. Total: 0.4142 s/iter. ETA=0:27:00\n",
            "\u001b[32m[04/30 13:39:58 d2.evaluation.evaluator]: \u001b[0mInference done 1099/5000. Dataloading: 0.0020 s/iter. Inference: 0.3928 s/iter. Eval: 0.0194 s/iter. Total: 0.4143 s/iter. ETA=0:26:56\n",
            "\u001b[32m[04/30 13:40:03 d2.evaluation.evaluator]: \u001b[0mInference done 1111/5000. Dataloading: 0.0020 s/iter. Inference: 0.3930 s/iter. Eval: 0.0194 s/iter. Total: 0.4144 s/iter. ETA=0:26:51\n",
            "\u001b[32m[04/30 13:40:08 d2.evaluation.evaluator]: \u001b[0mInference done 1123/5000. Dataloading: 0.0020 s/iter. Inference: 0.3931 s/iter. Eval: 0.0193 s/iter. Total: 0.4147 s/iter. ETA=0:26:47\n",
            "\u001b[32m[04/30 13:40:14 d2.evaluation.evaluator]: \u001b[0mInference done 1135/5000. Dataloading: 0.0020 s/iter. Inference: 0.3933 s/iter. Eval: 0.0193 s/iter. Total: 0.4149 s/iter. ETA=0:26:43\n",
            "\u001b[32m[04/30 13:40:19 d2.evaluation.evaluator]: \u001b[0mInference done 1147/5000. Dataloading: 0.0020 s/iter. Inference: 0.3934 s/iter. Eval: 0.0193 s/iter. Total: 0.4150 s/iter. ETA=0:26:38\n",
            "\u001b[32m[04/30 13:40:24 d2.evaluation.evaluator]: \u001b[0mInference done 1159/5000. Dataloading: 0.0020 s/iter. Inference: 0.3935 s/iter. Eval: 0.0194 s/iter. Total: 0.4152 s/iter. ETA=0:26:34\n",
            "\u001b[32m[04/30 13:40:29 d2.evaluation.evaluator]: \u001b[0mInference done 1171/5000. Dataloading: 0.0020 s/iter. Inference: 0.3937 s/iter. Eval: 0.0195 s/iter. Total: 0.4155 s/iter. ETA=0:26:30\n",
            "\u001b[32m[04/30 13:40:34 d2.evaluation.evaluator]: \u001b[0mInference done 1183/5000. Dataloading: 0.0020 s/iter. Inference: 0.3938 s/iter. Eval: 0.0195 s/iter. Total: 0.4156 s/iter. ETA=0:26:26\n",
            "\u001b[32m[04/30 13:40:39 d2.evaluation.evaluator]: \u001b[0mInference done 1195/5000. Dataloading: 0.0020 s/iter. Inference: 0.3939 s/iter. Eval: 0.0195 s/iter. Total: 0.4157 s/iter. ETA=0:26:21\n",
            "\u001b[32m[04/30 13:40:45 d2.evaluation.evaluator]: \u001b[0mInference done 1207/5000. Dataloading: 0.0020 s/iter. Inference: 0.3941 s/iter. Eval: 0.0197 s/iter. Total: 0.4161 s/iter. ETA=0:26:18\n",
            "\u001b[32m[04/30 13:40:50 d2.evaluation.evaluator]: \u001b[0mInference done 1219/5000. Dataloading: 0.0020 s/iter. Inference: 0.3942 s/iter. Eval: 0.0198 s/iter. Total: 0.4162 s/iter. ETA=0:26:13\n",
            "\u001b[32m[04/30 13:40:55 d2.evaluation.evaluator]: \u001b[0mInference done 1231/5000. Dataloading: 0.0020 s/iter. Inference: 0.3943 s/iter. Eval: 0.0198 s/iter. Total: 0.4164 s/iter. ETA=0:26:09\n",
            "\u001b[32m[04/30 13:41:00 d2.evaluation.evaluator]: \u001b[0mInference done 1243/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0198 s/iter. Total: 0.4165 s/iter. ETA=0:26:04\n",
            "\u001b[32m[04/30 13:41:06 d2.evaluation.evaluator]: \u001b[0mInference done 1255/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0199 s/iter. Total: 0.4167 s/iter. ETA=0:26:00\n",
            "\u001b[32m[04/30 13:41:11 d2.evaluation.evaluator]: \u001b[0mInference done 1268/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0199 s/iter. Total: 0.4167 s/iter. ETA=0:25:54\n",
            "\u001b[32m[04/30 13:41:16 d2.evaluation.evaluator]: \u001b[0mInference done 1280/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0199 s/iter. Total: 0.4168 s/iter. ETA=0:25:50\n",
            "\u001b[32m[04/30 13:41:21 d2.evaluation.evaluator]: \u001b[0mInference done 1292/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0198 s/iter. Total: 0.4169 s/iter. ETA=0:25:45\n",
            "\u001b[32m[04/30 13:41:26 d2.evaluation.evaluator]: \u001b[0mInference done 1304/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0198 s/iter. Total: 0.4169 s/iter. ETA=0:25:40\n",
            "\u001b[32m[04/30 13:41:31 d2.evaluation.evaluator]: \u001b[0mInference done 1316/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0198 s/iter. Total: 0.4169 s/iter. ETA=0:25:36\n",
            "\u001b[32m[04/30 13:41:37 d2.evaluation.evaluator]: \u001b[0mInference done 1329/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0198 s/iter. Total: 0.4170 s/iter. ETA=0:25:30\n",
            "\u001b[32m[04/30 13:41:42 d2.evaluation.evaluator]: \u001b[0mInference done 1341/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0199 s/iter. Total: 0.4172 s/iter. ETA=0:25:26\n",
            "\u001b[32m[04/30 13:41:47 d2.evaluation.evaluator]: \u001b[0mInference done 1353/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0200 s/iter. Total: 0.4174 s/iter. ETA=0:25:22\n",
            "\u001b[32m[04/30 13:41:52 d2.evaluation.evaluator]: \u001b[0mInference done 1365/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0199 s/iter. Total: 0.4174 s/iter. ETA=0:25:17\n",
            "\u001b[32m[04/30 13:41:57 d2.evaluation.evaluator]: \u001b[0mInference done 1377/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0199 s/iter. Total: 0.4174 s/iter. ETA=0:25:12\n",
            "\u001b[32m[04/30 13:42:02 d2.evaluation.evaluator]: \u001b[0mInference done 1389/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0199 s/iter. Total: 0.4175 s/iter. ETA=0:25:07\n",
            "\u001b[32m[04/30 13:42:08 d2.evaluation.evaluator]: \u001b[0mInference done 1401/5000. Dataloading: 0.0020 s/iter. Inference: 0.3954 s/iter. Eval: 0.0199 s/iter. Total: 0.4175 s/iter. ETA=0:25:02\n",
            "\u001b[32m[04/30 13:42:13 d2.evaluation.evaluator]: \u001b[0mInference done 1414/5000. Dataloading: 0.0020 s/iter. Inference: 0.3954 s/iter. Eval: 0.0198 s/iter. Total: 0.4175 s/iter. ETA=0:24:57\n",
            "\u001b[32m[04/30 13:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 1426/5000. Dataloading: 0.0020 s/iter. Inference: 0.3955 s/iter. Eval: 0.0199 s/iter. Total: 0.4176 s/iter. ETA=0:24:52\n",
            "\u001b[32m[04/30 13:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 1438/5000. Dataloading: 0.0020 s/iter. Inference: 0.3956 s/iter. Eval: 0.0199 s/iter. Total: 0.4177 s/iter. ETA=0:24:47\n",
            "\u001b[32m[04/30 13:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 1450/5000. Dataloading: 0.0020 s/iter. Inference: 0.3957 s/iter. Eval: 0.0198 s/iter. Total: 0.4178 s/iter. ETA=0:24:43\n",
            "\u001b[32m[04/30 13:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 1462/5000. Dataloading: 0.0020 s/iter. Inference: 0.3957 s/iter. Eval: 0.0198 s/iter. Total: 0.4178 s/iter. ETA=0:24:38\n",
            "\u001b[32m[04/30 13:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 1474/5000. Dataloading: 0.0020 s/iter. Inference: 0.3957 s/iter. Eval: 0.0198 s/iter. Total: 0.4178 s/iter. ETA=0:24:33\n",
            "\u001b[32m[04/30 13:42:44 d2.evaluation.evaluator]: \u001b[0mInference done 1486/5000. Dataloading: 0.0020 s/iter. Inference: 0.3958 s/iter. Eval: 0.0199 s/iter. Total: 0.4180 s/iter. ETA=0:24:28\n",
            "\u001b[32m[04/30 13:42:49 d2.evaluation.evaluator]: \u001b[0mInference done 1498/5000. Dataloading: 0.0020 s/iter. Inference: 0.3959 s/iter. Eval: 0.0199 s/iter. Total: 0.4180 s/iter. ETA=0:24:23\n",
            "\u001b[32m[04/30 13:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 1510/5000. Dataloading: 0.0020 s/iter. Inference: 0.3959 s/iter. Eval: 0.0199 s/iter. Total: 0.4181 s/iter. ETA=0:24:19\n",
            "\u001b[32m[04/30 13:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 1522/5000. Dataloading: 0.0020 s/iter. Inference: 0.3960 s/iter. Eval: 0.0199 s/iter. Total: 0.4181 s/iter. ETA=0:24:14\n",
            "\u001b[32m[04/30 13:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 1534/5000. Dataloading: 0.0020 s/iter. Inference: 0.3960 s/iter. Eval: 0.0199 s/iter. Total: 0.4181 s/iter. ETA=0:24:09\n",
            "\u001b[32m[04/30 13:43:09 d2.evaluation.evaluator]: \u001b[0mInference done 1546/5000. Dataloading: 0.0020 s/iter. Inference: 0.3961 s/iter. Eval: 0.0199 s/iter. Total: 0.4183 s/iter. ETA=0:24:04\n",
            "\u001b[32m[04/30 13:43:14 d2.evaluation.evaluator]: \u001b[0mInference done 1558/5000. Dataloading: 0.0020 s/iter. Inference: 0.3962 s/iter. Eval: 0.0199 s/iter. Total: 0.4184 s/iter. ETA=0:24:00\n",
            "\u001b[32m[04/30 13:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 1570/5000. Dataloading: 0.0020 s/iter. Inference: 0.3963 s/iter. Eval: 0.0199 s/iter. Total: 0.4185 s/iter. ETA=0:23:55\n",
            "\u001b[32m[04/30 13:43:25 d2.evaluation.evaluator]: \u001b[0mInference done 1582/5000. Dataloading: 0.0020 s/iter. Inference: 0.3963 s/iter. Eval: 0.0199 s/iter. Total: 0.4185 s/iter. ETA=0:23:50\n",
            "\u001b[32m[04/30 13:43:30 d2.evaluation.evaluator]: \u001b[0mInference done 1594/5000. Dataloading: 0.0020 s/iter. Inference: 0.3965 s/iter. Eval: 0.0200 s/iter. Total: 0.4187 s/iter. ETA=0:23:46\n",
            "\u001b[32m[04/30 13:43:35 d2.evaluation.evaluator]: \u001b[0mInference done 1606/5000. Dataloading: 0.0020 s/iter. Inference: 0.3965 s/iter. Eval: 0.0201 s/iter. Total: 0.4188 s/iter. ETA=0:23:41\n",
            "\u001b[32m[04/30 13:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 1619/5000. Dataloading: 0.0020 s/iter. Inference: 0.3966 s/iter. Eval: 0.0200 s/iter. Total: 0.4188 s/iter. ETA=0:23:36\n",
            "\u001b[32m[04/30 13:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 1631/5000. Dataloading: 0.0020 s/iter. Inference: 0.3966 s/iter. Eval: 0.0200 s/iter. Total: 0.4188 s/iter. ETA=0:23:31\n",
            "\u001b[32m[04/30 13:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 1643/5000. Dataloading: 0.0020 s/iter. Inference: 0.3967 s/iter. Eval: 0.0200 s/iter. Total: 0.4189 s/iter. ETA=0:23:26\n",
            "\u001b[32m[04/30 13:43:56 d2.evaluation.evaluator]: \u001b[0mInference done 1655/5000. Dataloading: 0.0020 s/iter. Inference: 0.3967 s/iter. Eval: 0.0200 s/iter. Total: 0.4189 s/iter. ETA=0:23:21\n",
            "\u001b[32m[04/30 13:44:01 d2.evaluation.evaluator]: \u001b[0mInference done 1667/5000. Dataloading: 0.0020 s/iter. Inference: 0.3968 s/iter. Eval: 0.0200 s/iter. Total: 0.4190 s/iter. ETA=0:23:16\n",
            "\u001b[32m[04/30 13:44:06 d2.evaluation.evaluator]: \u001b[0mInference done 1679/5000. Dataloading: 0.0020 s/iter. Inference: 0.3969 s/iter. Eval: 0.0200 s/iter. Total: 0.4191 s/iter. ETA=0:23:11\n",
            "\u001b[32m[04/30 13:44:11 d2.evaluation.evaluator]: \u001b[0mInference done 1691/5000. Dataloading: 0.0020 s/iter. Inference: 0.3969 s/iter. Eval: 0.0200 s/iter. Total: 0.4191 s/iter. ETA=0:23:06\n",
            "\u001b[32m[04/30 13:44:16 d2.evaluation.evaluator]: \u001b[0mInference done 1703/5000. Dataloading: 0.0020 s/iter. Inference: 0.3970 s/iter. Eval: 0.0199 s/iter. Total: 0.4192 s/iter. ETA=0:23:01\n",
            "\u001b[32m[04/30 13:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 1715/5000. Dataloading: 0.0020 s/iter. Inference: 0.3970 s/iter. Eval: 0.0200 s/iter. Total: 0.4192 s/iter. ETA=0:22:57\n",
            "\u001b[32m[04/30 13:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 1727/5000. Dataloading: 0.0020 s/iter. Inference: 0.3971 s/iter. Eval: 0.0200 s/iter. Total: 0.4193 s/iter. ETA=0:22:52\n",
            "\u001b[32m[04/30 13:44:32 d2.evaluation.evaluator]: \u001b[0mInference done 1740/5000. Dataloading: 0.0020 s/iter. Inference: 0.3971 s/iter. Eval: 0.0199 s/iter. Total: 0.4193 s/iter. ETA=0:22:46\n",
            "\u001b[32m[04/30 13:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 1752/5000. Dataloading: 0.0020 s/iter. Inference: 0.3972 s/iter. Eval: 0.0199 s/iter. Total: 0.4193 s/iter. ETA=0:22:41\n",
            "\u001b[32m[04/30 13:44:42 d2.evaluation.evaluator]: \u001b[0mInference done 1764/5000. Dataloading: 0.0020 s/iter. Inference: 0.3973 s/iter. Eval: 0.0198 s/iter. Total: 0.4193 s/iter. ETA=0:22:36\n",
            "\u001b[32m[04/30 13:44:48 d2.evaluation.evaluator]: \u001b[0mInference done 1777/5000. Dataloading: 0.0020 s/iter. Inference: 0.3973 s/iter. Eval: 0.0198 s/iter. Total: 0.4193 s/iter. ETA=0:22:31\n",
            "\u001b[32m[04/30 13:44:53 d2.evaluation.evaluator]: \u001b[0mInference done 1789/5000. Dataloading: 0.0020 s/iter. Inference: 0.3973 s/iter. Eval: 0.0198 s/iter. Total: 0.4193 s/iter. ETA=0:22:26\n",
            "\u001b[32m[04/30 13:44:58 d2.evaluation.evaluator]: \u001b[0mInference done 1801/5000. Dataloading: 0.0020 s/iter. Inference: 0.3973 s/iter. Eval: 0.0198 s/iter. Total: 0.4193 s/iter. ETA=0:22:21\n",
            "\u001b[32m[04/30 13:45:03 d2.evaluation.evaluator]: \u001b[0mInference done 1813/5000. Dataloading: 0.0020 s/iter. Inference: 0.3974 s/iter. Eval: 0.0198 s/iter. Total: 0.4194 s/iter. ETA=0:22:16\n",
            "\u001b[32m[04/30 13:45:08 d2.evaluation.evaluator]: \u001b[0mInference done 1825/5000. Dataloading: 0.0020 s/iter. Inference: 0.3975 s/iter. Eval: 0.0198 s/iter. Total: 0.4195 s/iter. ETA=0:22:12\n",
            "\u001b[32m[04/30 13:45:13 d2.evaluation.evaluator]: \u001b[0mInference done 1837/5000. Dataloading: 0.0020 s/iter. Inference: 0.3975 s/iter. Eval: 0.0198 s/iter. Total: 0.4196 s/iter. ETA=0:22:07\n",
            "\u001b[32m[04/30 13:45:18 d2.evaluation.evaluator]: \u001b[0mInference done 1849/5000. Dataloading: 0.0020 s/iter. Inference: 0.3975 s/iter. Eval: 0.0199 s/iter. Total: 0.4196 s/iter. ETA=0:22:02\n",
            "\u001b[32m[04/30 13:45:24 d2.evaluation.evaluator]: \u001b[0mInference done 1861/5000. Dataloading: 0.0020 s/iter. Inference: 0.3976 s/iter. Eval: 0.0199 s/iter. Total: 0.4197 s/iter. ETA=0:21:57\n",
            "\u001b[32m[04/30 13:45:29 d2.evaluation.evaluator]: \u001b[0mInference done 1873/5000. Dataloading: 0.0020 s/iter. Inference: 0.3976 s/iter. Eval: 0.0199 s/iter. Total: 0.4197 s/iter. ETA=0:21:52\n",
            "\u001b[32m[04/30 13:45:34 d2.evaluation.evaluator]: \u001b[0mInference done 1885/5000. Dataloading: 0.0020 s/iter. Inference: 0.3977 s/iter. Eval: 0.0199 s/iter. Total: 0.4197 s/iter. ETA=0:21:47\n",
            "\u001b[32m[04/30 13:45:39 d2.evaluation.evaluator]: \u001b[0mInference done 1897/5000. Dataloading: 0.0020 s/iter. Inference: 0.3977 s/iter. Eval: 0.0198 s/iter. Total: 0.4198 s/iter. ETA=0:21:42\n",
            "\u001b[32m[04/30 13:45:44 d2.evaluation.evaluator]: \u001b[0mInference done 1909/5000. Dataloading: 0.0020 s/iter. Inference: 0.3978 s/iter. Eval: 0.0198 s/iter. Total: 0.4198 s/iter. ETA=0:21:37\n",
            "\u001b[32m[04/30 13:45:49 d2.evaluation.evaluator]: \u001b[0mInference done 1922/5000. Dataloading: 0.0020 s/iter. Inference: 0.3978 s/iter. Eval: 0.0198 s/iter. Total: 0.4198 s/iter. ETA=0:21:32\n",
            "\u001b[32m[04/30 13:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 1934/5000. Dataloading: 0.0020 s/iter. Inference: 0.3978 s/iter. Eval: 0.0198 s/iter. Total: 0.4198 s/iter. ETA=0:21:27\n",
            "\u001b[32m[04/30 13:46:00 d2.evaluation.evaluator]: \u001b[0mInference done 1947/5000. Dataloading: 0.0020 s/iter. Inference: 0.3978 s/iter. Eval: 0.0197 s/iter. Total: 0.4198 s/iter. ETA=0:21:21\n",
            "\u001b[32m[04/30 13:46:05 d2.evaluation.evaluator]: \u001b[0mInference done 1959/5000. Dataloading: 0.0020 s/iter. Inference: 0.3979 s/iter. Eval: 0.0197 s/iter. Total: 0.4198 s/iter. ETA=0:21:16\n",
            "\u001b[32m[04/30 13:46:10 d2.evaluation.evaluator]: \u001b[0mInference done 1971/5000. Dataloading: 0.0020 s/iter. Inference: 0.3979 s/iter. Eval: 0.0197 s/iter. Total: 0.4198 s/iter. ETA=0:21:11\n",
            "\u001b[32m[04/30 13:46:15 d2.evaluation.evaluator]: \u001b[0mInference done 1983/5000. Dataloading: 0.0020 s/iter. Inference: 0.3979 s/iter. Eval: 0.0198 s/iter. Total: 0.4199 s/iter. ETA=0:21:06\n",
            "\u001b[32m[04/30 13:46:20 d2.evaluation.evaluator]: \u001b[0mInference done 1995/5000. Dataloading: 0.0020 s/iter. Inference: 0.3980 s/iter. Eval: 0.0198 s/iter. Total: 0.4200 s/iter. ETA=0:21:01\n",
            "\u001b[32m[04/30 13:46:26 d2.evaluation.evaluator]: \u001b[0mInference done 2007/5000. Dataloading: 0.0020 s/iter. Inference: 0.3980 s/iter. Eval: 0.0198 s/iter. Total: 0.4200 s/iter. ETA=0:20:57\n",
            "\u001b[32m[04/30 13:46:31 d2.evaluation.evaluator]: \u001b[0mInference done 2019/5000. Dataloading: 0.0020 s/iter. Inference: 0.3981 s/iter. Eval: 0.0198 s/iter. Total: 0.4201 s/iter. ETA=0:20:52\n",
            "\u001b[32m[04/30 13:46:36 d2.evaluation.evaluator]: \u001b[0mInference done 2031/5000. Dataloading: 0.0020 s/iter. Inference: 0.3981 s/iter. Eval: 0.0198 s/iter. Total: 0.4201 s/iter. ETA=0:20:47\n",
            "\u001b[32m[04/30 13:46:41 d2.evaluation.evaluator]: \u001b[0mInference done 2043/5000. Dataloading: 0.0020 s/iter. Inference: 0.3981 s/iter. Eval: 0.0198 s/iter. Total: 0.4202 s/iter. ETA=0:20:42\n",
            "\u001b[32m[04/30 13:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 2055/5000. Dataloading: 0.0020 s/iter. Inference: 0.3982 s/iter. Eval: 0.0198 s/iter. Total: 0.4202 s/iter. ETA=0:20:37\n",
            "\u001b[32m[04/30 13:46:51 d2.evaluation.evaluator]: \u001b[0mInference done 2067/5000. Dataloading: 0.0020 s/iter. Inference: 0.3982 s/iter. Eval: 0.0198 s/iter. Total: 0.4202 s/iter. ETA=0:20:32\n",
            "\u001b[32m[04/30 13:46:57 d2.evaluation.evaluator]: \u001b[0mInference done 2080/5000. Dataloading: 0.0020 s/iter. Inference: 0.3982 s/iter. Eval: 0.0197 s/iter. Total: 0.4202 s/iter. ETA=0:20:26\n",
            "\u001b[32m[04/30 13:47:02 d2.evaluation.evaluator]: \u001b[0mInference done 2092/5000. Dataloading: 0.0020 s/iter. Inference: 0.3983 s/iter. Eval: 0.0197 s/iter. Total: 0.4202 s/iter. ETA=0:20:21\n",
            "\u001b[32m[04/30 13:47:07 d2.evaluation.evaluator]: \u001b[0mInference done 2104/5000. Dataloading: 0.0020 s/iter. Inference: 0.3983 s/iter. Eval: 0.0197 s/iter. Total: 0.4202 s/iter. ETA=0:20:17\n",
            "\u001b[32m[04/30 13:47:12 d2.evaluation.evaluator]: \u001b[0mInference done 2116/5000. Dataloading: 0.0020 s/iter. Inference: 0.3984 s/iter. Eval: 0.0198 s/iter. Total: 0.4203 s/iter. ETA=0:20:12\n",
            "\u001b[32m[04/30 13:47:17 d2.evaluation.evaluator]: \u001b[0mInference done 2129/5000. Dataloading: 0.0020 s/iter. Inference: 0.3984 s/iter. Eval: 0.0197 s/iter. Total: 0.4203 s/iter. ETA=0:20:06\n",
            "\u001b[32m[04/30 13:47:22 d2.evaluation.evaluator]: \u001b[0mInference done 2141/5000. Dataloading: 0.0020 s/iter. Inference: 0.3984 s/iter. Eval: 0.0197 s/iter. Total: 0.4203 s/iter. ETA=0:20:01\n",
            "\u001b[32m[04/30 13:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 2153/5000. Dataloading: 0.0020 s/iter. Inference: 0.3984 s/iter. Eval: 0.0197 s/iter. Total: 0.4203 s/iter. ETA=0:19:56\n",
            "\u001b[32m[04/30 13:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 2165/5000. Dataloading: 0.0020 s/iter. Inference: 0.3984 s/iter. Eval: 0.0197 s/iter. Total: 0.4203 s/iter. ETA=0:19:51\n",
            "\u001b[32m[04/30 13:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 2177/5000. Dataloading: 0.0020 s/iter. Inference: 0.3984 s/iter. Eval: 0.0197 s/iter. Total: 0.4204 s/iter. ETA=0:19:46\n",
            "\u001b[32m[04/30 13:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 2190/5000. Dataloading: 0.0020 s/iter. Inference: 0.3984 s/iter. Eval: 0.0197 s/iter. Total: 0.4203 s/iter. ETA=0:19:41\n",
            "\u001b[32m[04/30 13:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 2202/5000. Dataloading: 0.0020 s/iter. Inference: 0.3985 s/iter. Eval: 0.0197 s/iter. Total: 0.4204 s/iter. ETA=0:19:36\n",
            "\u001b[32m[04/30 13:47:53 d2.evaluation.evaluator]: \u001b[0mInference done 2214/5000. Dataloading: 0.0020 s/iter. Inference: 0.3985 s/iter. Eval: 0.0197 s/iter. Total: 0.4204 s/iter. ETA=0:19:31\n",
            "\u001b[32m[04/30 13:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 2226/5000. Dataloading: 0.0020 s/iter. Inference: 0.3986 s/iter. Eval: 0.0197 s/iter. Total: 0.4205 s/iter. ETA=0:19:26\n",
            "\u001b[32m[04/30 13:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 2238/5000. Dataloading: 0.0020 s/iter. Inference: 0.3986 s/iter. Eval: 0.0197 s/iter. Total: 0.4205 s/iter. ETA=0:19:21\n",
            "\u001b[32m[04/30 13:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 2250/5000. Dataloading: 0.0020 s/iter. Inference: 0.3987 s/iter. Eval: 0.0197 s/iter. Total: 0.4206 s/iter. ETA=0:19:16\n",
            "\u001b[32m[04/30 13:48:14 d2.evaluation.evaluator]: \u001b[0mInference done 2262/5000. Dataloading: 0.0020 s/iter. Inference: 0.3988 s/iter. Eval: 0.0197 s/iter. Total: 0.4207 s/iter. ETA=0:19:11\n",
            "\u001b[32m[04/30 13:48:20 d2.evaluation.evaluator]: \u001b[0mInference done 2275/5000. Dataloading: 0.0020 s/iter. Inference: 0.3988 s/iter. Eval: 0.0197 s/iter. Total: 0.4207 s/iter. ETA=0:19:06\n",
            "\u001b[32m[04/30 13:48:25 d2.evaluation.evaluator]: \u001b[0mInference done 2288/5000. Dataloading: 0.0020 s/iter. Inference: 0.3989 s/iter. Eval: 0.0196 s/iter. Total: 0.4207 s/iter. ETA=0:19:00\n",
            "\u001b[32m[04/30 13:48:30 d2.evaluation.evaluator]: \u001b[0mInference done 2301/5000. Dataloading: 0.0020 s/iter. Inference: 0.3988 s/iter. Eval: 0.0196 s/iter. Total: 0.4206 s/iter. ETA=0:18:55\n",
            "\u001b[32m[04/30 13:48:36 d2.evaluation.evaluator]: \u001b[0mInference done 2313/5000. Dataloading: 0.0020 s/iter. Inference: 0.3989 s/iter. Eval: 0.0196 s/iter. Total: 0.4206 s/iter. ETA=0:18:50\n",
            "\u001b[32m[04/30 13:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 2325/5000. Dataloading: 0.0020 s/iter. Inference: 0.3989 s/iter. Eval: 0.0196 s/iter. Total: 0.4207 s/iter. ETA=0:18:45\n",
            "\u001b[32m[04/30 13:48:46 d2.evaluation.evaluator]: \u001b[0mInference done 2338/5000. Dataloading: 0.0020 s/iter. Inference: 0.3989 s/iter. Eval: 0.0195 s/iter. Total: 0.4206 s/iter. ETA=0:18:39\n",
            "\u001b[32m[04/30 13:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 2350/5000. Dataloading: 0.0020 s/iter. Inference: 0.3990 s/iter. Eval: 0.0195 s/iter. Total: 0.4206 s/iter. ETA=0:18:34\n",
            "\u001b[32m[04/30 13:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 2362/5000. Dataloading: 0.0020 s/iter. Inference: 0.3990 s/iter. Eval: 0.0195 s/iter. Total: 0.4207 s/iter. ETA=0:18:29\n",
            "\u001b[32m[04/30 13:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 2374/5000. Dataloading: 0.0020 s/iter. Inference: 0.3990 s/iter. Eval: 0.0195 s/iter. Total: 0.4207 s/iter. ETA=0:18:24\n",
            "\u001b[32m[04/30 13:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 2386/5000. Dataloading: 0.0020 s/iter. Inference: 0.3991 s/iter. Eval: 0.0195 s/iter. Total: 0.4207 s/iter. ETA=0:18:19\n",
            "\u001b[32m[04/30 13:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 2398/5000. Dataloading: 0.0020 s/iter. Inference: 0.3991 s/iter. Eval: 0.0195 s/iter. Total: 0.4208 s/iter. ETA=0:18:14\n",
            "\u001b[32m[04/30 13:49:17 d2.evaluation.evaluator]: \u001b[0mInference done 2410/5000. Dataloading: 0.0020 s/iter. Inference: 0.3991 s/iter. Eval: 0.0195 s/iter. Total: 0.4208 s/iter. ETA=0:18:09\n",
            "\u001b[32m[04/30 13:49:22 d2.evaluation.evaluator]: \u001b[0mInference done 2422/5000. Dataloading: 0.0020 s/iter. Inference: 0.3992 s/iter. Eval: 0.0195 s/iter. Total: 0.4209 s/iter. ETA=0:18:05\n",
            "\u001b[32m[04/30 13:49:27 d2.evaluation.evaluator]: \u001b[0mInference done 2434/5000. Dataloading: 0.0020 s/iter. Inference: 0.3992 s/iter. Eval: 0.0196 s/iter. Total: 0.4209 s/iter. ETA=0:18:00\n",
            "\u001b[32m[04/30 13:49:32 d2.evaluation.evaluator]: \u001b[0mInference done 2446/5000. Dataloading: 0.0020 s/iter. Inference: 0.3992 s/iter. Eval: 0.0195 s/iter. Total: 0.4210 s/iter. ETA=0:17:55\n",
            "\u001b[32m[04/30 13:49:37 d2.evaluation.evaluator]: \u001b[0mInference done 2458/5000. Dataloading: 0.0020 s/iter. Inference: 0.3993 s/iter. Eval: 0.0195 s/iter. Total: 0.4210 s/iter. ETA=0:17:50\n",
            "\u001b[32m[04/30 13:49:42 d2.evaluation.evaluator]: \u001b[0mInference done 2470/5000. Dataloading: 0.0020 s/iter. Inference: 0.3993 s/iter. Eval: 0.0195 s/iter. Total: 0.4210 s/iter. ETA=0:17:45\n",
            "\u001b[32m[04/30 13:49:48 d2.evaluation.evaluator]: \u001b[0mInference done 2482/5000. Dataloading: 0.0020 s/iter. Inference: 0.3993 s/iter. Eval: 0.0195 s/iter. Total: 0.4210 s/iter. ETA=0:17:40\n",
            "\u001b[32m[04/30 13:49:53 d2.evaluation.evaluator]: \u001b[0mInference done 2494/5000. Dataloading: 0.0020 s/iter. Inference: 0.3993 s/iter. Eval: 0.0195 s/iter. Total: 0.4210 s/iter. ETA=0:17:35\n",
            "\u001b[32m[04/30 13:49:58 d2.evaluation.evaluator]: \u001b[0mInference done 2506/5000. Dataloading: 0.0020 s/iter. Inference: 0.3993 s/iter. Eval: 0.0195 s/iter. Total: 0.4210 s/iter. ETA=0:17:30\n",
            "\u001b[32m[04/30 13:50:03 d2.evaluation.evaluator]: \u001b[0mInference done 2518/5000. Dataloading: 0.0020 s/iter. Inference: 0.3993 s/iter. Eval: 0.0196 s/iter. Total: 0.4211 s/iter. ETA=0:17:25\n",
            "\u001b[32m[04/30 13:50:08 d2.evaluation.evaluator]: \u001b[0mInference done 2530/5000. Dataloading: 0.0020 s/iter. Inference: 0.3993 s/iter. Eval: 0.0196 s/iter. Total: 0.4211 s/iter. ETA=0:17:20\n",
            "\u001b[32m[04/30 13:50:13 d2.evaluation.evaluator]: \u001b[0mInference done 2542/5000. Dataloading: 0.0020 s/iter. Inference: 0.3994 s/iter. Eval: 0.0196 s/iter. Total: 0.4211 s/iter. ETA=0:17:15\n",
            "\u001b[32m[04/30 13:50:18 d2.evaluation.evaluator]: \u001b[0mInference done 2554/5000. Dataloading: 0.0020 s/iter. Inference: 0.3994 s/iter. Eval: 0.0196 s/iter. Total: 0.4212 s/iter. ETA=0:17:10\n",
            "\u001b[32m[04/30 13:50:24 d2.evaluation.evaluator]: \u001b[0mInference done 2566/5000. Dataloading: 0.0020 s/iter. Inference: 0.3995 s/iter. Eval: 0.0196 s/iter. Total: 0.4212 s/iter. ETA=0:17:05\n",
            "\u001b[32m[04/30 13:50:29 d2.evaluation.evaluator]: \u001b[0mInference done 2578/5000. Dataloading: 0.0020 s/iter. Inference: 0.3995 s/iter. Eval: 0.0197 s/iter. Total: 0.4213 s/iter. ETA=0:17:00\n",
            "\u001b[32m[04/30 13:50:34 d2.evaluation.evaluator]: \u001b[0mInference done 2591/5000. Dataloading: 0.0020 s/iter. Inference: 0.3995 s/iter. Eval: 0.0197 s/iter. Total: 0.4213 s/iter. ETA=0:16:54\n",
            "\u001b[32m[04/30 13:50:39 d2.evaluation.evaluator]: \u001b[0mInference done 2603/5000. Dataloading: 0.0020 s/iter. Inference: 0.3995 s/iter. Eval: 0.0196 s/iter. Total: 0.4213 s/iter. ETA=0:16:49\n",
            "\u001b[32m[04/30 13:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 2615/5000. Dataloading: 0.0020 s/iter. Inference: 0.3995 s/iter. Eval: 0.0197 s/iter. Total: 0.4214 s/iter. ETA=0:16:44\n",
            "\u001b[32m[04/30 13:50:50 d2.evaluation.evaluator]: \u001b[0mInference done 2627/5000. Dataloading: 0.0020 s/iter. Inference: 0.3995 s/iter. Eval: 0.0197 s/iter. Total: 0.4214 s/iter. ETA=0:16:39\n",
            "\u001b[32m[04/30 13:50:55 d2.evaluation.evaluator]: \u001b[0mInference done 2639/5000. Dataloading: 0.0020 s/iter. Inference: 0.3996 s/iter. Eval: 0.0197 s/iter. Total: 0.4215 s/iter. ETA=0:16:35\n",
            "\u001b[32m[04/30 13:51:00 d2.evaluation.evaluator]: \u001b[0mInference done 2651/5000. Dataloading: 0.0020 s/iter. Inference: 0.3996 s/iter. Eval: 0.0197 s/iter. Total: 0.4215 s/iter. ETA=0:16:30\n",
            "\u001b[32m[04/30 13:51:05 d2.evaluation.evaluator]: \u001b[0mInference done 2663/5000. Dataloading: 0.0020 s/iter. Inference: 0.3996 s/iter. Eval: 0.0197 s/iter. Total: 0.4215 s/iter. ETA=0:16:25\n",
            "\u001b[32m[04/30 13:51:10 d2.evaluation.evaluator]: \u001b[0mInference done 2675/5000. Dataloading: 0.0020 s/iter. Inference: 0.3997 s/iter. Eval: 0.0197 s/iter. Total: 0.4215 s/iter. ETA=0:16:20\n",
            "\u001b[32m[04/30 13:51:15 d2.evaluation.evaluator]: \u001b[0mInference done 2687/5000. Dataloading: 0.0020 s/iter. Inference: 0.3997 s/iter. Eval: 0.0197 s/iter. Total: 0.4216 s/iter. ETA=0:16:15\n",
            "\u001b[32m[04/30 13:51:21 d2.evaluation.evaluator]: \u001b[0mInference done 2700/5000. Dataloading: 0.0020 s/iter. Inference: 0.3997 s/iter. Eval: 0.0196 s/iter. Total: 0.4215 s/iter. ETA=0:16:09\n",
            "\u001b[32m[04/30 13:51:26 d2.evaluation.evaluator]: \u001b[0mInference done 2712/5000. Dataloading: 0.0020 s/iter. Inference: 0.3998 s/iter. Eval: 0.0196 s/iter. Total: 0.4215 s/iter. ETA=0:16:04\n",
            "\u001b[32m[04/30 13:51:31 d2.evaluation.evaluator]: \u001b[0mInference done 2724/5000. Dataloading: 0.0020 s/iter. Inference: 0.3998 s/iter. Eval: 0.0196 s/iter. Total: 0.4216 s/iter. ETA=0:15:59\n",
            "\u001b[32m[04/30 13:51:36 d2.evaluation.evaluator]: \u001b[0mInference done 2736/5000. Dataloading: 0.0020 s/iter. Inference: 0.3998 s/iter. Eval: 0.0196 s/iter. Total: 0.4216 s/iter. ETA=0:15:54\n",
            "\u001b[32m[04/30 13:51:41 d2.evaluation.evaluator]: \u001b[0mInference done 2748/5000. Dataloading: 0.0020 s/iter. Inference: 0.3998 s/iter. Eval: 0.0196 s/iter. Total: 0.4215 s/iter. ETA=0:15:49\n",
            "\u001b[32m[04/30 13:51:46 d2.evaluation.evaluator]: \u001b[0mInference done 2760/5000. Dataloading: 0.0020 s/iter. Inference: 0.3998 s/iter. Eval: 0.0196 s/iter. Total: 0.4216 s/iter. ETA=0:15:44\n",
            "\u001b[32m[04/30 13:51:51 d2.evaluation.evaluator]: \u001b[0mInference done 2772/5000. Dataloading: 0.0020 s/iter. Inference: 0.3999 s/iter. Eval: 0.0196 s/iter. Total: 0.4216 s/iter. ETA=0:15:39\n",
            "\u001b[32m[04/30 13:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 2784/5000. Dataloading: 0.0020 s/iter. Inference: 0.3999 s/iter. Eval: 0.0196 s/iter. Total: 0.4216 s/iter. ETA=0:15:34\n",
            "\u001b[32m[04/30 13:52:01 d2.evaluation.evaluator]: \u001b[0mInference done 2796/5000. Dataloading: 0.0020 s/iter. Inference: 0.3999 s/iter. Eval: 0.0196 s/iter. Total: 0.4216 s/iter. ETA=0:15:29\n",
            "\u001b[32m[04/30 13:52:07 d2.evaluation.evaluator]: \u001b[0mInference done 2808/5000. Dataloading: 0.0020 s/iter. Inference: 0.3999 s/iter. Eval: 0.0196 s/iter. Total: 0.4216 s/iter. ETA=0:15:24\n",
            "\u001b[32m[04/30 13:52:12 d2.evaluation.evaluator]: \u001b[0mInference done 2820/5000. Dataloading: 0.0020 s/iter. Inference: 0.3999 s/iter. Eval: 0.0196 s/iter. Total: 0.4217 s/iter. ETA=0:15:19\n",
            "\u001b[32m[04/30 13:52:17 d2.evaluation.evaluator]: \u001b[0mInference done 2832/5000. Dataloading: 0.0020 s/iter. Inference: 0.3999 s/iter. Eval: 0.0196 s/iter. Total: 0.4217 s/iter. ETA=0:15:14\n",
            "\u001b[32m[04/30 13:52:22 d2.evaluation.evaluator]: \u001b[0mInference done 2844/5000. Dataloading: 0.0020 s/iter. Inference: 0.4000 s/iter. Eval: 0.0196 s/iter. Total: 0.4217 s/iter. ETA=0:15:09\n",
            "\u001b[32m[04/30 13:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 2856/5000. Dataloading: 0.0020 s/iter. Inference: 0.4000 s/iter. Eval: 0.0196 s/iter. Total: 0.4217 s/iter. ETA=0:15:04\n",
            "\u001b[32m[04/30 13:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 2868/5000. Dataloading: 0.0020 s/iter. Inference: 0.4000 s/iter. Eval: 0.0196 s/iter. Total: 0.4218 s/iter. ETA=0:14:59\n",
            "\u001b[32m[04/30 13:52:37 d2.evaluation.evaluator]: \u001b[0mInference done 2880/5000. Dataloading: 0.0020 s/iter. Inference: 0.4000 s/iter. Eval: 0.0196 s/iter. Total: 0.4218 s/iter. ETA=0:14:54\n",
            "\u001b[32m[04/30 13:52:42 d2.evaluation.evaluator]: \u001b[0mInference done 2892/5000. Dataloading: 0.0020 s/iter. Inference: 0.4001 s/iter. Eval: 0.0196 s/iter. Total: 0.4218 s/iter. ETA=0:14:49\n",
            "\u001b[32m[04/30 13:52:48 d2.evaluation.evaluator]: \u001b[0mInference done 2904/5000. Dataloading: 0.0020 s/iter. Inference: 0.4001 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:44\n",
            "\u001b[32m[04/30 13:52:53 d2.evaluation.evaluator]: \u001b[0mInference done 2916/5000. Dataloading: 0.0020 s/iter. Inference: 0.4001 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:39\n",
            "\u001b[32m[04/30 13:52:58 d2.evaluation.evaluator]: \u001b[0mInference done 2928/5000. Dataloading: 0.0020 s/iter. Inference: 0.4001 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:34\n",
            "\u001b[32m[04/30 13:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 2940/5000. Dataloading: 0.0020 s/iter. Inference: 0.4001 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:29\n",
            "\u001b[32m[04/30 13:53:08 d2.evaluation.evaluator]: \u001b[0mInference done 2952/5000. Dataloading: 0.0020 s/iter. Inference: 0.4001 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:24\n",
            "\u001b[32m[04/30 13:53:13 d2.evaluation.evaluator]: \u001b[0mInference done 2964/5000. Dataloading: 0.0020 s/iter. Inference: 0.4001 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:19\n",
            "\u001b[32m[04/30 13:53:19 d2.evaluation.evaluator]: \u001b[0mInference done 2977/5000. Dataloading: 0.0020 s/iter. Inference: 0.4002 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:13\n",
            "\u001b[32m[04/30 13:53:24 d2.evaluation.evaluator]: \u001b[0mInference done 2989/5000. Dataloading: 0.0020 s/iter. Inference: 0.4002 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:08\n",
            "\u001b[32m[04/30 13:53:29 d2.evaluation.evaluator]: \u001b[0mInference done 3001/5000. Dataloading: 0.0020 s/iter. Inference: 0.4002 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:03\n",
            "\u001b[32m[04/30 13:53:34 d2.evaluation.evaluator]: \u001b[0mInference done 3014/5000. Dataloading: 0.0020 s/iter. Inference: 0.4002 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:13:57\n",
            "\u001b[32m[04/30 13:53:39 d2.evaluation.evaluator]: \u001b[0mInference done 3026/5000. Dataloading: 0.0020 s/iter. Inference: 0.4002 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:13:52\n",
            "\u001b[32m[04/30 13:53:45 d2.evaluation.evaluator]: \u001b[0mInference done 3038/5000. Dataloading: 0.0020 s/iter. Inference: 0.4002 s/iter. Eval: 0.0196 s/iter. Total: 0.4220 s/iter. ETA=0:13:47\n",
            "\u001b[32m[04/30 13:53:50 d2.evaluation.evaluator]: \u001b[0mInference done 3050/5000. Dataloading: 0.0020 s/iter. Inference: 0.4003 s/iter. Eval: 0.0195 s/iter. Total: 0.4220 s/iter. ETA=0:13:42\n",
            "\u001b[32m[04/30 13:53:55 d2.evaluation.evaluator]: \u001b[0mInference done 3062/5000. Dataloading: 0.0020 s/iter. Inference: 0.4003 s/iter. Eval: 0.0195 s/iter. Total: 0.4220 s/iter. ETA=0:13:37\n",
            "\u001b[32m[04/30 13:54:00 d2.evaluation.evaluator]: \u001b[0mInference done 3074/5000. Dataloading: 0.0020 s/iter. Inference: 0.4003 s/iter. Eval: 0.0195 s/iter. Total: 0.4220 s/iter. ETA=0:13:32\n",
            "\u001b[32m[04/30 13:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 3086/5000. Dataloading: 0.0020 s/iter. Inference: 0.4004 s/iter. Eval: 0.0195 s/iter. Total: 0.4220 s/iter. ETA=0:13:27\n",
            "\u001b[32m[04/30 13:54:10 d2.evaluation.evaluator]: \u001b[0mInference done 3098/5000. Dataloading: 0.0020 s/iter. Inference: 0.4004 s/iter. Eval: 0.0195 s/iter. Total: 0.4220 s/iter. ETA=0:13:22\n",
            "\u001b[32m[04/30 13:54:15 d2.evaluation.evaluator]: \u001b[0mInference done 3110/5000. Dataloading: 0.0020 s/iter. Inference: 0.4004 s/iter. Eval: 0.0195 s/iter. Total: 0.4220 s/iter. ETA=0:13:17\n",
            "\u001b[32m[04/30 13:54:20 d2.evaluation.evaluator]: \u001b[0mInference done 3122/5000. Dataloading: 0.0020 s/iter. Inference: 0.4004 s/iter. Eval: 0.0195 s/iter. Total: 0.4220 s/iter. ETA=0:13:12\n",
            "\u001b[32m[04/30 13:54:25 d2.evaluation.evaluator]: \u001b[0mInference done 3134/5000. Dataloading: 0.0020 s/iter. Inference: 0.4004 s/iter. Eval: 0.0195 s/iter. Total: 0.4221 s/iter. ETA=0:13:07\n",
            "\u001b[32m[04/30 13:54:31 d2.evaluation.evaluator]: \u001b[0mInference done 3146/5000. Dataloading: 0.0020 s/iter. Inference: 0.4004 s/iter. Eval: 0.0195 s/iter. Total: 0.4221 s/iter. ETA=0:13:02\n",
            "\u001b[32m[04/30 13:54:36 d2.evaluation.evaluator]: \u001b[0mInference done 3159/5000. Dataloading: 0.0020 s/iter. Inference: 0.4004 s/iter. Eval: 0.0195 s/iter. Total: 0.4221 s/iter. ETA=0:12:57\n",
            "\u001b[32m[04/30 13:54:41 d2.evaluation.evaluator]: \u001b[0mInference done 3172/5000. Dataloading: 0.0020 s/iter. Inference: 0.4005 s/iter. Eval: 0.0194 s/iter. Total: 0.4220 s/iter. ETA=0:12:51\n",
            "\u001b[32m[04/30 13:54:46 d2.evaluation.evaluator]: \u001b[0mInference done 3184/5000. Dataloading: 0.0020 s/iter. Inference: 0.4005 s/iter. Eval: 0.0194 s/iter. Total: 0.4221 s/iter. ETA=0:12:46\n",
            "\u001b[32m[04/30 13:54:52 d2.evaluation.evaluator]: \u001b[0mInference done 3196/5000. Dataloading: 0.0020 s/iter. Inference: 0.4005 s/iter. Eval: 0.0194 s/iter. Total: 0.4221 s/iter. ETA=0:12:41\n",
            "\u001b[32m[04/30 13:54:57 d2.evaluation.evaluator]: \u001b[0mInference done 3208/5000. Dataloading: 0.0020 s/iter. Inference: 0.4005 s/iter. Eval: 0.0195 s/iter. Total: 0.4221 s/iter. ETA=0:12:36\n",
            "\u001b[32m[04/30 13:55:02 d2.evaluation.evaluator]: \u001b[0mInference done 3220/5000. Dataloading: 0.0020 s/iter. Inference: 0.4005 s/iter. Eval: 0.0195 s/iter. Total: 0.4222 s/iter. ETA=0:12:31\n",
            "\u001b[32m[04/30 13:55:07 d2.evaluation.evaluator]: \u001b[0mInference done 3232/5000. Dataloading: 0.0020 s/iter. Inference: 0.4005 s/iter. Eval: 0.0195 s/iter. Total: 0.4222 s/iter. ETA=0:12:26\n",
            "\u001b[32m[04/30 13:55:12 d2.evaluation.evaluator]: \u001b[0mInference done 3244/5000. Dataloading: 0.0020 s/iter. Inference: 0.4006 s/iter. Eval: 0.0195 s/iter. Total: 0.4222 s/iter. ETA=0:12:21\n",
            "\u001b[32m[04/30 13:55:17 d2.evaluation.evaluator]: \u001b[0mInference done 3256/5000. Dataloading: 0.0020 s/iter. Inference: 0.4006 s/iter. Eval: 0.0195 s/iter. Total: 0.4222 s/iter. ETA=0:12:16\n",
            "\u001b[32m[04/30 13:55:23 d2.evaluation.evaluator]: \u001b[0mInference done 3268/5000. Dataloading: 0.0020 s/iter. Inference: 0.4006 s/iter. Eval: 0.0195 s/iter. Total: 0.4223 s/iter. ETA=0:12:11\n",
            "\u001b[32m[04/30 13:55:28 d2.evaluation.evaluator]: \u001b[0mInference done 3280/5000. Dataloading: 0.0020 s/iter. Inference: 0.4006 s/iter. Eval: 0.0195 s/iter. Total: 0.4223 s/iter. ETA=0:12:06\n",
            "\u001b[32m[04/30 13:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 3292/5000. Dataloading: 0.0020 s/iter. Inference: 0.4007 s/iter. Eval: 0.0196 s/iter. Total: 0.4224 s/iter. ETA=0:12:01\n",
            "\u001b[32m[04/30 13:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 3304/5000. Dataloading: 0.0020 s/iter. Inference: 0.4007 s/iter. Eval: 0.0196 s/iter. Total: 0.4224 s/iter. ETA=0:11:56\n",
            "\u001b[32m[04/30 13:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 3316/5000. Dataloading: 0.0020 s/iter. Inference: 0.4007 s/iter. Eval: 0.0196 s/iter. Total: 0.4225 s/iter. ETA=0:11:51\n",
            "\u001b[32m[04/30 13:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 3328/5000. Dataloading: 0.0020 s/iter. Inference: 0.4007 s/iter. Eval: 0.0196 s/iter. Total: 0.4225 s/iter. ETA=0:11:46\n",
            "\u001b[32m[04/30 13:55:54 d2.evaluation.evaluator]: \u001b[0mInference done 3341/5000. Dataloading: 0.0020 s/iter. Inference: 0.4007 s/iter. Eval: 0.0196 s/iter. Total: 0.4225 s/iter. ETA=0:11:40\n",
            "\u001b[32m[04/30 13:55:59 d2.evaluation.evaluator]: \u001b[0mInference done 3353/5000. Dataloading: 0.0020 s/iter. Inference: 0.4007 s/iter. Eval: 0.0196 s/iter. Total: 0.4225 s/iter. ETA=0:11:35\n",
            "\u001b[32m[04/30 13:56:05 d2.evaluation.evaluator]: \u001b[0mInference done 3365/5000. Dataloading: 0.0020 s/iter. Inference: 0.4008 s/iter. Eval: 0.0197 s/iter. Total: 0.4226 s/iter. ETA=0:11:30\n",
            "\u001b[32m[04/30 13:56:10 d2.evaluation.evaluator]: \u001b[0mInference done 3377/5000. Dataloading: 0.0020 s/iter. Inference: 0.4008 s/iter. Eval: 0.0197 s/iter. Total: 0.4226 s/iter. ETA=0:11:25\n",
            "\u001b[32m[04/30 13:56:15 d2.evaluation.evaluator]: \u001b[0mInference done 3390/5000. Dataloading: 0.0020 s/iter. Inference: 0.4008 s/iter. Eval: 0.0197 s/iter. Total: 0.4226 s/iter. ETA=0:11:20\n",
            "\u001b[32m[04/30 13:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 3403/5000. Dataloading: 0.0020 s/iter. Inference: 0.4008 s/iter. Eval: 0.0196 s/iter. Total: 0.4226 s/iter. ETA=0:11:14\n",
            "\u001b[32m[04/30 13:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 3415/5000. Dataloading: 0.0020 s/iter. Inference: 0.4008 s/iter. Eval: 0.0196 s/iter. Total: 0.4226 s/iter. ETA=0:11:09\n",
            "\u001b[32m[04/30 13:56:31 d2.evaluation.evaluator]: \u001b[0mInference done 3427/5000. Dataloading: 0.0020 s/iter. Inference: 0.4008 s/iter. Eval: 0.0196 s/iter. Total: 0.4226 s/iter. ETA=0:11:04\n",
            "\u001b[32m[04/30 13:56:36 d2.evaluation.evaluator]: \u001b[0mInference done 3439/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4227 s/iter. ETA=0:10:59\n",
            "\u001b[32m[04/30 13:56:41 d2.evaluation.evaluator]: \u001b[0mInference done 3451/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4227 s/iter. ETA=0:10:54\n",
            "\u001b[32m[04/30 13:56:47 d2.evaluation.evaluator]: \u001b[0mInference done 3463/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4227 s/iter. ETA=0:10:49\n",
            "\u001b[32m[04/30 13:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 3475/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4227 s/iter. ETA=0:10:44\n",
            "\u001b[32m[04/30 13:56:57 d2.evaluation.evaluator]: \u001b[0mInference done 3488/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4227 s/iter. ETA=0:10:39\n",
            "\u001b[32m[04/30 13:57:02 d2.evaluation.evaluator]: \u001b[0mInference done 3500/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:10:34\n",
            "\u001b[32m[04/30 13:57:07 d2.evaluation.evaluator]: \u001b[0mInference done 3512/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:10:29\n",
            "\u001b[32m[04/30 13:57:13 d2.evaluation.evaluator]: \u001b[0mInference done 3525/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:10:23\n",
            "\u001b[32m[04/30 13:57:18 d2.evaluation.evaluator]: \u001b[0mInference done 3537/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4227 s/iter. ETA=0:10:18\n",
            "\u001b[32m[04/30 13:57:23 d2.evaluation.evaluator]: \u001b[0mInference done 3549/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:10:13\n",
            "\u001b[32m[04/30 13:57:28 d2.evaluation.evaluator]: \u001b[0mInference done 3561/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:10:08\n",
            "\u001b[32m[04/30 13:57:33 d2.evaluation.evaluator]: \u001b[0mInference done 3573/5000. Dataloading: 0.0020 s/iter. Inference: 0.4010 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:10:03\n",
            "\u001b[32m[04/30 13:57:38 d2.evaluation.evaluator]: \u001b[0mInference done 3585/5000. Dataloading: 0.0020 s/iter. Inference: 0.4010 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:09:58\n",
            "\u001b[32m[04/30 13:57:44 d2.evaluation.evaluator]: \u001b[0mInference done 3597/5000. Dataloading: 0.0020 s/iter. Inference: 0.4010 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:09:53\n",
            "\u001b[32m[04/30 13:57:49 d2.evaluation.evaluator]: \u001b[0mInference done 3609/5000. Dataloading: 0.0020 s/iter. Inference: 0.4010 s/iter. Eval: 0.0197 s/iter. Total: 0.4229 s/iter. ETA=0:09:48\n",
            "\u001b[32m[04/30 13:57:54 d2.evaluation.evaluator]: \u001b[0mInference done 3622/5000. Dataloading: 0.0020 s/iter. Inference: 0.4010 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:09:42\n",
            "\u001b[32m[04/30 13:57:59 d2.evaluation.evaluator]: \u001b[0mInference done 3634/5000. Dataloading: 0.0020 s/iter. Inference: 0.4010 s/iter. Eval: 0.0197 s/iter. Total: 0.4229 s/iter. ETA=0:09:37\n",
            "\u001b[32m[04/30 13:58:04 d2.evaluation.evaluator]: \u001b[0mInference done 3646/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0197 s/iter. Total: 0.4229 s/iter. ETA=0:09:32\n",
            "\u001b[32m[04/30 13:58:10 d2.evaluation.evaluator]: \u001b[0mInference done 3658/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0197 s/iter. Total: 0.4229 s/iter. ETA=0:09:27\n",
            "\u001b[32m[04/30 13:58:15 d2.evaluation.evaluator]: \u001b[0mInference done 3670/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0197 s/iter. Total: 0.4229 s/iter. ETA=0:09:22\n",
            "\u001b[32m[04/30 13:58:20 d2.evaluation.evaluator]: \u001b[0mInference done 3682/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0196 s/iter. Total: 0.4229 s/iter. ETA=0:09:17\n",
            "\u001b[32m[04/30 13:58:25 d2.evaluation.evaluator]: \u001b[0mInference done 3694/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0197 s/iter. Total: 0.4229 s/iter. ETA=0:09:12\n",
            "\u001b[32m[04/30 13:58:30 d2.evaluation.evaluator]: \u001b[0mInference done 3706/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0197 s/iter. Total: 0.4229 s/iter. ETA=0:09:07\n",
            "\u001b[32m[04/30 13:58:35 d2.evaluation.evaluator]: \u001b[0mInference done 3719/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0196 s/iter. Total: 0.4229 s/iter. ETA=0:09:01\n",
            "\u001b[32m[04/30 13:58:41 d2.evaluation.evaluator]: \u001b[0mInference done 3731/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0196 s/iter. Total: 0.4229 s/iter. ETA=0:08:56\n",
            "\u001b[32m[04/30 13:58:46 d2.evaluation.evaluator]: \u001b[0mInference done 3743/5000. Dataloading: 0.0020 s/iter. Inference: 0.4012 s/iter. Eval: 0.0196 s/iter. Total: 0.4230 s/iter. ETA=0:08:51\n",
            "\u001b[32m[04/30 13:58:51 d2.evaluation.evaluator]: \u001b[0mInference done 3755/5000. Dataloading: 0.0020 s/iter. Inference: 0.4012 s/iter. Eval: 0.0196 s/iter. Total: 0.4230 s/iter. ETA=0:08:46\n",
            "\u001b[32m[04/30 13:58:56 d2.evaluation.evaluator]: \u001b[0mInference done 3767/5000. Dataloading: 0.0020 s/iter. Inference: 0.4012 s/iter. Eval: 0.0196 s/iter. Total: 0.4230 s/iter. ETA=0:08:41\n",
            "\u001b[32m[04/30 13:59:01 d2.evaluation.evaluator]: \u001b[0mInference done 3779/5000. Dataloading: 0.0020 s/iter. Inference: 0.4012 s/iter. Eval: 0.0197 s/iter. Total: 0.4230 s/iter. ETA=0:08:36\n",
            "\u001b[32m[04/30 13:59:06 d2.evaluation.evaluator]: \u001b[0mInference done 3791/5000. Dataloading: 0.0020 s/iter. Inference: 0.4012 s/iter. Eval: 0.0197 s/iter. Total: 0.4230 s/iter. ETA=0:08:31\n",
            "\u001b[32m[04/30 13:59:12 d2.evaluation.evaluator]: \u001b[0mInference done 3803/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0197 s/iter. Total: 0.4231 s/iter. ETA=0:08:26\n",
            "\u001b[32m[04/30 13:59:17 d2.evaluation.evaluator]: \u001b[0mInference done 3816/5000. Dataloading: 0.0020 s/iter. Inference: 0.4012 s/iter. Eval: 0.0197 s/iter. Total: 0.4230 s/iter. ETA=0:08:20\n",
            "\u001b[32m[04/30 13:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 3828/5000. Dataloading: 0.0020 s/iter. Inference: 0.4012 s/iter. Eval: 0.0196 s/iter. Total: 0.4230 s/iter. ETA=0:08:15\n",
            "\u001b[32m[04/30 13:59:27 d2.evaluation.evaluator]: \u001b[0mInference done 3840/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4230 s/iter. ETA=0:08:10\n",
            "\u001b[32m[04/30 13:59:32 d2.evaluation.evaluator]: \u001b[0mInference done 3852/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4230 s/iter. ETA=0:08:05\n",
            "\u001b[32m[04/30 13:59:37 d2.evaluation.evaluator]: \u001b[0mInference done 3864/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:08:00\n",
            "\u001b[32m[04/30 13:59:42 d2.evaluation.evaluator]: \u001b[0mInference done 3876/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:55\n",
            "\u001b[32m[04/30 13:59:48 d2.evaluation.evaluator]: \u001b[0mInference done 3889/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:50\n",
            "\u001b[32m[04/30 13:59:53 d2.evaluation.evaluator]: \u001b[0mInference done 3902/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4230 s/iter. ETA=0:07:44\n",
            "\u001b[32m[04/30 13:59:58 d2.evaluation.evaluator]: \u001b[0mInference done 3914/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:39\n",
            "\u001b[32m[04/30 14:00:04 d2.evaluation.evaluator]: \u001b[0mInference done 3926/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:34\n",
            "\u001b[32m[04/30 14:00:09 d2.evaluation.evaluator]: \u001b[0mInference done 3938/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:29\n",
            "\u001b[32m[04/30 14:00:14 d2.evaluation.evaluator]: \u001b[0mInference done 3950/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:24\n",
            "\u001b[32m[04/30 14:00:19 d2.evaluation.evaluator]: \u001b[0mInference done 3962/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:19\n",
            "\u001b[32m[04/30 14:00:24 d2.evaluation.evaluator]: \u001b[0mInference done 3974/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:14\n",
            "\u001b[32m[04/30 14:00:29 d2.evaluation.evaluator]: \u001b[0mInference done 3987/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:08\n",
            "\u001b[32m[04/30 14:00:35 d2.evaluation.evaluator]: \u001b[0mInference done 3999/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:03\n",
            "\u001b[32m[04/30 14:00:40 d2.evaluation.evaluator]: \u001b[0mInference done 4011/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:06:58\n",
            "\u001b[32m[04/30 14:00:45 d2.evaluation.evaluator]: \u001b[0mInference done 4023/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:06:53\n",
            "\u001b[32m[04/30 14:00:50 d2.evaluation.evaluator]: \u001b[0mInference done 4035/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4232 s/iter. ETA=0:06:48\n",
            "\u001b[32m[04/30 14:00:55 d2.evaluation.evaluator]: \u001b[0mInference done 4047/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4232 s/iter. ETA=0:06:43\n",
            "\u001b[32m[04/30 14:01:00 d2.evaluation.evaluator]: \u001b[0mInference done 4059/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4232 s/iter. ETA=0:06:38\n",
            "\u001b[32m[04/30 14:01:06 d2.evaluation.evaluator]: \u001b[0mInference done 4071/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0197 s/iter. Total: 0.4232 s/iter. ETA=0:06:33\n",
            "\u001b[32m[04/30 14:01:11 d2.evaluation.evaluator]: \u001b[0mInference done 4083/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0197 s/iter. Total: 0.4233 s/iter. ETA=0:06:28\n",
            "\u001b[32m[04/30 14:01:16 d2.evaluation.evaluator]: \u001b[0mInference done 4095/5000. Dataloading: 0.0020 s/iter. Inference: 0.4015 s/iter. Eval: 0.0197 s/iter. Total: 0.4233 s/iter. ETA=0:06:23\n",
            "\u001b[32m[04/30 14:01:21 d2.evaluation.evaluator]: \u001b[0mInference done 4107/5000. Dataloading: 0.0020 s/iter. Inference: 0.4015 s/iter. Eval: 0.0197 s/iter. Total: 0.4233 s/iter. ETA=0:06:17\n",
            "\u001b[32m[04/30 14:01:26 d2.evaluation.evaluator]: \u001b[0mInference done 4119/5000. Dataloading: 0.0020 s/iter. Inference: 0.4015 s/iter. Eval: 0.0196 s/iter. Total: 0.4233 s/iter. ETA=0:06:12\n",
            "\u001b[32m[04/30 14:01:31 d2.evaluation.evaluator]: \u001b[0mInference done 4131/5000. Dataloading: 0.0020 s/iter. Inference: 0.4015 s/iter. Eval: 0.0196 s/iter. Total: 0.4233 s/iter. ETA=0:06:07\n",
            "\u001b[32m[04/30 14:01:36 d2.evaluation.evaluator]: \u001b[0mInference done 4143/5000. Dataloading: 0.0020 s/iter. Inference: 0.4015 s/iter. Eval: 0.0196 s/iter. Total: 0.4233 s/iter. ETA=0:06:02\n",
            "\u001b[32m[04/30 14:01:42 d2.evaluation.evaluator]: \u001b[0mInference done 4155/5000. Dataloading: 0.0020 s/iter. Inference: 0.4015 s/iter. Eval: 0.0197 s/iter. Total: 0.4233 s/iter. ETA=0:05:57\n",
            "\u001b[32m[04/30 14:01:47 d2.evaluation.evaluator]: \u001b[0mInference done 4167/5000. Dataloading: 0.0020 s/iter. Inference: 0.4015 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:05:52\n",
            "\u001b[32m[04/30 14:01:52 d2.evaluation.evaluator]: \u001b[0mInference done 4179/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:05:47\n",
            "\u001b[32m[04/30 14:01:58 d2.evaluation.evaluator]: \u001b[0mInference done 4192/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:05:42\n",
            "\u001b[32m[04/30 14:02:03 d2.evaluation.evaluator]: \u001b[0mInference done 4204/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:05:37\n",
            "\u001b[32m[04/30 14:02:08 d2.evaluation.evaluator]: \u001b[0mInference done 4216/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:05:31\n",
            "\u001b[32m[04/30 14:02:13 d2.evaluation.evaluator]: \u001b[0mInference done 4228/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:05:26\n",
            "\u001b[32m[04/30 14:02:18 d2.evaluation.evaluator]: \u001b[0mInference done 4241/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:05:21\n",
            "\u001b[32m[04/30 14:02:24 d2.evaluation.evaluator]: \u001b[0mInference done 4253/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:05:16\n",
            "\u001b[32m[04/30 14:02:29 d2.evaluation.evaluator]: \u001b[0mInference done 4265/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0198 s/iter. Total: 0.4235 s/iter. ETA=0:05:11\n",
            "\u001b[32m[04/30 14:02:34 d2.evaluation.evaluator]: \u001b[0mInference done 4278/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:05:05\n",
            "\u001b[32m[04/30 14:02:39 d2.evaluation.evaluator]: \u001b[0mInference done 4290/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0198 s/iter. Total: 0.4235 s/iter. ETA=0:05:00\n",
            "\u001b[32m[04/30 14:02:45 d2.evaluation.evaluator]: \u001b[0mInference done 4302/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0198 s/iter. Total: 0.4235 s/iter. ETA=0:04:55\n",
            "\u001b[32m[04/30 14:02:50 d2.evaluation.evaluator]: \u001b[0mInference done 4314/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:04:50\n",
            "\u001b[32m[04/30 14:02:55 d2.evaluation.evaluator]: \u001b[0mInference done 4326/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:04:45\n",
            "\u001b[32m[04/30 14:03:00 d2.evaluation.evaluator]: \u001b[0mInference done 4339/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:04:39\n",
            "\u001b[32m[04/30 14:03:05 d2.evaluation.evaluator]: \u001b[0mInference done 4351/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:04:34\n",
            "\u001b[32m[04/30 14:03:10 d2.evaluation.evaluator]: \u001b[0mInference done 4364/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:04:29\n",
            "\u001b[32m[04/30 14:03:16 d2.evaluation.evaluator]: \u001b[0mInference done 4376/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:04:24\n",
            "\u001b[32m[04/30 14:03:21 d2.evaluation.evaluator]: \u001b[0mInference done 4388/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:04:19\n",
            "\u001b[32m[04/30 14:03:26 d2.evaluation.evaluator]: \u001b[0mInference done 4400/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:04:14\n",
            "\u001b[32m[04/30 14:03:31 d2.evaluation.evaluator]: \u001b[0mInference done 4412/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:04:08\n",
            "\u001b[32m[04/30 14:03:36 d2.evaluation.evaluator]: \u001b[0mInference done 4424/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:04:03\n",
            "\u001b[32m[04/30 14:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 4436/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:03:58\n",
            "\u001b[32m[04/30 14:03:46 d2.evaluation.evaluator]: \u001b[0mInference done 4448/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:03:53\n",
            "\u001b[32m[04/30 14:03:51 d2.evaluation.evaluator]: \u001b[0mInference done 4460/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:03:48\n",
            "\u001b[32m[04/30 14:03:56 d2.evaluation.evaluator]: \u001b[0mInference done 4472/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:03:43\n",
            "\u001b[32m[04/30 14:04:01 d2.evaluation.evaluator]: \u001b[0mInference done 4484/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0196 s/iter. Total: 0.4234 s/iter. ETA=0:03:38\n",
            "\u001b[32m[04/30 14:04:06 d2.evaluation.evaluator]: \u001b[0mInference done 4496/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:03:33\n",
            "\u001b[32m[04/30 14:04:12 d2.evaluation.evaluator]: \u001b[0mInference done 4508/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:03:28\n",
            "\u001b[32m[04/30 14:04:17 d2.evaluation.evaluator]: \u001b[0mInference done 4520/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:03:23\n",
            "\u001b[32m[04/30 14:04:22 d2.evaluation.evaluator]: \u001b[0mInference done 4532/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:03:18\n",
            "\u001b[32m[04/30 14:04:27 d2.evaluation.evaluator]: \u001b[0mInference done 4544/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:03:13\n",
            "\u001b[32m[04/30 14:04:32 d2.evaluation.evaluator]: \u001b[0mInference done 4556/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:03:08\n",
            "\u001b[32m[04/30 14:04:37 d2.evaluation.evaluator]: \u001b[0mInference done 4568/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:03:02\n",
            "\u001b[32m[04/30 14:04:42 d2.evaluation.evaluator]: \u001b[0mInference done 4580/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:02:57\n",
            "\u001b[32m[04/30 14:04:48 d2.evaluation.evaluator]: \u001b[0mInference done 4592/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:02:52\n",
            "\u001b[32m[04/30 14:04:53 d2.evaluation.evaluator]: \u001b[0mInference done 4604/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:02:47\n",
            "\u001b[32m[04/30 14:04:58 d2.evaluation.evaluator]: \u001b[0mInference done 4616/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:02:42\n",
            "\u001b[32m[04/30 14:05:03 d2.evaluation.evaluator]: \u001b[0mInference done 4628/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:02:37\n",
            "\u001b[32m[04/30 14:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 4640/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:02:32\n",
            "\u001b[32m[04/30 14:05:13 d2.evaluation.evaluator]: \u001b[0mInference done 4652/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:02:27\n",
            "\u001b[32m[04/30 14:05:18 d2.evaluation.evaluator]: \u001b[0mInference done 4664/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:02:22\n",
            "\u001b[32m[04/30 14:05:23 d2.evaluation.evaluator]: \u001b[0mInference done 4676/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:02:17\n",
            "\u001b[32m[04/30 14:05:28 d2.evaluation.evaluator]: \u001b[0mInference done 4688/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:02:12\n",
            "\u001b[32m[04/30 14:05:34 d2.evaluation.evaluator]: \u001b[0mInference done 4700/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:02:07\n",
            "\u001b[32m[04/30 14:05:39 d2.evaluation.evaluator]: \u001b[0mInference done 4712/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:02:02\n",
            "\u001b[32m[04/30 14:05:44 d2.evaluation.evaluator]: \u001b[0mInference done 4724/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:56\n",
            "\u001b[32m[04/30 14:05:49 d2.evaluation.evaluator]: \u001b[0mInference done 4736/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:51\n",
            "\u001b[32m[04/30 14:05:54 d2.evaluation.evaluator]: \u001b[0mInference done 4748/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:46\n",
            "\u001b[32m[04/30 14:05:59 d2.evaluation.evaluator]: \u001b[0mInference done 4760/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4237 s/iter. ETA=0:01:41\n",
            "\u001b[32m[04/30 14:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 4772/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:36\n",
            "\u001b[32m[04/30 14:06:09 d2.evaluation.evaluator]: \u001b[0mInference done 4784/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:31\n",
            "\u001b[32m[04/30 14:06:14 d2.evaluation.evaluator]: \u001b[0mInference done 4796/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:26\n",
            "\u001b[32m[04/30 14:06:20 d2.evaluation.evaluator]: \u001b[0mInference done 4808/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0197 s/iter. Total: 0.4237 s/iter. ETA=0:01:21\n",
            "\u001b[32m[04/30 14:06:25 d2.evaluation.evaluator]: \u001b[0mInference done 4820/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:16\n",
            "\u001b[32m[04/30 14:06:30 d2.evaluation.evaluator]: \u001b[0mInference done 4833/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:10\n",
            "\u001b[32m[04/30 14:06:35 d2.evaluation.evaluator]: \u001b[0mInference done 4845/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:05\n",
            "\u001b[32m[04/30 14:06:40 d2.evaluation.evaluator]: \u001b[0mInference done 4857/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0196 s/iter. Total: 0.4236 s/iter. ETA=0:01:00\n",
            "\u001b[32m[04/30 14:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 4869/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0196 s/iter. Total: 0.4236 s/iter. ETA=0:00:55\n",
            "\u001b[32m[04/30 14:06:50 d2.evaluation.evaluator]: \u001b[0mInference done 4881/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0196 s/iter. Total: 0.4236 s/iter. ETA=0:00:50\n",
            "\u001b[32m[04/30 14:06:55 d2.evaluation.evaluator]: \u001b[0mInference done 4893/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0196 s/iter. Total: 0.4236 s/iter. ETA=0:00:45\n",
            "\u001b[32m[04/30 14:07:01 d2.evaluation.evaluator]: \u001b[0mInference done 4905/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0196 s/iter. Total: 0.4236 s/iter. ETA=0:00:40\n",
            "\u001b[32m[04/30 14:07:06 d2.evaluation.evaluator]: \u001b[0mInference done 4917/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0197 s/iter. Total: 0.4237 s/iter. ETA=0:00:35\n",
            "\u001b[32m[04/30 14:07:11 d2.evaluation.evaluator]: \u001b[0mInference done 4929/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0197 s/iter. Total: 0.4237 s/iter. ETA=0:00:30\n",
            "\u001b[32m[04/30 14:07:16 d2.evaluation.evaluator]: \u001b[0mInference done 4941/5000. Dataloading: 0.0020 s/iter. Inference: 0.4020 s/iter. Eval: 0.0197 s/iter. Total: 0.4237 s/iter. ETA=0:00:24\n",
            "\u001b[32m[04/30 14:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 4953/5000. Dataloading: 0.0020 s/iter. Inference: 0.4020 s/iter. Eval: 0.0197 s/iter. Total: 0.4237 s/iter. ETA=0:00:19\n",
            "\u001b[32m[04/30 14:07:26 d2.evaluation.evaluator]: \u001b[0mInference done 4965/5000. Dataloading: 0.0020 s/iter. Inference: 0.4020 s/iter. Eval: 0.0196 s/iter. Total: 0.4237 s/iter. ETA=0:00:14\n",
            "\u001b[32m[04/30 14:07:32 d2.evaluation.evaluator]: \u001b[0mInference done 4977/5000. Dataloading: 0.0020 s/iter. Inference: 0.4020 s/iter. Eval: 0.0196 s/iter. Total: 0.4237 s/iter. ETA=0:00:09\n",
            "\u001b[32m[04/30 14:07:37 d2.evaluation.evaluator]: \u001b[0mInference done 4989/5000. Dataloading: 0.0020 s/iter. Inference: 0.4020 s/iter. Eval: 0.0196 s/iter. Total: 0.4237 s/iter. ETA=0:00:04\n",
            "\u001b[32m[04/30 14:07:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:35:16.835977 (0.423791 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 14:07:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:33:27 (0.401987 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 14:07:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/30 14:07:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/30 14:07:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.19s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 14:07:46 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/30 14:07:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 8.28 seconds.\n",
            "\u001b[32m[04/30 14:07:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 14:07:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.90 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.646\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.501\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.289\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.498\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.573\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.602\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.422\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.636\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.737\n",
            "\u001b[32m[04/30 14:07:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 46.237 | 64.623 | 50.149 | 28.857 | 49.831 | 58.906 |\n",
            "\u001b[32m[04/30 14:07:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 59.770 | bicycle      | 33.646 | car            | 48.854 |\n",
            "| motorcycle    | 50.276 | airplane     | 71.318 | bus            | 69.074 |\n",
            "| train         | 67.608 | truck        | 40.494 | boat           | 30.846 |\n",
            "| traffic light | 30.997 | fire hydrant | 71.796 | stop sign      | 70.176 |\n",
            "| parking meter | 46.549 | bench        | 27.715 | bird           | 41.201 |\n",
            "| cat           | 73.339 | dog          | 68.959 | horse          | 63.672 |\n",
            "| sheep         | 56.762 | cow          | 61.638 | elephant       | 71.102 |\n",
            "| bear          | 71.154 | zebra        | 70.774 | giraffe        | 72.649 |\n",
            "| backpack      | 17.172 | umbrella     | 45.330 | handbag        | 17.464 |\n",
            "| tie           | 39.678 | suitcase     | 48.401 | frisbee        | 72.504 |\n",
            "| skis          | 30.603 | snowboard    | 44.802 | sports ball    | 51.808 |\n",
            "| kite          | 48.597 | baseball bat | 35.864 | baseball glove | 39.938 |\n",
            "| skateboard    | 59.873 | surfboard    | 44.559 | tennis racket  | 55.082 |\n",
            "| bottle        | 43.663 | wine glass   | 41.368 | cup            | 47.203 |\n",
            "| fork          | 42.446 | knife        | 25.125 | spoon          | 20.559 |\n",
            "| bowl          | 45.020 | banana       | 26.792 | apple          | 24.283 |\n",
            "| sandwich      | 39.009 | orange       | 32.839 | broccoli       | 25.089 |\n",
            "| carrot        | 26.337 | hot dog      | 39.991 | pizza          | 55.685 |\n",
            "| donut         | 54.052 | cake         | 40.592 | chair          | 31.909 |\n",
            "| couch         | 45.792 | potted plant | 28.816 | bed            | 47.121 |\n",
            "| dining table  | 30.966 | toilet       | 66.743 | tv             | 61.085 |\n",
            "| laptop        | 63.619 | mouse        | 64.320 | remote         | 42.078 |\n",
            "| keyboard      | 54.690 | cell phone   | 40.131 | microwave      | 57.373 |\n",
            "| oven          | 35.588 | toaster      | 34.159 | sink           | 39.207 |\n",
            "| refrigerator  | 64.114 | book         | 18.703 | clock          | 53.611 |\n",
            "| vase          | 41.691 | scissors     | 34.158 | teddy bear     | 52.536 |\n",
            "| hair drier    | 6.535  | toothbrush   | 31.924 |                |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=1.26s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 14:07:59 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
            "\u001b[32m[04/30 14:08:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 9.83 seconds.\n",
            "\u001b[32m[04/30 14:08:09 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 14:08:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.93 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.619\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.429\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.551\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.662\n",
            "\u001b[32m[04/30 14:08:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 39.640 | 61.864 | 42.880 | 20.836 | 42.424 | 55.520 |\n",
            "\u001b[32m[04/30 14:08:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 49.000 | bicycle      | 18.976 | car            | 43.559 |\n",
            "| motorcycle    | 36.316 | airplane     | 51.045 | bus            | 64.739 |\n",
            "| train         | 63.662 | truck        | 38.456 | boat           | 24.537 |\n",
            "| traffic light | 29.475 | fire hydrant | 65.524 | stop sign      | 67.308 |\n",
            "| parking meter | 46.539 | bench        | 18.931 | bird           | 33.201 |\n",
            "| cat           | 69.405 | dog          | 61.807 | horse          | 44.022 |\n",
            "| sheep         | 46.791 | cow          | 51.020 | elephant       | 61.154 |\n",
            "| bear          | 66.336 | zebra        | 58.699 | giraffe        | 53.112 |\n",
            "| backpack      | 16.062 | umbrella     | 48.724 | handbag        | 15.252 |\n",
            "| tie           | 34.845 | suitcase     | 47.285 | frisbee        | 66.643 |\n",
            "| skis          | 4.145  | snowboard    | 26.592 | sports ball    | 50.427 |\n",
            "| kite          | 34.849 | baseball bat | 26.633 | baseball glove | 40.004 |\n",
            "| skateboard    | 34.874 | surfboard    | 35.052 | tennis racket  | 58.314 |\n",
            "| bottle        | 39.822 | wine glass   | 34.686 | cup            | 46.155 |\n",
            "| fork          | 19.232 | knife        | 15.385 | spoon          | 13.585 |\n",
            "| bowl          | 40.994 | banana       | 19.844 | apple          | 22.703 |\n",
            "| sandwich      | 41.406 | orange       | 31.671 | broccoli       | 23.017 |\n",
            "| carrot        | 21.660 | hot dog      | 29.421 | pizza          | 51.781 |\n",
            "| donut         | 52.486 | cake         | 40.142 | chair          | 21.244 |\n",
            "| couch         | 36.603 | potted plant | 23.162 | bed            | 35.300 |\n",
            "| dining table  | 16.838 | toilet       | 61.205 | tv             | 61.869 |\n",
            "| laptop        | 59.761 | mouse        | 62.516 | remote         | 36.042 |\n",
            "| keyboard      | 51.605 | cell phone   | 37.641 | microwave      | 58.015 |\n",
            "| oven          | 31.262 | toaster      | 36.148 | sink           | 35.127 |\n",
            "| refrigerator  | 60.299 | book         | 12.884 | clock          | 52.577 |\n",
            "| vase          | 39.579 | scissors     | 22.637 | teddy bear     | 47.533 |\n",
            "| hair drier    | 2.624  | toothbrush   | 21.460 |                |        |\n",
            "\u001b[32m[04/30 14:08:15 d2.engine.defaults]: \u001b[0mEvaluation results for coco_2017_val in csv format:\n",
            "\u001b[32m[04/30 14:08:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/30 14:08:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 14:08:15 d2.evaluation.testing]: \u001b[0mcopypaste: 46.2371,64.6233,50.1493,28.8566,49.8315,58.9055\n",
            "\u001b[32m[04/30 14:08:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[04/30 14:08:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 14:08:15 d2.evaluation.testing]: \u001b[0mcopypaste: 39.6405,61.8638,42.8804,20.8359,42.4238,55.5196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mask_cascade_rcnn_ResNeSt_50 - evaluation results for coco_2017_val in csv format:\n",
        "\n",
        "Task\\metrics  | AP | AP50 | AP75 | APs | APm | APl |\n",
        "--------------|----|------|------|-----|-----|-----|\n",
        "**bbox**    | 46.2371 | 64.6233 | 50.1493 | 28.8566 | 49.8315 | 58.9055 \n",
        "**segm**   | 39.6405 | 61.8638 | 42.8804 | 20.8359 | 42.4238 | 55.5196 \n"
      ],
      "metadata": {
        "id": "uDfdbBFU2E67"
      },
      "id": "uDfdbBFU2E67"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x-62448b9c.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yso-wdzlguq8",
        "outputId": "dae200f1-4bdc-4595-f7e8-d3e080eacbb1"
      },
      "id": "Yso-wdzlguq8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command Line Args: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x-62448b9c.pth'], resume=False)\n",
            "\u001b[32m[04/30 16:16:43 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[04/30 16:16:44 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ----------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "numpy                   1.21.6\n",
            "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.5\n",
            "CUDA compiler           CUDA 11.1\n",
            "detectron2 arch flags   7.5\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.11.0+cu113 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           Yes\n",
            "GPU 0                   Tesla T4 (arch=7.5)\n",
            "Driver version          460.32.03\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.12.0+cu113 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
            "fvcore                  0.1.5.post20220414\n",
            "iopath                  0.1.9\n",
            "cv2                     4.1.2\n",
            "----------------------  ----------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.3\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.2\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "\u001b[32m[04/30 16:16:44 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x-62448b9c.pth'], resume=False)\n",
            "\u001b[32m[04/30 16:16:44 detectron2]: \u001b[0mContents of args.config_file=./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x.yaml:\n",
            "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186m../ResNest-Base-RCNN-FPN.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mhttps://s3.us-west-1.wasabisys.com/resnest/detectron/resnest101_detectron-486f69a8.pth\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m101\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mFastRCNNConvFCHead\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m123.68\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m116.779\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m103.939\u001b[39m]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m58.393\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.12\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.375\u001b[39m]\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\u001b[38;5;15m    \u001b[39m\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mRGB\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\n",
            "\u001b[32m[04/30 16:16:44 detectron2]: \u001b[0mRunning with full config:\n",
            "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRGB\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mpolygon\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m672\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m704\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m736\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m768\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mchoice\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnest_fpn_backbone\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGeneralizedRCNN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.68\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.779\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.939\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m58.393\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.12\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.375\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRPN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVG_DOWN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOTTLENECK_WIDTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEEP_STEM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m101\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_NUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFastRCNNConvFCHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_FED_LOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_SIGMOID_CE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x-62448b9c.pth\n",
            "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./output\n",
            "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR_END\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m90000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m60000\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m80000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\n",
            "\u001b[32m[04/30 16:16:44 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[04/30 16:16:44 d2.utils.env]: \u001b[0mUsing a generated random seed 44505354\n",
            "\u001b[32m[04/30 16:16:50 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(\n",
            "      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output2): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral3): Conv2d(\n",
            "      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output3): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral4): Conv2d(\n",
            "      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output4): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral5): Conv2d(\n",
            "      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output5): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNeSt(\n",
            "      (stem): BasicStem(\n",
            "        (conv1_1): Conv2d(\n",
            "          3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv1_2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv1_3): Conv2d(\n",
            "          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): CascadeROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): ModuleList(\n",
            "      (0): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (1): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (2): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): ModuleList(\n",
            "      (0): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (1): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (2): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/30 16:16:50 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from ./checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x-62448b9c.pth ...\n",
            "\u001b[32m[04/30 16:16:53 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
            "| Names in Model                                  | Names in Checkpoint                                                                                                           | Shapes                                             |\n",
            "|:------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------|\n",
            "| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,128,1,1)               |\n",
            "| backbone.bottom_up.res2.0.conv2.bn0.*           | backbone.bottom_up.res2.0.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.0.conv2.bn1.*           | backbone.bottom_up.res2.0.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.0.conv2.conv.weight     | backbone.bottom_up.res2.0.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.0.conv2.fc1.*           | backbone.bottom_up.res2.0.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.0.conv2.fc2.*           | backbone.bottom_up.res2.0.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,128,1,1)          |\n",
            "| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.1.conv2.bn0.*           | backbone.bottom_up.res2.1.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.1.conv2.bn1.*           | backbone.bottom_up.res2.1.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.1.conv2.conv.weight     | backbone.bottom_up.res2.1.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.1.conv2.fc1.*           | backbone.bottom_up.res2.1.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.1.conv2.fc2.*           | backbone.bottom_up.res2.1.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.2.conv2.bn0.*           | backbone.bottom_up.res2.2.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.2.conv2.bn1.*           | backbone.bottom_up.res2.2.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.2.conv2.conv.weight     | backbone.bottom_up.res2.2.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.2.conv2.fc1.*           | backbone.bottom_up.res2.2.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.2.conv2.fc2.*           | backbone.bottom_up.res2.2.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv2.bn0.*           | backbone.bottom_up.res3.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.0.conv2.bn1.*           | backbone.bottom_up.res3.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.0.conv2.conv.weight     | backbone.bottom_up.res3.0.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.0.conv2.fc1.*           | backbone.bottom_up.res3.0.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.0.conv2.fc2.*           | backbone.bottom_up.res3.0.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv2.bn0.*           | backbone.bottom_up.res3.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.1.conv2.bn1.*           | backbone.bottom_up.res3.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.1.conv2.conv.weight     | backbone.bottom_up.res3.1.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.1.conv2.fc1.*           | backbone.bottom_up.res3.1.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.1.conv2.fc2.*           | backbone.bottom_up.res3.1.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv2.bn0.*           | backbone.bottom_up.res3.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.2.conv2.bn1.*           | backbone.bottom_up.res3.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.2.conv2.conv.weight     | backbone.bottom_up.res3.2.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.2.conv2.fc1.*           | backbone.bottom_up.res3.2.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.2.conv2.fc2.*           | backbone.bottom_up.res3.2.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv2.bn0.*           | backbone.bottom_up.res3.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.3.conv2.bn1.*           | backbone.bottom_up.res3.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.3.conv2.conv.weight     | backbone.bottom_up.res3.3.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.3.conv2.fc1.*           | backbone.bottom_up.res3.3.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.3.conv2.fc2.*           | backbone.bottom_up.res3.3.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv2.bn0.*           | backbone.bottom_up.res4.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.bn1.*           | backbone.bottom_up.res4.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.conv.weight     | backbone.bottom_up.res4.0.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.0.conv2.fc1.*           | backbone.bottom_up.res4.0.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv2.fc2.*           | backbone.bottom_up.res4.0.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.1.conv2.bn0.*           | backbone.bottom_up.res4.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.bn1.*           | backbone.bottom_up.res4.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.conv.weight     | backbone.bottom_up.res4.1.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.1.conv2.fc1.*           | backbone.bottom_up.res4.1.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv2.fc2.*           | backbone.bottom_up.res4.1.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.10.conv1.*              | backbone.bottom_up.res4.10.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.10.conv2.bn0.*          | backbone.bottom_up.res4.10.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.10.conv2.bn1.*          | backbone.bottom_up.res4.10.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.10.conv2.conv.weight    | backbone.bottom_up.res4.10.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.10.conv2.fc1.*          | backbone.bottom_up.res4.10.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.10.conv2.fc2.*          | backbone.bottom_up.res4.10.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.10.conv3.*              | backbone.bottom_up.res4.10.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.11.conv1.*              | backbone.bottom_up.res4.11.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.11.conv2.bn0.*          | backbone.bottom_up.res4.11.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.11.conv2.bn1.*          | backbone.bottom_up.res4.11.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.11.conv2.conv.weight    | backbone.bottom_up.res4.11.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.11.conv2.fc1.*          | backbone.bottom_up.res4.11.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.11.conv2.fc2.*          | backbone.bottom_up.res4.11.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.11.conv3.*              | backbone.bottom_up.res4.11.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.12.conv1.*              | backbone.bottom_up.res4.12.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.12.conv2.bn0.*          | backbone.bottom_up.res4.12.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.12.conv2.bn1.*          | backbone.bottom_up.res4.12.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.12.conv2.conv.weight    | backbone.bottom_up.res4.12.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.12.conv2.fc1.*          | backbone.bottom_up.res4.12.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.12.conv2.fc2.*          | backbone.bottom_up.res4.12.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.12.conv3.*              | backbone.bottom_up.res4.12.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.13.conv1.*              | backbone.bottom_up.res4.13.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.13.conv2.bn0.*          | backbone.bottom_up.res4.13.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.13.conv2.bn1.*          | backbone.bottom_up.res4.13.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.13.conv2.conv.weight    | backbone.bottom_up.res4.13.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.13.conv2.fc1.*          | backbone.bottom_up.res4.13.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.13.conv2.fc2.*          | backbone.bottom_up.res4.13.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.13.conv3.*              | backbone.bottom_up.res4.13.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.14.conv1.*              | backbone.bottom_up.res4.14.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.14.conv2.bn0.*          | backbone.bottom_up.res4.14.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.14.conv2.bn1.*          | backbone.bottom_up.res4.14.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.14.conv2.conv.weight    | backbone.bottom_up.res4.14.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.14.conv2.fc1.*          | backbone.bottom_up.res4.14.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.14.conv2.fc2.*          | backbone.bottom_up.res4.14.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.14.conv3.*              | backbone.bottom_up.res4.14.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.15.conv1.*              | backbone.bottom_up.res4.15.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.15.conv2.bn0.*          | backbone.bottom_up.res4.15.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.15.conv2.bn1.*          | backbone.bottom_up.res4.15.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.15.conv2.conv.weight    | backbone.bottom_up.res4.15.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.15.conv2.fc1.*          | backbone.bottom_up.res4.15.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.15.conv2.fc2.*          | backbone.bottom_up.res4.15.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.15.conv3.*              | backbone.bottom_up.res4.15.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.16.conv1.*              | backbone.bottom_up.res4.16.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.16.conv2.bn0.*          | backbone.bottom_up.res4.16.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.16.conv2.bn1.*          | backbone.bottom_up.res4.16.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.16.conv2.conv.weight    | backbone.bottom_up.res4.16.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.16.conv2.fc1.*          | backbone.bottom_up.res4.16.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.16.conv2.fc2.*          | backbone.bottom_up.res4.16.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.16.conv3.*              | backbone.bottom_up.res4.16.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.17.conv1.*              | backbone.bottom_up.res4.17.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.17.conv2.bn0.*          | backbone.bottom_up.res4.17.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.17.conv2.bn1.*          | backbone.bottom_up.res4.17.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.17.conv2.conv.weight    | backbone.bottom_up.res4.17.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.17.conv2.fc1.*          | backbone.bottom_up.res4.17.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.17.conv2.fc2.*          | backbone.bottom_up.res4.17.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.17.conv3.*              | backbone.bottom_up.res4.17.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.18.conv1.*              | backbone.bottom_up.res4.18.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.18.conv2.bn0.*          | backbone.bottom_up.res4.18.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.18.conv2.bn1.*          | backbone.bottom_up.res4.18.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.18.conv2.conv.weight    | backbone.bottom_up.res4.18.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.18.conv2.fc1.*          | backbone.bottom_up.res4.18.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.18.conv2.fc2.*          | backbone.bottom_up.res4.18.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.18.conv3.*              | backbone.bottom_up.res4.18.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.19.conv1.*              | backbone.bottom_up.res4.19.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.19.conv2.bn0.*          | backbone.bottom_up.res4.19.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.19.conv2.bn1.*          | backbone.bottom_up.res4.19.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.19.conv2.conv.weight    | backbone.bottom_up.res4.19.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.19.conv2.fc1.*          | backbone.bottom_up.res4.19.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.19.conv2.fc2.*          | backbone.bottom_up.res4.19.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.19.conv3.*              | backbone.bottom_up.res4.19.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.2.conv2.bn0.*           | backbone.bottom_up.res4.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.bn1.*           | backbone.bottom_up.res4.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.conv.weight     | backbone.bottom_up.res4.2.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.2.conv2.fc1.*           | backbone.bottom_up.res4.2.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv2.fc2.*           | backbone.bottom_up.res4.2.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.20.conv1.*              | backbone.bottom_up.res4.20.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.20.conv2.bn0.*          | backbone.bottom_up.res4.20.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.20.conv2.bn1.*          | backbone.bottom_up.res4.20.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.20.conv2.conv.weight    | backbone.bottom_up.res4.20.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.20.conv2.fc1.*          | backbone.bottom_up.res4.20.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.20.conv2.fc2.*          | backbone.bottom_up.res4.20.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.20.conv3.*              | backbone.bottom_up.res4.20.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.21.conv1.*              | backbone.bottom_up.res4.21.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.21.conv2.bn0.*          | backbone.bottom_up.res4.21.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.21.conv2.bn1.*          | backbone.bottom_up.res4.21.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.21.conv2.conv.weight    | backbone.bottom_up.res4.21.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.21.conv2.fc1.*          | backbone.bottom_up.res4.21.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.21.conv2.fc2.*          | backbone.bottom_up.res4.21.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.21.conv3.*              | backbone.bottom_up.res4.21.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.22.conv1.*              | backbone.bottom_up.res4.22.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.22.conv2.bn0.*          | backbone.bottom_up.res4.22.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.22.conv2.bn1.*          | backbone.bottom_up.res4.22.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.22.conv2.conv.weight    | backbone.bottom_up.res4.22.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.22.conv2.fc1.*          | backbone.bottom_up.res4.22.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.22.conv2.fc2.*          | backbone.bottom_up.res4.22.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.22.conv3.*              | backbone.bottom_up.res4.22.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.3.conv2.bn0.*           | backbone.bottom_up.res4.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.bn1.*           | backbone.bottom_up.res4.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.conv.weight     | backbone.bottom_up.res4.3.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.3.conv2.fc1.*           | backbone.bottom_up.res4.3.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv2.fc2.*           | backbone.bottom_up.res4.3.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.4.conv2.bn0.*           | backbone.bottom_up.res4.4.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.bn1.*           | backbone.bottom_up.res4.4.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.conv.weight     | backbone.bottom_up.res4.4.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.4.conv2.fc1.*           | backbone.bottom_up.res4.4.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv2.fc2.*           | backbone.bottom_up.res4.4.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.5.conv2.bn0.*           | backbone.bottom_up.res4.5.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.bn1.*           | backbone.bottom_up.res4.5.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.conv.weight     | backbone.bottom_up.res4.5.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.5.conv2.fc1.*           | backbone.bottom_up.res4.5.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv2.fc2.*           | backbone.bottom_up.res4.5.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.6.conv1.*               | backbone.bottom_up.res4.6.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.6.conv2.bn0.*           | backbone.bottom_up.res4.6.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.6.conv2.bn1.*           | backbone.bottom_up.res4.6.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.6.conv2.conv.weight     | backbone.bottom_up.res4.6.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.6.conv2.fc1.*           | backbone.bottom_up.res4.6.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.6.conv2.fc2.*           | backbone.bottom_up.res4.6.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.6.conv3.*               | backbone.bottom_up.res4.6.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.7.conv1.*               | backbone.bottom_up.res4.7.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.7.conv2.bn0.*           | backbone.bottom_up.res4.7.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.7.conv2.bn1.*           | backbone.bottom_up.res4.7.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.7.conv2.conv.weight     | backbone.bottom_up.res4.7.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.7.conv2.fc1.*           | backbone.bottom_up.res4.7.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.7.conv2.fc2.*           | backbone.bottom_up.res4.7.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.7.conv3.*               | backbone.bottom_up.res4.7.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.8.conv1.*               | backbone.bottom_up.res4.8.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.8.conv2.bn0.*           | backbone.bottom_up.res4.8.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.8.conv2.bn1.*           | backbone.bottom_up.res4.8.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.8.conv2.conv.weight     | backbone.bottom_up.res4.8.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.8.conv2.fc1.*           | backbone.bottom_up.res4.8.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.8.conv2.fc2.*           | backbone.bottom_up.res4.8.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.8.conv3.*               | backbone.bottom_up.res4.8.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.9.conv1.*               | backbone.bottom_up.res4.9.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.9.conv2.bn0.*           | backbone.bottom_up.res4.9.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.9.conv2.bn1.*           | backbone.bottom_up.res4.9.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.9.conv2.conv.weight     | backbone.bottom_up.res4.9.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.9.conv2.fc1.*           | backbone.bottom_up.res4.9.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.9.conv2.fc2.*           | backbone.bottom_up.res4.9.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.9.conv3.*               | backbone.bottom_up.res4.9.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| backbone.bottom_up.res5.0.conv2.bn0.*           | backbone.bottom_up.res5.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.0.conv2.bn1.*           | backbone.bottom_up.res5.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.0.conv2.conv.weight     | backbone.bottom_up.res5.0.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.0.conv2.fc1.*           | backbone.bottom_up.res5.0.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.0.conv2.fc2.*           | backbone.bottom_up.res5.0.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.1.conv2.bn0.*           | backbone.bottom_up.res5.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.1.conv2.bn1.*           | backbone.bottom_up.res5.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.1.conv2.conv.weight     | backbone.bottom_up.res5.1.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.1.conv2.fc1.*           | backbone.bottom_up.res5.1.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.1.conv2.fc2.*           | backbone.bottom_up.res5.1.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.2.conv2.bn0.*           | backbone.bottom_up.res5.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.2.conv2.bn1.*           | backbone.bottom_up.res5.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.2.conv2.conv.weight     | backbone.bottom_up.res5.2.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.2.conv2.fc1.*           | backbone.bottom_up.res5.2.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.2.conv2.fc2.*           | backbone.bottom_up.res5.2.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.stem.conv1_1.*               | backbone.bottom_up.stem.conv1_1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,3,3,3)                 |\n",
            "| backbone.bottom_up.stem.conv1_2.*               | backbone.bottom_up.stem.conv1_2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |\n",
            "| backbone.bottom_up.stem.conv1_3.*               | backbone.bottom_up.stem.conv1_3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,64,3,3)           |\n",
            "| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,2048,1,1)      |\n",
            "| backbone.fpn_output2.*                          | backbone.fpn_output2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output3.*                          | backbone.fpn_output3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output4.*                          | backbone.fpn_output4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output5.*                          | backbone.fpn_output5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                                                       | (12,) (12,256,1,1)                                 |\n",
            "| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                                                | (256,) (256,256,3,3)                               |\n",
            "| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                                                   | (3,) (3,256,1,1)                                   |\n",
            "| roi_heads.box_head.0.conv1.*                    | roi_heads.box_head.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv2.*                    | roi_heads.box_head.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv3.*                    | roi_heads.box_head.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv4.*                    | roi_heads.box_head.0.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.fc1.*                      | roi_heads.box_head.0.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_head.1.conv1.*                    | roi_heads.box_head.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv2.*                    | roi_heads.box_head.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv3.*                    | roi_heads.box_head.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv4.*                    | roi_heads.box_head.1.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.fc1.*                      | roi_heads.box_head.1.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_head.2.conv1.*                    | roi_heads.box_head.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv2.*                    | roi_heads.box_head.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv3.*                    | roi_heads.box_head.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv4.*                    | roi_heads.box_head.2.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.fc1.*                      | roi_heads.box_head.2.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_predictor.0.bbox_pred.*           | roi_heads.box_predictor.0.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.0.cls_score.*           | roi_heads.box_predictor.0.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.box_predictor.1.bbox_pred.*           | roi_heads.box_predictor.1.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.1.cls_score.*           | roi_heads.box_predictor.1.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.box_predictor.2.bbox_pred.*           | roi_heads.box_predictor.2.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.2.cls_score.*           | roi_heads.box_predictor.2.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.mask_head.deconv.*                    | roi_heads.mask_head.deconv.{bias,weight}                                                                                      | (256,) (256,256,2,2)                               |\n",
            "| roi_heads.mask_head.mask_fcn1.*                 | roi_heads.mask_head.mask_fcn1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.mask_fcn2.*                 | roi_heads.mask_head.mask_fcn2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.mask_fcn3.*                 | roi_heads.mask_head.mask_fcn3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.mask_fcn4.*                 | roi_heads.mask_head.mask_fcn4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.predictor.*                 | roi_heads.mask_head.predictor.{bias,weight}                                                                                   | (80,) (80,256,1,1)                                 |\n",
            "\u001b[32m[04/30 16:16:54 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json\n",
            "\u001b[32m[04/30 16:16:54 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n",
            "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
            "|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\n",
            "|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\n",
            "|     train     | 190          |    truck     | 414          |     boat      | 424          |\n",
            "| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\n",
            "| parking meter | 60           |    bench     | 411          |     bird      | 427          |\n",
            "|      cat      | 202          |     dog      | 218          |     horse     | 272          |\n",
            "|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\n",
            "|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\n",
            "|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\n",
            "|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\n",
            "|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\n",
            "|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\n",
            "|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\n",
            "|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\n",
            "|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\n",
            "|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\n",
            "|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\n",
            "|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\n",
            "|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\n",
            "|     couch     | 261          | potted plant | 342          |      bed      | 163          |\n",
            "| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\n",
            "|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\n",
            "|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\n",
            "|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\n",
            "| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\n",
            "|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\n",
            "|  hair drier   | 11           |  toothbrush  | 57           |               |              |\n",
            "|     total     | 36335        |              |              |               |              |\u001b[0m\n",
            "\u001b[32m[04/30 16:16:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/30 16:16:54 d2.data.common]: \u001b[0mSerializing 5000 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/30 16:16:54 d2.data.common]: \u001b[0mSerialized dataset takes 19.10 MiB\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[32m[04/30 16:16:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 5000 batches\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m[04/30 16:17:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/5000. Dataloading: 0.0011 s/iter. Inference: 0.4073 s/iter. Eval: 0.0236 s/iter. Total: 0.4319 s/iter. ETA=0:35:54\n",
            "\u001b[32m[04/30 16:17:06 d2.evaluation.evaluator]: \u001b[0mInference done 23/5000. Dataloading: 0.0018 s/iter. Inference: 0.4042 s/iter. Eval: 0.0173 s/iter. Total: 0.4234 s/iter. ETA=0:35:07\n",
            "\u001b[32m[04/30 16:17:11 d2.evaluation.evaluator]: \u001b[0mInference done 35/5000. Dataloading: 0.0019 s/iter. Inference: 0.4072 s/iter. Eval: 0.0189 s/iter. Total: 0.4281 s/iter. ETA=0:35:25\n",
            "\u001b[32m[04/30 16:17:16 d2.evaluation.evaluator]: \u001b[0mInference done 47/5000. Dataloading: 0.0019 s/iter. Inference: 0.4076 s/iter. Eval: 0.0195 s/iter. Total: 0.4291 s/iter. ETA=0:35:25\n",
            "\u001b[32m[04/30 16:17:21 d2.evaluation.evaluator]: \u001b[0mInference done 59/5000. Dataloading: 0.0020 s/iter. Inference: 0.4097 s/iter. Eval: 0.0190 s/iter. Total: 0.4307 s/iter. ETA=0:35:28\n",
            "\u001b[32m[04/30 16:17:26 d2.evaluation.evaluator]: \u001b[0mInference done 71/5000. Dataloading: 0.0020 s/iter. Inference: 0.4105 s/iter. Eval: 0.0172 s/iter. Total: 0.4298 s/iter. ETA=0:35:18\n",
            "\u001b[32m[04/30 16:17:32 d2.evaluation.evaluator]: \u001b[0mInference done 83/5000. Dataloading: 0.0020 s/iter. Inference: 0.4117 s/iter. Eval: 0.0179 s/iter. Total: 0.4316 s/iter. ETA=0:35:22\n",
            "\u001b[32m[04/30 16:17:37 d2.evaluation.evaluator]: \u001b[0mInference done 95/5000. Dataloading: 0.0020 s/iter. Inference: 0.4109 s/iter. Eval: 0.0183 s/iter. Total: 0.4313 s/iter. ETA=0:35:15\n",
            "\u001b[32m[04/30 16:17:42 d2.evaluation.evaluator]: \u001b[0mInference done 107/5000. Dataloading: 0.0020 s/iter. Inference: 0.4112 s/iter. Eval: 0.0190 s/iter. Total: 0.4323 s/iter. ETA=0:35:15\n",
            "\u001b[32m[04/30 16:17:47 d2.evaluation.evaluator]: \u001b[0mInference done 119/5000. Dataloading: 0.0020 s/iter. Inference: 0.4122 s/iter. Eval: 0.0186 s/iter. Total: 0.4329 s/iter. ETA=0:35:13\n",
            "\u001b[32m[04/30 16:17:53 d2.evaluation.evaluator]: \u001b[0mInference done 131/5000. Dataloading: 0.0020 s/iter. Inference: 0.4134 s/iter. Eval: 0.0188 s/iter. Total: 0.4344 s/iter. ETA=0:35:15\n",
            "\u001b[32m[04/30 16:17:58 d2.evaluation.evaluator]: \u001b[0mInference done 142/5000. Dataloading: 0.0020 s/iter. Inference: 0.4146 s/iter. Eval: 0.0196 s/iter. Total: 0.4363 s/iter. ETA=0:35:19\n",
            "\u001b[32m[04/30 16:18:03 d2.evaluation.evaluator]: \u001b[0mInference done 154/5000. Dataloading: 0.0021 s/iter. Inference: 0.4154 s/iter. Eval: 0.0194 s/iter. Total: 0.4370 s/iter. ETA=0:35:17\n",
            "\u001b[32m[04/30 16:18:08 d2.evaluation.evaluator]: \u001b[0mInference done 166/5000. Dataloading: 0.0021 s/iter. Inference: 0.4160 s/iter. Eval: 0.0192 s/iter. Total: 0.4373 s/iter. ETA=0:35:13\n",
            "\u001b[32m[04/30 16:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 178/5000. Dataloading: 0.0021 s/iter. Inference: 0.4162 s/iter. Eval: 0.0190 s/iter. Total: 0.4374 s/iter. ETA=0:35:09\n",
            "\u001b[32m[04/30 16:18:19 d2.evaluation.evaluator]: \u001b[0mInference done 189/5000. Dataloading: 0.0021 s/iter. Inference: 0.4171 s/iter. Eval: 0.0194 s/iter. Total: 0.4386 s/iter. ETA=0:35:10\n",
            "\u001b[32m[04/30 16:18:24 d2.evaluation.evaluator]: \u001b[0mInference done 201/5000. Dataloading: 0.0021 s/iter. Inference: 0.4178 s/iter. Eval: 0.0189 s/iter. Total: 0.4388 s/iter. ETA=0:35:05\n",
            "\u001b[32m[04/30 16:18:29 d2.evaluation.evaluator]: \u001b[0mInference done 212/5000. Dataloading: 0.0021 s/iter. Inference: 0.4191 s/iter. Eval: 0.0187 s/iter. Total: 0.4400 s/iter. ETA=0:35:06\n",
            "\u001b[32m[04/30 16:18:34 d2.evaluation.evaluator]: \u001b[0mInference done 224/5000. Dataloading: 0.0021 s/iter. Inference: 0.4192 s/iter. Eval: 0.0182 s/iter. Total: 0.4396 s/iter. ETA=0:34:59\n",
            "\u001b[32m[04/30 16:18:40 d2.evaluation.evaluator]: \u001b[0mInference done 236/5000. Dataloading: 0.0020 s/iter. Inference: 0.4200 s/iter. Eval: 0.0180 s/iter. Total: 0.4402 s/iter. ETA=0:34:57\n",
            "\u001b[32m[04/30 16:18:45 d2.evaluation.evaluator]: \u001b[0mInference done 247/5000. Dataloading: 0.0020 s/iter. Inference: 0.4208 s/iter. Eval: 0.0182 s/iter. Total: 0.4412 s/iter. ETA=0:34:57\n",
            "\u001b[32m[04/30 16:18:50 d2.evaluation.evaluator]: \u001b[0mInference done 258/5000. Dataloading: 0.0020 s/iter. Inference: 0.4217 s/iter. Eval: 0.0187 s/iter. Total: 0.4425 s/iter. ETA=0:34:58\n",
            "\u001b[32m[04/30 16:18:55 d2.evaluation.evaluator]: \u001b[0mInference done 270/5000. Dataloading: 0.0020 s/iter. Inference: 0.4220 s/iter. Eval: 0.0183 s/iter. Total: 0.4425 s/iter. ETA=0:34:52\n",
            "\u001b[32m[04/30 16:19:01 d2.evaluation.evaluator]: \u001b[0mInference done 282/5000. Dataloading: 0.0020 s/iter. Inference: 0.4223 s/iter. Eval: 0.0182 s/iter. Total: 0.4427 s/iter. ETA=0:34:48\n",
            "\u001b[32m[04/30 16:19:06 d2.evaluation.evaluator]: \u001b[0mInference done 293/5000. Dataloading: 0.0020 s/iter. Inference: 0.4233 s/iter. Eval: 0.0186 s/iter. Total: 0.4441 s/iter. ETA=0:34:50\n",
            "\u001b[32m[04/30 16:19:11 d2.evaluation.evaluator]: \u001b[0mInference done 305/5000. Dataloading: 0.0020 s/iter. Inference: 0.4238 s/iter. Eval: 0.0183 s/iter. Total: 0.4443 s/iter. ETA=0:34:46\n",
            "\u001b[32m[04/30 16:19:16 d2.evaluation.evaluator]: \u001b[0mInference done 316/5000. Dataloading: 0.0021 s/iter. Inference: 0.4244 s/iter. Eval: 0.0184 s/iter. Total: 0.4449 s/iter. ETA=0:34:44\n",
            "\u001b[32m[04/30 16:19:22 d2.evaluation.evaluator]: \u001b[0mInference done 327/5000. Dataloading: 0.0021 s/iter. Inference: 0.4250 s/iter. Eval: 0.0184 s/iter. Total: 0.4456 s/iter. ETA=0:34:42\n",
            "\u001b[32m[04/30 16:19:27 d2.evaluation.evaluator]: \u001b[0mInference done 338/5000. Dataloading: 0.0021 s/iter. Inference: 0.4259 s/iter. Eval: 0.0184 s/iter. Total: 0.4465 s/iter. ETA=0:34:41\n",
            "\u001b[32m[04/30 16:19:32 d2.evaluation.evaluator]: \u001b[0mInference done 349/5000. Dataloading: 0.0021 s/iter. Inference: 0.4266 s/iter. Eval: 0.0186 s/iter. Total: 0.4473 s/iter. ETA=0:34:40\n",
            "\u001b[32m[04/30 16:19:37 d2.evaluation.evaluator]: \u001b[0mInference done 360/5000. Dataloading: 0.0021 s/iter. Inference: 0.4274 s/iter. Eval: 0.0187 s/iter. Total: 0.4483 s/iter. ETA=0:34:40\n",
            "\u001b[32m[04/30 16:19:42 d2.evaluation.evaluator]: \u001b[0mInference done 371/5000. Dataloading: 0.0021 s/iter. Inference: 0.4280 s/iter. Eval: 0.0185 s/iter. Total: 0.4487 s/iter. ETA=0:34:37\n",
            "\u001b[32m[04/30 16:19:48 d2.evaluation.evaluator]: \u001b[0mInference done 383/5000. Dataloading: 0.0021 s/iter. Inference: 0.4281 s/iter. Eval: 0.0182 s/iter. Total: 0.4486 s/iter. ETA=0:34:31\n",
            "\u001b[32m[04/30 16:19:53 d2.evaluation.evaluator]: \u001b[0mInference done 394/5000. Dataloading: 0.0021 s/iter. Inference: 0.4285 s/iter. Eval: 0.0181 s/iter. Total: 0.4488 s/iter. ETA=0:34:26\n",
            "\u001b[32m[04/30 16:19:58 d2.evaluation.evaluator]: \u001b[0mInference done 405/5000. Dataloading: 0.0021 s/iter. Inference: 0.4290 s/iter. Eval: 0.0182 s/iter. Total: 0.4494 s/iter. ETA=0:34:24\n",
            "\u001b[32m[04/30 16:20:03 d2.evaluation.evaluator]: \u001b[0mInference done 416/5000. Dataloading: 0.0021 s/iter. Inference: 0.4294 s/iter. Eval: 0.0180 s/iter. Total: 0.4496 s/iter. ETA=0:34:21\n",
            "\u001b[32m[04/30 16:20:08 d2.evaluation.evaluator]: \u001b[0mInference done 427/5000. Dataloading: 0.0021 s/iter. Inference: 0.4297 s/iter. Eval: 0.0179 s/iter. Total: 0.4498 s/iter. ETA=0:34:17\n",
            "\u001b[32m[04/30 16:20:13 d2.evaluation.evaluator]: \u001b[0mInference done 438/5000. Dataloading: 0.0021 s/iter. Inference: 0.4303 s/iter. Eval: 0.0178 s/iter. Total: 0.4503 s/iter. ETA=0:34:14\n",
            "\u001b[32m[04/30 16:20:18 d2.evaluation.evaluator]: \u001b[0mInference done 449/5000. Dataloading: 0.0021 s/iter. Inference: 0.4308 s/iter. Eval: 0.0177 s/iter. Total: 0.4507 s/iter. ETA=0:34:11\n",
            "\u001b[32m[04/30 16:20:23 d2.evaluation.evaluator]: \u001b[0mInference done 460/5000. Dataloading: 0.0021 s/iter. Inference: 0.4312 s/iter. Eval: 0.0175 s/iter. Total: 0.4509 s/iter. ETA=0:34:07\n",
            "\u001b[32m[04/30 16:20:28 d2.evaluation.evaluator]: \u001b[0mInference done 471/5000. Dataloading: 0.0021 s/iter. Inference: 0.4318 s/iter. Eval: 0.0174 s/iter. Total: 0.4514 s/iter. ETA=0:34:04\n",
            "\u001b[32m[04/30 16:20:34 d2.evaluation.evaluator]: \u001b[0mInference done 482/5000. Dataloading: 0.0021 s/iter. Inference: 0.4323 s/iter. Eval: 0.0174 s/iter. Total: 0.4519 s/iter. ETA=0:34:01\n",
            "\u001b[32m[04/30 16:20:39 d2.evaluation.evaluator]: \u001b[0mInference done 493/5000. Dataloading: 0.0021 s/iter. Inference: 0.4329 s/iter. Eval: 0.0176 s/iter. Total: 0.4527 s/iter. ETA=0:34:00\n",
            "\u001b[32m[04/30 16:20:44 d2.evaluation.evaluator]: \u001b[0mInference done 504/5000. Dataloading: 0.0021 s/iter. Inference: 0.4331 s/iter. Eval: 0.0175 s/iter. Total: 0.4528 s/iter. ETA=0:33:55\n",
            "\u001b[32m[04/30 16:20:49 d2.evaluation.evaluator]: \u001b[0mInference done 515/5000. Dataloading: 0.0021 s/iter. Inference: 0.4334 s/iter. Eval: 0.0175 s/iter. Total: 0.4531 s/iter. ETA=0:33:52\n",
            "\u001b[32m[04/30 16:20:54 d2.evaluation.evaluator]: \u001b[0mInference done 526/5000. Dataloading: 0.0021 s/iter. Inference: 0.4338 s/iter. Eval: 0.0176 s/iter. Total: 0.4537 s/iter. ETA=0:33:49\n",
            "\u001b[32m[04/30 16:21:00 d2.evaluation.evaluator]: \u001b[0mInference done 537/5000. Dataloading: 0.0021 s/iter. Inference: 0.4343 s/iter. Eval: 0.0177 s/iter. Total: 0.4542 s/iter. ETA=0:33:47\n",
            "\u001b[32m[04/30 16:21:05 d2.evaluation.evaluator]: \u001b[0mInference done 548/5000. Dataloading: 0.0021 s/iter. Inference: 0.4347 s/iter. Eval: 0.0178 s/iter. Total: 0.4547 s/iter. ETA=0:33:44\n",
            "\u001b[32m[04/30 16:21:10 d2.evaluation.evaluator]: \u001b[0mInference done 559/5000. Dataloading: 0.0021 s/iter. Inference: 0.4350 s/iter. Eval: 0.0179 s/iter. Total: 0.4551 s/iter. ETA=0:33:40\n",
            "\u001b[32m[04/30 16:21:15 d2.evaluation.evaluator]: \u001b[0mInference done 570/5000. Dataloading: 0.0021 s/iter. Inference: 0.4354 s/iter. Eval: 0.0177 s/iter. Total: 0.4553 s/iter. ETA=0:33:36\n",
            "\u001b[32m[04/30 16:21:21 d2.evaluation.evaluator]: \u001b[0mInference done 581/5000. Dataloading: 0.0021 s/iter. Inference: 0.4359 s/iter. Eval: 0.0179 s/iter. Total: 0.4560 s/iter. ETA=0:33:35\n",
            "\u001b[32m[04/30 16:21:26 d2.evaluation.evaluator]: \u001b[0mInference done 592/5000. Dataloading: 0.0021 s/iter. Inference: 0.4361 s/iter. Eval: 0.0179 s/iter. Total: 0.4562 s/iter. ETA=0:33:31\n",
            "\u001b[32m[04/30 16:21:31 d2.evaluation.evaluator]: \u001b[0mInference done 603/5000. Dataloading: 0.0020 s/iter. Inference: 0.4365 s/iter. Eval: 0.0178 s/iter. Total: 0.4564 s/iter. ETA=0:33:26\n",
            "\u001b[32m[04/30 16:21:36 d2.evaluation.evaluator]: \u001b[0mInference done 614/5000. Dataloading: 0.0020 s/iter. Inference: 0.4369 s/iter. Eval: 0.0179 s/iter. Total: 0.4569 s/iter. ETA=0:33:24\n",
            "\u001b[32m[04/30 16:21:42 d2.evaluation.evaluator]: \u001b[0mInference done 625/5000. Dataloading: 0.0021 s/iter. Inference: 0.4373 s/iter. Eval: 0.0177 s/iter. Total: 0.4572 s/iter. ETA=0:33:20\n",
            "\u001b[32m[04/30 16:21:47 d2.evaluation.evaluator]: \u001b[0mInference done 636/5000. Dataloading: 0.0021 s/iter. Inference: 0.4377 s/iter. Eval: 0.0179 s/iter. Total: 0.4578 s/iter. ETA=0:33:17\n",
            "\u001b[32m[04/30 16:21:52 d2.evaluation.evaluator]: \u001b[0mInference done 647/5000. Dataloading: 0.0021 s/iter. Inference: 0.4380 s/iter. Eval: 0.0179 s/iter. Total: 0.4581 s/iter. ETA=0:33:13\n",
            "\u001b[32m[04/30 16:21:58 d2.evaluation.evaluator]: \u001b[0mInference done 658/5000. Dataloading: 0.0021 s/iter. Inference: 0.4384 s/iter. Eval: 0.0181 s/iter. Total: 0.4587 s/iter. ETA=0:33:11\n",
            "\u001b[32m[04/30 16:22:03 d2.evaluation.evaluator]: \u001b[0mInference done 669/5000. Dataloading: 0.0020 s/iter. Inference: 0.4388 s/iter. Eval: 0.0182 s/iter. Total: 0.4591 s/iter. ETA=0:33:08\n",
            "\u001b[32m[04/30 16:22:08 d2.evaluation.evaluator]: \u001b[0mInference done 680/5000. Dataloading: 0.0020 s/iter. Inference: 0.4391 s/iter. Eval: 0.0181 s/iter. Total: 0.4593 s/iter. ETA=0:33:04\n",
            "\u001b[32m[04/30 16:22:13 d2.evaluation.evaluator]: \u001b[0mInference done 691/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0180 s/iter. Total: 0.4596 s/iter. ETA=0:33:00\n",
            "\u001b[32m[04/30 16:22:19 d2.evaluation.evaluator]: \u001b[0mInference done 702/5000. Dataloading: 0.0020 s/iter. Inference: 0.4398 s/iter. Eval: 0.0180 s/iter. Total: 0.4599 s/iter. ETA=0:32:56\n",
            "\u001b[32m[04/30 16:22:24 d2.evaluation.evaluator]: \u001b[0mInference done 713/5000. Dataloading: 0.0020 s/iter. Inference: 0.4402 s/iter. Eval: 0.0180 s/iter. Total: 0.4604 s/iter. ETA=0:32:53\n",
            "\u001b[32m[04/30 16:22:29 d2.evaluation.evaluator]: \u001b[0mInference done 724/5000. Dataloading: 0.0020 s/iter. Inference: 0.4406 s/iter. Eval: 0.0181 s/iter. Total: 0.4608 s/iter. ETA=0:32:50\n",
            "\u001b[32m[04/30 16:22:35 d2.evaluation.evaluator]: \u001b[0mInference done 735/5000. Dataloading: 0.0020 s/iter. Inference: 0.4408 s/iter. Eval: 0.0181 s/iter. Total: 0.4611 s/iter. ETA=0:32:46\n",
            "\u001b[32m[04/30 16:22:40 d2.evaluation.evaluator]: \u001b[0mInference done 746/5000. Dataloading: 0.0021 s/iter. Inference: 0.4411 s/iter. Eval: 0.0180 s/iter. Total: 0.4613 s/iter. ETA=0:32:42\n",
            "\u001b[32m[04/30 16:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 757/5000. Dataloading: 0.0021 s/iter. Inference: 0.4414 s/iter. Eval: 0.0180 s/iter. Total: 0.4615 s/iter. ETA=0:32:38\n",
            "\u001b[32m[04/30 16:22:50 d2.evaluation.evaluator]: \u001b[0mInference done 768/5000. Dataloading: 0.0021 s/iter. Inference: 0.4417 s/iter. Eval: 0.0180 s/iter. Total: 0.4618 s/iter. ETA=0:32:34\n",
            "\u001b[32m[04/30 16:22:56 d2.evaluation.evaluator]: \u001b[0mInference done 779/5000. Dataloading: 0.0021 s/iter. Inference: 0.4419 s/iter. Eval: 0.0178 s/iter. Total: 0.4619 s/iter. ETA=0:32:29\n",
            "\u001b[32m[04/30 16:23:01 d2.evaluation.evaluator]: \u001b[0mInference done 790/5000. Dataloading: 0.0021 s/iter. Inference: 0.4422 s/iter. Eval: 0.0179 s/iter. Total: 0.4623 s/iter. ETA=0:32:26\n",
            "\u001b[32m[04/30 16:23:06 d2.evaluation.evaluator]: \u001b[0mInference done 801/5000. Dataloading: 0.0020 s/iter. Inference: 0.4425 s/iter. Eval: 0.0179 s/iter. Total: 0.4626 s/iter. ETA=0:32:22\n",
            "\u001b[32m[04/30 16:23:12 d2.evaluation.evaluator]: \u001b[0mInference done 812/5000. Dataloading: 0.0020 s/iter. Inference: 0.4428 s/iter. Eval: 0.0179 s/iter. Total: 0.4628 s/iter. ETA=0:32:18\n",
            "\u001b[32m[04/30 16:23:17 d2.evaluation.evaluator]: \u001b[0mInference done 823/5000. Dataloading: 0.0020 s/iter. Inference: 0.4430 s/iter. Eval: 0.0178 s/iter. Total: 0.4629 s/iter. ETA=0:32:13\n",
            "\u001b[32m[04/30 16:23:22 d2.evaluation.evaluator]: \u001b[0mInference done 834/5000. Dataloading: 0.0020 s/iter. Inference: 0.4431 s/iter. Eval: 0.0178 s/iter. Total: 0.4631 s/iter. ETA=0:32:09\n",
            "\u001b[32m[04/30 16:23:27 d2.evaluation.evaluator]: \u001b[0mInference done 845/5000. Dataloading: 0.0020 s/iter. Inference: 0.4435 s/iter. Eval: 0.0178 s/iter. Total: 0.4634 s/iter. ETA=0:32:05\n",
            "\u001b[32m[04/30 16:23:33 d2.evaluation.evaluator]: \u001b[0mInference done 856/5000. Dataloading: 0.0020 s/iter. Inference: 0.4437 s/iter. Eval: 0.0178 s/iter. Total: 0.4637 s/iter. ETA=0:32:01\n",
            "\u001b[32m[04/30 16:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 867/5000. Dataloading: 0.0020 s/iter. Inference: 0.4440 s/iter. Eval: 0.0177 s/iter. Total: 0.4639 s/iter. ETA=0:31:57\n",
            "\u001b[32m[04/30 16:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 878/5000. Dataloading: 0.0020 s/iter. Inference: 0.4441 s/iter. Eval: 0.0177 s/iter. Total: 0.4640 s/iter. ETA=0:31:52\n",
            "\u001b[32m[04/30 16:23:48 d2.evaluation.evaluator]: \u001b[0mInference done 889/5000. Dataloading: 0.0021 s/iter. Inference: 0.4444 s/iter. Eval: 0.0177 s/iter. Total: 0.4643 s/iter. ETA=0:31:48\n",
            "\u001b[32m[04/30 16:23:54 d2.evaluation.evaluator]: \u001b[0mInference done 900/5000. Dataloading: 0.0021 s/iter. Inference: 0.4445 s/iter. Eval: 0.0177 s/iter. Total: 0.4644 s/iter. ETA=0:31:44\n",
            "\u001b[32m[04/30 16:23:59 d2.evaluation.evaluator]: \u001b[0mInference done 911/5000. Dataloading: 0.0021 s/iter. Inference: 0.4446 s/iter. Eval: 0.0177 s/iter. Total: 0.4645 s/iter. ETA=0:31:39\n",
            "\u001b[32m[04/30 16:24:04 d2.evaluation.evaluator]: \u001b[0mInference done 922/5000. Dataloading: 0.0021 s/iter. Inference: 0.4448 s/iter. Eval: 0.0176 s/iter. Total: 0.4646 s/iter. ETA=0:31:34\n",
            "\u001b[32m[04/30 16:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 933/5000. Dataloading: 0.0021 s/iter. Inference: 0.4450 s/iter. Eval: 0.0177 s/iter. Total: 0.4648 s/iter. ETA=0:31:30\n",
            "\u001b[32m[04/30 16:24:15 d2.evaluation.evaluator]: \u001b[0mInference done 944/5000. Dataloading: 0.0021 s/iter. Inference: 0.4452 s/iter. Eval: 0.0176 s/iter. Total: 0.4649 s/iter. ETA=0:31:25\n",
            "\u001b[32m[04/30 16:24:20 d2.evaluation.evaluator]: \u001b[0mInference done 955/5000. Dataloading: 0.0021 s/iter. Inference: 0.4454 s/iter. Eval: 0.0175 s/iter. Total: 0.4650 s/iter. ETA=0:31:21\n",
            "\u001b[32m[04/30 16:24:25 d2.evaluation.evaluator]: \u001b[0mInference done 966/5000. Dataloading: 0.0020 s/iter. Inference: 0.4456 s/iter. Eval: 0.0175 s/iter. Total: 0.4653 s/iter. ETA=0:31:16\n",
            "\u001b[32m[04/30 16:24:31 d2.evaluation.evaluator]: \u001b[0mInference done 977/5000. Dataloading: 0.0020 s/iter. Inference: 0.4457 s/iter. Eval: 0.0176 s/iter. Total: 0.4655 s/iter. ETA=0:31:12\n",
            "\u001b[32m[04/30 16:24:36 d2.evaluation.evaluator]: \u001b[0mInference done 988/5000. Dataloading: 0.0020 s/iter. Inference: 0.4459 s/iter. Eval: 0.0177 s/iter. Total: 0.4658 s/iter. ETA=0:31:08\n",
            "\u001b[32m[04/30 16:24:41 d2.evaluation.evaluator]: \u001b[0mInference done 999/5000. Dataloading: 0.0021 s/iter. Inference: 0.4460 s/iter. Eval: 0.0175 s/iter. Total: 0.4658 s/iter. ETA=0:31:03\n",
            "\u001b[32m[04/30 16:24:46 d2.evaluation.evaluator]: \u001b[0mInference done 1010/5000. Dataloading: 0.0020 s/iter. Inference: 0.4462 s/iter. Eval: 0.0175 s/iter. Total: 0.4659 s/iter. ETA=0:30:58\n",
            "\u001b[32m[04/30 16:24:52 d2.evaluation.evaluator]: \u001b[0mInference done 1021/5000. Dataloading: 0.0020 s/iter. Inference: 0.4463 s/iter. Eval: 0.0176 s/iter. Total: 0.4661 s/iter. ETA=0:30:54\n",
            "\u001b[32m[04/30 16:24:57 d2.evaluation.evaluator]: \u001b[0mInference done 1032/5000. Dataloading: 0.0020 s/iter. Inference: 0.4465 s/iter. Eval: 0.0176 s/iter. Total: 0.4663 s/iter. ETA=0:30:50\n",
            "\u001b[32m[04/30 16:25:02 d2.evaluation.evaluator]: \u001b[0mInference done 1043/5000. Dataloading: 0.0020 s/iter. Inference: 0.4466 s/iter. Eval: 0.0177 s/iter. Total: 0.4664 s/iter. ETA=0:30:45\n",
            "\u001b[32m[04/30 16:25:08 d2.evaluation.evaluator]: \u001b[0mInference done 1054/5000. Dataloading: 0.0020 s/iter. Inference: 0.4468 s/iter. Eval: 0.0176 s/iter. Total: 0.4666 s/iter. ETA=0:30:41\n",
            "\u001b[32m[04/30 16:25:13 d2.evaluation.evaluator]: \u001b[0mInference done 1065/5000. Dataloading: 0.0020 s/iter. Inference: 0.4470 s/iter. Eval: 0.0177 s/iter. Total: 0.4668 s/iter. ETA=0:30:36\n",
            "\u001b[32m[04/30 16:25:18 d2.evaluation.evaluator]: \u001b[0mInference done 1076/5000. Dataloading: 0.0020 s/iter. Inference: 0.4472 s/iter. Eval: 0.0177 s/iter. Total: 0.4670 s/iter. ETA=0:30:32\n",
            "\u001b[32m[04/30 16:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 1087/5000. Dataloading: 0.0020 s/iter. Inference: 0.4474 s/iter. Eval: 0.0177 s/iter. Total: 0.4673 s/iter. ETA=0:30:28\n",
            "\u001b[32m[04/30 16:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 1098/5000. Dataloading: 0.0020 s/iter. Inference: 0.4475 s/iter. Eval: 0.0177 s/iter. Total: 0.4673 s/iter. ETA=0:30:23\n",
            "\u001b[32m[04/30 16:25:34 d2.evaluation.evaluator]: \u001b[0mInference done 1109/5000. Dataloading: 0.0020 s/iter. Inference: 0.4477 s/iter. Eval: 0.0177 s/iter. Total: 0.4675 s/iter. ETA=0:30:18\n",
            "\u001b[32m[04/30 16:25:39 d2.evaluation.evaluator]: \u001b[0mInference done 1120/5000. Dataloading: 0.0020 s/iter. Inference: 0.4477 s/iter. Eval: 0.0176 s/iter. Total: 0.4675 s/iter. ETA=0:30:13\n",
            "\u001b[32m[04/30 16:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 1131/5000. Dataloading: 0.0020 s/iter. Inference: 0.4479 s/iter. Eval: 0.0176 s/iter. Total: 0.4677 s/iter. ETA=0:30:09\n",
            "\u001b[32m[04/30 16:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 1141/5000. Dataloading: 0.0020 s/iter. Inference: 0.4481 s/iter. Eval: 0.0177 s/iter. Total: 0.4680 s/iter. ETA=0:30:05\n",
            "\u001b[32m[04/30 16:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 1152/5000. Dataloading: 0.0020 s/iter. Inference: 0.4482 s/iter. Eval: 0.0178 s/iter. Total: 0.4682 s/iter. ETA=0:30:01\n",
            "\u001b[32m[04/30 16:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 1163/5000. Dataloading: 0.0021 s/iter. Inference: 0.4484 s/iter. Eval: 0.0178 s/iter. Total: 0.4684 s/iter. ETA=0:29:57\n",
            "\u001b[32m[04/30 16:26:06 d2.evaluation.evaluator]: \u001b[0mInference done 1174/5000. Dataloading: 0.0020 s/iter. Inference: 0.4485 s/iter. Eval: 0.0178 s/iter. Total: 0.4685 s/iter. ETA=0:29:52\n",
            "\u001b[32m[04/30 16:26:11 d2.evaluation.evaluator]: \u001b[0mInference done 1185/5000. Dataloading: 0.0020 s/iter. Inference: 0.4487 s/iter. Eval: 0.0179 s/iter. Total: 0.4687 s/iter. ETA=0:29:48\n",
            "\u001b[32m[04/30 16:26:16 d2.evaluation.evaluator]: \u001b[0mInference done 1196/5000. Dataloading: 0.0020 s/iter. Inference: 0.4488 s/iter. Eval: 0.0179 s/iter. Total: 0.4688 s/iter. ETA=0:29:43\n",
            "\u001b[32m[04/30 16:26:22 d2.evaluation.evaluator]: \u001b[0mInference done 1207/5000. Dataloading: 0.0020 s/iter. Inference: 0.4490 s/iter. Eval: 0.0179 s/iter. Total: 0.4691 s/iter. ETA=0:29:39\n",
            "\u001b[32m[04/30 16:26:27 d2.evaluation.evaluator]: \u001b[0mInference done 1218/5000. Dataloading: 0.0020 s/iter. Inference: 0.4491 s/iter. Eval: 0.0180 s/iter. Total: 0.4693 s/iter. ETA=0:29:34\n",
            "\u001b[32m[04/30 16:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 1229/5000. Dataloading: 0.0020 s/iter. Inference: 0.4492 s/iter. Eval: 0.0180 s/iter. Total: 0.4694 s/iter. ETA=0:29:30\n",
            "\u001b[32m[04/30 16:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 1240/5000. Dataloading: 0.0020 s/iter. Inference: 0.4494 s/iter. Eval: 0.0180 s/iter. Total: 0.4696 s/iter. ETA=0:29:25\n",
            "\u001b[32m[04/30 16:26:43 d2.evaluation.evaluator]: \u001b[0mInference done 1251/5000. Dataloading: 0.0020 s/iter. Inference: 0.4495 s/iter. Eval: 0.0181 s/iter. Total: 0.4698 s/iter. ETA=0:29:21\n",
            "\u001b[32m[04/30 16:26:49 d2.evaluation.evaluator]: \u001b[0mInference done 1262/5000. Dataloading: 0.0020 s/iter. Inference: 0.4496 s/iter. Eval: 0.0181 s/iter. Total: 0.4699 s/iter. ETA=0:29:16\n",
            "\u001b[32m[04/30 16:26:54 d2.evaluation.evaluator]: \u001b[0mInference done 1273/5000. Dataloading: 0.0020 s/iter. Inference: 0.4496 s/iter. Eval: 0.0182 s/iter. Total: 0.4699 s/iter. ETA=0:29:11\n",
            "\u001b[32m[04/30 16:26:59 d2.evaluation.evaluator]: \u001b[0mInference done 1284/5000. Dataloading: 0.0020 s/iter. Inference: 0.4498 s/iter. Eval: 0.0181 s/iter. Total: 0.4701 s/iter. ETA=0:29:06\n",
            "\u001b[32m[04/30 16:27:04 d2.evaluation.evaluator]: \u001b[0mInference done 1295/5000. Dataloading: 0.0020 s/iter. Inference: 0.4498 s/iter. Eval: 0.0181 s/iter. Total: 0.4701 s/iter. ETA=0:29:01\n",
            "\u001b[32m[04/30 16:27:10 d2.evaluation.evaluator]: \u001b[0mInference done 1306/5000. Dataloading: 0.0020 s/iter. Inference: 0.4499 s/iter. Eval: 0.0181 s/iter. Total: 0.4701 s/iter. ETA=0:28:56\n",
            "\u001b[32m[04/30 16:27:15 d2.evaluation.evaluator]: \u001b[0mInference done 1317/5000. Dataloading: 0.0020 s/iter. Inference: 0.4500 s/iter. Eval: 0.0180 s/iter. Total: 0.4702 s/iter. ETA=0:28:51\n",
            "\u001b[32m[04/30 16:27:20 d2.evaluation.evaluator]: \u001b[0mInference done 1328/5000. Dataloading: 0.0020 s/iter. Inference: 0.4500 s/iter. Eval: 0.0180 s/iter. Total: 0.4701 s/iter. ETA=0:28:46\n",
            "\u001b[32m[04/30 16:27:25 d2.evaluation.evaluator]: \u001b[0mInference done 1338/5000. Dataloading: 0.0020 s/iter. Inference: 0.4502 s/iter. Eval: 0.0181 s/iter. Total: 0.4704 s/iter. ETA=0:28:42\n",
            "\u001b[32m[04/30 16:27:31 d2.evaluation.evaluator]: \u001b[0mInference done 1349/5000. Dataloading: 0.0020 s/iter. Inference: 0.4503 s/iter. Eval: 0.0181 s/iter. Total: 0.4706 s/iter. ETA=0:28:38\n",
            "\u001b[32m[04/30 16:27:36 d2.evaluation.evaluator]: \u001b[0mInference done 1360/5000. Dataloading: 0.0020 s/iter. Inference: 0.4503 s/iter. Eval: 0.0181 s/iter. Total: 0.4706 s/iter. ETA=0:28:33\n",
            "\u001b[32m[04/30 16:27:41 d2.evaluation.evaluator]: \u001b[0mInference done 1371/5000. Dataloading: 0.0020 s/iter. Inference: 0.4505 s/iter. Eval: 0.0181 s/iter. Total: 0.4707 s/iter. ETA=0:28:28\n",
            "\u001b[32m[04/30 16:27:46 d2.evaluation.evaluator]: \u001b[0mInference done 1382/5000. Dataloading: 0.0020 s/iter. Inference: 0.4505 s/iter. Eval: 0.0181 s/iter. Total: 0.4707 s/iter. ETA=0:28:23\n",
            "\u001b[32m[04/30 16:27:51 d2.evaluation.evaluator]: \u001b[0mInference done 1393/5000. Dataloading: 0.0020 s/iter. Inference: 0.4505 s/iter. Eval: 0.0180 s/iter. Total: 0.4707 s/iter. ETA=0:28:17\n",
            "\u001b[32m[04/30 16:27:57 d2.evaluation.evaluator]: \u001b[0mInference done 1404/5000. Dataloading: 0.0020 s/iter. Inference: 0.4506 s/iter. Eval: 0.0180 s/iter. Total: 0.4708 s/iter. ETA=0:28:12\n",
            "\u001b[32m[04/30 16:28:02 d2.evaluation.evaluator]: \u001b[0mInference done 1415/5000. Dataloading: 0.0021 s/iter. Inference: 0.4506 s/iter. Eval: 0.0180 s/iter. Total: 0.4708 s/iter. ETA=0:28:07\n",
            "\u001b[32m[04/30 16:28:07 d2.evaluation.evaluator]: \u001b[0mInference done 1426/5000. Dataloading: 0.0021 s/iter. Inference: 0.4507 s/iter. Eval: 0.0180 s/iter. Total: 0.4708 s/iter. ETA=0:28:02\n",
            "\u001b[32m[04/30 16:28:13 d2.evaluation.evaluator]: \u001b[0mInference done 1437/5000. Dataloading: 0.0021 s/iter. Inference: 0.4508 s/iter. Eval: 0.0180 s/iter. Total: 0.4710 s/iter. ETA=0:27:58\n",
            "\u001b[32m[04/30 16:28:18 d2.evaluation.evaluator]: \u001b[0mInference done 1448/5000. Dataloading: 0.0020 s/iter. Inference: 0.4509 s/iter. Eval: 0.0180 s/iter. Total: 0.4711 s/iter. ETA=0:27:53\n",
            "\u001b[32m[04/30 16:28:23 d2.evaluation.evaluator]: \u001b[0mInference done 1459/5000. Dataloading: 0.0020 s/iter. Inference: 0.4509 s/iter. Eval: 0.0180 s/iter. Total: 0.4710 s/iter. ETA=0:27:47\n",
            "\u001b[32m[04/30 16:28:28 d2.evaluation.evaluator]: \u001b[0mInference done 1470/5000. Dataloading: 0.0021 s/iter. Inference: 0.4509 s/iter. Eval: 0.0180 s/iter. Total: 0.4710 s/iter. ETA=0:27:42\n",
            "\u001b[32m[04/30 16:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 1481/5000. Dataloading: 0.0020 s/iter. Inference: 0.4510 s/iter. Eval: 0.0180 s/iter. Total: 0.4712 s/iter. ETA=0:27:38\n",
            "\u001b[32m[04/30 16:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 1492/5000. Dataloading: 0.0020 s/iter. Inference: 0.4511 s/iter. Eval: 0.0180 s/iter. Total: 0.4712 s/iter. ETA=0:27:33\n",
            "\u001b[32m[04/30 16:28:44 d2.evaluation.evaluator]: \u001b[0mInference done 1503/5000. Dataloading: 0.0020 s/iter. Inference: 0.4511 s/iter. Eval: 0.0180 s/iter. Total: 0.4713 s/iter. ETA=0:27:28\n",
            "\u001b[32m[04/30 16:28:49 d2.evaluation.evaluator]: \u001b[0mInference done 1514/5000. Dataloading: 0.0020 s/iter. Inference: 0.4511 s/iter. Eval: 0.0180 s/iter. Total: 0.4713 s/iter. ETA=0:27:22\n",
            "\u001b[32m[04/30 16:28:54 d2.evaluation.evaluator]: \u001b[0mInference done 1525/5000. Dataloading: 0.0020 s/iter. Inference: 0.4511 s/iter. Eval: 0.0180 s/iter. Total: 0.4713 s/iter. ETA=0:27:17\n",
            "\u001b[32m[04/30 16:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 1536/5000. Dataloading: 0.0020 s/iter. Inference: 0.4512 s/iter. Eval: 0.0180 s/iter. Total: 0.4714 s/iter. ETA=0:27:12\n",
            "\u001b[32m[04/30 16:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 1547/5000. Dataloading: 0.0021 s/iter. Inference: 0.4513 s/iter. Eval: 0.0181 s/iter. Total: 0.4716 s/iter. ETA=0:27:08\n",
            "\u001b[32m[04/30 16:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 1558/5000. Dataloading: 0.0021 s/iter. Inference: 0.4514 s/iter. Eval: 0.0181 s/iter. Total: 0.4717 s/iter. ETA=0:27:03\n",
            "\u001b[32m[04/30 16:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 1569/5000. Dataloading: 0.0021 s/iter. Inference: 0.4515 s/iter. Eval: 0.0181 s/iter. Total: 0.4718 s/iter. ETA=0:26:58\n",
            "\u001b[32m[04/30 16:29:21 d2.evaluation.evaluator]: \u001b[0mInference done 1579/5000. Dataloading: 0.0021 s/iter. Inference: 0.4516 s/iter. Eval: 0.0182 s/iter. Total: 0.4720 s/iter. ETA=0:26:54\n",
            "\u001b[32m[04/30 16:29:26 d2.evaluation.evaluator]: \u001b[0mInference done 1589/5000. Dataloading: 0.0021 s/iter. Inference: 0.4519 s/iter. Eval: 0.0184 s/iter. Total: 0.4724 s/iter. ETA=0:26:51\n",
            "\u001b[32m[04/30 16:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 1599/5000. Dataloading: 0.0021 s/iter. Inference: 0.4521 s/iter. Eval: 0.0186 s/iter. Total: 0.4728 s/iter. ETA=0:26:48\n",
            "\u001b[32m[04/30 16:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 1609/5000. Dataloading: 0.0021 s/iter. Inference: 0.4522 s/iter. Eval: 0.0186 s/iter. Total: 0.4731 s/iter. ETA=0:26:44\n",
            "\u001b[32m[04/30 16:29:42 d2.evaluation.evaluator]: \u001b[0mInference done 1620/5000. Dataloading: 0.0021 s/iter. Inference: 0.4522 s/iter. Eval: 0.0186 s/iter. Total: 0.4731 s/iter. ETA=0:26:39\n",
            "\u001b[32m[04/30 16:29:47 d2.evaluation.evaluator]: \u001b[0mInference done 1631/5000. Dataloading: 0.0021 s/iter. Inference: 0.4523 s/iter. Eval: 0.0185 s/iter. Total: 0.4731 s/iter. ETA=0:26:33\n",
            "\u001b[32m[04/30 16:29:53 d2.evaluation.evaluator]: \u001b[0mInference done 1642/5000. Dataloading: 0.0021 s/iter. Inference: 0.4523 s/iter. Eval: 0.0185 s/iter. Total: 0.4732 s/iter. ETA=0:26:28\n",
            "\u001b[32m[04/30 16:29:58 d2.evaluation.evaluator]: \u001b[0mInference done 1653/5000. Dataloading: 0.0021 s/iter. Inference: 0.4524 s/iter. Eval: 0.0185 s/iter. Total: 0.4732 s/iter. ETA=0:26:23\n",
            "\u001b[32m[04/30 16:30:03 d2.evaluation.evaluator]: \u001b[0mInference done 1664/5000. Dataloading: 0.0021 s/iter. Inference: 0.4525 s/iter. Eval: 0.0186 s/iter. Total: 0.4734 s/iter. ETA=0:26:19\n",
            "\u001b[32m[04/30 16:30:09 d2.evaluation.evaluator]: \u001b[0mInference done 1675/5000. Dataloading: 0.0021 s/iter. Inference: 0.4525 s/iter. Eval: 0.0186 s/iter. Total: 0.4734 s/iter. ETA=0:26:13\n",
            "\u001b[32m[04/30 16:30:14 d2.evaluation.evaluator]: \u001b[0mInference done 1686/5000. Dataloading: 0.0021 s/iter. Inference: 0.4526 s/iter. Eval: 0.0185 s/iter. Total: 0.4734 s/iter. ETA=0:26:08\n",
            "\u001b[32m[04/30 16:30:19 d2.evaluation.evaluator]: \u001b[0mInference done 1697/5000. Dataloading: 0.0021 s/iter. Inference: 0.4527 s/iter. Eval: 0.0185 s/iter. Total: 0.4735 s/iter. ETA=0:26:03\n",
            "\u001b[32m[04/30 16:30:24 d2.evaluation.evaluator]: \u001b[0mInference done 1708/5000. Dataloading: 0.0021 s/iter. Inference: 0.4527 s/iter. Eval: 0.0185 s/iter. Total: 0.4735 s/iter. ETA=0:25:58\n",
            "\u001b[32m[04/30 16:30:29 d2.evaluation.evaluator]: \u001b[0mInference done 1718/5000. Dataloading: 0.0021 s/iter. Inference: 0.4528 s/iter. Eval: 0.0186 s/iter. Total: 0.4736 s/iter. ETA=0:25:54\n",
            "\u001b[32m[04/30 16:30:35 d2.evaluation.evaluator]: \u001b[0mInference done 1729/5000. Dataloading: 0.0021 s/iter. Inference: 0.4528 s/iter. Eval: 0.0185 s/iter. Total: 0.4737 s/iter. ETA=0:25:49\n",
            "\u001b[32m[04/30 16:30:40 d2.evaluation.evaluator]: \u001b[0mInference done 1740/5000. Dataloading: 0.0021 s/iter. Inference: 0.4528 s/iter. Eval: 0.0185 s/iter. Total: 0.4736 s/iter. ETA=0:25:43\n",
            "\u001b[32m[04/30 16:30:45 d2.evaluation.evaluator]: \u001b[0mInference done 1751/5000. Dataloading: 0.0021 s/iter. Inference: 0.4529 s/iter. Eval: 0.0184 s/iter. Total: 0.4736 s/iter. ETA=0:25:38\n",
            "\u001b[32m[04/30 16:30:50 d2.evaluation.evaluator]: \u001b[0mInference done 1762/5000. Dataloading: 0.0021 s/iter. Inference: 0.4530 s/iter. Eval: 0.0184 s/iter. Total: 0.4737 s/iter. ETA=0:25:33\n",
            "\u001b[32m[04/30 16:30:56 d2.evaluation.evaluator]: \u001b[0mInference done 1774/5000. Dataloading: 0.0021 s/iter. Inference: 0.4529 s/iter. Eval: 0.0184 s/iter. Total: 0.4735 s/iter. ETA=0:25:27\n",
            "\u001b[32m[04/30 16:31:01 d2.evaluation.evaluator]: \u001b[0mInference done 1785/5000. Dataloading: 0.0021 s/iter. Inference: 0.4529 s/iter. Eval: 0.0184 s/iter. Total: 0.4736 s/iter. ETA=0:25:22\n",
            "\u001b[32m[04/30 16:31:06 d2.evaluation.evaluator]: \u001b[0mInference done 1796/5000. Dataloading: 0.0021 s/iter. Inference: 0.4530 s/iter. Eval: 0.0184 s/iter. Total: 0.4736 s/iter. ETA=0:25:17\n",
            "\u001b[32m[04/30 16:31:11 d2.evaluation.evaluator]: \u001b[0mInference done 1807/5000. Dataloading: 0.0021 s/iter. Inference: 0.4530 s/iter. Eval: 0.0183 s/iter. Total: 0.4736 s/iter. ETA=0:25:12\n",
            "\u001b[32m[04/30 16:31:17 d2.evaluation.evaluator]: \u001b[0mInference done 1817/5000. Dataloading: 0.0021 s/iter. Inference: 0.4531 s/iter. Eval: 0.0184 s/iter. Total: 0.4738 s/iter. ETA=0:25:08\n",
            "\u001b[32m[04/30 16:31:22 d2.evaluation.evaluator]: \u001b[0mInference done 1828/5000. Dataloading: 0.0021 s/iter. Inference: 0.4531 s/iter. Eval: 0.0184 s/iter. Total: 0.4738 s/iter. ETA=0:25:02\n",
            "\u001b[32m[04/30 16:31:27 d2.evaluation.evaluator]: \u001b[0mInference done 1839/5000. Dataloading: 0.0021 s/iter. Inference: 0.4531 s/iter. Eval: 0.0184 s/iter. Total: 0.4738 s/iter. ETA=0:24:57\n",
            "\u001b[32m[04/30 16:31:32 d2.evaluation.evaluator]: \u001b[0mInference done 1850/5000. Dataloading: 0.0021 s/iter. Inference: 0.4531 s/iter. Eval: 0.0184 s/iter. Total: 0.4738 s/iter. ETA=0:24:52\n",
            "\u001b[32m[04/30 16:31:38 d2.evaluation.evaluator]: \u001b[0mInference done 1861/5000. Dataloading: 0.0021 s/iter. Inference: 0.4532 s/iter. Eval: 0.0184 s/iter. Total: 0.4739 s/iter. ETA=0:24:47\n",
            "\u001b[32m[04/30 16:31:43 d2.evaluation.evaluator]: \u001b[0mInference done 1872/5000. Dataloading: 0.0021 s/iter. Inference: 0.4533 s/iter. Eval: 0.0184 s/iter. Total: 0.4739 s/iter. ETA=0:24:42\n",
            "\u001b[32m[04/30 16:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 1883/5000. Dataloading: 0.0021 s/iter. Inference: 0.4533 s/iter. Eval: 0.0184 s/iter. Total: 0.4739 s/iter. ETA=0:24:37\n",
            "\u001b[32m[04/30 16:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 1894/5000. Dataloading: 0.0021 s/iter. Inference: 0.4533 s/iter. Eval: 0.0184 s/iter. Total: 0.4740 s/iter. ETA=0:24:32\n",
            "\u001b[32m[04/30 16:31:59 d2.evaluation.evaluator]: \u001b[0mInference done 1905/5000. Dataloading: 0.0021 s/iter. Inference: 0.4534 s/iter. Eval: 0.0184 s/iter. Total: 0.4740 s/iter. ETA=0:24:27\n",
            "\u001b[32m[04/30 16:32:04 d2.evaluation.evaluator]: \u001b[0mInference done 1916/5000. Dataloading: 0.0021 s/iter. Inference: 0.4534 s/iter. Eval: 0.0183 s/iter. Total: 0.4740 s/iter. ETA=0:24:21\n",
            "\u001b[32m[04/30 16:32:09 d2.evaluation.evaluator]: \u001b[0mInference done 1927/5000. Dataloading: 0.0021 s/iter. Inference: 0.4534 s/iter. Eval: 0.0183 s/iter. Total: 0.4740 s/iter. ETA=0:24:16\n",
            "\u001b[32m[04/30 16:32:14 d2.evaluation.evaluator]: \u001b[0mInference done 1938/5000. Dataloading: 0.0021 s/iter. Inference: 0.4535 s/iter. Eval: 0.0182 s/iter. Total: 0.4740 s/iter. ETA=0:24:11\n",
            "\u001b[32m[04/30 16:32:19 d2.evaluation.evaluator]: \u001b[0mInference done 1949/5000. Dataloading: 0.0021 s/iter. Inference: 0.4534 s/iter. Eval: 0.0182 s/iter. Total: 0.4739 s/iter. ETA=0:24:05\n",
            "\u001b[32m[04/30 16:32:25 d2.evaluation.evaluator]: \u001b[0mInference done 1960/5000. Dataloading: 0.0021 s/iter. Inference: 0.4535 s/iter. Eval: 0.0182 s/iter. Total: 0.4740 s/iter. ETA=0:24:00\n",
            "\u001b[32m[04/30 16:32:30 d2.evaluation.evaluator]: \u001b[0mInference done 1971/5000. Dataloading: 0.0021 s/iter. Inference: 0.4535 s/iter. Eval: 0.0182 s/iter. Total: 0.4740 s/iter. ETA=0:23:55\n",
            "\u001b[32m[04/30 16:32:35 d2.evaluation.evaluator]: \u001b[0mInference done 1982/5000. Dataloading: 0.0021 s/iter. Inference: 0.4536 s/iter. Eval: 0.0182 s/iter. Total: 0.4741 s/iter. ETA=0:23:50\n",
            "\u001b[32m[04/30 16:32:41 d2.evaluation.evaluator]: \u001b[0mInference done 1993/5000. Dataloading: 0.0021 s/iter. Inference: 0.4536 s/iter. Eval: 0.0182 s/iter. Total: 0.4741 s/iter. ETA=0:23:45\n",
            "\u001b[32m[04/30 16:32:46 d2.evaluation.evaluator]: \u001b[0mInference done 2004/5000. Dataloading: 0.0021 s/iter. Inference: 0.4537 s/iter. Eval: 0.0183 s/iter. Total: 0.4742 s/iter. ETA=0:23:40\n",
            "\u001b[32m[04/30 16:32:51 d2.evaluation.evaluator]: \u001b[0mInference done 2015/5000. Dataloading: 0.0021 s/iter. Inference: 0.4537 s/iter. Eval: 0.0183 s/iter. Total: 0.4743 s/iter. ETA=0:23:35\n",
            "\u001b[32m[04/30 16:32:57 d2.evaluation.evaluator]: \u001b[0mInference done 2026/5000. Dataloading: 0.0021 s/iter. Inference: 0.4538 s/iter. Eval: 0.0183 s/iter. Total: 0.4744 s/iter. ETA=0:23:30\n",
            "\u001b[32m[04/30 16:33:02 d2.evaluation.evaluator]: \u001b[0mInference done 2037/5000. Dataloading: 0.0021 s/iter. Inference: 0.4538 s/iter. Eval: 0.0182 s/iter. Total: 0.4743 s/iter. ETA=0:23:25\n",
            "\u001b[32m[04/30 16:33:07 d2.evaluation.evaluator]: \u001b[0mInference done 2048/5000. Dataloading: 0.0021 s/iter. Inference: 0.4538 s/iter. Eval: 0.0183 s/iter. Total: 0.4743 s/iter. ETA=0:23:20\n",
            "\u001b[32m[04/30 16:33:12 d2.evaluation.evaluator]: \u001b[0mInference done 2059/5000. Dataloading: 0.0021 s/iter. Inference: 0.4538 s/iter. Eval: 0.0182 s/iter. Total: 0.4743 s/iter. ETA=0:23:14\n",
            "\u001b[32m[04/30 16:33:18 d2.evaluation.evaluator]: \u001b[0mInference done 2070/5000. Dataloading: 0.0021 s/iter. Inference: 0.4539 s/iter. Eval: 0.0182 s/iter. Total: 0.4744 s/iter. ETA=0:23:09\n",
            "\u001b[32m[04/30 16:33:23 d2.evaluation.evaluator]: \u001b[0mInference done 2081/5000. Dataloading: 0.0021 s/iter. Inference: 0.4539 s/iter. Eval: 0.0181 s/iter. Total: 0.4743 s/iter. ETA=0:23:04\n",
            "\u001b[32m[04/30 16:33:28 d2.evaluation.evaluator]: \u001b[0mInference done 2092/5000. Dataloading: 0.0021 s/iter. Inference: 0.4539 s/iter. Eval: 0.0182 s/iter. Total: 0.4744 s/iter. ETA=0:22:59\n",
            "\u001b[32m[04/30 16:33:33 d2.evaluation.evaluator]: \u001b[0mInference done 2103/5000. Dataloading: 0.0021 s/iter. Inference: 0.4539 s/iter. Eval: 0.0182 s/iter. Total: 0.4744 s/iter. ETA=0:22:54\n",
            "\u001b[32m[04/30 16:33:39 d2.evaluation.evaluator]: \u001b[0mInference done 2114/5000. Dataloading: 0.0021 s/iter. Inference: 0.4540 s/iter. Eval: 0.0182 s/iter. Total: 0.4745 s/iter. ETA=0:22:49\n",
            "\u001b[32m[04/30 16:33:44 d2.evaluation.evaluator]: \u001b[0mInference done 2125/5000. Dataloading: 0.0021 s/iter. Inference: 0.4540 s/iter. Eval: 0.0182 s/iter. Total: 0.4744 s/iter. ETA=0:22:44\n",
            "\u001b[32m[04/30 16:33:49 d2.evaluation.evaluator]: \u001b[0mInference done 2136/5000. Dataloading: 0.0021 s/iter. Inference: 0.4540 s/iter. Eval: 0.0182 s/iter. Total: 0.4745 s/iter. ETA=0:22:38\n",
            "\u001b[32m[04/30 16:33:54 d2.evaluation.evaluator]: \u001b[0mInference done 2147/5000. Dataloading: 0.0021 s/iter. Inference: 0.4540 s/iter. Eval: 0.0181 s/iter. Total: 0.4744 s/iter. ETA=0:22:33\n",
            "\u001b[32m[04/30 16:33:59 d2.evaluation.evaluator]: \u001b[0mInference done 2158/5000. Dataloading: 0.0021 s/iter. Inference: 0.4540 s/iter. Eval: 0.0181 s/iter. Total: 0.4744 s/iter. ETA=0:22:28\n",
            "\u001b[32m[04/30 16:34:05 d2.evaluation.evaluator]: \u001b[0mInference done 2169/5000. Dataloading: 0.0021 s/iter. Inference: 0.4540 s/iter. Eval: 0.0181 s/iter. Total: 0.4744 s/iter. ETA=0:22:23\n",
            "\u001b[32m[04/30 16:34:10 d2.evaluation.evaluator]: \u001b[0mInference done 2180/5000. Dataloading: 0.0021 s/iter. Inference: 0.4541 s/iter. Eval: 0.0181 s/iter. Total: 0.4745 s/iter. ETA=0:22:17\n",
            "\u001b[32m[04/30 16:34:15 d2.evaluation.evaluator]: \u001b[0mInference done 2191/5000. Dataloading: 0.0021 s/iter. Inference: 0.4541 s/iter. Eval: 0.0181 s/iter. Total: 0.4744 s/iter. ETA=0:22:12\n",
            "\u001b[32m[04/30 16:34:21 d2.evaluation.evaluator]: \u001b[0mInference done 2202/5000. Dataloading: 0.0021 s/iter. Inference: 0.4541 s/iter. Eval: 0.0181 s/iter. Total: 0.4745 s/iter. ETA=0:22:07\n",
            "\u001b[32m[04/30 16:34:26 d2.evaluation.evaluator]: \u001b[0mInference done 2213/5000. Dataloading: 0.0021 s/iter. Inference: 0.4541 s/iter. Eval: 0.0182 s/iter. Total: 0.4746 s/iter. ETA=0:22:02\n",
            "\u001b[32m[04/30 16:34:31 d2.evaluation.evaluator]: \u001b[0mInference done 2224/5000. Dataloading: 0.0021 s/iter. Inference: 0.4542 s/iter. Eval: 0.0182 s/iter. Total: 0.4747 s/iter. ETA=0:21:57\n",
            "\u001b[32m[04/30 16:34:37 d2.evaluation.evaluator]: \u001b[0mInference done 2235/5000. Dataloading: 0.0021 s/iter. Inference: 0.4542 s/iter. Eval: 0.0182 s/iter. Total: 0.4747 s/iter. ETA=0:21:52\n",
            "\u001b[32m[04/30 16:34:42 d2.evaluation.evaluator]: \u001b[0mInference done 2246/5000. Dataloading: 0.0021 s/iter. Inference: 0.4543 s/iter. Eval: 0.0182 s/iter. Total: 0.4748 s/iter. ETA=0:21:47\n",
            "\u001b[32m[04/30 16:34:48 d2.evaluation.evaluator]: \u001b[0mInference done 2257/5000. Dataloading: 0.0021 s/iter. Inference: 0.4544 s/iter. Eval: 0.0182 s/iter. Total: 0.4749 s/iter. ETA=0:21:42\n",
            "\u001b[32m[04/30 16:34:53 d2.evaluation.evaluator]: \u001b[0mInference done 2268/5000. Dataloading: 0.0021 s/iter. Inference: 0.4544 s/iter. Eval: 0.0182 s/iter. Total: 0.4749 s/iter. ETA=0:21:37\n",
            "\u001b[32m[04/30 16:34:58 d2.evaluation.evaluator]: \u001b[0mInference done 2279/5000. Dataloading: 0.0021 s/iter. Inference: 0.4544 s/iter. Eval: 0.0182 s/iter. Total: 0.4749 s/iter. ETA=0:21:32\n",
            "\u001b[32m[04/30 16:35:03 d2.evaluation.evaluator]: \u001b[0mInference done 2290/5000. Dataloading: 0.0021 s/iter. Inference: 0.4545 s/iter. Eval: 0.0181 s/iter. Total: 0.4749 s/iter. ETA=0:21:26\n",
            "\u001b[32m[04/30 16:35:08 d2.evaluation.evaluator]: \u001b[0mInference done 2301/5000. Dataloading: 0.0021 s/iter. Inference: 0.4545 s/iter. Eval: 0.0181 s/iter. Total: 0.4748 s/iter. ETA=0:21:21\n",
            "\u001b[32m[04/30 16:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 2312/5000. Dataloading: 0.0021 s/iter. Inference: 0.4545 s/iter. Eval: 0.0181 s/iter. Total: 0.4749 s/iter. ETA=0:21:16\n",
            "\u001b[32m[04/30 16:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 2323/5000. Dataloading: 0.0021 s/iter. Inference: 0.4545 s/iter. Eval: 0.0181 s/iter. Total: 0.4749 s/iter. ETA=0:21:11\n",
            "\u001b[32m[04/30 16:35:24 d2.evaluation.evaluator]: \u001b[0mInference done 2334/5000. Dataloading: 0.0021 s/iter. Inference: 0.4545 s/iter. Eval: 0.0180 s/iter. Total: 0.4748 s/iter. ETA=0:21:05\n",
            "\u001b[32m[04/30 16:35:29 d2.evaluation.evaluator]: \u001b[0mInference done 2345/5000. Dataloading: 0.0021 s/iter. Inference: 0.4546 s/iter. Eval: 0.0180 s/iter. Total: 0.4748 s/iter. ETA=0:21:00\n",
            "\u001b[32m[04/30 16:35:35 d2.evaluation.evaluator]: \u001b[0mInference done 2356/5000. Dataloading: 0.0021 s/iter. Inference: 0.4546 s/iter. Eval: 0.0180 s/iter. Total: 0.4749 s/iter. ETA=0:20:55\n",
            "\u001b[32m[04/30 16:35:40 d2.evaluation.evaluator]: \u001b[0mInference done 2367/5000. Dataloading: 0.0021 s/iter. Inference: 0.4546 s/iter. Eval: 0.0180 s/iter. Total: 0.4749 s/iter. ETA=0:20:50\n",
            "\u001b[32m[04/30 16:35:45 d2.evaluation.evaluator]: \u001b[0mInference done 2378/5000. Dataloading: 0.0021 s/iter. Inference: 0.4546 s/iter. Eval: 0.0180 s/iter. Total: 0.4749 s/iter. ETA=0:20:45\n",
            "\u001b[32m[04/30 16:35:50 d2.evaluation.evaluator]: \u001b[0mInference done 2389/5000. Dataloading: 0.0021 s/iter. Inference: 0.4547 s/iter. Eval: 0.0180 s/iter. Total: 0.4749 s/iter. ETA=0:20:40\n",
            "\u001b[32m[04/30 16:35:56 d2.evaluation.evaluator]: \u001b[0mInference done 2400/5000. Dataloading: 0.0021 s/iter. Inference: 0.4547 s/iter. Eval: 0.0180 s/iter. Total: 0.4750 s/iter. ETA=0:20:35\n",
            "\u001b[32m[04/30 16:36:01 d2.evaluation.evaluator]: \u001b[0mInference done 2411/5000. Dataloading: 0.0021 s/iter. Inference: 0.4548 s/iter. Eval: 0.0180 s/iter. Total: 0.4751 s/iter. ETA=0:20:29\n",
            "\u001b[32m[04/30 16:36:07 d2.evaluation.evaluator]: \u001b[0mInference done 2422/5000. Dataloading: 0.0021 s/iter. Inference: 0.4548 s/iter. Eval: 0.0181 s/iter. Total: 0.4752 s/iter. ETA=0:20:24\n",
            "\u001b[32m[04/30 16:36:12 d2.evaluation.evaluator]: \u001b[0mInference done 2433/5000. Dataloading: 0.0021 s/iter. Inference: 0.4549 s/iter. Eval: 0.0181 s/iter. Total: 0.4752 s/iter. ETA=0:20:19\n",
            "\u001b[32m[04/30 16:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 2444/5000. Dataloading: 0.0021 s/iter. Inference: 0.4549 s/iter. Eval: 0.0181 s/iter. Total: 0.4753 s/iter. ETA=0:20:14\n",
            "\u001b[32m[04/30 16:36:23 d2.evaluation.evaluator]: \u001b[0mInference done 2455/5000. Dataloading: 0.0021 s/iter. Inference: 0.4550 s/iter. Eval: 0.0181 s/iter. Total: 0.4753 s/iter. ETA=0:20:09\n",
            "\u001b[32m[04/30 16:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 2466/5000. Dataloading: 0.0021 s/iter. Inference: 0.4550 s/iter. Eval: 0.0180 s/iter. Total: 0.4753 s/iter. ETA=0:20:04\n",
            "\u001b[32m[04/30 16:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 2477/5000. Dataloading: 0.0021 s/iter. Inference: 0.4550 s/iter. Eval: 0.0181 s/iter. Total: 0.4753 s/iter. ETA=0:19:59\n",
            "\u001b[32m[04/30 16:36:38 d2.evaluation.evaluator]: \u001b[0mInference done 2488/5000. Dataloading: 0.0021 s/iter. Inference: 0.4550 s/iter. Eval: 0.0180 s/iter. Total: 0.4753 s/iter. ETA=0:19:53\n",
            "\u001b[32m[04/30 16:36:44 d2.evaluation.evaluator]: \u001b[0mInference done 2499/5000. Dataloading: 0.0021 s/iter. Inference: 0.4550 s/iter. Eval: 0.0180 s/iter. Total: 0.4753 s/iter. ETA=0:19:48\n",
            "\u001b[32m[04/30 16:36:49 d2.evaluation.evaluator]: \u001b[0mInference done 2510/5000. Dataloading: 0.0021 s/iter. Inference: 0.4550 s/iter. Eval: 0.0181 s/iter. Total: 0.4754 s/iter. ETA=0:19:43\n",
            "\u001b[32m[04/30 16:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 2520/5000. Dataloading: 0.0021 s/iter. Inference: 0.4551 s/iter. Eval: 0.0182 s/iter. Total: 0.4755 s/iter. ETA=0:19:39\n",
            "\u001b[32m[04/30 16:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 2531/5000. Dataloading: 0.0021 s/iter. Inference: 0.4551 s/iter. Eval: 0.0182 s/iter. Total: 0.4756 s/iter. ETA=0:19:34\n",
            "\u001b[32m[04/30 16:37:05 d2.evaluation.evaluator]: \u001b[0mInference done 2542/5000. Dataloading: 0.0021 s/iter. Inference: 0.4551 s/iter. Eval: 0.0182 s/iter. Total: 0.4756 s/iter. ETA=0:19:29\n",
            "\u001b[32m[04/30 16:37:10 d2.evaluation.evaluator]: \u001b[0mInference done 2553/5000. Dataloading: 0.0021 s/iter. Inference: 0.4552 s/iter. Eval: 0.0182 s/iter. Total: 0.4756 s/iter. ETA=0:19:23\n",
            "\u001b[32m[04/30 16:37:15 d2.evaluation.evaluator]: \u001b[0mInference done 2564/5000. Dataloading: 0.0021 s/iter. Inference: 0.4552 s/iter. Eval: 0.0182 s/iter. Total: 0.4757 s/iter. ETA=0:19:18\n",
            "\u001b[32m[04/30 16:37:21 d2.evaluation.evaluator]: \u001b[0mInference done 2575/5000. Dataloading: 0.0021 s/iter. Inference: 0.4553 s/iter. Eval: 0.0183 s/iter. Total: 0.4758 s/iter. ETA=0:19:13\n",
            "\u001b[32m[04/30 16:37:26 d2.evaluation.evaluator]: \u001b[0mInference done 2586/5000. Dataloading: 0.0021 s/iter. Inference: 0.4552 s/iter. Eval: 0.0183 s/iter. Total: 0.4758 s/iter. ETA=0:19:08\n",
            "\u001b[32m[04/30 16:37:31 d2.evaluation.evaluator]: \u001b[0mInference done 2597/5000. Dataloading: 0.0021 s/iter. Inference: 0.4552 s/iter. Eval: 0.0183 s/iter. Total: 0.4758 s/iter. ETA=0:19:03\n",
            "\u001b[32m[04/30 16:37:37 d2.evaluation.evaluator]: \u001b[0mInference done 2608/5000. Dataloading: 0.0021 s/iter. Inference: 0.4553 s/iter. Eval: 0.0183 s/iter. Total: 0.4758 s/iter. ETA=0:18:58\n",
            "\u001b[32m[04/30 16:37:42 d2.evaluation.evaluator]: \u001b[0mInference done 2618/5000. Dataloading: 0.0021 s/iter. Inference: 0.4553 s/iter. Eval: 0.0183 s/iter. Total: 0.4759 s/iter. ETA=0:18:53\n",
            "\u001b[32m[04/30 16:37:47 d2.evaluation.evaluator]: \u001b[0mInference done 2629/5000. Dataloading: 0.0021 s/iter. Inference: 0.4554 s/iter. Eval: 0.0183 s/iter. Total: 0.4759 s/iter. ETA=0:18:48\n",
            "\u001b[32m[04/30 16:37:52 d2.evaluation.evaluator]: \u001b[0mInference done 2640/5000. Dataloading: 0.0021 s/iter. Inference: 0.4554 s/iter. Eval: 0.0183 s/iter. Total: 0.4760 s/iter. ETA=0:18:43\n",
            "\u001b[32m[04/30 16:37:58 d2.evaluation.evaluator]: \u001b[0mInference done 2651/5000. Dataloading: 0.0021 s/iter. Inference: 0.4555 s/iter. Eval: 0.0183 s/iter. Total: 0.4760 s/iter. ETA=0:18:38\n",
            "\u001b[32m[04/30 16:38:03 d2.evaluation.evaluator]: \u001b[0mInference done 2662/5000. Dataloading: 0.0021 s/iter. Inference: 0.4555 s/iter. Eval: 0.0183 s/iter. Total: 0.4760 s/iter. ETA=0:18:32\n",
            "\u001b[32m[04/30 16:38:08 d2.evaluation.evaluator]: \u001b[0mInference done 2673/5000. Dataloading: 0.0021 s/iter. Inference: 0.4555 s/iter. Eval: 0.0183 s/iter. Total: 0.4760 s/iter. ETA=0:18:27\n",
            "\u001b[32m[04/30 16:38:13 d2.evaluation.evaluator]: \u001b[0mInference done 2684/5000. Dataloading: 0.0021 s/iter. Inference: 0.4555 s/iter. Eval: 0.0183 s/iter. Total: 0.4761 s/iter. ETA=0:18:22\n",
            "\u001b[32m[04/30 16:38:19 d2.evaluation.evaluator]: \u001b[0mInference done 2695/5000. Dataloading: 0.0021 s/iter. Inference: 0.4555 s/iter. Eval: 0.0182 s/iter. Total: 0.4760 s/iter. ETA=0:18:17\n",
            "\u001b[32m[04/30 16:38:24 d2.evaluation.evaluator]: \u001b[0mInference done 2706/5000. Dataloading: 0.0021 s/iter. Inference: 0.4556 s/iter. Eval: 0.0182 s/iter. Total: 0.4760 s/iter. ETA=0:18:11\n",
            "\u001b[32m[04/30 16:38:29 d2.evaluation.evaluator]: \u001b[0mInference done 2717/5000. Dataloading: 0.0021 s/iter. Inference: 0.4556 s/iter. Eval: 0.0182 s/iter. Total: 0.4760 s/iter. ETA=0:18:06\n",
            "\u001b[32m[04/30 16:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 2728/5000. Dataloading: 0.0021 s/iter. Inference: 0.4556 s/iter. Eval: 0.0182 s/iter. Total: 0.4761 s/iter. ETA=0:18:01\n",
            "\u001b[32m[04/30 16:38:40 d2.evaluation.evaluator]: \u001b[0mInference done 2739/5000. Dataloading: 0.0021 s/iter. Inference: 0.4556 s/iter. Eval: 0.0182 s/iter. Total: 0.4761 s/iter. ETA=0:17:56\n",
            "\u001b[32m[04/30 16:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 2750/5000. Dataloading: 0.0021 s/iter. Inference: 0.4556 s/iter. Eval: 0.0182 s/iter. Total: 0.4760 s/iter. ETA=0:17:51\n",
            "\u001b[32m[04/30 16:38:50 d2.evaluation.evaluator]: \u001b[0mInference done 2761/5000. Dataloading: 0.0021 s/iter. Inference: 0.4556 s/iter. Eval: 0.0182 s/iter. Total: 0.4760 s/iter. ETA=0:17:45\n",
            "\u001b[32m[04/30 16:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 2772/5000. Dataloading: 0.0021 s/iter. Inference: 0.4556 s/iter. Eval: 0.0182 s/iter. Total: 0.4761 s/iter. ETA=0:17:40\n",
            "\u001b[32m[04/30 16:39:01 d2.evaluation.evaluator]: \u001b[0mInference done 2783/5000. Dataloading: 0.0021 s/iter. Inference: 0.4557 s/iter. Eval: 0.0182 s/iter. Total: 0.4761 s/iter. ETA=0:17:35\n",
            "\u001b[32m[04/30 16:39:06 d2.evaluation.evaluator]: \u001b[0mInference done 2794/5000. Dataloading: 0.0021 s/iter. Inference: 0.4557 s/iter. Eval: 0.0181 s/iter. Total: 0.4761 s/iter. ETA=0:17:30\n",
            "\u001b[32m[04/30 16:39:11 d2.evaluation.evaluator]: \u001b[0mInference done 2805/5000. Dataloading: 0.0021 s/iter. Inference: 0.4557 s/iter. Eval: 0.0181 s/iter. Total: 0.4761 s/iter. ETA=0:17:24\n",
            "\u001b[32m[04/30 16:39:16 d2.evaluation.evaluator]: \u001b[0mInference done 2816/5000. Dataloading: 0.0021 s/iter. Inference: 0.4557 s/iter. Eval: 0.0181 s/iter. Total: 0.4761 s/iter. ETA=0:17:19\n",
            "\u001b[32m[04/30 16:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 2827/5000. Dataloading: 0.0021 s/iter. Inference: 0.4557 s/iter. Eval: 0.0182 s/iter. Total: 0.4761 s/iter. ETA=0:17:14\n",
            "\u001b[32m[04/30 16:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 2838/5000. Dataloading: 0.0021 s/iter. Inference: 0.4558 s/iter. Eval: 0.0182 s/iter. Total: 0.4762 s/iter. ETA=0:17:09\n",
            "\u001b[32m[04/30 16:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 2849/5000. Dataloading: 0.0021 s/iter. Inference: 0.4558 s/iter. Eval: 0.0181 s/iter. Total: 0.4762 s/iter. ETA=0:17:04\n",
            "\u001b[32m[04/30 16:39:38 d2.evaluation.evaluator]: \u001b[0mInference done 2860/5000. Dataloading: 0.0021 s/iter. Inference: 0.4558 s/iter. Eval: 0.0181 s/iter. Total: 0.4762 s/iter. ETA=0:16:59\n",
            "\u001b[32m[04/30 16:39:43 d2.evaluation.evaluator]: \u001b[0mInference done 2871/5000. Dataloading: 0.0021 s/iter. Inference: 0.4558 s/iter. Eval: 0.0181 s/iter. Total: 0.4762 s/iter. ETA=0:16:53\n",
            "\u001b[32m[04/30 16:39:48 d2.evaluation.evaluator]: \u001b[0mInference done 2882/5000. Dataloading: 0.0021 s/iter. Inference: 0.4559 s/iter. Eval: 0.0181 s/iter. Total: 0.4762 s/iter. ETA=0:16:48\n",
            "\u001b[32m[04/30 16:39:54 d2.evaluation.evaluator]: \u001b[0mInference done 2893/5000. Dataloading: 0.0021 s/iter. Inference: 0.4559 s/iter. Eval: 0.0181 s/iter. Total: 0.4763 s/iter. ETA=0:16:43\n",
            "\u001b[32m[04/30 16:39:59 d2.evaluation.evaluator]: \u001b[0mInference done 2904/5000. Dataloading: 0.0021 s/iter. Inference: 0.4559 s/iter. Eval: 0.0181 s/iter. Total: 0.4763 s/iter. ETA=0:16:38\n",
            "\u001b[32m[04/30 16:40:04 d2.evaluation.evaluator]: \u001b[0mInference done 2915/5000. Dataloading: 0.0021 s/iter. Inference: 0.4559 s/iter. Eval: 0.0182 s/iter. Total: 0.4764 s/iter. ETA=0:16:33\n",
            "\u001b[32m[04/30 16:40:09 d2.evaluation.evaluator]: \u001b[0mInference done 2920/5000. Dataloading: 0.0021 s/iter. Inference: 0.4560 s/iter. Eval: 0.0182 s/iter. Total: 0.4773 s/iter. ETA=0:16:32\n",
            "\u001b[32m[04/30 16:40:15 d2.evaluation.evaluator]: \u001b[0mInference done 2931/5000. Dataloading: 0.0021 s/iter. Inference: 0.4560 s/iter. Eval: 0.0182 s/iter. Total: 0.4774 s/iter. ETA=0:16:27\n",
            "\u001b[32m[04/30 16:40:20 d2.evaluation.evaluator]: \u001b[0mInference done 2942/5000. Dataloading: 0.0021 s/iter. Inference: 0.4560 s/iter. Eval: 0.0182 s/iter. Total: 0.4774 s/iter. ETA=0:16:22\n",
            "\u001b[32m[04/30 16:40:25 d2.evaluation.evaluator]: \u001b[0mInference done 2953/5000. Dataloading: 0.0021 s/iter. Inference: 0.4560 s/iter. Eval: 0.0182 s/iter. Total: 0.4774 s/iter. ETA=0:16:17\n",
            "\u001b[32m[04/30 16:40:31 d2.evaluation.evaluator]: \u001b[0mInference done 2964/5000. Dataloading: 0.0021 s/iter. Inference: 0.4560 s/iter. Eval: 0.0182 s/iter. Total: 0.4773 s/iter. ETA=0:16:11\n",
            "\u001b[32m[04/30 16:40:36 d2.evaluation.evaluator]: \u001b[0mInference done 2975/5000. Dataloading: 0.0021 s/iter. Inference: 0.4560 s/iter. Eval: 0.0181 s/iter. Total: 0.4773 s/iter. ETA=0:16:06\n",
            "\u001b[32m[04/30 16:40:41 d2.evaluation.evaluator]: \u001b[0mInference done 2986/5000. Dataloading: 0.0021 s/iter. Inference: 0.4561 s/iter. Eval: 0.0181 s/iter. Total: 0.4774 s/iter. ETA=0:16:01\n",
            "\u001b[32m[04/30 16:40:46 d2.evaluation.evaluator]: \u001b[0mInference done 2997/5000. Dataloading: 0.0021 s/iter. Inference: 0.4561 s/iter. Eval: 0.0181 s/iter. Total: 0.4774 s/iter. ETA=0:15:56\n",
            "\u001b[32m[04/30 16:40:52 d2.evaluation.evaluator]: \u001b[0mInference done 3008/5000. Dataloading: 0.0021 s/iter. Inference: 0.4561 s/iter. Eval: 0.0181 s/iter. Total: 0.4773 s/iter. ETA=0:15:50\n",
            "\u001b[32m[04/30 16:40:57 d2.evaluation.evaluator]: \u001b[0mInference done 3019/5000. Dataloading: 0.0021 s/iter. Inference: 0.4561 s/iter. Eval: 0.0181 s/iter. Total: 0.4773 s/iter. ETA=0:15:45\n",
            "\u001b[32m[04/30 16:41:02 d2.evaluation.evaluator]: \u001b[0mInference done 3030/5000. Dataloading: 0.0021 s/iter. Inference: 0.4562 s/iter. Eval: 0.0181 s/iter. Total: 0.4774 s/iter. ETA=0:15:40\n",
            "\u001b[32m[04/30 16:41:08 d2.evaluation.evaluator]: \u001b[0mInference done 3041/5000. Dataloading: 0.0021 s/iter. Inference: 0.4562 s/iter. Eval: 0.0181 s/iter. Total: 0.4774 s/iter. ETA=0:15:35\n",
            "\u001b[32m[04/30 16:41:13 d2.evaluation.evaluator]: \u001b[0mInference done 3052/5000. Dataloading: 0.0021 s/iter. Inference: 0.4562 s/iter. Eval: 0.0181 s/iter. Total: 0.4774 s/iter. ETA=0:15:29\n",
            "\u001b[32m[04/30 16:41:18 d2.evaluation.evaluator]: \u001b[0mInference done 3063/5000. Dataloading: 0.0021 s/iter. Inference: 0.4563 s/iter. Eval: 0.0180 s/iter. Total: 0.4774 s/iter. ETA=0:15:24\n",
            "\u001b[32m[04/30 16:41:23 d2.evaluation.evaluator]: \u001b[0mInference done 3074/5000. Dataloading: 0.0021 s/iter. Inference: 0.4563 s/iter. Eval: 0.0180 s/iter. Total: 0.4774 s/iter. ETA=0:15:19\n",
            "\u001b[32m[04/30 16:41:29 d2.evaluation.evaluator]: \u001b[0mInference done 3085/5000. Dataloading: 0.0021 s/iter. Inference: 0.4563 s/iter. Eval: 0.0180 s/iter. Total: 0.4775 s/iter. ETA=0:15:14\n",
            "\u001b[32m[04/30 16:41:34 d2.evaluation.evaluator]: \u001b[0mInference done 3096/5000. Dataloading: 0.0021 s/iter. Inference: 0.4563 s/iter. Eval: 0.0180 s/iter. Total: 0.4774 s/iter. ETA=0:15:09\n",
            "\u001b[32m[04/30 16:41:39 d2.evaluation.evaluator]: \u001b[0mInference done 3107/5000. Dataloading: 0.0021 s/iter. Inference: 0.4563 s/iter. Eval: 0.0180 s/iter. Total: 0.4774 s/iter. ETA=0:15:03\n",
            "\u001b[32m[04/30 16:41:44 d2.evaluation.evaluator]: \u001b[0mInference done 3118/5000. Dataloading: 0.0021 s/iter. Inference: 0.4563 s/iter. Eval: 0.0180 s/iter. Total: 0.4774 s/iter. ETA=0:14:58\n",
            "\u001b[32m[04/30 16:41:50 d2.evaluation.evaluator]: \u001b[0mInference done 3129/5000. Dataloading: 0.0021 s/iter. Inference: 0.4564 s/iter. Eval: 0.0180 s/iter. Total: 0.4774 s/iter. ETA=0:14:53\n",
            "\u001b[32m[04/30 16:41:55 d2.evaluation.evaluator]: \u001b[0mInference done 3140/5000. Dataloading: 0.0021 s/iter. Inference: 0.4564 s/iter. Eval: 0.0180 s/iter. Total: 0.4775 s/iter. ETA=0:14:48\n",
            "\u001b[32m[04/30 16:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 3151/5000. Dataloading: 0.0021 s/iter. Inference: 0.4564 s/iter. Eval: 0.0180 s/iter. Total: 0.4775 s/iter. ETA=0:14:42\n",
            "\u001b[32m[04/30 16:42:05 d2.evaluation.evaluator]: \u001b[0mInference done 3162/5000. Dataloading: 0.0021 s/iter. Inference: 0.4564 s/iter. Eval: 0.0180 s/iter. Total: 0.4775 s/iter. ETA=0:14:37\n",
            "\u001b[32m[04/30 16:42:11 d2.evaluation.evaluator]: \u001b[0mInference done 3173/5000. Dataloading: 0.0021 s/iter. Inference: 0.4564 s/iter. Eval: 0.0180 s/iter. Total: 0.4775 s/iter. ETA=0:14:32\n",
            "\u001b[32m[04/30 16:42:16 d2.evaluation.evaluator]: \u001b[0mInference done 3184/5000. Dataloading: 0.0021 s/iter. Inference: 0.4564 s/iter. Eval: 0.0180 s/iter. Total: 0.4775 s/iter. ETA=0:14:27\n",
            "\u001b[32m[04/30 16:42:21 d2.evaluation.evaluator]: \u001b[0mInference done 3195/5000. Dataloading: 0.0021 s/iter. Inference: 0.4564 s/iter. Eval: 0.0180 s/iter. Total: 0.4775 s/iter. ETA=0:14:21\n",
            "\u001b[32m[04/30 16:42:27 d2.evaluation.evaluator]: \u001b[0mInference done 3206/5000. Dataloading: 0.0021 s/iter. Inference: 0.4564 s/iter. Eval: 0.0180 s/iter. Total: 0.4775 s/iter. ETA=0:14:16\n",
            "\u001b[32m[04/30 16:42:32 d2.evaluation.evaluator]: \u001b[0mInference done 3217/5000. Dataloading: 0.0021 s/iter. Inference: 0.4564 s/iter. Eval: 0.0180 s/iter. Total: 0.4775 s/iter. ETA=0:14:11\n",
            "\u001b[32m[04/30 16:42:37 d2.evaluation.evaluator]: \u001b[0mInference done 3228/5000. Dataloading: 0.0021 s/iter. Inference: 0.4565 s/iter. Eval: 0.0180 s/iter. Total: 0.4776 s/iter. ETA=0:14:06\n",
            "\u001b[32m[04/30 16:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 3239/5000. Dataloading: 0.0021 s/iter. Inference: 0.4565 s/iter. Eval: 0.0180 s/iter. Total: 0.4776 s/iter. ETA=0:14:00\n",
            "\u001b[32m[04/30 16:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 3250/5000. Dataloading: 0.0021 s/iter. Inference: 0.4565 s/iter. Eval: 0.0180 s/iter. Total: 0.4775 s/iter. ETA=0:13:55\n",
            "\u001b[32m[04/30 16:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 3261/5000. Dataloading: 0.0021 s/iter. Inference: 0.4565 s/iter. Eval: 0.0180 s/iter. Total: 0.4776 s/iter. ETA=0:13:50\n",
            "\u001b[32m[04/30 16:42:58 d2.evaluation.evaluator]: \u001b[0mInference done 3272/5000. Dataloading: 0.0021 s/iter. Inference: 0.4565 s/iter. Eval: 0.0180 s/iter. Total: 0.4776 s/iter. ETA=0:13:45\n",
            "\u001b[32m[04/30 16:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 3283/5000. Dataloading: 0.0021 s/iter. Inference: 0.4566 s/iter. Eval: 0.0180 s/iter. Total: 0.4776 s/iter. ETA=0:13:40\n",
            "\u001b[32m[04/30 16:43:09 d2.evaluation.evaluator]: \u001b[0mInference done 3293/5000. Dataloading: 0.0021 s/iter. Inference: 0.4566 s/iter. Eval: 0.0181 s/iter. Total: 0.4777 s/iter. ETA=0:13:35\n",
            "\u001b[32m[04/30 16:43:14 d2.evaluation.evaluator]: \u001b[0mInference done 3304/5000. Dataloading: 0.0021 s/iter. Inference: 0.4566 s/iter. Eval: 0.0181 s/iter. Total: 0.4777 s/iter. ETA=0:13:30\n",
            "\u001b[32m[04/30 16:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 3315/5000. Dataloading: 0.0021 s/iter. Inference: 0.4567 s/iter. Eval: 0.0181 s/iter. Total: 0.4778 s/iter. ETA=0:13:25\n",
            "\u001b[32m[04/30 16:43:25 d2.evaluation.evaluator]: \u001b[0mInference done 3326/5000. Dataloading: 0.0021 s/iter. Inference: 0.4566 s/iter. Eval: 0.0181 s/iter. Total: 0.4777 s/iter. ETA=0:13:19\n",
            "\u001b[32m[04/30 16:43:30 d2.evaluation.evaluator]: \u001b[0mInference done 3337/5000. Dataloading: 0.0021 s/iter. Inference: 0.4567 s/iter. Eval: 0.0180 s/iter. Total: 0.4778 s/iter. ETA=0:13:14\n",
            "\u001b[32m[04/30 16:43:35 d2.evaluation.evaluator]: \u001b[0mInference done 3348/5000. Dataloading: 0.0021 s/iter. Inference: 0.4566 s/iter. Eval: 0.0181 s/iter. Total: 0.4777 s/iter. ETA=0:13:09\n",
            "\u001b[32m[04/30 16:43:40 d2.evaluation.evaluator]: \u001b[0mInference done 3358/5000. Dataloading: 0.0021 s/iter. Inference: 0.4567 s/iter. Eval: 0.0181 s/iter. Total: 0.4778 s/iter. ETA=0:13:04\n",
            "\u001b[32m[04/30 16:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 3369/5000. Dataloading: 0.0021 s/iter. Inference: 0.4567 s/iter. Eval: 0.0181 s/iter. Total: 0.4779 s/iter. ETA=0:12:59\n",
            "\u001b[32m[04/30 16:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 3380/5000. Dataloading: 0.0021 s/iter. Inference: 0.4567 s/iter. Eval: 0.0181 s/iter. Total: 0.4779 s/iter. ETA=0:12:54\n",
            "\u001b[32m[04/30 16:43:56 d2.evaluation.evaluator]: \u001b[0mInference done 3391/5000. Dataloading: 0.0021 s/iter. Inference: 0.4567 s/iter. Eval: 0.0181 s/iter. Total: 0.4778 s/iter. ETA=0:12:48\n",
            "\u001b[32m[04/30 16:44:01 d2.evaluation.evaluator]: \u001b[0mInference done 3402/5000. Dataloading: 0.0021 s/iter. Inference: 0.4567 s/iter. Eval: 0.0181 s/iter. Total: 0.4778 s/iter. ETA=0:12:43\n",
            "\u001b[32m[04/30 16:44:06 d2.evaluation.evaluator]: \u001b[0mInference done 3413/5000. Dataloading: 0.0021 s/iter. Inference: 0.4567 s/iter. Eval: 0.0181 s/iter. Total: 0.4778 s/iter. ETA=0:12:38\n",
            "\u001b[32m[04/30 16:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 3424/5000. Dataloading: 0.0021 s/iter. Inference: 0.4567 s/iter. Eval: 0.0181 s/iter. Total: 0.4778 s/iter. ETA=0:12:33\n",
            "\u001b[32m[04/30 16:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 3435/5000. Dataloading: 0.0021 s/iter. Inference: 0.4568 s/iter. Eval: 0.0181 s/iter. Total: 0.4779 s/iter. ETA=0:12:27\n",
            "\u001b[32m[04/30 16:44:23 d2.evaluation.evaluator]: \u001b[0mInference done 3446/5000. Dataloading: 0.0021 s/iter. Inference: 0.4568 s/iter. Eval: 0.0181 s/iter. Total: 0.4779 s/iter. ETA=0:12:22\n",
            "\u001b[32m[04/30 16:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 3457/5000. Dataloading: 0.0021 s/iter. Inference: 0.4568 s/iter. Eval: 0.0181 s/iter. Total: 0.4780 s/iter. ETA=0:12:17\n",
            "\u001b[32m[04/30 16:44:33 d2.evaluation.evaluator]: \u001b[0mInference done 3468/5000. Dataloading: 0.0021 s/iter. Inference: 0.4568 s/iter. Eval: 0.0181 s/iter. Total: 0.4779 s/iter. ETA=0:12:12\n",
            "\u001b[32m[04/30 16:44:38 d2.evaluation.evaluator]: \u001b[0mInference done 3479/5000. Dataloading: 0.0021 s/iter. Inference: 0.4568 s/iter. Eval: 0.0181 s/iter. Total: 0.4779 s/iter. ETA=0:12:06\n",
            "\u001b[32m[04/30 16:44:43 d2.evaluation.evaluator]: \u001b[0mInference done 3490/5000. Dataloading: 0.0021 s/iter. Inference: 0.4568 s/iter. Eval: 0.0180 s/iter. Total: 0.4779 s/iter. ETA=0:12:01\n",
            "\u001b[32m[04/30 16:44:49 d2.evaluation.evaluator]: \u001b[0mInference done 3501/5000. Dataloading: 0.0021 s/iter. Inference: 0.4568 s/iter. Eval: 0.0181 s/iter. Total: 0.4779 s/iter. ETA=0:11:56\n",
            "\u001b[32m[04/30 16:44:54 d2.evaluation.evaluator]: \u001b[0mInference done 3512/5000. Dataloading: 0.0021 s/iter. Inference: 0.4568 s/iter. Eval: 0.0181 s/iter. Total: 0.4779 s/iter. ETA=0:11:51\n",
            "\u001b[32m[04/30 16:44:59 d2.evaluation.evaluator]: \u001b[0mInference done 3523/5000. Dataloading: 0.0021 s/iter. Inference: 0.4568 s/iter. Eval: 0.0181 s/iter. Total: 0.4779 s/iter. ETA=0:11:45\n",
            "\u001b[32m[04/30 16:45:04 d2.evaluation.evaluator]: \u001b[0mInference done 3534/5000. Dataloading: 0.0021 s/iter. Inference: 0.4568 s/iter. Eval: 0.0180 s/iter. Total: 0.4779 s/iter. ETA=0:11:40\n",
            "\u001b[32m[04/30 16:45:10 d2.evaluation.evaluator]: \u001b[0mInference done 3545/5000. Dataloading: 0.0021 s/iter. Inference: 0.4568 s/iter. Eval: 0.0180 s/iter. Total: 0.4778 s/iter. ETA=0:11:35\n",
            "\u001b[32m[04/30 16:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 3556/5000. Dataloading: 0.0021 s/iter. Inference: 0.4568 s/iter. Eval: 0.0180 s/iter. Total: 0.4779 s/iter. ETA=0:11:30\n",
            "\u001b[32m[04/30 16:45:20 d2.evaluation.evaluator]: \u001b[0mInference done 3567/5000. Dataloading: 0.0021 s/iter. Inference: 0.4568 s/iter. Eval: 0.0180 s/iter. Total: 0.4779 s/iter. ETA=0:11:24\n",
            "\u001b[32m[04/30 16:45:26 d2.evaluation.evaluator]: \u001b[0mInference done 3578/5000. Dataloading: 0.0021 s/iter. Inference: 0.4569 s/iter. Eval: 0.0180 s/iter. Total: 0.4779 s/iter. ETA=0:11:19\n",
            "\u001b[32m[04/30 16:45:31 d2.evaluation.evaluator]: \u001b[0mInference done 3589/5000. Dataloading: 0.0021 s/iter. Inference: 0.4569 s/iter. Eval: 0.0180 s/iter. Total: 0.4779 s/iter. ETA=0:11:14\n",
            "\u001b[32m[04/30 16:45:36 d2.evaluation.evaluator]: \u001b[0mInference done 3599/5000. Dataloading: 0.0021 s/iter. Inference: 0.4569 s/iter. Eval: 0.0181 s/iter. Total: 0.4780 s/iter. ETA=0:11:09\n",
            "\u001b[32m[04/30 16:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 3610/5000. Dataloading: 0.0021 s/iter. Inference: 0.4569 s/iter. Eval: 0.0181 s/iter. Total: 0.4780 s/iter. ETA=0:11:04\n",
            "\u001b[32m[04/30 16:45:46 d2.evaluation.evaluator]: \u001b[0mInference done 3621/5000. Dataloading: 0.0021 s/iter. Inference: 0.4569 s/iter. Eval: 0.0181 s/iter. Total: 0.4779 s/iter. ETA=0:10:59\n",
            "\u001b[32m[04/30 16:45:52 d2.evaluation.evaluator]: \u001b[0mInference done 3632/5000. Dataloading: 0.0021 s/iter. Inference: 0.4569 s/iter. Eval: 0.0181 s/iter. Total: 0.4780 s/iter. ETA=0:10:53\n",
            "\u001b[32m[04/30 16:45:57 d2.evaluation.evaluator]: \u001b[0mInference done 3643/5000. Dataloading: 0.0021 s/iter. Inference: 0.4569 s/iter. Eval: 0.0181 s/iter. Total: 0.4780 s/iter. ETA=0:10:48\n",
            "\u001b[32m[04/30 16:46:02 d2.evaluation.evaluator]: \u001b[0mInference done 3654/5000. Dataloading: 0.0021 s/iter. Inference: 0.4569 s/iter. Eval: 0.0181 s/iter. Total: 0.4780 s/iter. ETA=0:10:43\n",
            "\u001b[32m[04/30 16:46:07 d2.evaluation.evaluator]: \u001b[0mInference done 3665/5000. Dataloading: 0.0021 s/iter. Inference: 0.4569 s/iter. Eval: 0.0181 s/iter. Total: 0.4780 s/iter. ETA=0:10:38\n",
            "\u001b[32m[04/30 16:46:13 d2.evaluation.evaluator]: \u001b[0mInference done 3676/5000. Dataloading: 0.0021 s/iter. Inference: 0.4570 s/iter. Eval: 0.0181 s/iter. Total: 0.4780 s/iter. ETA=0:10:32\n",
            "\u001b[32m[04/30 16:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 3687/5000. Dataloading: 0.0021 s/iter. Inference: 0.4570 s/iter. Eval: 0.0180 s/iter. Total: 0.4779 s/iter. ETA=0:10:27\n",
            "\u001b[32m[04/30 16:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 3698/5000. Dataloading: 0.0021 s/iter. Inference: 0.4570 s/iter. Eval: 0.0181 s/iter. Total: 0.4780 s/iter. ETA=0:10:22\n",
            "\u001b[32m[04/30 16:46:29 d2.evaluation.evaluator]: \u001b[0mInference done 3709/5000. Dataloading: 0.0021 s/iter. Inference: 0.4570 s/iter. Eval: 0.0181 s/iter. Total: 0.4780 s/iter. ETA=0:10:17\n",
            "\u001b[32m[04/30 16:46:34 d2.evaluation.evaluator]: \u001b[0mInference done 3720/5000. Dataloading: 0.0021 s/iter. Inference: 0.4570 s/iter. Eval: 0.0180 s/iter. Total: 0.4780 s/iter. ETA=0:10:11\n",
            "\u001b[32m[04/30 16:46:39 d2.evaluation.evaluator]: \u001b[0mInference done 3731/5000. Dataloading: 0.0021 s/iter. Inference: 0.4570 s/iter. Eval: 0.0180 s/iter. Total: 0.4780 s/iter. ETA=0:10:06\n",
            "\u001b[32m[04/30 16:46:44 d2.evaluation.evaluator]: \u001b[0mInference done 3742/5000. Dataloading: 0.0021 s/iter. Inference: 0.4570 s/iter. Eval: 0.0180 s/iter. Total: 0.4780 s/iter. ETA=0:10:01\n",
            "\u001b[32m[04/30 16:46:50 d2.evaluation.evaluator]: \u001b[0mInference done 3753/5000. Dataloading: 0.0021 s/iter. Inference: 0.4571 s/iter. Eval: 0.0180 s/iter. Total: 0.4780 s/iter. ETA=0:09:56\n",
            "\u001b[32m[04/30 16:46:55 d2.evaluation.evaluator]: \u001b[0mInference done 3764/5000. Dataloading: 0.0021 s/iter. Inference: 0.4571 s/iter. Eval: 0.0180 s/iter. Total: 0.4780 s/iter. ETA=0:09:50\n",
            "\u001b[32m[04/30 16:47:00 d2.evaluation.evaluator]: \u001b[0mInference done 3775/5000. Dataloading: 0.0021 s/iter. Inference: 0.4571 s/iter. Eval: 0.0180 s/iter. Total: 0.4780 s/iter. ETA=0:09:45\n",
            "\u001b[32m[04/30 16:47:06 d2.evaluation.evaluator]: \u001b[0mInference done 3786/5000. Dataloading: 0.0021 s/iter. Inference: 0.4571 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:09:40\n",
            "\u001b[32m[04/30 16:47:11 d2.evaluation.evaluator]: \u001b[0mInference done 3797/5000. Dataloading: 0.0021 s/iter. Inference: 0.4571 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:09:35\n",
            "\u001b[32m[04/30 16:47:16 d2.evaluation.evaluator]: \u001b[0mInference done 3808/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0181 s/iter. Total: 0.4781 s/iter. ETA=0:09:29\n",
            "\u001b[32m[04/30 16:47:22 d2.evaluation.evaluator]: \u001b[0mInference done 3819/5000. Dataloading: 0.0021 s/iter. Inference: 0.4571 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:09:24\n",
            "\u001b[32m[04/30 16:47:27 d2.evaluation.evaluator]: \u001b[0mInference done 3830/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:09:19\n",
            "\u001b[32m[04/30 16:47:32 d2.evaluation.evaluator]: \u001b[0mInference done 3841/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:09:14\n",
            "\u001b[32m[04/30 16:47:37 d2.evaluation.evaluator]: \u001b[0mInference done 3852/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:09:08\n",
            "\u001b[32m[04/30 16:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 3863/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:09:03\n",
            "\u001b[32m[04/30 16:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 3874/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:08:58\n",
            "\u001b[32m[04/30 16:47:53 d2.evaluation.evaluator]: \u001b[0mInference done 3885/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:08:53\n",
            "\u001b[32m[04/30 16:47:58 d2.evaluation.evaluator]: \u001b[0mInference done 3896/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:08:47\n",
            "\u001b[32m[04/30 16:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 3907/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:08:42\n",
            "\u001b[32m[04/30 16:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 3918/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0179 s/iter. Total: 0.4781 s/iter. ETA=0:08:37\n",
            "\u001b[32m[04/30 16:48:14 d2.evaluation.evaluator]: \u001b[0mInference done 3929/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:08:32\n",
            "\u001b[32m[04/30 16:48:19 d2.evaluation.evaluator]: \u001b[0mInference done 3940/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0179 s/iter. Total: 0.4781 s/iter. ETA=0:08:26\n",
            "\u001b[32m[04/30 16:48:25 d2.evaluation.evaluator]: \u001b[0mInference done 3951/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:08:21\n",
            "\u001b[32m[04/30 16:48:30 d2.evaluation.evaluator]: \u001b[0mInference done 3962/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:08:16\n",
            "\u001b[32m[04/30 16:48:35 d2.evaluation.evaluator]: \u001b[0mInference done 3973/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:08:10\n",
            "\u001b[32m[04/30 16:48:40 d2.evaluation.evaluator]: \u001b[0mInference done 3984/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0179 s/iter. Total: 0.4780 s/iter. ETA=0:08:05\n",
            "\u001b[32m[04/30 16:48:45 d2.evaluation.evaluator]: \u001b[0mInference done 3995/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0179 s/iter. Total: 0.4780 s/iter. ETA=0:08:00\n",
            "\u001b[32m[04/30 16:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 4006/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4780 s/iter. ETA=0:07:55\n",
            "\u001b[32m[04/30 16:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 4017/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:07:49\n",
            "\u001b[32m[04/30 16:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 4028/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:07:44\n",
            "\u001b[32m[04/30 16:49:07 d2.evaluation.evaluator]: \u001b[0mInference done 4039/5000. Dataloading: 0.0021 s/iter. Inference: 0.4572 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:07:39\n",
            "\u001b[32m[04/30 16:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 4050/5000. Dataloading: 0.0021 s/iter. Inference: 0.4573 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:07:34\n",
            "\u001b[32m[04/30 16:49:17 d2.evaluation.evaluator]: \u001b[0mInference done 4061/5000. Dataloading: 0.0021 s/iter. Inference: 0.4573 s/iter. Eval: 0.0180 s/iter. Total: 0.4781 s/iter. ETA=0:07:28\n",
            "\u001b[32m[04/30 16:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 4072/5000. Dataloading: 0.0021 s/iter. Inference: 0.4573 s/iter. Eval: 0.0180 s/iter. Total: 0.4782 s/iter. ETA=0:07:23\n",
            "\u001b[32m[04/30 16:49:28 d2.evaluation.evaluator]: \u001b[0mInference done 4083/5000. Dataloading: 0.0021 s/iter. Inference: 0.4573 s/iter. Eval: 0.0181 s/iter. Total: 0.4782 s/iter. ETA=0:07:18\n",
            "\u001b[32m[04/30 16:49:34 d2.evaluation.evaluator]: \u001b[0mInference done 4094/5000. Dataloading: 0.0021 s/iter. Inference: 0.4573 s/iter. Eval: 0.0181 s/iter. Total: 0.4782 s/iter. ETA=0:07:13\n",
            "\u001b[32m[04/30 16:49:39 d2.evaluation.evaluator]: \u001b[0mInference done 4105/5000. Dataloading: 0.0021 s/iter. Inference: 0.4573 s/iter. Eval: 0.0180 s/iter. Total: 0.4782 s/iter. ETA=0:07:08\n",
            "\u001b[32m[04/30 16:49:44 d2.evaluation.evaluator]: \u001b[0mInference done 4116/5000. Dataloading: 0.0021 s/iter. Inference: 0.4573 s/iter. Eval: 0.0180 s/iter. Total: 0.4782 s/iter. ETA=0:07:02\n",
            "\u001b[32m[04/30 16:49:49 d2.evaluation.evaluator]: \u001b[0mInference done 4127/5000. Dataloading: 0.0021 s/iter. Inference: 0.4574 s/iter. Eval: 0.0180 s/iter. Total: 0.4782 s/iter. ETA=0:06:57\n",
            "\u001b[32m[04/30 16:49:55 d2.evaluation.evaluator]: \u001b[0mInference done 4138/5000. Dataloading: 0.0021 s/iter. Inference: 0.4574 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:06:52\n",
            "\u001b[32m[04/30 16:50:00 d2.evaluation.evaluator]: \u001b[0mInference done 4149/5000. Dataloading: 0.0021 s/iter. Inference: 0.4574 s/iter. Eval: 0.0180 s/iter. Total: 0.4782 s/iter. ETA=0:06:46\n",
            "\u001b[32m[04/30 16:50:05 d2.evaluation.evaluator]: \u001b[0mInference done 4160/5000. Dataloading: 0.0021 s/iter. Inference: 0.4574 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:06:41\n",
            "\u001b[32m[04/30 16:50:10 d2.evaluation.evaluator]: \u001b[0mInference done 4170/5000. Dataloading: 0.0021 s/iter. Inference: 0.4574 s/iter. Eval: 0.0181 s/iter. Total: 0.4783 s/iter. ETA=0:06:37\n",
            "\u001b[32m[04/30 16:50:16 d2.evaluation.evaluator]: \u001b[0mInference done 4181/5000. Dataloading: 0.0021 s/iter. Inference: 0.4574 s/iter. Eval: 0.0181 s/iter. Total: 0.4783 s/iter. ETA=0:06:31\n",
            "\u001b[32m[04/30 16:50:21 d2.evaluation.evaluator]: \u001b[0mInference done 4192/5000. Dataloading: 0.0021 s/iter. Inference: 0.4574 s/iter. Eval: 0.0181 s/iter. Total: 0.4783 s/iter. ETA=0:06:26\n",
            "\u001b[32m[04/30 16:50:26 d2.evaluation.evaluator]: \u001b[0mInference done 4203/5000. Dataloading: 0.0021 s/iter. Inference: 0.4574 s/iter. Eval: 0.0181 s/iter. Total: 0.4784 s/iter. ETA=0:06:21\n",
            "\u001b[32m[04/30 16:50:31 d2.evaluation.evaluator]: \u001b[0mInference done 4214/5000. Dataloading: 0.0021 s/iter. Inference: 0.4574 s/iter. Eval: 0.0181 s/iter. Total: 0.4784 s/iter. ETA=0:06:15\n",
            "\u001b[32m[04/30 16:50:37 d2.evaluation.evaluator]: \u001b[0mInference done 4225/5000. Dataloading: 0.0021 s/iter. Inference: 0.4574 s/iter. Eval: 0.0181 s/iter. Total: 0.4784 s/iter. ETA=0:06:10\n",
            "\u001b[32m[04/30 16:50:42 d2.evaluation.evaluator]: \u001b[0mInference done 4236/5000. Dataloading: 0.0021 s/iter. Inference: 0.4574 s/iter. Eval: 0.0181 s/iter. Total: 0.4783 s/iter. ETA=0:06:05\n",
            "\u001b[32m[04/30 16:50:47 d2.evaluation.evaluator]: \u001b[0mInference done 4247/5000. Dataloading: 0.0021 s/iter. Inference: 0.4574 s/iter. Eval: 0.0181 s/iter. Total: 0.4783 s/iter. ETA=0:06:00\n",
            "\u001b[32m[04/30 16:50:53 d2.evaluation.evaluator]: \u001b[0mInference done 4258/5000. Dataloading: 0.0021 s/iter. Inference: 0.4574 s/iter. Eval: 0.0181 s/iter. Total: 0.4784 s/iter. ETA=0:05:54\n",
            "\u001b[32m[04/30 16:50:58 d2.evaluation.evaluator]: \u001b[0mInference done 4269/5000. Dataloading: 0.0021 s/iter. Inference: 0.4574 s/iter. Eval: 0.0181 s/iter. Total: 0.4784 s/iter. ETA=0:05:49\n",
            "\u001b[32m[04/30 16:51:03 d2.evaluation.evaluator]: \u001b[0mInference done 4280/5000. Dataloading: 0.0021 s/iter. Inference: 0.4574 s/iter. Eval: 0.0181 s/iter. Total: 0.4784 s/iter. ETA=0:05:44\n",
            "\u001b[32m[04/30 16:51:09 d2.evaluation.evaluator]: \u001b[0mInference done 4291/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0181 s/iter. Total: 0.4784 s/iter. ETA=0:05:39\n",
            "\u001b[32m[04/30 16:51:14 d2.evaluation.evaluator]: \u001b[0mInference done 4302/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0181 s/iter. Total: 0.4784 s/iter. ETA=0:05:33\n",
            "\u001b[32m[04/30 16:51:19 d2.evaluation.evaluator]: \u001b[0mInference done 4313/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0181 s/iter. Total: 0.4784 s/iter. ETA=0:05:28\n",
            "\u001b[32m[04/30 16:51:24 d2.evaluation.evaluator]: \u001b[0mInference done 4324/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0181 s/iter. Total: 0.4784 s/iter. ETA=0:05:23\n",
            "\u001b[32m[04/30 16:51:29 d2.evaluation.evaluator]: \u001b[0mInference done 4335/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0181 s/iter. Total: 0.4784 s/iter. ETA=0:05:18\n",
            "\u001b[32m[04/30 16:51:35 d2.evaluation.evaluator]: \u001b[0mInference done 4346/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:05:12\n",
            "\u001b[32m[04/30 16:51:40 d2.evaluation.evaluator]: \u001b[0mInference done 4357/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:05:07\n",
            "\u001b[32m[04/30 16:51:45 d2.evaluation.evaluator]: \u001b[0mInference done 4368/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:05:02\n",
            "\u001b[32m[04/30 16:51:50 d2.evaluation.evaluator]: \u001b[0mInference done 4379/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:04:57\n",
            "\u001b[32m[04/30 16:51:55 d2.evaluation.evaluator]: \u001b[0mInference done 4390/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:04:51\n",
            "\u001b[32m[04/30 16:52:01 d2.evaluation.evaluator]: \u001b[0mInference done 4401/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:04:46\n",
            "\u001b[32m[04/30 16:52:06 d2.evaluation.evaluator]: \u001b[0mInference done 4412/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:04:41\n",
            "\u001b[32m[04/30 16:52:11 d2.evaluation.evaluator]: \u001b[0mInference done 4423/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:04:35\n",
            "\u001b[32m[04/30 16:52:17 d2.evaluation.evaluator]: \u001b[0mInference done 4434/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:04:30\n",
            "\u001b[32m[04/30 16:52:22 d2.evaluation.evaluator]: \u001b[0mInference done 4445/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:04:25\n",
            "\u001b[32m[04/30 16:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 4456/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:04:20\n",
            "\u001b[32m[04/30 16:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 4467/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:04:14\n",
            "\u001b[32m[04/30 16:52:38 d2.evaluation.evaluator]: \u001b[0mInference done 4478/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:04:09\n",
            "\u001b[32m[04/30 16:52:43 d2.evaluation.evaluator]: \u001b[0mInference done 4489/5000. Dataloading: 0.0021 s/iter. Inference: 0.4575 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:04:04\n",
            "\u001b[32m[04/30 16:52:48 d2.evaluation.evaluator]: \u001b[0mInference done 4500/5000. Dataloading: 0.0021 s/iter. Inference: 0.4576 s/iter. Eval: 0.0180 s/iter. Total: 0.4784 s/iter. ETA=0:03:59\n",
            "\u001b[32m[04/30 16:52:54 d2.evaluation.evaluator]: \u001b[0mInference done 4511/5000. Dataloading: 0.0021 s/iter. Inference: 0.4576 s/iter. Eval: 0.0180 s/iter. Total: 0.4784 s/iter. ETA=0:03:53\n",
            "\u001b[32m[04/30 16:52:59 d2.evaluation.evaluator]: \u001b[0mInference done 4522/5000. Dataloading: 0.0021 s/iter. Inference: 0.4576 s/iter. Eval: 0.0180 s/iter. Total: 0.4784 s/iter. ETA=0:03:48\n",
            "\u001b[32m[04/30 16:53:04 d2.evaluation.evaluator]: \u001b[0mInference done 4533/5000. Dataloading: 0.0021 s/iter. Inference: 0.4576 s/iter. Eval: 0.0180 s/iter. Total: 0.4783 s/iter. ETA=0:03:43\n",
            "\u001b[32m[04/30 16:53:09 d2.evaluation.evaluator]: \u001b[0mInference done 4544/5000. Dataloading: 0.0021 s/iter. Inference: 0.4576 s/iter. Eval: 0.0180 s/iter. Total: 0.4784 s/iter. ETA=0:03:38\n",
            "\u001b[32m[04/30 16:53:15 d2.evaluation.evaluator]: \u001b[0mInference done 4555/5000. Dataloading: 0.0021 s/iter. Inference: 0.4576 s/iter. Eval: 0.0180 s/iter. Total: 0.4784 s/iter. ETA=0:03:32\n",
            "\u001b[32m[04/30 16:53:20 d2.evaluation.evaluator]: \u001b[0mInference done 4566/5000. Dataloading: 0.0021 s/iter. Inference: 0.4576 s/iter. Eval: 0.0180 s/iter. Total: 0.4784 s/iter. ETA=0:03:27\n",
            "\u001b[32m[04/30 16:53:26 d2.evaluation.evaluator]: \u001b[0mInference done 4577/5000. Dataloading: 0.0021 s/iter. Inference: 0.4576 s/iter. Eval: 0.0180 s/iter. Total: 0.4784 s/iter. ETA=0:03:22\n",
            "\u001b[32m[04/30 16:53:31 d2.evaluation.evaluator]: \u001b[0mInference done 4588/5000. Dataloading: 0.0021 s/iter. Inference: 0.4576 s/iter. Eval: 0.0181 s/iter. Total: 0.4785 s/iter. ETA=0:03:17\n",
            "\u001b[32m[04/30 16:53:36 d2.evaluation.evaluator]: \u001b[0mInference done 4599/5000. Dataloading: 0.0021 s/iter. Inference: 0.4576 s/iter. Eval: 0.0180 s/iter. Total: 0.4785 s/iter. ETA=0:03:11\n",
            "\u001b[32m[04/30 16:53:42 d2.evaluation.evaluator]: \u001b[0mInference done 4609/5000. Dataloading: 0.0021 s/iter. Inference: 0.4577 s/iter. Eval: 0.0180 s/iter. Total: 0.4786 s/iter. ETA=0:03:07\n",
            "\u001b[32m[04/30 16:53:47 d2.evaluation.evaluator]: \u001b[0mInference done 4620/5000. Dataloading: 0.0021 s/iter. Inference: 0.4576 s/iter. Eval: 0.0180 s/iter. Total: 0.4786 s/iter. ETA=0:03:01\n",
            "\u001b[32m[04/30 16:53:52 d2.evaluation.evaluator]: \u001b[0mInference done 4631/5000. Dataloading: 0.0021 s/iter. Inference: 0.4577 s/iter. Eval: 0.0180 s/iter. Total: 0.4786 s/iter. ETA=0:02:56\n",
            "\u001b[32m[04/30 16:53:57 d2.evaluation.evaluator]: \u001b[0mInference done 4642/5000. Dataloading: 0.0021 s/iter. Inference: 0.4577 s/iter. Eval: 0.0180 s/iter. Total: 0.4786 s/iter. ETA=0:02:51\n",
            "\u001b[32m[04/30 16:54:03 d2.evaluation.evaluator]: \u001b[0mInference done 4653/5000. Dataloading: 0.0021 s/iter. Inference: 0.4577 s/iter. Eval: 0.0180 s/iter. Total: 0.4786 s/iter. ETA=0:02:46\n",
            "\u001b[32m[04/30 16:54:08 d2.evaluation.evaluator]: \u001b[0mInference done 4664/5000. Dataloading: 0.0021 s/iter. Inference: 0.4577 s/iter. Eval: 0.0181 s/iter. Total: 0.4786 s/iter. ETA=0:02:40\n",
            "\u001b[32m[04/30 16:54:13 d2.evaluation.evaluator]: \u001b[0mInference done 4675/5000. Dataloading: 0.0021 s/iter. Inference: 0.4577 s/iter. Eval: 0.0181 s/iter. Total: 0.4786 s/iter. ETA=0:02:35\n",
            "\u001b[32m[04/30 16:54:19 d2.evaluation.evaluator]: \u001b[0mInference done 4686/5000. Dataloading: 0.0021 s/iter. Inference: 0.4577 s/iter. Eval: 0.0180 s/iter. Total: 0.4786 s/iter. ETA=0:02:30\n",
            "\u001b[32m[04/30 16:54:24 d2.evaluation.evaluator]: \u001b[0mInference done 4697/5000. Dataloading: 0.0021 s/iter. Inference: 0.4577 s/iter. Eval: 0.0181 s/iter. Total: 0.4787 s/iter. ETA=0:02:25\n",
            "\u001b[32m[04/30 16:54:29 d2.evaluation.evaluator]: \u001b[0mInference done 4708/5000. Dataloading: 0.0021 s/iter. Inference: 0.4577 s/iter. Eval: 0.0180 s/iter. Total: 0.4786 s/iter. ETA=0:02:19\n",
            "\u001b[32m[04/30 16:54:35 d2.evaluation.evaluator]: \u001b[0mInference done 4719/5000. Dataloading: 0.0021 s/iter. Inference: 0.4577 s/iter. Eval: 0.0181 s/iter. Total: 0.4787 s/iter. ETA=0:02:14\n",
            "\u001b[32m[04/30 16:54:40 d2.evaluation.evaluator]: \u001b[0mInference done 4730/5000. Dataloading: 0.0021 s/iter. Inference: 0.4577 s/iter. Eval: 0.0181 s/iter. Total: 0.4787 s/iter. ETA=0:02:09\n",
            "\u001b[32m[04/30 16:54:45 d2.evaluation.evaluator]: \u001b[0mInference done 4741/5000. Dataloading: 0.0021 s/iter. Inference: 0.4577 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:02:03\n",
            "\u001b[32m[04/30 16:54:50 d2.evaluation.evaluator]: \u001b[0mInference done 4752/5000. Dataloading: 0.0021 s/iter. Inference: 0.4577 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:01:58\n",
            "\u001b[32m[04/30 16:54:56 d2.evaluation.evaluator]: \u001b[0mInference done 4763/5000. Dataloading: 0.0021 s/iter. Inference: 0.4578 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:01:53\n",
            "\u001b[32m[04/30 16:55:01 d2.evaluation.evaluator]: \u001b[0mInference done 4774/5000. Dataloading: 0.0021 s/iter. Inference: 0.4578 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:01:48\n",
            "\u001b[32m[04/30 16:55:06 d2.evaluation.evaluator]: \u001b[0mInference done 4785/5000. Dataloading: 0.0021 s/iter. Inference: 0.4578 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:01:42\n",
            "\u001b[32m[04/30 16:55:11 d2.evaluation.evaluator]: \u001b[0mInference done 4796/5000. Dataloading: 0.0021 s/iter. Inference: 0.4578 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:01:37\n",
            "\u001b[32m[04/30 16:55:17 d2.evaluation.evaluator]: \u001b[0mInference done 4807/5000. Dataloading: 0.0021 s/iter. Inference: 0.4578 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:01:32\n",
            "\u001b[32m[04/30 16:55:22 d2.evaluation.evaluator]: \u001b[0mInference done 4818/5000. Dataloading: 0.0021 s/iter. Inference: 0.4578 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:01:27\n",
            "\u001b[32m[04/30 16:55:27 d2.evaluation.evaluator]: \u001b[0mInference done 4829/5000. Dataloading: 0.0021 s/iter. Inference: 0.4578 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:01:21\n",
            "\u001b[32m[04/30 16:55:32 d2.evaluation.evaluator]: \u001b[0mInference done 4840/5000. Dataloading: 0.0021 s/iter. Inference: 0.4578 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:01:16\n",
            "\u001b[32m[04/30 16:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 4851/5000. Dataloading: 0.0021 s/iter. Inference: 0.4578 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:01:11\n",
            "\u001b[32m[04/30 16:55:43 d2.evaluation.evaluator]: \u001b[0mInference done 4862/5000. Dataloading: 0.0021 s/iter. Inference: 0.4578 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:01:06\n",
            "\u001b[32m[04/30 16:55:48 d2.evaluation.evaluator]: \u001b[0mInference done 4873/5000. Dataloading: 0.0021 s/iter. Inference: 0.4578 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:01:00\n",
            "\u001b[32m[04/30 16:55:54 d2.evaluation.evaluator]: \u001b[0mInference done 4884/5000. Dataloading: 0.0021 s/iter. Inference: 0.4579 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:00:55\n",
            "\u001b[32m[04/30 16:55:59 d2.evaluation.evaluator]: \u001b[0mInference done 4895/5000. Dataloading: 0.0021 s/iter. Inference: 0.4579 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:00:50\n",
            "\u001b[32m[04/30 16:56:04 d2.evaluation.evaluator]: \u001b[0mInference done 4906/5000. Dataloading: 0.0021 s/iter. Inference: 0.4579 s/iter. Eval: 0.0180 s/iter. Total: 0.4787 s/iter. ETA=0:00:45\n",
            "\u001b[32m[04/30 16:56:10 d2.evaluation.evaluator]: \u001b[0mInference done 4917/5000. Dataloading: 0.0021 s/iter. Inference: 0.4579 s/iter. Eval: 0.0180 s/iter. Total: 0.4788 s/iter. ETA=0:00:39\n",
            "\u001b[32m[04/30 16:56:15 d2.evaluation.evaluator]: \u001b[0mInference done 4928/5000. Dataloading: 0.0021 s/iter. Inference: 0.4579 s/iter. Eval: 0.0180 s/iter. Total: 0.4788 s/iter. ETA=0:00:34\n",
            "\u001b[32m[04/30 16:56:20 d2.evaluation.evaluator]: \u001b[0mInference done 4939/5000. Dataloading: 0.0021 s/iter. Inference: 0.4579 s/iter. Eval: 0.0180 s/iter. Total: 0.4788 s/iter. ETA=0:00:29\n",
            "\u001b[32m[04/30 16:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 4950/5000. Dataloading: 0.0021 s/iter. Inference: 0.4579 s/iter. Eval: 0.0180 s/iter. Total: 0.4788 s/iter. ETA=0:00:23\n",
            "\u001b[32m[04/30 16:56:31 d2.evaluation.evaluator]: \u001b[0mInference done 4961/5000. Dataloading: 0.0021 s/iter. Inference: 0.4579 s/iter. Eval: 0.0180 s/iter. Total: 0.4788 s/iter. ETA=0:00:18\n",
            "\u001b[32m[04/30 16:56:36 d2.evaluation.evaluator]: \u001b[0mInference done 4972/5000. Dataloading: 0.0021 s/iter. Inference: 0.4579 s/iter. Eval: 0.0180 s/iter. Total: 0.4788 s/iter. ETA=0:00:13\n",
            "\u001b[32m[04/30 16:56:41 d2.evaluation.evaluator]: \u001b[0mInference done 4983/5000. Dataloading: 0.0021 s/iter. Inference: 0.4579 s/iter. Eval: 0.0180 s/iter. Total: 0.4788 s/iter. ETA=0:00:08\n",
            "\u001b[32m[04/30 16:56:47 d2.evaluation.evaluator]: \u001b[0mInference done 4994/5000. Dataloading: 0.0021 s/iter. Inference: 0.4579 s/iter. Eval: 0.0180 s/iter. Total: 0.4788 s/iter. ETA=0:00:02\n",
            "\u001b[32m[04/30 16:56:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:39:51.710562 (0.478821 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 16:56:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:38:07 (0.457944 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 16:56:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/30 16:56:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/30 16:56:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.10s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 16:56:53 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/30 16:57:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 7.83 seconds.\n",
            "\u001b[32m[04/30 16:57:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 16:57:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.89 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.668\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.526\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.522\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.631\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.369\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.584\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.425\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761\n",
            "\u001b[32m[04/30 16:57:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 48.443 | 66.804 | 52.601 | 30.653 | 52.200 | 63.081 |\n",
            "\u001b[32m[04/30 16:57:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 61.008 | bicycle      | 36.585 | car            | 51.259 |\n",
            "| motorcycle    | 50.293 | airplane     | 73.939 | bus            | 71.853 |\n",
            "| train         | 70.746 | truck        | 42.704 | boat           | 33.138 |\n",
            "| traffic light | 31.832 | fire hydrant | 73.274 | stop sign      | 69.071 |\n",
            "| parking meter | 46.638 | bench        | 30.708 | bird           | 43.918 |\n",
            "| cat           | 78.270 | dog          | 70.247 | horse          | 64.166 |\n",
            "| sheep         | 59.052 | cow          | 65.360 | elephant       | 69.932 |\n",
            "| bear          | 73.197 | zebra        | 72.499 | giraffe        | 74.661 |\n",
            "| backpack      | 19.481 | umbrella     | 46.751 | handbag        | 20.676 |\n",
            "| tie           | 43.393 | suitcase     | 47.754 | frisbee        | 72.189 |\n",
            "| skis          | 29.824 | snowboard    | 50.381 | sports ball    | 52.738 |\n",
            "| kite          | 52.311 | baseball bat | 40.836 | baseball glove | 45.667 |\n",
            "| skateboard    | 63.117 | surfboard    | 46.307 | tennis racket  | 59.716 |\n",
            "| bottle        | 45.558 | wine glass   | 42.779 | cup            | 49.783 |\n",
            "| fork          | 44.735 | knife        | 29.781 | spoon          | 24.527 |\n",
            "| bowl          | 47.705 | banana       | 30.387 | apple          | 25.080 |\n",
            "| sandwich      | 39.635 | orange       | 31.880 | broccoli       | 26.915 |\n",
            "| carrot        | 27.046 | hot dog      | 44.326 | pizza          | 58.460 |\n",
            "| donut         | 55.028 | cake         | 41.690 | chair          | 34.365 |\n",
            "| couch         | 47.064 | potted plant | 32.961 | bed            | 48.911 |\n",
            "| dining table  | 32.987 | toilet       | 67.054 | tv             | 60.544 |\n",
            "| laptop        | 68.109 | mouse        | 66.965 | remote         | 45.298 |\n",
            "| keyboard      | 56.297 | cell phone   | 42.750 | microwave      | 59.237 |\n",
            "| oven          | 38.549 | toaster      | 37.481 | sink           | 42.601 |\n",
            "| refrigerator  | 66.234 | book         | 19.952 | clock          | 55.589 |\n",
            "| vase          | 43.445 | scissors     | 35.382 | teddy bear     | 55.370 |\n",
            "| hair drier    | 9.829  | toothbrush   | 37.681 |                |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=1.08s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 16:57:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
            "\u001b[32m[04/30 16:57:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 9.32 seconds.\n",
            "\u001b[32m[04/30 16:57:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 16:57:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.87 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.415\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.640\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.450\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.223\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.444\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.327\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.507\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.352\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.562\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.677\n",
            "\u001b[32m[04/30 16:57:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 41.524 | 64.028 | 45.023 | 22.329 | 44.408 | 58.938 |\n",
            "\u001b[32m[04/30 16:57:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 50.252 | bicycle      | 20.104 | car            | 45.404 |\n",
            "| motorcycle    | 37.534 | airplane     | 54.789 | bus            | 67.144 |\n",
            "| train         | 66.002 | truck        | 40.115 | boat           | 27.122 |\n",
            "| traffic light | 30.183 | fire hydrant | 67.429 | stop sign      | 67.472 |\n",
            "| parking meter | 46.561 | bench        | 21.202 | bird           | 34.671 |\n",
            "| cat           | 72.246 | dog          | 62.309 | horse          | 45.954 |\n",
            "| sheep         | 49.160 | cow          | 53.653 | elephant       | 61.423 |\n",
            "| bear          | 69.042 | zebra        | 60.408 | giraffe        | 56.089 |\n",
            "| backpack      | 18.953 | umbrella     | 49.345 | handbag        | 18.568 |\n",
            "| tie           | 37.673 | suitcase     | 48.073 | frisbee        | 66.787 |\n",
            "| skis          | 5.104  | snowboard    | 30.857 | sports ball    | 51.808 |\n",
            "| kite          | 36.409 | baseball bat | 30.329 | baseball glove | 46.234 |\n",
            "| skateboard    | 37.585 | surfboard    | 37.058 | tennis racket  | 59.762 |\n",
            "| bottle        | 42.251 | wine glass   | 36.725 | cup            | 47.785 |\n",
            "| fork          | 21.584 | knife        | 18.170 | spoon          | 14.774 |\n",
            "| bowl          | 42.524 | banana       | 22.614 | apple          | 23.256 |\n",
            "| sandwich      | 40.521 | orange       | 30.825 | broccoli       | 24.549 |\n",
            "| carrot        | 23.423 | hot dog      | 34.232 | pizza          | 53.770 |\n",
            "| donut         | 52.679 | cake         | 40.287 | chair          | 23.294 |\n",
            "| couch         | 38.172 | potted plant | 26.238 | bed            | 36.926 |\n",
            "| dining table  | 18.649 | toilet       | 61.150 | tv             | 60.675 |\n",
            "| laptop        | 63.749 | mouse        | 65.099 | remote         | 38.103 |\n",
            "| keyboard      | 51.821 | cell phone   | 39.676 | microwave      | 57.928 |\n",
            "| oven          | 33.409 | toaster      | 41.576 | sink           | 39.324 |\n",
            "| refrigerator  | 63.178 | book         | 13.517 | clock          | 53.964 |\n",
            "| vase          | 41.269 | scissors     | 24.569 | teddy bear     | 51.204 |\n",
            "| hair drier    | 5.794  | toothbrush   | 21.887 |                |        |\n",
            "\u001b[32m[04/30 16:57:19 d2.engine.defaults]: \u001b[0mEvaluation results for coco_2017_val in csv format:\n",
            "\u001b[32m[04/30 16:57:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/30 16:57:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 16:57:19 d2.evaluation.testing]: \u001b[0mcopypaste: 48.4433,66.8035,52.6005,30.6532,52.1998,63.0812\n",
            "\u001b[32m[04/30 16:57:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[04/30 16:57:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 16:57:19 d2.evaluation.testing]: \u001b[0mcopypaste: 41.5244,64.0281,45.0233,22.3294,44.4083,58.9381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mask_cascade_rcnn_ResNeSt_101 - evaluation results for coco_2017_val in csv format:\n",
        "\n",
        "Task\\metrics  | AP | AP50 | AP75 | APs | APm | APl |\n",
        "--------------|----|------|------|-----|-----|-----|\n",
        "**bbox**    | 48.4433 | 66.8035 | 52.6005 | 30.6532 | 52.1998 | 63.0812 \n",
        "**segm**   | 41.5244 | 64.0281 | 45.0233 | 22.3294 | 44.4083 | 58.9381 "
      ],
      "metadata": {
        "id": "3qtFUxrAF4MC"
      },
      "id": "3qtFUxrAF4MC"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_50_FPN_syncBN_1x-f442d863.pth"
      ],
      "metadata": {
        "id": "gD8MnapUX1uK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62e2a4d-d1eb-4f2b-de34-b79971df0534"
      },
      "id": "gD8MnapUX1uK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command Line Args: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_50_FPN_syncBN_1x-f442d863.pth'], resume=False)\n",
            "\u001b[32m[04/30 17:18:09 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[04/30 17:18:10 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ----------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "numpy                   1.21.6\n",
            "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.5\n",
            "CUDA compiler           CUDA 11.1\n",
            "detectron2 arch flags   7.5\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.11.0+cu113 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           Yes\n",
            "GPU 0                   Tesla T4 (arch=7.5)\n",
            "Driver version          460.32.03\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.12.0+cu113 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
            "fvcore                  0.1.5.post20220414\n",
            "iopath                  0.1.9\n",
            "cv2                     4.1.2\n",
            "----------------------  ----------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.3\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.2\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "\u001b[32m[04/30 17:18:10 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_50_FPN_syncBN_1x-f442d863.pth'], resume=False)\n",
            "\u001b[32m[04/30 17:18:10 detectron2]: \u001b[0mContents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml:\n",
            "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186m../ResNest-Base-RCNN-FPN.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mhttps://s3.us-west-1.wasabisys.com/resnest/detectron/resnest50_detectron-255b5649.pth\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\u001b[38;5;15m        \u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mFastRCNNConvFCHead\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m123.68\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m116.779\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m103.939\u001b[39m]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m58.393\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.12\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.375\u001b[39m]\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\u001b[38;5;15m    \u001b[39m\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mRGB\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\n",
            "\u001b[32m[04/30 17:18:10 detectron2]: \u001b[0mRunning with full config:\n",
            "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRGB\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mpolygon\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m672\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m704\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m736\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m768\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mchoice\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnest_fpn_backbone\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGeneralizedRCNN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.68\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.779\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.939\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m58.393\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.12\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.375\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRPN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVG_DOWN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOTTLENECK_WIDTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEEP_STEM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_NUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFastRCNNConvFCHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_FED_LOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_SIGMOID_CE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardROIHeads\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./checkpoints/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_50_FPN_syncBN_1x-f442d863.pth\n",
            "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./output\n",
            "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR_END\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m90000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m60000\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m80000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\n",
            "\u001b[32m[04/30 17:18:10 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[04/30 17:18:10 d2.utils.env]: \u001b[0mUsing a generated random seed 10758725\n",
            "\u001b[32m[04/30 17:18:15 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(\n",
            "      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output2): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral3): Conv2d(\n",
            "      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output3): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral4): Conv2d(\n",
            "      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output4): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral5): Conv2d(\n",
            "      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output5): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNeSt(\n",
            "      (stem): BasicStem(\n",
            "        (conv1_1): Conv2d(\n",
            "          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "        )\n",
            "        (conv1_2): Conv2d(\n",
            "          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "        )\n",
            "        (conv1_3): Conv2d(\n",
            "          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (conv1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (conv4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/30 17:18:15 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from ./checkpoints/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_50_FPN_syncBN_1x-f442d863.pth ...\n",
            "\u001b[32m[04/30 17:18:16 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
            "| Names in Model                                  | Names in Checkpoint                                                                                                           | Shapes                                             |\n",
            "|:------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------|\n",
            "| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,1,1)                |\n",
            "| backbone.bottom_up.res2.0.conv2.bn0.*           | backbone.bottom_up.res2.0.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.0.conv2.bn1.*           | backbone.bottom_up.res2.0.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.0.conv2.conv.weight     | backbone.bottom_up.res2.0.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.0.conv2.fc1.*           | backbone.bottom_up.res2.0.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.0.conv2.fc2.*           | backbone.bottom_up.res2.0.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.1.conv2.bn0.*           | backbone.bottom_up.res2.1.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.1.conv2.bn1.*           | backbone.bottom_up.res2.1.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.1.conv2.conv.weight     | backbone.bottom_up.res2.1.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.1.conv2.fc1.*           | backbone.bottom_up.res2.1.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.1.conv2.fc2.*           | backbone.bottom_up.res2.1.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.2.conv2.bn0.*           | backbone.bottom_up.res2.2.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.2.conv2.bn1.*           | backbone.bottom_up.res2.2.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.2.conv2.conv.weight     | backbone.bottom_up.res2.2.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.2.conv2.fc1.*           | backbone.bottom_up.res2.2.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.2.conv2.fc2.*           | backbone.bottom_up.res2.2.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv2.bn0.*           | backbone.bottom_up.res3.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.0.conv2.bn1.*           | backbone.bottom_up.res3.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.0.conv2.conv.weight     | backbone.bottom_up.res3.0.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.0.conv2.fc1.*           | backbone.bottom_up.res3.0.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.0.conv2.fc2.*           | backbone.bottom_up.res3.0.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv2.bn0.*           | backbone.bottom_up.res3.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.1.conv2.bn1.*           | backbone.bottom_up.res3.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.1.conv2.conv.weight     | backbone.bottom_up.res3.1.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.1.conv2.fc1.*           | backbone.bottom_up.res3.1.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.1.conv2.fc2.*           | backbone.bottom_up.res3.1.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv2.bn0.*           | backbone.bottom_up.res3.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.2.conv2.bn1.*           | backbone.bottom_up.res3.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.2.conv2.conv.weight     | backbone.bottom_up.res3.2.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.2.conv2.fc1.*           | backbone.bottom_up.res3.2.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.2.conv2.fc2.*           | backbone.bottom_up.res3.2.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv2.bn0.*           | backbone.bottom_up.res3.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.3.conv2.bn1.*           | backbone.bottom_up.res3.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.3.conv2.conv.weight     | backbone.bottom_up.res3.3.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.3.conv2.fc1.*           | backbone.bottom_up.res3.3.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.3.conv2.fc2.*           | backbone.bottom_up.res3.3.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv2.bn0.*           | backbone.bottom_up.res4.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.bn1.*           | backbone.bottom_up.res4.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.conv.weight     | backbone.bottom_up.res4.0.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.0.conv2.fc1.*           | backbone.bottom_up.res4.0.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv2.fc2.*           | backbone.bottom_up.res4.0.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.1.conv2.bn0.*           | backbone.bottom_up.res4.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.bn1.*           | backbone.bottom_up.res4.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.conv.weight     | backbone.bottom_up.res4.1.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.1.conv2.fc1.*           | backbone.bottom_up.res4.1.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv2.fc2.*           | backbone.bottom_up.res4.1.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.2.conv2.bn0.*           | backbone.bottom_up.res4.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.bn1.*           | backbone.bottom_up.res4.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.conv.weight     | backbone.bottom_up.res4.2.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.2.conv2.fc1.*           | backbone.bottom_up.res4.2.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv2.fc2.*           | backbone.bottom_up.res4.2.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.3.conv2.bn0.*           | backbone.bottom_up.res4.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.bn1.*           | backbone.bottom_up.res4.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.conv.weight     | backbone.bottom_up.res4.3.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.3.conv2.fc1.*           | backbone.bottom_up.res4.3.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv2.fc2.*           | backbone.bottom_up.res4.3.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.4.conv2.bn0.*           | backbone.bottom_up.res4.4.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.bn1.*           | backbone.bottom_up.res4.4.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.conv.weight     | backbone.bottom_up.res4.4.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.4.conv2.fc1.*           | backbone.bottom_up.res4.4.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv2.fc2.*           | backbone.bottom_up.res4.4.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.5.conv2.bn0.*           | backbone.bottom_up.res4.5.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.bn1.*           | backbone.bottom_up.res4.5.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.conv.weight     | backbone.bottom_up.res4.5.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.5.conv2.fc1.*           | backbone.bottom_up.res4.5.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv2.fc2.*           | backbone.bottom_up.res4.5.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| backbone.bottom_up.res5.0.conv2.bn0.*           | backbone.bottom_up.res5.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.0.conv2.bn1.*           | backbone.bottom_up.res5.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.0.conv2.conv.weight     | backbone.bottom_up.res5.0.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.0.conv2.fc1.*           | backbone.bottom_up.res5.0.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.0.conv2.fc2.*           | backbone.bottom_up.res5.0.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.1.conv2.bn0.*           | backbone.bottom_up.res5.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.1.conv2.bn1.*           | backbone.bottom_up.res5.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.1.conv2.conv.weight     | backbone.bottom_up.res5.1.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.1.conv2.fc1.*           | backbone.bottom_up.res5.1.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.1.conv2.fc2.*           | backbone.bottom_up.res5.1.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.2.conv2.bn0.*           | backbone.bottom_up.res5.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.2.conv2.bn1.*           | backbone.bottom_up.res5.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.2.conv2.conv.weight     | backbone.bottom_up.res5.2.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.2.conv2.fc1.*           | backbone.bottom_up.res5.2.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.2.conv2.fc2.*           | backbone.bottom_up.res5.2.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.stem.conv1_1.*               | backbone.bottom_up.stem.conv1_1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (32,) (32,) (32,) (32,) (32,3,3,3)                 |\n",
            "| backbone.bottom_up.stem.conv1_2.*               | backbone.bottom_up.stem.conv1_2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (32,) (32,) (32,) (32,) (32,32,3,3)                |\n",
            "| backbone.bottom_up.stem.conv1_3.*               | backbone.bottom_up.stem.conv1_3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,32,3,3)                |\n",
            "| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,2048,1,1)      |\n",
            "| backbone.fpn_output2.*                          | backbone.fpn_output2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output3.*                          | backbone.fpn_output3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output4.*                          | backbone.fpn_output4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output5.*                          | backbone.fpn_output5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                                                       | (12,) (12,256,1,1)                                 |\n",
            "| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                                                | (256,) (256,256,3,3)                               |\n",
            "| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                                                   | (3,) (3,256,1,1)                                   |\n",
            "| roi_heads.box_head.conv1.*                      | roi_heads.box_head.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.conv2.*                      | roi_heads.box_head.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.conv3.*                      | roi_heads.box_head.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.conv4.*                      | roi_heads.box_head.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                                          | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                                               | (320,) (320,1024)                                  |\n",
            "| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                                               | (81,) (81,1024)                                    |\n",
            "| roi_heads.mask_head.deconv.*                    | roi_heads.mask_head.deconv.{bias,weight}                                                                                      | (256,) (256,256,2,2)                               |\n",
            "| roi_heads.mask_head.mask_fcn1.*                 | roi_heads.mask_head.mask_fcn1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.mask_fcn2.*                 | roi_heads.mask_head.mask_fcn2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.mask_fcn3.*                 | roi_heads.mask_head.mask_fcn3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.mask_fcn4.*                 | roi_heads.mask_head.mask_fcn4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.predictor.*                 | roi_heads.mask_head.predictor.{bias,weight}                                                                                   | (80,) (80,256,1,1)                                 |\n",
            "\u001b[32m[04/30 17:18:17 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json\n",
            "\u001b[32m[04/30 17:18:17 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n",
            "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
            "|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\n",
            "|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\n",
            "|     train     | 190          |    truck     | 414          |     boat      | 424          |\n",
            "| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\n",
            "| parking meter | 60           |    bench     | 411          |     bird      | 427          |\n",
            "|      cat      | 202          |     dog      | 218          |     horse     | 272          |\n",
            "|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\n",
            "|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\n",
            "|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\n",
            "|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\n",
            "|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\n",
            "|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\n",
            "|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\n",
            "|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\n",
            "|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\n",
            "|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\n",
            "|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\n",
            "|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\n",
            "|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\n",
            "|     couch     | 261          | potted plant | 342          |      bed      | 163          |\n",
            "| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\n",
            "|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\n",
            "|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\n",
            "|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\n",
            "| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\n",
            "|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\n",
            "|  hair drier   | 11           |  toothbrush  | 57           |               |              |\n",
            "|     total     | 36335        |              |              |               |              |\u001b[0m\n",
            "\u001b[32m[04/30 17:18:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/30 17:18:17 d2.data.common]: \u001b[0mSerializing 5000 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/30 17:18:17 d2.data.common]: \u001b[0mSerialized dataset takes 19.10 MiB\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[32m[04/30 17:18:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 5000 batches\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m[04/30 17:18:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/5000. Dataloading: 0.0013 s/iter. Inference: 0.1951 s/iter. Eval: 0.0190 s/iter. Total: 0.2154 s/iter. ETA=0:17:54\n",
            "\u001b[32m[04/30 17:18:27 d2.evaluation.evaluator]: \u001b[0mInference done 35/5000. Dataloading: 0.0017 s/iter. Inference: 0.1966 s/iter. Eval: 0.0186 s/iter. Total: 0.2169 s/iter. ETA=0:17:57\n",
            "\u001b[32m[04/30 17:18:32 d2.evaluation.evaluator]: \u001b[0mInference done 58/5000. Dataloading: 0.0018 s/iter. Inference: 0.1977 s/iter. Eval: 0.0184 s/iter. Total: 0.2180 s/iter. ETA=0:17:57\n",
            "\u001b[32m[04/30 17:18:37 d2.evaluation.evaluator]: \u001b[0mInference done 82/5000. Dataloading: 0.0019 s/iter. Inference: 0.1980 s/iter. Eval: 0.0177 s/iter. Total: 0.2177 s/iter. ETA=0:17:50\n",
            "\u001b[32m[04/30 17:18:42 d2.evaluation.evaluator]: \u001b[0mInference done 105/5000. Dataloading: 0.0019 s/iter. Inference: 0.1980 s/iter. Eval: 0.0201 s/iter. Total: 0.2201 s/iter. ETA=0:17:57\n",
            "\u001b[32m[04/30 17:18:47 d2.evaluation.evaluator]: \u001b[0mInference done 128/5000. Dataloading: 0.0019 s/iter. Inference: 0.1985 s/iter. Eval: 0.0196 s/iter. Total: 0.2201 s/iter. ETA=0:17:52\n",
            "\u001b[32m[04/30 17:18:52 d2.evaluation.evaluator]: \u001b[0mInference done 150/5000. Dataloading: 0.0020 s/iter. Inference: 0.1998 s/iter. Eval: 0.0203 s/iter. Total: 0.2222 s/iter. ETA=0:17:57\n",
            "\u001b[32m[04/30 17:18:57 d2.evaluation.evaluator]: \u001b[0mInference done 173/5000. Dataloading: 0.0020 s/iter. Inference: 0.1998 s/iter. Eval: 0.0197 s/iter. Total: 0.2216 s/iter. ETA=0:17:49\n",
            "\u001b[32m[04/30 17:19:02 d2.evaluation.evaluator]: \u001b[0mInference done 195/5000. Dataloading: 0.0020 s/iter. Inference: 0.2003 s/iter. Eval: 0.0204 s/iter. Total: 0.2228 s/iter. ETA=0:17:50\n",
            "\u001b[32m[04/30 17:19:07 d2.evaluation.evaluator]: \u001b[0mInference done 219/5000. Dataloading: 0.0020 s/iter. Inference: 0.2001 s/iter. Eval: 0.0194 s/iter. Total: 0.2215 s/iter. ETA=0:17:39\n",
            "\u001b[32m[04/30 17:19:13 d2.evaluation.evaluator]: \u001b[0mInference done 242/5000. Dataloading: 0.0020 s/iter. Inference: 0.2005 s/iter. Eval: 0.0192 s/iter. Total: 0.2217 s/iter. ETA=0:17:35\n",
            "\u001b[32m[04/30 17:19:18 d2.evaluation.evaluator]: \u001b[0mInference done 264/5000. Dataloading: 0.0020 s/iter. Inference: 0.2010 s/iter. Eval: 0.0197 s/iter. Total: 0.2228 s/iter. ETA=0:17:35\n",
            "\u001b[32m[04/30 17:19:23 d2.evaluation.evaluator]: \u001b[0mInference done 287/5000. Dataloading: 0.0020 s/iter. Inference: 0.2011 s/iter. Eval: 0.0194 s/iter. Total: 0.2226 s/iter. ETA=0:17:29\n",
            "\u001b[32m[04/30 17:19:28 d2.evaluation.evaluator]: \u001b[0mInference done 309/5000. Dataloading: 0.0020 s/iter. Inference: 0.2015 s/iter. Eval: 0.0196 s/iter. Total: 0.2232 s/iter. ETA=0:17:26\n",
            "\u001b[32m[04/30 17:19:33 d2.evaluation.evaluator]: \u001b[0mInference done 331/5000. Dataloading: 0.0020 s/iter. Inference: 0.2018 s/iter. Eval: 0.0201 s/iter. Total: 0.2240 s/iter. ETA=0:17:25\n",
            "\u001b[32m[04/30 17:19:38 d2.evaluation.evaluator]: \u001b[0mInference done 352/5000. Dataloading: 0.0020 s/iter. Inference: 0.2025 s/iter. Eval: 0.0203 s/iter. Total: 0.2249 s/iter. ETA=0:17:25\n",
            "\u001b[32m[04/30 17:19:43 d2.evaluation.evaluator]: \u001b[0mInference done 374/5000. Dataloading: 0.0020 s/iter. Inference: 0.2028 s/iter. Eval: 0.0202 s/iter. Total: 0.2251 s/iter. ETA=0:17:21\n",
            "\u001b[32m[04/30 17:19:48 d2.evaluation.evaluator]: \u001b[0mInference done 398/5000. Dataloading: 0.0020 s/iter. Inference: 0.2026 s/iter. Eval: 0.0198 s/iter. Total: 0.2245 s/iter. ETA=0:17:13\n",
            "\u001b[32m[04/30 17:19:53 d2.evaluation.evaluator]: \u001b[0mInference done 421/5000. Dataloading: 0.0020 s/iter. Inference: 0.2028 s/iter. Eval: 0.0196 s/iter. Total: 0.2245 s/iter. ETA=0:17:08\n",
            "\u001b[32m[04/30 17:19:58 d2.evaluation.evaluator]: \u001b[0mInference done 443/5000. Dataloading: 0.0020 s/iter. Inference: 0.2031 s/iter. Eval: 0.0195 s/iter. Total: 0.2247 s/iter. ETA=0:17:04\n",
            "\u001b[32m[04/30 17:20:04 d2.evaluation.evaluator]: \u001b[0mInference done 466/5000. Dataloading: 0.0020 s/iter. Inference: 0.2033 s/iter. Eval: 0.0193 s/iter. Total: 0.2248 s/iter. ETA=0:16:59\n",
            "\u001b[32m[04/30 17:20:09 d2.evaluation.evaluator]: \u001b[0mInference done 488/5000. Dataloading: 0.0020 s/iter. Inference: 0.2037 s/iter. Eval: 0.0193 s/iter. Total: 0.2251 s/iter. ETA=0:16:55\n",
            "\u001b[32m[04/30 17:20:14 d2.evaluation.evaluator]: \u001b[0mInference done 510/5000. Dataloading: 0.0020 s/iter. Inference: 0.2039 s/iter. Eval: 0.0195 s/iter. Total: 0.2255 s/iter. ETA=0:16:52\n",
            "\u001b[32m[04/30 17:20:19 d2.evaluation.evaluator]: \u001b[0mInference done 532/5000. Dataloading: 0.0020 s/iter. Inference: 0.2041 s/iter. Eval: 0.0195 s/iter. Total: 0.2257 s/iter. ETA=0:16:48\n",
            "\u001b[32m[04/30 17:20:24 d2.evaluation.evaluator]: \u001b[0mInference done 553/5000. Dataloading: 0.0020 s/iter. Inference: 0.2045 s/iter. Eval: 0.0198 s/iter. Total: 0.2264 s/iter. ETA=0:16:46\n",
            "\u001b[32m[04/30 17:20:29 d2.evaluation.evaluator]: \u001b[0mInference done 575/5000. Dataloading: 0.0020 s/iter. Inference: 0.2048 s/iter. Eval: 0.0198 s/iter. Total: 0.2267 s/iter. ETA=0:16:43\n",
            "\u001b[32m[04/30 17:20:34 d2.evaluation.evaluator]: \u001b[0mInference done 596/5000. Dataloading: 0.0020 s/iter. Inference: 0.2050 s/iter. Eval: 0.0200 s/iter. Total: 0.2272 s/iter. ETA=0:16:40\n",
            "\u001b[32m[04/30 17:20:39 d2.evaluation.evaluator]: \u001b[0mInference done 618/5000. Dataloading: 0.0021 s/iter. Inference: 0.2053 s/iter. Eval: 0.0199 s/iter. Total: 0.2274 s/iter. ETA=0:16:36\n",
            "\u001b[32m[04/30 17:20:44 d2.evaluation.evaluator]: \u001b[0mInference done 639/5000. Dataloading: 0.0021 s/iter. Inference: 0.2056 s/iter. Eval: 0.0201 s/iter. Total: 0.2278 s/iter. ETA=0:16:33\n",
            "\u001b[32m[04/30 17:20:50 d2.evaluation.evaluator]: \u001b[0mInference done 660/5000. Dataloading: 0.0021 s/iter. Inference: 0.2058 s/iter. Eval: 0.0202 s/iter. Total: 0.2282 s/iter. ETA=0:16:30\n",
            "\u001b[32m[04/30 17:20:55 d2.evaluation.evaluator]: \u001b[0mInference done 682/5000. Dataloading: 0.0021 s/iter. Inference: 0.2061 s/iter. Eval: 0.0202 s/iter. Total: 0.2284 s/iter. ETA=0:16:26\n",
            "\u001b[32m[04/30 17:21:00 d2.evaluation.evaluator]: \u001b[0mInference done 704/5000. Dataloading: 0.0021 s/iter. Inference: 0.2063 s/iter. Eval: 0.0201 s/iter. Total: 0.2285 s/iter. ETA=0:16:21\n",
            "\u001b[32m[04/30 17:21:05 d2.evaluation.evaluator]: \u001b[0mInference done 725/5000. Dataloading: 0.0021 s/iter. Inference: 0.2067 s/iter. Eval: 0.0202 s/iter. Total: 0.2290 s/iter. ETA=0:16:18\n",
            "\u001b[32m[04/30 17:21:10 d2.evaluation.evaluator]: \u001b[0mInference done 747/5000. Dataloading: 0.0021 s/iter. Inference: 0.2069 s/iter. Eval: 0.0202 s/iter. Total: 0.2293 s/iter. ETA=0:16:15\n",
            "\u001b[32m[04/30 17:21:15 d2.evaluation.evaluator]: \u001b[0mInference done 769/5000. Dataloading: 0.0021 s/iter. Inference: 0.2071 s/iter. Eval: 0.0201 s/iter. Total: 0.2294 s/iter. ETA=0:16:10\n",
            "\u001b[32m[04/30 17:21:20 d2.evaluation.evaluator]: \u001b[0mInference done 791/5000. Dataloading: 0.0021 s/iter. Inference: 0.2073 s/iter. Eval: 0.0200 s/iter. Total: 0.2295 s/iter. ETA=0:16:06\n",
            "\u001b[32m[04/30 17:21:25 d2.evaluation.evaluator]: \u001b[0mInference done 812/5000. Dataloading: 0.0021 s/iter. Inference: 0.2076 s/iter. Eval: 0.0200 s/iter. Total: 0.2298 s/iter. ETA=0:16:02\n",
            "\u001b[32m[04/30 17:21:30 d2.evaluation.evaluator]: \u001b[0mInference done 834/5000. Dataloading: 0.0021 s/iter. Inference: 0.2077 s/iter. Eval: 0.0199 s/iter. Total: 0.2297 s/iter. ETA=0:15:57\n",
            "\u001b[32m[04/30 17:21:36 d2.evaluation.evaluator]: \u001b[0mInference done 855/5000. Dataloading: 0.0021 s/iter. Inference: 0.2080 s/iter. Eval: 0.0199 s/iter. Total: 0.2300 s/iter. ETA=0:15:53\n",
            "\u001b[32m[04/30 17:21:41 d2.evaluation.evaluator]: \u001b[0mInference done 877/5000. Dataloading: 0.0021 s/iter. Inference: 0.2081 s/iter. Eval: 0.0197 s/iter. Total: 0.2300 s/iter. ETA=0:15:48\n",
            "\u001b[32m[04/30 17:21:46 d2.evaluation.evaluator]: \u001b[0mInference done 899/5000. Dataloading: 0.0021 s/iter. Inference: 0.2083 s/iter. Eval: 0.0197 s/iter. Total: 0.2302 s/iter. ETA=0:15:43\n",
            "\u001b[32m[04/30 17:21:51 d2.evaluation.evaluator]: \u001b[0mInference done 921/5000. Dataloading: 0.0021 s/iter. Inference: 0.2084 s/iter. Eval: 0.0196 s/iter. Total: 0.2302 s/iter. ETA=0:15:38\n",
            "\u001b[32m[04/30 17:21:56 d2.evaluation.evaluator]: \u001b[0mInference done 943/5000. Dataloading: 0.0021 s/iter. Inference: 0.2086 s/iter. Eval: 0.0195 s/iter. Total: 0.2302 s/iter. ETA=0:15:34\n",
            "\u001b[32m[04/30 17:22:01 d2.evaluation.evaluator]: \u001b[0mInference done 965/5000. Dataloading: 0.0021 s/iter. Inference: 0.2087 s/iter. Eval: 0.0194 s/iter. Total: 0.2303 s/iter. ETA=0:15:29\n",
            "\u001b[32m[04/30 17:22:06 d2.evaluation.evaluator]: \u001b[0mInference done 986/5000. Dataloading: 0.0021 s/iter. Inference: 0.2089 s/iter. Eval: 0.0195 s/iter. Total: 0.2306 s/iter. ETA=0:15:25\n",
            "\u001b[32m[04/30 17:22:11 d2.evaluation.evaluator]: \u001b[0mInference done 1008/5000. Dataloading: 0.0021 s/iter. Inference: 0.2091 s/iter. Eval: 0.0194 s/iter. Total: 0.2307 s/iter. ETA=0:15:20\n",
            "\u001b[32m[04/30 17:22:16 d2.evaluation.evaluator]: \u001b[0mInference done 1029/5000. Dataloading: 0.0021 s/iter. Inference: 0.2092 s/iter. Eval: 0.0196 s/iter. Total: 0.2309 s/iter. ETA=0:15:16\n",
            "\u001b[32m[04/30 17:22:22 d2.evaluation.evaluator]: \u001b[0mInference done 1050/5000. Dataloading: 0.0021 s/iter. Inference: 0.2094 s/iter. Eval: 0.0196 s/iter. Total: 0.2312 s/iter. ETA=0:15:13\n",
            "\u001b[32m[04/30 17:22:27 d2.evaluation.evaluator]: \u001b[0mInference done 1071/5000. Dataloading: 0.0021 s/iter. Inference: 0.2097 s/iter. Eval: 0.0197 s/iter. Total: 0.2315 s/iter. ETA=0:15:09\n",
            "\u001b[32m[04/30 17:22:32 d2.evaluation.evaluator]: \u001b[0mInference done 1092/5000. Dataloading: 0.0021 s/iter. Inference: 0.2099 s/iter. Eval: 0.0197 s/iter. Total: 0.2317 s/iter. ETA=0:15:05\n",
            "\u001b[32m[04/30 17:22:37 d2.evaluation.evaluator]: \u001b[0mInference done 1114/5000. Dataloading: 0.0021 s/iter. Inference: 0.2100 s/iter. Eval: 0.0196 s/iter. Total: 0.2317 s/iter. ETA=0:15:00\n",
            "\u001b[32m[04/30 17:22:42 d2.evaluation.evaluator]: \u001b[0mInference done 1135/5000. Dataloading: 0.0021 s/iter. Inference: 0.2102 s/iter. Eval: 0.0195 s/iter. Total: 0.2318 s/iter. ETA=0:14:56\n",
            "\u001b[32m[04/30 17:22:47 d2.evaluation.evaluator]: \u001b[0mInference done 1155/5000. Dataloading: 0.0021 s/iter. Inference: 0.2103 s/iter. Eval: 0.0197 s/iter. Total: 0.2322 s/iter. ETA=0:14:52\n",
            "\u001b[32m[04/30 17:22:52 d2.evaluation.evaluator]: \u001b[0mInference done 1176/5000. Dataloading: 0.0021 s/iter. Inference: 0.2105 s/iter. Eval: 0.0197 s/iter. Total: 0.2324 s/iter. ETA=0:14:48\n",
            "\u001b[32m[04/30 17:22:57 d2.evaluation.evaluator]: \u001b[0mInference done 1197/5000. Dataloading: 0.0021 s/iter. Inference: 0.2107 s/iter. Eval: 0.0198 s/iter. Total: 0.2326 s/iter. ETA=0:14:44\n",
            "\u001b[32m[04/30 17:23:02 d2.evaluation.evaluator]: \u001b[0mInference done 1217/5000. Dataloading: 0.0021 s/iter. Inference: 0.2109 s/iter. Eval: 0.0199 s/iter. Total: 0.2330 s/iter. ETA=0:14:41\n",
            "\u001b[32m[04/30 17:23:07 d2.evaluation.evaluator]: \u001b[0mInference done 1237/5000. Dataloading: 0.0021 s/iter. Inference: 0.2111 s/iter. Eval: 0.0200 s/iter. Total: 0.2333 s/iter. ETA=0:14:37\n",
            "\u001b[32m[04/30 17:23:13 d2.evaluation.evaluator]: \u001b[0mInference done 1258/5000. Dataloading: 0.0021 s/iter. Inference: 0.2113 s/iter. Eval: 0.0201 s/iter. Total: 0.2336 s/iter. ETA=0:14:33\n",
            "\u001b[32m[04/30 17:23:18 d2.evaluation.evaluator]: \u001b[0mInference done 1279/5000. Dataloading: 0.0021 s/iter. Inference: 0.2114 s/iter. Eval: 0.0201 s/iter. Total: 0.2337 s/iter. ETA=0:14:29\n",
            "\u001b[32m[04/30 17:23:23 d2.evaluation.evaluator]: \u001b[0mInference done 1301/5000. Dataloading: 0.0021 s/iter. Inference: 0.2115 s/iter. Eval: 0.0200 s/iter. Total: 0.2337 s/iter. ETA=0:14:24\n",
            "\u001b[32m[04/30 17:23:28 d2.evaluation.evaluator]: \u001b[0mInference done 1323/5000. Dataloading: 0.0021 s/iter. Inference: 0.2115 s/iter. Eval: 0.0200 s/iter. Total: 0.2336 s/iter. ETA=0:14:19\n",
            "\u001b[32m[04/30 17:23:33 d2.evaluation.evaluator]: \u001b[0mInference done 1343/5000. Dataloading: 0.0021 s/iter. Inference: 0.2117 s/iter. Eval: 0.0201 s/iter. Total: 0.2339 s/iter. ETA=0:14:15\n",
            "\u001b[32m[04/30 17:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 1364/5000. Dataloading: 0.0021 s/iter. Inference: 0.2118 s/iter. Eval: 0.0201 s/iter. Total: 0.2340 s/iter. ETA=0:14:10\n",
            "\u001b[32m[04/30 17:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 1386/5000. Dataloading: 0.0021 s/iter. Inference: 0.2119 s/iter. Eval: 0.0201 s/iter. Total: 0.2341 s/iter. ETA=0:14:05\n",
            "\u001b[32m[04/30 17:23:48 d2.evaluation.evaluator]: \u001b[0mInference done 1408/5000. Dataloading: 0.0021 s/iter. Inference: 0.2119 s/iter. Eval: 0.0200 s/iter. Total: 0.2340 s/iter. ETA=0:14:00\n",
            "\u001b[32m[04/30 17:23:53 d2.evaluation.evaluator]: \u001b[0mInference done 1429/5000. Dataloading: 0.0021 s/iter. Inference: 0.2120 s/iter. Eval: 0.0200 s/iter. Total: 0.2341 s/iter. ETA=0:13:56\n",
            "\u001b[32m[04/30 17:23:58 d2.evaluation.evaluator]: \u001b[0mInference done 1450/5000. Dataloading: 0.0021 s/iter. Inference: 0.2121 s/iter. Eval: 0.0200 s/iter. Total: 0.2342 s/iter. ETA=0:13:51\n",
            "\u001b[32m[04/30 17:24:04 d2.evaluation.evaluator]: \u001b[0mInference done 1472/5000. Dataloading: 0.0021 s/iter. Inference: 0.2121 s/iter. Eval: 0.0199 s/iter. Total: 0.2341 s/iter. ETA=0:13:46\n",
            "\u001b[32m[04/30 17:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 1493/5000. Dataloading: 0.0021 s/iter. Inference: 0.2122 s/iter. Eval: 0.0199 s/iter. Total: 0.2343 s/iter. ETA=0:13:41\n",
            "\u001b[32m[04/30 17:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 1515/5000. Dataloading: 0.0021 s/iter. Inference: 0.2122 s/iter. Eval: 0.0200 s/iter. Total: 0.2344 s/iter. ETA=0:13:36\n",
            "\u001b[32m[04/30 17:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 1536/5000. Dataloading: 0.0021 s/iter. Inference: 0.2123 s/iter. Eval: 0.0199 s/iter. Total: 0.2344 s/iter. ETA=0:13:32\n",
            "\u001b[32m[04/30 17:24:24 d2.evaluation.evaluator]: \u001b[0mInference done 1556/5000. Dataloading: 0.0021 s/iter. Inference: 0.2125 s/iter. Eval: 0.0200 s/iter. Total: 0.2347 s/iter. ETA=0:13:28\n",
            "\u001b[32m[04/30 17:24:29 d2.evaluation.evaluator]: \u001b[0mInference done 1577/5000. Dataloading: 0.0021 s/iter. Inference: 0.2126 s/iter. Eval: 0.0200 s/iter. Total: 0.2348 s/iter. ETA=0:13:23\n",
            "\u001b[32m[04/30 17:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 1597/5000. Dataloading: 0.0021 s/iter. Inference: 0.2128 s/iter. Eval: 0.0201 s/iter. Total: 0.2350 s/iter. ETA=0:13:19\n",
            "\u001b[32m[04/30 17:24:39 d2.evaluation.evaluator]: \u001b[0mInference done 1619/5000. Dataloading: 0.0021 s/iter. Inference: 0.2128 s/iter. Eval: 0.0200 s/iter. Total: 0.2350 s/iter. ETA=0:13:14\n",
            "\u001b[32m[04/30 17:24:45 d2.evaluation.evaluator]: \u001b[0mInference done 1641/5000. Dataloading: 0.0021 s/iter. Inference: 0.2129 s/iter. Eval: 0.0200 s/iter. Total: 0.2350 s/iter. ETA=0:13:09\n",
            "\u001b[32m[04/30 17:24:50 d2.evaluation.evaluator]: \u001b[0mInference done 1662/5000. Dataloading: 0.0021 s/iter. Inference: 0.2130 s/iter. Eval: 0.0200 s/iter. Total: 0.2352 s/iter. ETA=0:13:04\n",
            "\u001b[32m[04/30 17:24:55 d2.evaluation.evaluator]: \u001b[0mInference done 1684/5000. Dataloading: 0.0021 s/iter. Inference: 0.2131 s/iter. Eval: 0.0199 s/iter. Total: 0.2352 s/iter. ETA=0:12:59\n",
            "\u001b[32m[04/30 17:25:00 d2.evaluation.evaluator]: \u001b[0mInference done 1705/5000. Dataloading: 0.0021 s/iter. Inference: 0.2132 s/iter. Eval: 0.0199 s/iter. Total: 0.2352 s/iter. ETA=0:12:55\n",
            "\u001b[32m[04/30 17:25:05 d2.evaluation.evaluator]: \u001b[0mInference done 1726/5000. Dataloading: 0.0021 s/iter. Inference: 0.2132 s/iter. Eval: 0.0199 s/iter. Total: 0.2353 s/iter. ETA=0:12:50\n",
            "\u001b[32m[04/30 17:25:10 d2.evaluation.evaluator]: \u001b[0mInference done 1748/5000. Dataloading: 0.0021 s/iter. Inference: 0.2133 s/iter. Eval: 0.0199 s/iter. Total: 0.2353 s/iter. ETA=0:12:45\n",
            "\u001b[32m[04/30 17:25:15 d2.evaluation.evaluator]: \u001b[0mInference done 1770/5000. Dataloading: 0.0021 s/iter. Inference: 0.2133 s/iter. Eval: 0.0198 s/iter. Total: 0.2353 s/iter. ETA=0:12:39\n",
            "\u001b[32m[04/30 17:25:20 d2.evaluation.evaluator]: \u001b[0mInference done 1791/5000. Dataloading: 0.0021 s/iter. Inference: 0.2134 s/iter. Eval: 0.0198 s/iter. Total: 0.2353 s/iter. ETA=0:12:35\n",
            "\u001b[32m[04/30 17:25:25 d2.evaluation.evaluator]: \u001b[0mInference done 1812/5000. Dataloading: 0.0021 s/iter. Inference: 0.2135 s/iter. Eval: 0.0198 s/iter. Total: 0.2354 s/iter. ETA=0:12:30\n",
            "\u001b[32m[04/30 17:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 1832/5000. Dataloading: 0.0021 s/iter. Inference: 0.2136 s/iter. Eval: 0.0198 s/iter. Total: 0.2356 s/iter. ETA=0:12:26\n",
            "\u001b[32m[04/30 17:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 1853/5000. Dataloading: 0.0021 s/iter. Inference: 0.2136 s/iter. Eval: 0.0198 s/iter. Total: 0.2356 s/iter. ETA=0:12:21\n",
            "\u001b[32m[04/30 17:25:41 d2.evaluation.evaluator]: \u001b[0mInference done 1874/5000. Dataloading: 0.0021 s/iter. Inference: 0.2137 s/iter. Eval: 0.0198 s/iter. Total: 0.2357 s/iter. ETA=0:12:16\n",
            "\u001b[32m[04/30 17:25:46 d2.evaluation.evaluator]: \u001b[0mInference done 1895/5000. Dataloading: 0.0021 s/iter. Inference: 0.2138 s/iter. Eval: 0.0198 s/iter. Total: 0.2358 s/iter. ETA=0:12:12\n",
            "\u001b[32m[04/30 17:25:51 d2.evaluation.evaluator]: \u001b[0mInference done 1917/5000. Dataloading: 0.0021 s/iter. Inference: 0.2139 s/iter. Eval: 0.0198 s/iter. Total: 0.2358 s/iter. ETA=0:12:06\n",
            "\u001b[32m[04/30 17:25:56 d2.evaluation.evaluator]: \u001b[0mInference done 1939/5000. Dataloading: 0.0021 s/iter. Inference: 0.2139 s/iter. Eval: 0.0197 s/iter. Total: 0.2358 s/iter. ETA=0:12:01\n",
            "\u001b[32m[04/30 17:26:01 d2.evaluation.evaluator]: \u001b[0mInference done 1961/5000. Dataloading: 0.0021 s/iter. Inference: 0.2139 s/iter. Eval: 0.0197 s/iter. Total: 0.2358 s/iter. ETA=0:11:56\n",
            "\u001b[32m[04/30 17:26:06 d2.evaluation.evaluator]: \u001b[0mInference done 1982/5000. Dataloading: 0.0021 s/iter. Inference: 0.2140 s/iter. Eval: 0.0197 s/iter. Total: 0.2359 s/iter. ETA=0:11:51\n",
            "\u001b[32m[04/30 17:26:11 d2.evaluation.evaluator]: \u001b[0mInference done 2002/5000. Dataloading: 0.0021 s/iter. Inference: 0.2141 s/iter. Eval: 0.0198 s/iter. Total: 0.2360 s/iter. ETA=0:11:47\n",
            "\u001b[32m[04/30 17:26:17 d2.evaluation.evaluator]: \u001b[0mInference done 2023/5000. Dataloading: 0.0021 s/iter. Inference: 0.2142 s/iter. Eval: 0.0198 s/iter. Total: 0.2361 s/iter. ETA=0:11:43\n",
            "\u001b[32m[04/30 17:26:22 d2.evaluation.evaluator]: \u001b[0mInference done 2044/5000. Dataloading: 0.0021 s/iter. Inference: 0.2143 s/iter. Eval: 0.0199 s/iter. Total: 0.2363 s/iter. ETA=0:11:38\n",
            "\u001b[32m[04/30 17:26:27 d2.evaluation.evaluator]: \u001b[0mInference done 2066/5000. Dataloading: 0.0021 s/iter. Inference: 0.2143 s/iter. Eval: 0.0198 s/iter. Total: 0.2362 s/iter. ETA=0:11:32\n",
            "\u001b[32m[04/30 17:26:32 d2.evaluation.evaluator]: \u001b[0mInference done 2088/5000. Dataloading: 0.0021 s/iter. Inference: 0.2143 s/iter. Eval: 0.0197 s/iter. Total: 0.2362 s/iter. ETA=0:11:27\n",
            "\u001b[32m[04/30 17:26:37 d2.evaluation.evaluator]: \u001b[0mInference done 2109/5000. Dataloading: 0.0021 s/iter. Inference: 0.2144 s/iter. Eval: 0.0197 s/iter. Total: 0.2363 s/iter. ETA=0:11:23\n",
            "\u001b[32m[04/30 17:26:42 d2.evaluation.evaluator]: \u001b[0mInference done 2131/5000. Dataloading: 0.0021 s/iter. Inference: 0.2144 s/iter. Eval: 0.0197 s/iter. Total: 0.2363 s/iter. ETA=0:11:17\n",
            "\u001b[32m[04/30 17:26:47 d2.evaluation.evaluator]: \u001b[0mInference done 2152/5000. Dataloading: 0.0021 s/iter. Inference: 0.2144 s/iter. Eval: 0.0197 s/iter. Total: 0.2363 s/iter. ETA=0:11:12\n",
            "\u001b[32m[04/30 17:26:53 d2.evaluation.evaluator]: \u001b[0mInference done 2174/5000. Dataloading: 0.0021 s/iter. Inference: 0.2145 s/iter. Eval: 0.0197 s/iter. Total: 0.2363 s/iter. ETA=0:11:07\n",
            "\u001b[32m[04/30 17:26:58 d2.evaluation.evaluator]: \u001b[0mInference done 2195/5000. Dataloading: 0.0021 s/iter. Inference: 0.2146 s/iter. Eval: 0.0196 s/iter. Total: 0.2363 s/iter. ETA=0:11:02\n",
            "\u001b[32m[04/30 17:27:03 d2.evaluation.evaluator]: \u001b[0mInference done 2216/5000. Dataloading: 0.0021 s/iter. Inference: 0.2146 s/iter. Eval: 0.0196 s/iter. Total: 0.2364 s/iter. ETA=0:10:58\n",
            "\u001b[32m[04/30 17:27:08 d2.evaluation.evaluator]: \u001b[0mInference done 2237/5000. Dataloading: 0.0021 s/iter. Inference: 0.2147 s/iter. Eval: 0.0196 s/iter. Total: 0.2364 s/iter. ETA=0:10:53\n",
            "\u001b[32m[04/30 17:27:13 d2.evaluation.evaluator]: \u001b[0mInference done 2257/5000. Dataloading: 0.0021 s/iter. Inference: 0.2148 s/iter. Eval: 0.0197 s/iter. Total: 0.2366 s/iter. ETA=0:10:49\n",
            "\u001b[32m[04/30 17:27:18 d2.evaluation.evaluator]: \u001b[0mInference done 2279/5000. Dataloading: 0.0021 s/iter. Inference: 0.2148 s/iter. Eval: 0.0197 s/iter. Total: 0.2366 s/iter. ETA=0:10:43\n",
            "\u001b[32m[04/30 17:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 2301/5000. Dataloading: 0.0021 s/iter. Inference: 0.2148 s/iter. Eval: 0.0196 s/iter. Total: 0.2365 s/iter. ETA=0:10:38\n",
            "\u001b[32m[04/30 17:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 2322/5000. Dataloading: 0.0021 s/iter. Inference: 0.2149 s/iter. Eval: 0.0196 s/iter. Total: 0.2366 s/iter. ETA=0:10:33\n",
            "\u001b[32m[04/30 17:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 2344/5000. Dataloading: 0.0021 s/iter. Inference: 0.2149 s/iter. Eval: 0.0195 s/iter. Total: 0.2365 s/iter. ETA=0:10:28\n",
            "\u001b[32m[04/30 17:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 2365/5000. Dataloading: 0.0021 s/iter. Inference: 0.2150 s/iter. Eval: 0.0195 s/iter. Total: 0.2366 s/iter. ETA=0:10:23\n",
            "\u001b[32m[04/30 17:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 2386/5000. Dataloading: 0.0021 s/iter. Inference: 0.2150 s/iter. Eval: 0.0195 s/iter. Total: 0.2366 s/iter. ETA=0:10:18\n",
            "\u001b[32m[04/30 17:27:49 d2.evaluation.evaluator]: \u001b[0mInference done 2407/5000. Dataloading: 0.0021 s/iter. Inference: 0.2151 s/iter. Eval: 0.0195 s/iter. Total: 0.2368 s/iter. ETA=0:10:13\n",
            "\u001b[32m[04/30 17:27:54 d2.evaluation.evaluator]: \u001b[0mInference done 2428/5000. Dataloading: 0.0021 s/iter. Inference: 0.2151 s/iter. Eval: 0.0196 s/iter. Total: 0.2369 s/iter. ETA=0:10:09\n",
            "\u001b[32m[04/30 17:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 2449/5000. Dataloading: 0.0021 s/iter. Inference: 0.2152 s/iter. Eval: 0.0196 s/iter. Total: 0.2369 s/iter. ETA=0:10:04\n",
            "\u001b[32m[04/30 17:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 2470/5000. Dataloading: 0.0021 s/iter. Inference: 0.2153 s/iter. Eval: 0.0195 s/iter. Total: 0.2369 s/iter. ETA=0:09:59\n",
            "\u001b[32m[04/30 17:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 2491/5000. Dataloading: 0.0021 s/iter. Inference: 0.2153 s/iter. Eval: 0.0195 s/iter. Total: 0.2370 s/iter. ETA=0:09:54\n",
            "\u001b[32m[04/30 17:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 2512/5000. Dataloading: 0.0021 s/iter. Inference: 0.2153 s/iter. Eval: 0.0196 s/iter. Total: 0.2370 s/iter. ETA=0:09:49\n",
            "\u001b[32m[04/30 17:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 2534/5000. Dataloading: 0.0021 s/iter. Inference: 0.2153 s/iter. Eval: 0.0195 s/iter. Total: 0.2370 s/iter. ETA=0:09:44\n",
            "\u001b[32m[04/30 17:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 2554/5000. Dataloading: 0.0021 s/iter. Inference: 0.2154 s/iter. Eval: 0.0196 s/iter. Total: 0.2371 s/iter. ETA=0:09:39\n",
            "\u001b[32m[04/30 17:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 2574/5000. Dataloading: 0.0021 s/iter. Inference: 0.2154 s/iter. Eval: 0.0197 s/iter. Total: 0.2372 s/iter. ETA=0:09:35\n",
            "\u001b[32m[04/30 17:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 2595/5000. Dataloading: 0.0021 s/iter. Inference: 0.2154 s/iter. Eval: 0.0197 s/iter. Total: 0.2373 s/iter. ETA=0:09:30\n",
            "\u001b[32m[04/30 17:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 2616/5000. Dataloading: 0.0021 s/iter. Inference: 0.2155 s/iter. Eval: 0.0197 s/iter. Total: 0.2373 s/iter. ETA=0:09:25\n",
            "\u001b[32m[04/30 17:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 2637/5000. Dataloading: 0.0021 s/iter. Inference: 0.2156 s/iter. Eval: 0.0197 s/iter. Total: 0.2374 s/iter. ETA=0:09:20\n",
            "\u001b[32m[04/30 17:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 2658/5000. Dataloading: 0.0021 s/iter. Inference: 0.2156 s/iter. Eval: 0.0197 s/iter. Total: 0.2375 s/iter. ETA=0:09:16\n",
            "\u001b[32m[04/30 17:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 2679/5000. Dataloading: 0.0021 s/iter. Inference: 0.2157 s/iter. Eval: 0.0197 s/iter. Total: 0.2375 s/iter. ETA=0:09:11\n",
            "\u001b[32m[04/30 17:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 2701/5000. Dataloading: 0.0021 s/iter. Inference: 0.2157 s/iter. Eval: 0.0196 s/iter. Total: 0.2374 s/iter. ETA=0:09:05\n",
            "\u001b[32m[04/30 17:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 2722/5000. Dataloading: 0.0021 s/iter. Inference: 0.2157 s/iter. Eval: 0.0196 s/iter. Total: 0.2374 s/iter. ETA=0:09:00\n",
            "\u001b[32m[04/30 17:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 2744/5000. Dataloading: 0.0020 s/iter. Inference: 0.2157 s/iter. Eval: 0.0196 s/iter. Total: 0.2374 s/iter. ETA=0:08:55\n",
            "\u001b[32m[04/30 17:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 2766/5000. Dataloading: 0.0020 s/iter. Inference: 0.2157 s/iter. Eval: 0.0196 s/iter. Total: 0.2374 s/iter. ETA=0:08:50\n",
            "\u001b[32m[04/30 17:29:21 d2.evaluation.evaluator]: \u001b[0mInference done 2787/5000. Dataloading: 0.0021 s/iter. Inference: 0.2158 s/iter. Eval: 0.0196 s/iter. Total: 0.2375 s/iter. ETA=0:08:45\n",
            "\u001b[32m[04/30 17:29:26 d2.evaluation.evaluator]: \u001b[0mInference done 2809/5000. Dataloading: 0.0021 s/iter. Inference: 0.2158 s/iter. Eval: 0.0196 s/iter. Total: 0.2375 s/iter. ETA=0:08:40\n",
            "\u001b[32m[04/30 17:29:31 d2.evaluation.evaluator]: \u001b[0mInference done 2830/5000. Dataloading: 0.0020 s/iter. Inference: 0.2158 s/iter. Eval: 0.0196 s/iter. Total: 0.2376 s/iter. ETA=0:08:35\n",
            "\u001b[32m[04/30 17:29:36 d2.evaluation.evaluator]: \u001b[0mInference done 2851/5000. Dataloading: 0.0020 s/iter. Inference: 0.2159 s/iter. Eval: 0.0196 s/iter. Total: 0.2376 s/iter. ETA=0:08:30\n",
            "\u001b[32m[04/30 17:29:41 d2.evaluation.evaluator]: \u001b[0mInference done 2873/5000. Dataloading: 0.0020 s/iter. Inference: 0.2159 s/iter. Eval: 0.0196 s/iter. Total: 0.2376 s/iter. ETA=0:08:25\n",
            "\u001b[32m[04/30 17:29:47 d2.evaluation.evaluator]: \u001b[0mInference done 2894/5000. Dataloading: 0.0020 s/iter. Inference: 0.2160 s/iter. Eval: 0.0196 s/iter. Total: 0.2376 s/iter. ETA=0:08:20\n",
            "\u001b[32m[04/30 17:29:52 d2.evaluation.evaluator]: \u001b[0mInference done 2915/5000. Dataloading: 0.0020 s/iter. Inference: 0.2160 s/iter. Eval: 0.0196 s/iter. Total: 0.2377 s/iter. ETA=0:08:15\n",
            "\u001b[32m[04/30 17:29:57 d2.evaluation.evaluator]: \u001b[0mInference done 2936/5000. Dataloading: 0.0020 s/iter. Inference: 0.2160 s/iter. Eval: 0.0196 s/iter. Total: 0.2378 s/iter. ETA=0:08:10\n",
            "\u001b[32m[04/30 17:30:02 d2.evaluation.evaluator]: \u001b[0mInference done 2957/5000. Dataloading: 0.0020 s/iter. Inference: 0.2160 s/iter. Eval: 0.0196 s/iter. Total: 0.2378 s/iter. ETA=0:08:05\n",
            "\u001b[32m[04/30 17:30:07 d2.evaluation.evaluator]: \u001b[0mInference done 2979/5000. Dataloading: 0.0020 s/iter. Inference: 0.2161 s/iter. Eval: 0.0195 s/iter. Total: 0.2378 s/iter. ETA=0:08:00\n",
            "\u001b[32m[04/30 17:30:12 d2.evaluation.evaluator]: \u001b[0mInference done 3000/5000. Dataloading: 0.0020 s/iter. Inference: 0.2161 s/iter. Eval: 0.0195 s/iter. Total: 0.2378 s/iter. ETA=0:07:55\n",
            "\u001b[32m[04/30 17:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 3022/5000. Dataloading: 0.0020 s/iter. Inference: 0.2161 s/iter. Eval: 0.0195 s/iter. Total: 0.2377 s/iter. ETA=0:07:50\n",
            "\u001b[32m[04/30 17:30:22 d2.evaluation.evaluator]: \u001b[0mInference done 3043/5000. Dataloading: 0.0020 s/iter. Inference: 0.2162 s/iter. Eval: 0.0195 s/iter. Total: 0.2378 s/iter. ETA=0:07:45\n",
            "\u001b[32m[04/30 17:30:28 d2.evaluation.evaluator]: \u001b[0mInference done 3064/5000. Dataloading: 0.0020 s/iter. Inference: 0.2162 s/iter. Eval: 0.0195 s/iter. Total: 0.2378 s/iter. ETA=0:07:40\n",
            "\u001b[32m[04/30 17:30:33 d2.evaluation.evaluator]: \u001b[0mInference done 3085/5000. Dataloading: 0.0020 s/iter. Inference: 0.2163 s/iter. Eval: 0.0195 s/iter. Total: 0.2378 s/iter. ETA=0:07:35\n",
            "\u001b[32m[04/30 17:30:38 d2.evaluation.evaluator]: \u001b[0mInference done 3107/5000. Dataloading: 0.0020 s/iter. Inference: 0.2163 s/iter. Eval: 0.0194 s/iter. Total: 0.2378 s/iter. ETA=0:07:30\n",
            "\u001b[32m[04/30 17:30:43 d2.evaluation.evaluator]: \u001b[0mInference done 3128/5000. Dataloading: 0.0020 s/iter. Inference: 0.2163 s/iter. Eval: 0.0194 s/iter. Total: 0.2378 s/iter. ETA=0:07:25\n",
            "\u001b[32m[04/30 17:30:48 d2.evaluation.evaluator]: \u001b[0mInference done 3149/5000. Dataloading: 0.0020 s/iter. Inference: 0.2163 s/iter. Eval: 0.0194 s/iter. Total: 0.2379 s/iter. ETA=0:07:20\n",
            "\u001b[32m[04/30 17:30:53 d2.evaluation.evaluator]: \u001b[0mInference done 3171/5000. Dataloading: 0.0020 s/iter. Inference: 0.2163 s/iter. Eval: 0.0194 s/iter. Total: 0.2378 s/iter. ETA=0:07:14\n",
            "\u001b[32m[04/30 17:30:58 d2.evaluation.evaluator]: \u001b[0mInference done 3192/5000. Dataloading: 0.0020 s/iter. Inference: 0.2163 s/iter. Eval: 0.0194 s/iter. Total: 0.2379 s/iter. ETA=0:07:10\n",
            "\u001b[32m[04/30 17:31:03 d2.evaluation.evaluator]: \u001b[0mInference done 3212/5000. Dataloading: 0.0020 s/iter. Inference: 0.2164 s/iter. Eval: 0.0194 s/iter. Total: 0.2379 s/iter. ETA=0:07:05\n",
            "\u001b[32m[04/30 17:31:08 d2.evaluation.evaluator]: \u001b[0mInference done 3233/5000. Dataloading: 0.0020 s/iter. Inference: 0.2164 s/iter. Eval: 0.0194 s/iter. Total: 0.2380 s/iter. ETA=0:07:00\n",
            "\u001b[32m[04/30 17:31:13 d2.evaluation.evaluator]: \u001b[0mInference done 3254/5000. Dataloading: 0.0020 s/iter. Inference: 0.2164 s/iter. Eval: 0.0194 s/iter. Total: 0.2380 s/iter. ETA=0:06:55\n",
            "\u001b[32m[04/30 17:31:19 d2.evaluation.evaluator]: \u001b[0mInference done 3275/5000. Dataloading: 0.0020 s/iter. Inference: 0.2165 s/iter. Eval: 0.0195 s/iter. Total: 0.2381 s/iter. ETA=0:06:50\n",
            "\u001b[32m[04/30 17:31:24 d2.evaluation.evaluator]: \u001b[0mInference done 3295/5000. Dataloading: 0.0020 s/iter. Inference: 0.2165 s/iter. Eval: 0.0195 s/iter. Total: 0.2382 s/iter. ETA=0:06:46\n",
            "\u001b[32m[04/30 17:31:29 d2.evaluation.evaluator]: \u001b[0mInference done 3316/5000. Dataloading: 0.0020 s/iter. Inference: 0.2166 s/iter. Eval: 0.0195 s/iter. Total: 0.2382 s/iter. ETA=0:06:41\n",
            "\u001b[32m[04/30 17:31:34 d2.evaluation.evaluator]: \u001b[0mInference done 3338/5000. Dataloading: 0.0020 s/iter. Inference: 0.2166 s/iter. Eval: 0.0195 s/iter. Total: 0.2382 s/iter. ETA=0:06:35\n",
            "\u001b[32m[04/30 17:31:39 d2.evaluation.evaluator]: \u001b[0mInference done 3358/5000. Dataloading: 0.0020 s/iter. Inference: 0.2166 s/iter. Eval: 0.0196 s/iter. Total: 0.2383 s/iter. ETA=0:06:31\n",
            "\u001b[32m[04/30 17:31:44 d2.evaluation.evaluator]: \u001b[0mInference done 3379/5000. Dataloading: 0.0020 s/iter. Inference: 0.2167 s/iter. Eval: 0.0196 s/iter. Total: 0.2384 s/iter. ETA=0:06:26\n",
            "\u001b[32m[04/30 17:31:49 d2.evaluation.evaluator]: \u001b[0mInference done 3401/5000. Dataloading: 0.0020 s/iter. Inference: 0.2166 s/iter. Eval: 0.0195 s/iter. Total: 0.2383 s/iter. ETA=0:06:21\n",
            "\u001b[32m[04/30 17:31:54 d2.evaluation.evaluator]: \u001b[0mInference done 3422/5000. Dataloading: 0.0020 s/iter. Inference: 0.2167 s/iter. Eval: 0.0196 s/iter. Total: 0.2383 s/iter. ETA=0:06:16\n",
            "\u001b[32m[04/30 17:32:00 d2.evaluation.evaluator]: \u001b[0mInference done 3442/5000. Dataloading: 0.0020 s/iter. Inference: 0.2167 s/iter. Eval: 0.0196 s/iter. Total: 0.2384 s/iter. ETA=0:06:11\n",
            "\u001b[32m[04/30 17:32:05 d2.evaluation.evaluator]: \u001b[0mInference done 3462/5000. Dataloading: 0.0020 s/iter. Inference: 0.2168 s/iter. Eval: 0.0196 s/iter. Total: 0.2385 s/iter. ETA=0:06:06\n",
            "\u001b[32m[04/30 17:32:10 d2.evaluation.evaluator]: \u001b[0mInference done 3484/5000. Dataloading: 0.0020 s/iter. Inference: 0.2168 s/iter. Eval: 0.0196 s/iter. Total: 0.2385 s/iter. ETA=0:06:01\n",
            "\u001b[32m[04/30 17:32:15 d2.evaluation.evaluator]: \u001b[0mInference done 3505/5000. Dataloading: 0.0020 s/iter. Inference: 0.2168 s/iter. Eval: 0.0196 s/iter. Total: 0.2385 s/iter. ETA=0:05:56\n",
            "\u001b[32m[04/30 17:32:20 d2.evaluation.evaluator]: \u001b[0mInference done 3527/5000. Dataloading: 0.0020 s/iter. Inference: 0.2168 s/iter. Eval: 0.0195 s/iter. Total: 0.2385 s/iter. ETA=0:05:51\n",
            "\u001b[32m[04/30 17:32:25 d2.evaluation.evaluator]: \u001b[0mInference done 3549/5000. Dataloading: 0.0020 s/iter. Inference: 0.2169 s/iter. Eval: 0.0195 s/iter. Total: 0.2385 s/iter. ETA=0:05:46\n",
            "\u001b[32m[04/30 17:32:30 d2.evaluation.evaluator]: \u001b[0mInference done 3570/5000. Dataloading: 0.0020 s/iter. Inference: 0.2169 s/iter. Eval: 0.0195 s/iter. Total: 0.2385 s/iter. ETA=0:05:41\n",
            "\u001b[32m[04/30 17:32:36 d2.evaluation.evaluator]: \u001b[0mInference done 3591/5000. Dataloading: 0.0020 s/iter. Inference: 0.2169 s/iter. Eval: 0.0195 s/iter. Total: 0.2386 s/iter. ETA=0:05:36\n",
            "\u001b[32m[04/30 17:32:41 d2.evaluation.evaluator]: \u001b[0mInference done 3612/5000. Dataloading: 0.0020 s/iter. Inference: 0.2169 s/iter. Eval: 0.0196 s/iter. Total: 0.2386 s/iter. ETA=0:05:31\n",
            "\u001b[32m[04/30 17:32:46 d2.evaluation.evaluator]: \u001b[0mInference done 3634/5000. Dataloading: 0.0020 s/iter. Inference: 0.2169 s/iter. Eval: 0.0195 s/iter. Total: 0.2386 s/iter. ETA=0:05:25\n",
            "\u001b[32m[04/30 17:32:51 d2.evaluation.evaluator]: \u001b[0mInference done 3655/5000. Dataloading: 0.0020 s/iter. Inference: 0.2170 s/iter. Eval: 0.0195 s/iter. Total: 0.2386 s/iter. ETA=0:05:20\n",
            "\u001b[32m[04/30 17:32:56 d2.evaluation.evaluator]: \u001b[0mInference done 3676/5000. Dataloading: 0.0020 s/iter. Inference: 0.2170 s/iter. Eval: 0.0195 s/iter. Total: 0.2386 s/iter. ETA=0:05:15\n",
            "\u001b[32m[04/30 17:33:01 d2.evaluation.evaluator]: \u001b[0mInference done 3697/5000. Dataloading: 0.0020 s/iter. Inference: 0.2170 s/iter. Eval: 0.0195 s/iter. Total: 0.2386 s/iter. ETA=0:05:10\n",
            "\u001b[32m[04/30 17:33:06 d2.evaluation.evaluator]: \u001b[0mInference done 3718/5000. Dataloading: 0.0020 s/iter. Inference: 0.2170 s/iter. Eval: 0.0195 s/iter. Total: 0.2386 s/iter. ETA=0:05:05\n",
            "\u001b[32m[04/30 17:33:11 d2.evaluation.evaluator]: \u001b[0mInference done 3739/5000. Dataloading: 0.0020 s/iter. Inference: 0.2170 s/iter. Eval: 0.0195 s/iter. Total: 0.2387 s/iter. ETA=0:05:00\n",
            "\u001b[32m[04/30 17:33:16 d2.evaluation.evaluator]: \u001b[0mInference done 3759/5000. Dataloading: 0.0020 s/iter. Inference: 0.2171 s/iter. Eval: 0.0195 s/iter. Total: 0.2387 s/iter. ETA=0:04:56\n",
            "\u001b[32m[04/30 17:33:21 d2.evaluation.evaluator]: \u001b[0mInference done 3780/5000. Dataloading: 0.0020 s/iter. Inference: 0.2171 s/iter. Eval: 0.0195 s/iter. Total: 0.2387 s/iter. ETA=0:04:51\n",
            "\u001b[32m[04/30 17:33:27 d2.evaluation.evaluator]: \u001b[0mInference done 3801/5000. Dataloading: 0.0020 s/iter. Inference: 0.2171 s/iter. Eval: 0.0195 s/iter. Total: 0.2388 s/iter. ETA=0:04:46\n",
            "\u001b[32m[04/30 17:33:32 d2.evaluation.evaluator]: \u001b[0mInference done 3823/5000. Dataloading: 0.0020 s/iter. Inference: 0.2171 s/iter. Eval: 0.0195 s/iter. Total: 0.2388 s/iter. ETA=0:04:41\n",
            "\u001b[32m[04/30 17:33:37 d2.evaluation.evaluator]: \u001b[0mInference done 3845/5000. Dataloading: 0.0020 s/iter. Inference: 0.2172 s/iter. Eval: 0.0195 s/iter. Total: 0.2388 s/iter. ETA=0:04:35\n",
            "\u001b[32m[04/30 17:33:42 d2.evaluation.evaluator]: \u001b[0mInference done 3866/5000. Dataloading: 0.0020 s/iter. Inference: 0.2172 s/iter. Eval: 0.0195 s/iter. Total: 0.2388 s/iter. ETA=0:04:30\n",
            "\u001b[32m[04/30 17:33:47 d2.evaluation.evaluator]: \u001b[0mInference done 3888/5000. Dataloading: 0.0020 s/iter. Inference: 0.2172 s/iter. Eval: 0.0195 s/iter. Total: 0.2388 s/iter. ETA=0:04:25\n",
            "\u001b[32m[04/30 17:33:52 d2.evaluation.evaluator]: \u001b[0mInference done 3910/5000. Dataloading: 0.0020 s/iter. Inference: 0.2172 s/iter. Eval: 0.0195 s/iter. Total: 0.2388 s/iter. ETA=0:04:20\n",
            "\u001b[32m[04/30 17:33:58 d2.evaluation.evaluator]: \u001b[0mInference done 3931/5000. Dataloading: 0.0020 s/iter. Inference: 0.2172 s/iter. Eval: 0.0195 s/iter. Total: 0.2388 s/iter. ETA=0:04:15\n",
            "\u001b[32m[04/30 17:34:03 d2.evaluation.evaluator]: \u001b[0mInference done 3952/5000. Dataloading: 0.0020 s/iter. Inference: 0.2172 s/iter. Eval: 0.0195 s/iter. Total: 0.2388 s/iter. ETA=0:04:10\n",
            "\u001b[32m[04/30 17:34:08 d2.evaluation.evaluator]: \u001b[0mInference done 3973/5000. Dataloading: 0.0020 s/iter. Inference: 0.2173 s/iter. Eval: 0.0195 s/iter. Total: 0.2389 s/iter. ETA=0:04:05\n",
            "\u001b[32m[04/30 17:34:13 d2.evaluation.evaluator]: \u001b[0mInference done 3995/5000. Dataloading: 0.0020 s/iter. Inference: 0.2172 s/iter. Eval: 0.0194 s/iter. Total: 0.2388 s/iter. ETA=0:03:59\n",
            "\u001b[32m[04/30 17:34:18 d2.evaluation.evaluator]: \u001b[0mInference done 4015/5000. Dataloading: 0.0020 s/iter. Inference: 0.2173 s/iter. Eval: 0.0195 s/iter. Total: 0.2389 s/iter. ETA=0:03:55\n",
            "\u001b[32m[04/30 17:34:23 d2.evaluation.evaluator]: \u001b[0mInference done 4036/5000. Dataloading: 0.0020 s/iter. Inference: 0.2173 s/iter. Eval: 0.0195 s/iter. Total: 0.2389 s/iter. ETA=0:03:50\n",
            "\u001b[32m[04/30 17:34:28 d2.evaluation.evaluator]: \u001b[0mInference done 4056/5000. Dataloading: 0.0020 s/iter. Inference: 0.2173 s/iter. Eval: 0.0196 s/iter. Total: 0.2390 s/iter. ETA=0:03:45\n",
            "\u001b[32m[04/30 17:34:33 d2.evaluation.evaluator]: \u001b[0mInference done 4077/5000. Dataloading: 0.0020 s/iter. Inference: 0.2173 s/iter. Eval: 0.0196 s/iter. Total: 0.2390 s/iter. ETA=0:03:40\n",
            "\u001b[32m[04/30 17:34:38 d2.evaluation.evaluator]: \u001b[0mInference done 4097/5000. Dataloading: 0.0020 s/iter. Inference: 0.2174 s/iter. Eval: 0.0196 s/iter. Total: 0.2391 s/iter. ETA=0:03:35\n",
            "\u001b[32m[04/30 17:34:43 d2.evaluation.evaluator]: \u001b[0mInference done 4118/5000. Dataloading: 0.0020 s/iter. Inference: 0.2174 s/iter. Eval: 0.0196 s/iter. Total: 0.2391 s/iter. ETA=0:03:30\n",
            "\u001b[32m[04/30 17:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 4139/5000. Dataloading: 0.0020 s/iter. Inference: 0.2174 s/iter. Eval: 0.0196 s/iter. Total: 0.2391 s/iter. ETA=0:03:25\n",
            "\u001b[32m[04/30 17:34:54 d2.evaluation.evaluator]: \u001b[0mInference done 4160/5000. Dataloading: 0.0020 s/iter. Inference: 0.2174 s/iter. Eval: 0.0196 s/iter. Total: 0.2392 s/iter. ETA=0:03:20\n",
            "\u001b[32m[04/30 17:34:59 d2.evaluation.evaluator]: \u001b[0mInference done 4180/5000. Dataloading: 0.0020 s/iter. Inference: 0.2175 s/iter. Eval: 0.0197 s/iter. Total: 0.2393 s/iter. ETA=0:03:16\n",
            "\u001b[32m[04/30 17:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 4201/5000. Dataloading: 0.0020 s/iter. Inference: 0.2175 s/iter. Eval: 0.0197 s/iter. Total: 0.2393 s/iter. ETA=0:03:11\n",
            "\u001b[32m[04/30 17:35:09 d2.evaluation.evaluator]: \u001b[0mInference done 4223/5000. Dataloading: 0.0020 s/iter. Inference: 0.2175 s/iter. Eval: 0.0196 s/iter. Total: 0.2393 s/iter. ETA=0:03:05\n",
            "\u001b[32m[04/30 17:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 4244/5000. Dataloading: 0.0020 s/iter. Inference: 0.2175 s/iter. Eval: 0.0197 s/iter. Total: 0.2393 s/iter. ETA=0:03:00\n",
            "\u001b[32m[04/30 17:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 4264/5000. Dataloading: 0.0020 s/iter. Inference: 0.2175 s/iter. Eval: 0.0197 s/iter. Total: 0.2394 s/iter. ETA=0:02:56\n",
            "\u001b[32m[04/30 17:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 4286/5000. Dataloading: 0.0020 s/iter. Inference: 0.2175 s/iter. Eval: 0.0197 s/iter. Total: 0.2393 s/iter. ETA=0:02:50\n",
            "\u001b[32m[04/30 17:35:30 d2.evaluation.evaluator]: \u001b[0mInference done 4307/5000. Dataloading: 0.0020 s/iter. Inference: 0.2175 s/iter. Eval: 0.0197 s/iter. Total: 0.2394 s/iter. ETA=0:02:45\n",
            "\u001b[32m[04/30 17:35:35 d2.evaluation.evaluator]: \u001b[0mInference done 4329/5000. Dataloading: 0.0020 s/iter. Inference: 0.2175 s/iter. Eval: 0.0197 s/iter. Total: 0.2394 s/iter. ETA=0:02:40\n",
            "\u001b[32m[04/30 17:35:40 d2.evaluation.evaluator]: \u001b[0mInference done 4352/5000. Dataloading: 0.0020 s/iter. Inference: 0.2175 s/iter. Eval: 0.0196 s/iter. Total: 0.2393 s/iter. ETA=0:02:35\n",
            "\u001b[32m[04/30 17:35:45 d2.evaluation.evaluator]: \u001b[0mInference done 4373/5000. Dataloading: 0.0020 s/iter. Inference: 0.2175 s/iter. Eval: 0.0196 s/iter. Total: 0.2393 s/iter. ETA=0:02:30\n",
            "\u001b[32m[04/30 17:35:50 d2.evaluation.evaluator]: \u001b[0mInference done 4394/5000. Dataloading: 0.0020 s/iter. Inference: 0.2175 s/iter. Eval: 0.0196 s/iter. Total: 0.2393 s/iter. ETA=0:02:25\n",
            "\u001b[32m[04/30 17:35:55 d2.evaluation.evaluator]: \u001b[0mInference done 4415/5000. Dataloading: 0.0020 s/iter. Inference: 0.2175 s/iter. Eval: 0.0197 s/iter. Total: 0.2393 s/iter. ETA=0:02:20\n",
            "\u001b[32m[04/30 17:36:01 d2.evaluation.evaluator]: \u001b[0mInference done 4436/5000. Dataloading: 0.0020 s/iter. Inference: 0.2176 s/iter. Eval: 0.0197 s/iter. Total: 0.2393 s/iter. ETA=0:02:14\n",
            "\u001b[32m[04/30 17:36:06 d2.evaluation.evaluator]: \u001b[0mInference done 4457/5000. Dataloading: 0.0020 s/iter. Inference: 0.2176 s/iter. Eval: 0.0197 s/iter. Total: 0.2394 s/iter. ETA=0:02:09\n",
            "\u001b[32m[04/30 17:36:11 d2.evaluation.evaluator]: \u001b[0mInference done 4478/5000. Dataloading: 0.0020 s/iter. Inference: 0.2176 s/iter. Eval: 0.0197 s/iter. Total: 0.2394 s/iter. ETA=0:02:04\n",
            "\u001b[32m[04/30 17:36:16 d2.evaluation.evaluator]: \u001b[0mInference done 4499/5000. Dataloading: 0.0020 s/iter. Inference: 0.2176 s/iter. Eval: 0.0197 s/iter. Total: 0.2394 s/iter. ETA=0:01:59\n",
            "\u001b[32m[04/30 17:36:21 d2.evaluation.evaluator]: \u001b[0mInference done 4521/5000. Dataloading: 0.0020 s/iter. Inference: 0.2176 s/iter. Eval: 0.0197 s/iter. Total: 0.2394 s/iter. ETA=0:01:54\n",
            "\u001b[32m[04/30 17:36:26 d2.evaluation.evaluator]: \u001b[0mInference done 4542/5000. Dataloading: 0.0020 s/iter. Inference: 0.2176 s/iter. Eval: 0.0197 s/iter. Total: 0.2394 s/iter. ETA=0:01:49\n",
            "\u001b[32m[04/30 17:36:31 d2.evaluation.evaluator]: \u001b[0mInference done 4563/5000. Dataloading: 0.0020 s/iter. Inference: 0.2176 s/iter. Eval: 0.0197 s/iter. Total: 0.2394 s/iter. ETA=0:01:44\n",
            "\u001b[32m[04/30 17:36:37 d2.evaluation.evaluator]: \u001b[0mInference done 4584/5000. Dataloading: 0.0020 s/iter. Inference: 0.2177 s/iter. Eval: 0.0197 s/iter. Total: 0.2395 s/iter. ETA=0:01:39\n",
            "\u001b[32m[04/30 17:36:42 d2.evaluation.evaluator]: \u001b[0mInference done 4606/5000. Dataloading: 0.0020 s/iter. Inference: 0.2177 s/iter. Eval: 0.0197 s/iter. Total: 0.2395 s/iter. ETA=0:01:34\n",
            "\u001b[32m[04/30 17:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 4628/5000. Dataloading: 0.0020 s/iter. Inference: 0.2177 s/iter. Eval: 0.0197 s/iter. Total: 0.2395 s/iter. ETA=0:01:29\n",
            "\u001b[32m[04/30 17:36:52 d2.evaluation.evaluator]: \u001b[0mInference done 4649/5000. Dataloading: 0.0020 s/iter. Inference: 0.2177 s/iter. Eval: 0.0197 s/iter. Total: 0.2395 s/iter. ETA=0:01:24\n",
            "\u001b[32m[04/30 17:36:57 d2.evaluation.evaluator]: \u001b[0mInference done 4669/5000. Dataloading: 0.0020 s/iter. Inference: 0.2177 s/iter. Eval: 0.0197 s/iter. Total: 0.2396 s/iter. ETA=0:01:19\n",
            "\u001b[32m[04/30 17:37:03 d2.evaluation.evaluator]: \u001b[0mInference done 4691/5000. Dataloading: 0.0020 s/iter. Inference: 0.2177 s/iter. Eval: 0.0197 s/iter. Total: 0.2396 s/iter. ETA=0:01:14\n",
            "\u001b[32m[04/30 17:37:08 d2.evaluation.evaluator]: \u001b[0mInference done 4712/5000. Dataloading: 0.0020 s/iter. Inference: 0.2177 s/iter. Eval: 0.0197 s/iter. Total: 0.2396 s/iter. ETA=0:01:08\n",
            "\u001b[32m[04/30 17:37:13 d2.evaluation.evaluator]: \u001b[0mInference done 4733/5000. Dataloading: 0.0020 s/iter. Inference: 0.2177 s/iter. Eval: 0.0197 s/iter. Total: 0.2396 s/iter. ETA=0:01:03\n",
            "\u001b[32m[04/30 17:37:18 d2.evaluation.evaluator]: \u001b[0mInference done 4754/5000. Dataloading: 0.0020 s/iter. Inference: 0.2178 s/iter. Eval: 0.0197 s/iter. Total: 0.2396 s/iter. ETA=0:00:58\n",
            "\u001b[32m[04/30 17:37:23 d2.evaluation.evaluator]: \u001b[0mInference done 4775/5000. Dataloading: 0.0020 s/iter. Inference: 0.2178 s/iter. Eval: 0.0197 s/iter. Total: 0.2396 s/iter. ETA=0:00:53\n",
            "\u001b[32m[04/30 17:37:28 d2.evaluation.evaluator]: \u001b[0mInference done 4797/5000. Dataloading: 0.0020 s/iter. Inference: 0.2178 s/iter. Eval: 0.0197 s/iter. Total: 0.2396 s/iter. ETA=0:00:48\n",
            "\u001b[32m[04/30 17:37:33 d2.evaluation.evaluator]: \u001b[0mInference done 4818/5000. Dataloading: 0.0020 s/iter. Inference: 0.2178 s/iter. Eval: 0.0197 s/iter. Total: 0.2396 s/iter. ETA=0:00:43\n",
            "\u001b[32m[04/30 17:37:38 d2.evaluation.evaluator]: \u001b[0mInference done 4840/5000. Dataloading: 0.0020 s/iter. Inference: 0.2178 s/iter. Eval: 0.0197 s/iter. Total: 0.2396 s/iter. ETA=0:00:38\n",
            "\u001b[32m[04/30 17:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 4861/5000. Dataloading: 0.0020 s/iter. Inference: 0.2178 s/iter. Eval: 0.0197 s/iter. Total: 0.2396 s/iter. ETA=0:00:33\n",
            "\u001b[32m[04/30 17:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 4882/5000. Dataloading: 0.0020 s/iter. Inference: 0.2178 s/iter. Eval: 0.0197 s/iter. Total: 0.2396 s/iter. ETA=0:00:28\n",
            "\u001b[32m[04/30 17:37:54 d2.evaluation.evaluator]: \u001b[0mInference done 4903/5000. Dataloading: 0.0020 s/iter. Inference: 0.2178 s/iter. Eval: 0.0197 s/iter. Total: 0.2396 s/iter. ETA=0:00:23\n",
            "\u001b[32m[04/30 17:37:59 d2.evaluation.evaluator]: \u001b[0mInference done 4923/5000. Dataloading: 0.0020 s/iter. Inference: 0.2179 s/iter. Eval: 0.0197 s/iter. Total: 0.2397 s/iter. ETA=0:00:18\n",
            "\u001b[32m[04/30 17:38:04 d2.evaluation.evaluator]: \u001b[0mInference done 4944/5000. Dataloading: 0.0020 s/iter. Inference: 0.2179 s/iter. Eval: 0.0197 s/iter. Total: 0.2397 s/iter. ETA=0:00:13\n",
            "\u001b[32m[04/30 17:38:09 d2.evaluation.evaluator]: \u001b[0mInference done 4966/5000. Dataloading: 0.0020 s/iter. Inference: 0.2179 s/iter. Eval: 0.0197 s/iter. Total: 0.2397 s/iter. ETA=0:00:08\n",
            "\u001b[32m[04/30 17:38:14 d2.evaluation.evaluator]: \u001b[0mInference done 4987/5000. Dataloading: 0.0020 s/iter. Inference: 0.2179 s/iter. Eval: 0.0197 s/iter. Total: 0.2397 s/iter. ETA=0:00:03\n",
            "\u001b[32m[04/30 17:38:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:19:57.524022 (0.239745 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 17:38:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:18:08 (0.217924 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 17:38:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/30 17:38:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/30 17:38:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.12s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 17:38:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/30 17:38:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 8.22 seconds.\n",
            "\u001b[32m[04/30 17:38:29 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 17:38:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.92 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.428\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.639\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.468\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.463\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.545\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.536\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.563\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.384\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694\n",
            "\u001b[32m[04/30 17:38:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 42.807 | 63.927 | 46.845 | 27.187 | 46.329 | 54.470 |\n",
            "\u001b[32m[04/30 17:38:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 55.822 | bicycle      | 32.740 | car            | 45.960 |\n",
            "| motorcycle    | 44.502 | airplane     | 64.611 | bus            | 64.675 |\n",
            "| train         | 62.923 | truck        | 36.317 | boat           | 27.920 |\n",
            "| traffic light | 29.188 | fire hydrant | 69.029 | stop sign      | 66.746 |\n",
            "| parking meter | 42.763 | bench        | 25.958 | bird           | 36.238 |\n",
            "| cat           | 69.156 | dog          | 64.664 | horse          | 58.239 |\n",
            "| sheep         | 53.872 | cow          | 57.104 | elephant       | 63.241 |\n",
            "| bear          | 68.827 | zebra        | 67.318 | giraffe        | 66.499 |\n",
            "| backpack      | 14.923 | umbrella     | 40.689 | handbag        | 16.882 |\n",
            "| tie           | 35.250 | suitcase     | 39.988 | frisbee        | 67.469 |\n",
            "| skis          | 27.838 | snowboard    | 39.090 | sports ball    | 50.215 |\n",
            "| kite          | 44.918 | baseball bat | 36.386 | baseball glove | 40.098 |\n",
            "| skateboard    | 55.989 | surfboard    | 41.701 | tennis racket  | 51.101 |\n",
            "| bottle        | 40.342 | wine glass   | 38.597 | cup            | 45.704 |\n",
            "| fork          | 39.685 | knife        | 22.396 | spoon          | 19.997 |\n",
            "| bowl          | 43.767 | banana       | 26.141 | apple          | 21.030 |\n",
            "| sandwich      | 35.729 | orange       | 29.921 | broccoli       | 23.315 |\n",
            "| carrot        | 23.733 | hot dog      | 33.908 | pizza          | 53.156 |\n",
            "| donut         | 49.569 | cake         | 37.747 | chair          | 29.073 |\n",
            "| couch         | 42.320 | potted plant | 24.925 | bed            | 40.584 |\n",
            "| dining table  | 28.340 | toilet       | 60.541 | tv             | 56.458 |\n",
            "| laptop        | 61.034 | mouse        | 61.777 | remote         | 38.295 |\n",
            "| keyboard      | 52.668 | cell phone   | 36.964 | microwave      | 54.448 |\n",
            "| oven          | 33.795 | toaster      | 28.026 | sink           | 38.315 |\n",
            "| refrigerator  | 57.168 | book         | 16.346 | clock          | 52.261 |\n",
            "| vase          | 37.508 | scissors     | 30.156 | teddy bear     | 46.966 |\n",
            "| hair drier    | 5.941  | toothbrush   | 29.044 |                |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=1.20s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 17:38:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
            "\u001b[32m[04/30 17:38:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 9.97 seconds.\n",
            "\u001b[32m[04/30 17:38:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 17:38:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.92 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.381\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.605\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.407\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.409\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.507\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.328\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647\n",
            "\u001b[32m[04/30 17:38:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 38.140 | 60.542 | 40.689 | 20.006 | 40.945 | 54.144 |\n",
            "\u001b[32m[04/30 17:38:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 47.783 | bicycle      | 18.995 | car            | 41.928 |\n",
            "| motorcycle    | 34.268 | airplane     | 49.984 | bus            | 63.337 |\n",
            "| train         | 62.088 | truck        | 34.354 | boat           | 22.849 |\n",
            "| traffic light | 28.256 | fire hydrant | 65.955 | stop sign      | 67.628 |\n",
            "| parking meter | 43.163 | bench        | 18.209 | bird           | 30.054 |\n",
            "| cat           | 67.426 | dog          | 60.312 | horse          | 41.945 |\n",
            "| sheep         | 45.675 | cow          | 48.386 | elephant       | 57.007 |\n",
            "| bear          | 66.763 | zebra        | 56.898 | giraffe        | 50.525 |\n",
            "| backpack      | 14.492 | umbrella     | 47.234 | handbag        | 15.544 |\n",
            "| tie           | 32.679 | suitcase     | 41.770 | frisbee        | 64.225 |\n",
            "| skis          | 3.844  | snowboard    | 26.095 | sports ball    | 50.233 |\n",
            "| kite          | 33.806 | baseball bat | 28.150 | baseball glove | 40.692 |\n",
            "| skateboard    | 33.933 | surfboard    | 34.721 | tennis racket  | 56.140 |\n",
            "| bottle        | 38.554 | wine glass   | 32.907 | cup            | 45.550 |\n",
            "| fork          | 18.224 | knife        | 14.323 | spoon          | 12.669 |\n",
            "| bowl          | 41.041 | banana       | 20.733 | apple          | 20.671 |\n",
            "| sandwich      | 37.923 | orange       | 29.226 | broccoli       | 21.379 |\n",
            "| carrot        | 20.640 | hot dog      | 22.892 | pizza          | 51.107 |\n",
            "| donut         | 49.136 | cake         | 37.883 | chair          | 19.926 |\n",
            "| couch         | 35.628 | potted plant | 20.473 | bed            | 34.009 |\n",
            "| dining table  | 16.228 | toilet       | 58.228 | tv             | 58.007 |\n",
            "| laptop        | 60.824 | mouse        | 62.114 | remote         | 33.830 |\n",
            "| keyboard      | 50.494 | cell phone   | 35.457 | microwave      | 55.665 |\n",
            "| oven          | 31.139 | toaster      | 31.223 | sink           | 35.893 |\n",
            "| refrigerator  | 58.148 | book         | 11.196 | clock          | 52.633 |\n",
            "| vase          | 36.491 | scissors     | 21.583 | teddy bear     | 45.692 |\n",
            "| hair drier    | 4.174  | toothbrush   | 19.929 |                |        |\n",
            "\u001b[32m[04/30 17:38:51 d2.engine.defaults]: \u001b[0mEvaluation results for coco_2017_val in csv format:\n",
            "\u001b[32m[04/30 17:38:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/30 17:38:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 17:38:51 d2.evaluation.testing]: \u001b[0mcopypaste: 42.8067,63.9268,46.8453,27.1872,46.3290,54.4697\n",
            "\u001b[32m[04/30 17:38:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[04/30 17:38:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 17:38:51 d2.evaluation.testing]: \u001b[0mcopypaste: 38.1398,60.5425,40.6892,20.0065,40.9452,54.1442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mask_rcnn_ResNeSt_50 - evaluation results for coco_2017_val in csv format:\n",
        "\n",
        "Task\\metrics  | AP | AP50 | AP75 | APs | APm | APl |\n",
        "--------------|----|------|------|-----|-----|-----|\n",
        "**bbox**    | 42.8067 | 63.9268 | 46.8453 | 27.1872 | 46.3290 | 54.4697\n",
        "**segm**   | 38.1398 | 60.5425 | 40.6892 | 20.0065 | 40.9452 | 54.1442"
      ],
      "metadata": {
        "id": "8sBwb_9nF7X3"
      },
      "id": "8sBwb_9nF7X3"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_101_FPN_syncBN_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_101_FPN_syncBN_1x-528502c6.pth"
      ],
      "metadata": {
        "id": "nIisTojAhX7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "607aabac-6e54-4d33-937b-e0df1217004f"
      },
      "id": "nIisTojAhX7v",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command Line Args: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_101_FPN_syncBN_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_101_FPN_syncBN_1x-528502c6.pth'], resume=False)\n",
            "\u001b[32m[04/30 18:22:26 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[04/30 18:22:27 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ----------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "numpy                   1.21.6\n",
            "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.5\n",
            "CUDA compiler           CUDA 11.1\n",
            "detectron2 arch flags   7.5\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.11.0+cu113 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           Yes\n",
            "GPU 0                   Tesla T4 (arch=7.5)\n",
            "Driver version          460.32.03\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.12.0+cu113 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
            "fvcore                  0.1.5.post20220414\n",
            "iopath                  0.1.9\n",
            "cv2                     4.1.2\n",
            "----------------------  ----------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.3\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.2\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "\u001b[32m[04/30 18:22:27 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_101_FPN_syncBN_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_101_FPN_syncBN_1x-528502c6.pth'], resume=False)\n",
            "\u001b[32m[04/30 18:22:27 detectron2]: \u001b[0mContents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_101_FPN_syncBN_1x.yaml:\n",
            "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186m../ResNest-Base-RCNN-FPN.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mhttps://s3.us-west-1.wasabisys.com/resnest/detectron/resnest101_detectron-486f69a8.pth\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m101\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\u001b[38;5;15m        \u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mFastRCNNConvFCHead\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m123.68\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m116.779\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m103.939\u001b[39m]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m58.393\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.12\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.375\u001b[39m]\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\u001b[38;5;15m    \u001b[39m\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mRGB\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\n",
            "\u001b[32m[04/30 18:22:27 detectron2]: \u001b[0mRunning with full config:\n",
            "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRGB\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mpolygon\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m672\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m704\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m736\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m768\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mchoice\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnest_fpn_backbone\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGeneralizedRCNN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.68\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.779\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.939\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m58.393\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.12\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.375\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRPN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVG_DOWN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOTTLENECK_WIDTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEEP_STEM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m101\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_NUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFastRCNNConvFCHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_FED_LOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_SIGMOID_CE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardROIHeads\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./checkpoints/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_101_FPN_syncBN_1x-528502c6.pth\n",
            "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./output\n",
            "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR_END\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m90000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m60000\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m80000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\n",
            "\u001b[32m[04/30 18:22:27 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[04/30 18:22:27 d2.utils.env]: \u001b[0mUsing a generated random seed 27538630\n",
            "\u001b[32m[04/30 18:22:32 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(\n",
            "      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output2): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral3): Conv2d(\n",
            "      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output3): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral4): Conv2d(\n",
            "      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output4): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral5): Conv2d(\n",
            "      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output5): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNeSt(\n",
            "      (stem): BasicStem(\n",
            "        (conv1_1): Conv2d(\n",
            "          3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv1_2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv1_3): Conv2d(\n",
            "          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (conv1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (conv4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/30 18:22:32 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from ./checkpoints/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_101_FPN_syncBN_1x-528502c6.pth ...\n",
            "\u001b[32m[04/30 18:22:34 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
            "| Names in Model                                  | Names in Checkpoint                                                                                                           | Shapes                                             |\n",
            "|:------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------|\n",
            "| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,128,1,1)               |\n",
            "| backbone.bottom_up.res2.0.conv2.bn0.*           | backbone.bottom_up.res2.0.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.0.conv2.bn1.*           | backbone.bottom_up.res2.0.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.0.conv2.conv.weight     | backbone.bottom_up.res2.0.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.0.conv2.fc1.*           | backbone.bottom_up.res2.0.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.0.conv2.fc2.*           | backbone.bottom_up.res2.0.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,128,1,1)          |\n",
            "| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.1.conv2.bn0.*           | backbone.bottom_up.res2.1.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.1.conv2.bn1.*           | backbone.bottom_up.res2.1.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.1.conv2.conv.weight     | backbone.bottom_up.res2.1.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.1.conv2.fc1.*           | backbone.bottom_up.res2.1.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.1.conv2.fc2.*           | backbone.bottom_up.res2.1.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.2.conv2.bn0.*           | backbone.bottom_up.res2.2.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.2.conv2.bn1.*           | backbone.bottom_up.res2.2.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.2.conv2.conv.weight     | backbone.bottom_up.res2.2.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.2.conv2.fc1.*           | backbone.bottom_up.res2.2.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.2.conv2.fc2.*           | backbone.bottom_up.res2.2.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv2.bn0.*           | backbone.bottom_up.res3.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.0.conv2.bn1.*           | backbone.bottom_up.res3.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.0.conv2.conv.weight     | backbone.bottom_up.res3.0.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.0.conv2.fc1.*           | backbone.bottom_up.res3.0.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.0.conv2.fc2.*           | backbone.bottom_up.res3.0.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv2.bn0.*           | backbone.bottom_up.res3.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.1.conv2.bn1.*           | backbone.bottom_up.res3.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.1.conv2.conv.weight     | backbone.bottom_up.res3.1.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.1.conv2.fc1.*           | backbone.bottom_up.res3.1.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.1.conv2.fc2.*           | backbone.bottom_up.res3.1.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv2.bn0.*           | backbone.bottom_up.res3.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.2.conv2.bn1.*           | backbone.bottom_up.res3.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.2.conv2.conv.weight     | backbone.bottom_up.res3.2.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.2.conv2.fc1.*           | backbone.bottom_up.res3.2.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.2.conv2.fc2.*           | backbone.bottom_up.res3.2.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv2.bn0.*           | backbone.bottom_up.res3.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.3.conv2.bn1.*           | backbone.bottom_up.res3.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.3.conv2.conv.weight     | backbone.bottom_up.res3.3.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.3.conv2.fc1.*           | backbone.bottom_up.res3.3.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.3.conv2.fc2.*           | backbone.bottom_up.res3.3.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv2.bn0.*           | backbone.bottom_up.res4.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.bn1.*           | backbone.bottom_up.res4.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.conv.weight     | backbone.bottom_up.res4.0.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.0.conv2.fc1.*           | backbone.bottom_up.res4.0.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv2.fc2.*           | backbone.bottom_up.res4.0.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.1.conv2.bn0.*           | backbone.bottom_up.res4.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.bn1.*           | backbone.bottom_up.res4.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.conv.weight     | backbone.bottom_up.res4.1.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.1.conv2.fc1.*           | backbone.bottom_up.res4.1.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv2.fc2.*           | backbone.bottom_up.res4.1.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.10.conv1.*              | backbone.bottom_up.res4.10.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.10.conv2.bn0.*          | backbone.bottom_up.res4.10.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.10.conv2.bn1.*          | backbone.bottom_up.res4.10.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.10.conv2.conv.weight    | backbone.bottom_up.res4.10.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.10.conv2.fc1.*          | backbone.bottom_up.res4.10.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.10.conv2.fc2.*          | backbone.bottom_up.res4.10.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.10.conv3.*              | backbone.bottom_up.res4.10.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.11.conv1.*              | backbone.bottom_up.res4.11.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.11.conv2.bn0.*          | backbone.bottom_up.res4.11.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.11.conv2.bn1.*          | backbone.bottom_up.res4.11.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.11.conv2.conv.weight    | backbone.bottom_up.res4.11.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.11.conv2.fc1.*          | backbone.bottom_up.res4.11.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.11.conv2.fc2.*          | backbone.bottom_up.res4.11.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.11.conv3.*              | backbone.bottom_up.res4.11.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.12.conv1.*              | backbone.bottom_up.res4.12.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.12.conv2.bn0.*          | backbone.bottom_up.res4.12.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.12.conv2.bn1.*          | backbone.bottom_up.res4.12.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.12.conv2.conv.weight    | backbone.bottom_up.res4.12.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.12.conv2.fc1.*          | backbone.bottom_up.res4.12.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.12.conv2.fc2.*          | backbone.bottom_up.res4.12.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.12.conv3.*              | backbone.bottom_up.res4.12.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.13.conv1.*              | backbone.bottom_up.res4.13.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.13.conv2.bn0.*          | backbone.bottom_up.res4.13.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.13.conv2.bn1.*          | backbone.bottom_up.res4.13.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.13.conv2.conv.weight    | backbone.bottom_up.res4.13.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.13.conv2.fc1.*          | backbone.bottom_up.res4.13.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.13.conv2.fc2.*          | backbone.bottom_up.res4.13.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.13.conv3.*              | backbone.bottom_up.res4.13.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.14.conv1.*              | backbone.bottom_up.res4.14.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.14.conv2.bn0.*          | backbone.bottom_up.res4.14.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.14.conv2.bn1.*          | backbone.bottom_up.res4.14.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.14.conv2.conv.weight    | backbone.bottom_up.res4.14.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.14.conv2.fc1.*          | backbone.bottom_up.res4.14.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.14.conv2.fc2.*          | backbone.bottom_up.res4.14.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.14.conv3.*              | backbone.bottom_up.res4.14.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.15.conv1.*              | backbone.bottom_up.res4.15.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.15.conv2.bn0.*          | backbone.bottom_up.res4.15.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.15.conv2.bn1.*          | backbone.bottom_up.res4.15.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.15.conv2.conv.weight    | backbone.bottom_up.res4.15.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.15.conv2.fc1.*          | backbone.bottom_up.res4.15.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.15.conv2.fc2.*          | backbone.bottom_up.res4.15.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.15.conv3.*              | backbone.bottom_up.res4.15.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.16.conv1.*              | backbone.bottom_up.res4.16.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.16.conv2.bn0.*          | backbone.bottom_up.res4.16.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.16.conv2.bn1.*          | backbone.bottom_up.res4.16.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.16.conv2.conv.weight    | backbone.bottom_up.res4.16.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.16.conv2.fc1.*          | backbone.bottom_up.res4.16.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.16.conv2.fc2.*          | backbone.bottom_up.res4.16.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.16.conv3.*              | backbone.bottom_up.res4.16.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.17.conv1.*              | backbone.bottom_up.res4.17.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.17.conv2.bn0.*          | backbone.bottom_up.res4.17.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.17.conv2.bn1.*          | backbone.bottom_up.res4.17.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.17.conv2.conv.weight    | backbone.bottom_up.res4.17.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.17.conv2.fc1.*          | backbone.bottom_up.res4.17.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.17.conv2.fc2.*          | backbone.bottom_up.res4.17.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.17.conv3.*              | backbone.bottom_up.res4.17.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.18.conv1.*              | backbone.bottom_up.res4.18.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.18.conv2.bn0.*          | backbone.bottom_up.res4.18.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.18.conv2.bn1.*          | backbone.bottom_up.res4.18.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.18.conv2.conv.weight    | backbone.bottom_up.res4.18.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.18.conv2.fc1.*          | backbone.bottom_up.res4.18.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.18.conv2.fc2.*          | backbone.bottom_up.res4.18.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.18.conv3.*              | backbone.bottom_up.res4.18.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.19.conv1.*              | backbone.bottom_up.res4.19.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.19.conv2.bn0.*          | backbone.bottom_up.res4.19.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.19.conv2.bn1.*          | backbone.bottom_up.res4.19.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.19.conv2.conv.weight    | backbone.bottom_up.res4.19.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.19.conv2.fc1.*          | backbone.bottom_up.res4.19.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.19.conv2.fc2.*          | backbone.bottom_up.res4.19.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.19.conv3.*              | backbone.bottom_up.res4.19.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.2.conv2.bn0.*           | backbone.bottom_up.res4.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.bn1.*           | backbone.bottom_up.res4.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.conv.weight     | backbone.bottom_up.res4.2.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.2.conv2.fc1.*           | backbone.bottom_up.res4.2.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv2.fc2.*           | backbone.bottom_up.res4.2.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.20.conv1.*              | backbone.bottom_up.res4.20.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.20.conv2.bn0.*          | backbone.bottom_up.res4.20.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.20.conv2.bn1.*          | backbone.bottom_up.res4.20.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.20.conv2.conv.weight    | backbone.bottom_up.res4.20.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.20.conv2.fc1.*          | backbone.bottom_up.res4.20.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.20.conv2.fc2.*          | backbone.bottom_up.res4.20.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.20.conv3.*              | backbone.bottom_up.res4.20.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.21.conv1.*              | backbone.bottom_up.res4.21.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.21.conv2.bn0.*          | backbone.bottom_up.res4.21.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.21.conv2.bn1.*          | backbone.bottom_up.res4.21.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.21.conv2.conv.weight    | backbone.bottom_up.res4.21.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.21.conv2.fc1.*          | backbone.bottom_up.res4.21.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.21.conv2.fc2.*          | backbone.bottom_up.res4.21.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.21.conv3.*              | backbone.bottom_up.res4.21.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.22.conv1.*              | backbone.bottom_up.res4.22.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.22.conv2.bn0.*          | backbone.bottom_up.res4.22.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.22.conv2.bn1.*          | backbone.bottom_up.res4.22.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.22.conv2.conv.weight    | backbone.bottom_up.res4.22.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.22.conv2.fc1.*          | backbone.bottom_up.res4.22.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.22.conv2.fc2.*          | backbone.bottom_up.res4.22.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.22.conv3.*              | backbone.bottom_up.res4.22.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.3.conv2.bn0.*           | backbone.bottom_up.res4.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.bn1.*           | backbone.bottom_up.res4.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.conv.weight     | backbone.bottom_up.res4.3.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.3.conv2.fc1.*           | backbone.bottom_up.res4.3.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv2.fc2.*           | backbone.bottom_up.res4.3.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.4.conv2.bn0.*           | backbone.bottom_up.res4.4.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.bn1.*           | backbone.bottom_up.res4.4.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.conv.weight     | backbone.bottom_up.res4.4.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.4.conv2.fc1.*           | backbone.bottom_up.res4.4.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv2.fc2.*           | backbone.bottom_up.res4.4.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.5.conv2.bn0.*           | backbone.bottom_up.res4.5.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.bn1.*           | backbone.bottom_up.res4.5.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.conv.weight     | backbone.bottom_up.res4.5.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.5.conv2.fc1.*           | backbone.bottom_up.res4.5.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv2.fc2.*           | backbone.bottom_up.res4.5.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.6.conv1.*               | backbone.bottom_up.res4.6.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.6.conv2.bn0.*           | backbone.bottom_up.res4.6.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.6.conv2.bn1.*           | backbone.bottom_up.res4.6.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.6.conv2.conv.weight     | backbone.bottom_up.res4.6.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.6.conv2.fc1.*           | backbone.bottom_up.res4.6.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.6.conv2.fc2.*           | backbone.bottom_up.res4.6.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.6.conv3.*               | backbone.bottom_up.res4.6.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.7.conv1.*               | backbone.bottom_up.res4.7.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.7.conv2.bn0.*           | backbone.bottom_up.res4.7.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.7.conv2.bn1.*           | backbone.bottom_up.res4.7.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.7.conv2.conv.weight     | backbone.bottom_up.res4.7.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.7.conv2.fc1.*           | backbone.bottom_up.res4.7.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.7.conv2.fc2.*           | backbone.bottom_up.res4.7.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.7.conv3.*               | backbone.bottom_up.res4.7.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.8.conv1.*               | backbone.bottom_up.res4.8.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.8.conv2.bn0.*           | backbone.bottom_up.res4.8.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.8.conv2.bn1.*           | backbone.bottom_up.res4.8.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.8.conv2.conv.weight     | backbone.bottom_up.res4.8.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.8.conv2.fc1.*           | backbone.bottom_up.res4.8.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.8.conv2.fc2.*           | backbone.bottom_up.res4.8.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.8.conv3.*               | backbone.bottom_up.res4.8.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.9.conv1.*               | backbone.bottom_up.res4.9.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.9.conv2.bn0.*           | backbone.bottom_up.res4.9.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.9.conv2.bn1.*           | backbone.bottom_up.res4.9.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.9.conv2.conv.weight     | backbone.bottom_up.res4.9.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.9.conv2.fc1.*           | backbone.bottom_up.res4.9.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.9.conv2.fc2.*           | backbone.bottom_up.res4.9.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.9.conv3.*               | backbone.bottom_up.res4.9.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| backbone.bottom_up.res5.0.conv2.bn0.*           | backbone.bottom_up.res5.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.0.conv2.bn1.*           | backbone.bottom_up.res5.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.0.conv2.conv.weight     | backbone.bottom_up.res5.0.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.0.conv2.fc1.*           | backbone.bottom_up.res5.0.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.0.conv2.fc2.*           | backbone.bottom_up.res5.0.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.1.conv2.bn0.*           | backbone.bottom_up.res5.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.1.conv2.bn1.*           | backbone.bottom_up.res5.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.1.conv2.conv.weight     | backbone.bottom_up.res5.1.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.1.conv2.fc1.*           | backbone.bottom_up.res5.1.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.1.conv2.fc2.*           | backbone.bottom_up.res5.1.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.2.conv2.bn0.*           | backbone.bottom_up.res5.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.2.conv2.bn1.*           | backbone.bottom_up.res5.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.2.conv2.conv.weight     | backbone.bottom_up.res5.2.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.2.conv2.fc1.*           | backbone.bottom_up.res5.2.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.2.conv2.fc2.*           | backbone.bottom_up.res5.2.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.stem.conv1_1.*               | backbone.bottom_up.stem.conv1_1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,3,3,3)                 |\n",
            "| backbone.bottom_up.stem.conv1_2.*               | backbone.bottom_up.stem.conv1_2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |\n",
            "| backbone.bottom_up.stem.conv1_3.*               | backbone.bottom_up.stem.conv1_3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,64,3,3)           |\n",
            "| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,2048,1,1)      |\n",
            "| backbone.fpn_output2.*                          | backbone.fpn_output2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output3.*                          | backbone.fpn_output3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output4.*                          | backbone.fpn_output4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output5.*                          | backbone.fpn_output5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                                                       | (12,) (12,256,1,1)                                 |\n",
            "| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                                                | (256,) (256,256,3,3)                               |\n",
            "| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                                                   | (3,) (3,256,1,1)                                   |\n",
            "| roi_heads.box_head.conv1.*                      | roi_heads.box_head.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.conv2.*                      | roi_heads.box_head.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.conv3.*                      | roi_heads.box_head.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.conv4.*                      | roi_heads.box_head.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                                          | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                                               | (320,) (320,1024)                                  |\n",
            "| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                                               | (81,) (81,1024)                                    |\n",
            "| roi_heads.mask_head.deconv.*                    | roi_heads.mask_head.deconv.{bias,weight}                                                                                      | (256,) (256,256,2,2)                               |\n",
            "| roi_heads.mask_head.mask_fcn1.*                 | roi_heads.mask_head.mask_fcn1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.mask_fcn2.*                 | roi_heads.mask_head.mask_fcn2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.mask_fcn3.*                 | roi_heads.mask_head.mask_fcn3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.mask_fcn4.*                 | roi_heads.mask_head.mask_fcn4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.predictor.*                 | roi_heads.mask_head.predictor.{bias,weight}                                                                                   | (80,) (80,256,1,1)                                 |\n",
            "\u001b[32m[04/30 18:22:34 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json\n",
            "\u001b[32m[04/30 18:22:35 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n",
            "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
            "|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\n",
            "|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\n",
            "|     train     | 190          |    truck     | 414          |     boat      | 424          |\n",
            "| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\n",
            "| parking meter | 60           |    bench     | 411          |     bird      | 427          |\n",
            "|      cat      | 202          |     dog      | 218          |     horse     | 272          |\n",
            "|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\n",
            "|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\n",
            "|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\n",
            "|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\n",
            "|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\n",
            "|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\n",
            "|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\n",
            "|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\n",
            "|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\n",
            "|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\n",
            "|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\n",
            "|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\n",
            "|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\n",
            "|     couch     | 261          | potted plant | 342          |      bed      | 163          |\n",
            "| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\n",
            "|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\n",
            "|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\n",
            "|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\n",
            "| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\n",
            "|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\n",
            "|  hair drier   | 11           |  toothbrush  | 57           |               |              |\n",
            "|     total     | 36335        |              |              |               |              |\u001b[0m\n",
            "\u001b[32m[04/30 18:22:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/30 18:22:35 d2.data.common]: \u001b[0mSerializing 5000 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/30 18:22:35 d2.data.common]: \u001b[0mSerialized dataset takes 19.10 MiB\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[32m[04/30 18:22:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 5000 batches\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m[04/30 18:22:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/5000. Dataloading: 0.0009 s/iter. Inference: 0.2460 s/iter. Eval: 0.0237 s/iter. Total: 0.2705 s/iter. ETA=0:22:29\n",
            "\u001b[32m[04/30 18:22:44 d2.evaluation.evaluator]: \u001b[0mInference done 30/5000. Dataloading: 0.0016 s/iter. Inference: 0.2471 s/iter. Eval: 0.0179 s/iter. Total: 0.2667 s/iter. ETA=0:22:05\n",
            "\u001b[32m[04/30 18:22:50 d2.evaluation.evaluator]: \u001b[0mInference done 49/5000. Dataloading: 0.0018 s/iter. Inference: 0.2479 s/iter. Eval: 0.0196 s/iter. Total: 0.2693 s/iter. ETA=0:22:13\n",
            "\u001b[32m[04/30 18:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 68/5000. Dataloading: 0.0019 s/iter. Inference: 0.2497 s/iter. Eval: 0.0174 s/iter. Total: 0.2690 s/iter. ETA=0:22:06\n",
            "\u001b[32m[04/30 18:23:00 d2.evaluation.evaluator]: \u001b[0mInference done 87/5000. Dataloading: 0.0019 s/iter. Inference: 0.2497 s/iter. Eval: 0.0180 s/iter. Total: 0.2698 s/iter. ETA=0:22:05\n",
            "\u001b[32m[04/30 18:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 106/5000. Dataloading: 0.0020 s/iter. Inference: 0.2492 s/iter. Eval: 0.0193 s/iter. Total: 0.2706 s/iter. ETA=0:22:04\n",
            "\u001b[32m[04/30 18:23:10 d2.evaluation.evaluator]: \u001b[0mInference done 125/5000. Dataloading: 0.0020 s/iter. Inference: 0.2500 s/iter. Eval: 0.0194 s/iter. Total: 0.2715 s/iter. ETA=0:22:03\n",
            "\u001b[32m[04/30 18:23:15 d2.evaluation.evaluator]: \u001b[0mInference done 143/5000. Dataloading: 0.0020 s/iter. Inference: 0.2513 s/iter. Eval: 0.0195 s/iter. Total: 0.2728 s/iter. ETA=0:22:05\n",
            "\u001b[32m[04/30 18:23:21 d2.evaluation.evaluator]: \u001b[0mInference done 161/5000. Dataloading: 0.0020 s/iter. Inference: 0.2523 s/iter. Eval: 0.0193 s/iter. Total: 0.2736 s/iter. ETA=0:22:03\n",
            "\u001b[32m[04/30 18:23:26 d2.evaluation.evaluator]: \u001b[0mInference done 180/5000. Dataloading: 0.0020 s/iter. Inference: 0.2523 s/iter. Eval: 0.0191 s/iter. Total: 0.2734 s/iter. ETA=0:21:57\n",
            "\u001b[32m[04/30 18:23:31 d2.evaluation.evaluator]: \u001b[0mInference done 198/5000. Dataloading: 0.0020 s/iter. Inference: 0.2529 s/iter. Eval: 0.0189 s/iter. Total: 0.2739 s/iter. ETA=0:21:55\n",
            "\u001b[32m[04/30 18:23:36 d2.evaluation.evaluator]: \u001b[0mInference done 217/5000. Dataloading: 0.0020 s/iter. Inference: 0.2532 s/iter. Eval: 0.0181 s/iter. Total: 0.2734 s/iter. ETA=0:21:47\n",
            "\u001b[32m[04/30 18:23:41 d2.evaluation.evaluator]: \u001b[0mInference done 235/5000. Dataloading: 0.0020 s/iter. Inference: 0.2539 s/iter. Eval: 0.0178 s/iter. Total: 0.2738 s/iter. ETA=0:21:44\n",
            "\u001b[32m[04/30 18:23:46 d2.evaluation.evaluator]: \u001b[0mInference done 253/5000. Dataloading: 0.0020 s/iter. Inference: 0.2549 s/iter. Eval: 0.0184 s/iter. Total: 0.2753 s/iter. ETA=0:21:46\n",
            "\u001b[32m[04/30 18:23:51 d2.evaluation.evaluator]: \u001b[0mInference done 272/5000. Dataloading: 0.0020 s/iter. Inference: 0.2552 s/iter. Eval: 0.0180 s/iter. Total: 0.2753 s/iter. ETA=0:21:41\n",
            "\u001b[32m[04/30 18:23:57 d2.evaluation.evaluator]: \u001b[0mInference done 290/5000. Dataloading: 0.0020 s/iter. Inference: 0.2562 s/iter. Eval: 0.0180 s/iter. Total: 0.2762 s/iter. ETA=0:21:41\n",
            "\u001b[32m[04/30 18:24:02 d2.evaluation.evaluator]: \u001b[0mInference done 307/5000. Dataloading: 0.0020 s/iter. Inference: 0.2575 s/iter. Eval: 0.0181 s/iter. Total: 0.2777 s/iter. ETA=0:21:43\n",
            "\u001b[32m[04/30 18:24:07 d2.evaluation.evaluator]: \u001b[0mInference done 325/5000. Dataloading: 0.0020 s/iter. Inference: 0.2582 s/iter. Eval: 0.0182 s/iter. Total: 0.2785 s/iter. ETA=0:21:42\n",
            "\u001b[32m[04/30 18:24:12 d2.evaluation.evaluator]: \u001b[0mInference done 342/5000. Dataloading: 0.0020 s/iter. Inference: 0.2592 s/iter. Eval: 0.0184 s/iter. Total: 0.2796 s/iter. ETA=0:21:42\n",
            "\u001b[32m[04/30 18:24:17 d2.evaluation.evaluator]: \u001b[0mInference done 359/5000. Dataloading: 0.0020 s/iter. Inference: 0.2600 s/iter. Eval: 0.0184 s/iter. Total: 0.2805 s/iter. ETA=0:21:41\n",
            "\u001b[32m[04/30 18:24:22 d2.evaluation.evaluator]: \u001b[0mInference done 377/5000. Dataloading: 0.0020 s/iter. Inference: 0.2603 s/iter. Eval: 0.0182 s/iter. Total: 0.2806 s/iter. ETA=0:21:37\n",
            "\u001b[32m[04/30 18:24:27 d2.evaluation.evaluator]: \u001b[0mInference done 396/5000. Dataloading: 0.0020 s/iter. Inference: 0.2603 s/iter. Eval: 0.0179 s/iter. Total: 0.2802 s/iter. ETA=0:21:30\n",
            "\u001b[32m[04/30 18:24:32 d2.evaluation.evaluator]: \u001b[0mInference done 414/5000. Dataloading: 0.0020 s/iter. Inference: 0.2605 s/iter. Eval: 0.0177 s/iter. Total: 0.2803 s/iter. ETA=0:21:25\n",
            "\u001b[32m[04/30 18:24:37 d2.evaluation.evaluator]: \u001b[0mInference done 432/5000. Dataloading: 0.0020 s/iter. Inference: 0.2606 s/iter. Eval: 0.0176 s/iter. Total: 0.2803 s/iter. ETA=0:21:20\n",
            "\u001b[32m[04/30 18:24:43 d2.evaluation.evaluator]: \u001b[0mInference done 450/5000. Dataloading: 0.0020 s/iter. Inference: 0.2608 s/iter. Eval: 0.0175 s/iter. Total: 0.2804 s/iter. ETA=0:21:15\n",
            "\u001b[32m[04/30 18:24:48 d2.evaluation.evaluator]: \u001b[0mInference done 468/5000. Dataloading: 0.0020 s/iter. Inference: 0.2610 s/iter. Eval: 0.0172 s/iter. Total: 0.2804 s/iter. ETA=0:21:10\n",
            "\u001b[32m[04/30 18:24:53 d2.evaluation.evaluator]: \u001b[0mInference done 486/5000. Dataloading: 0.0020 s/iter. Inference: 0.2614 s/iter. Eval: 0.0173 s/iter. Total: 0.2808 s/iter. ETA=0:21:07\n",
            "\u001b[32m[04/30 18:24:58 d2.evaluation.evaluator]: \u001b[0mInference done 504/5000. Dataloading: 0.0020 s/iter. Inference: 0.2614 s/iter. Eval: 0.0173 s/iter. Total: 0.2808 s/iter. ETA=0:21:02\n",
            "\u001b[32m[04/30 18:25:03 d2.evaluation.evaluator]: \u001b[0mInference done 522/5000. Dataloading: 0.0020 s/iter. Inference: 0.2615 s/iter. Eval: 0.0174 s/iter. Total: 0.2810 s/iter. ETA=0:20:58\n",
            "\u001b[32m[04/30 18:25:08 d2.evaluation.evaluator]: \u001b[0mInference done 540/5000. Dataloading: 0.0020 s/iter. Inference: 0.2617 s/iter. Eval: 0.0175 s/iter. Total: 0.2814 s/iter. ETA=0:20:54\n",
            "\u001b[32m[04/30 18:25:14 d2.evaluation.evaluator]: \u001b[0mInference done 558/5000. Dataloading: 0.0020 s/iter. Inference: 0.2619 s/iter. Eval: 0.0177 s/iter. Total: 0.2816 s/iter. ETA=0:20:50\n",
            "\u001b[32m[04/30 18:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 576/5000. Dataloading: 0.0020 s/iter. Inference: 0.2621 s/iter. Eval: 0.0176 s/iter. Total: 0.2818 s/iter. ETA=0:20:46\n",
            "\u001b[32m[04/30 18:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 594/5000. Dataloading: 0.0020 s/iter. Inference: 0.2622 s/iter. Eval: 0.0177 s/iter. Total: 0.2820 s/iter. ETA=0:20:42\n",
            "\u001b[32m[04/30 18:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 612/5000. Dataloading: 0.0020 s/iter. Inference: 0.2624 s/iter. Eval: 0.0178 s/iter. Total: 0.2822 s/iter. ETA=0:20:38\n",
            "\u001b[32m[04/30 18:25:34 d2.evaluation.evaluator]: \u001b[0mInference done 630/5000. Dataloading: 0.0020 s/iter. Inference: 0.2626 s/iter. Eval: 0.0176 s/iter. Total: 0.2823 s/iter. ETA=0:20:33\n",
            "\u001b[32m[04/30 18:25:39 d2.evaluation.evaluator]: \u001b[0mInference done 647/5000. Dataloading: 0.0020 s/iter. Inference: 0.2628 s/iter. Eval: 0.0178 s/iter. Total: 0.2827 s/iter. ETA=0:20:30\n",
            "\u001b[32m[04/30 18:25:44 d2.evaluation.evaluator]: \u001b[0mInference done 664/5000. Dataloading: 0.0020 s/iter. Inference: 0.2630 s/iter. Eval: 0.0180 s/iter. Total: 0.2831 s/iter. ETA=0:20:27\n",
            "\u001b[32m[04/30 18:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 682/5000. Dataloading: 0.0020 s/iter. Inference: 0.2632 s/iter. Eval: 0.0180 s/iter. Total: 0.2833 s/iter. ETA=0:20:23\n",
            "\u001b[32m[04/30 18:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 700/5000. Dataloading: 0.0020 s/iter. Inference: 0.2633 s/iter. Eval: 0.0178 s/iter. Total: 0.2832 s/iter. ETA=0:20:17\n",
            "\u001b[32m[04/30 18:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 717/5000. Dataloading: 0.0020 s/iter. Inference: 0.2637 s/iter. Eval: 0.0179 s/iter. Total: 0.2836 s/iter. ETA=0:20:14\n",
            "\u001b[32m[04/30 18:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 735/5000. Dataloading: 0.0020 s/iter. Inference: 0.2637 s/iter. Eval: 0.0179 s/iter. Total: 0.2837 s/iter. ETA=0:20:10\n",
            "\u001b[32m[04/30 18:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 753/5000. Dataloading: 0.0020 s/iter. Inference: 0.2638 s/iter. Eval: 0.0179 s/iter. Total: 0.2837 s/iter. ETA=0:20:04\n",
            "\u001b[32m[04/30 18:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 771/5000. Dataloading: 0.0020 s/iter. Inference: 0.2638 s/iter. Eval: 0.0178 s/iter. Total: 0.2837 s/iter. ETA=0:19:59\n",
            "\u001b[32m[04/30 18:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 789/5000. Dataloading: 0.0020 s/iter. Inference: 0.2640 s/iter. Eval: 0.0177 s/iter. Total: 0.2838 s/iter. ETA=0:19:55\n",
            "\u001b[32m[04/30 18:26:26 d2.evaluation.evaluator]: \u001b[0mInference done 807/5000. Dataloading: 0.0020 s/iter. Inference: 0.2641 s/iter. Eval: 0.0178 s/iter. Total: 0.2840 s/iter. ETA=0:19:50\n",
            "\u001b[32m[04/30 18:26:31 d2.evaluation.evaluator]: \u001b[0mInference done 826/5000. Dataloading: 0.0020 s/iter. Inference: 0.2641 s/iter. Eval: 0.0176 s/iter. Total: 0.2838 s/iter. ETA=0:19:44\n",
            "\u001b[32m[04/30 18:26:36 d2.evaluation.evaluator]: \u001b[0mInference done 844/5000. Dataloading: 0.0020 s/iter. Inference: 0.2642 s/iter. Eval: 0.0176 s/iter. Total: 0.2839 s/iter. ETA=0:19:40\n",
            "\u001b[32m[04/30 18:26:41 d2.evaluation.evaluator]: \u001b[0mInference done 862/5000. Dataloading: 0.0020 s/iter. Inference: 0.2643 s/iter. Eval: 0.0176 s/iter. Total: 0.2840 s/iter. ETA=0:19:35\n",
            "\u001b[32m[04/30 18:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 880/5000. Dataloading: 0.0020 s/iter. Inference: 0.2644 s/iter. Eval: 0.0175 s/iter. Total: 0.2840 s/iter. ETA=0:19:29\n",
            "\u001b[32m[04/30 18:26:52 d2.evaluation.evaluator]: \u001b[0mInference done 898/5000. Dataloading: 0.0020 s/iter. Inference: 0.2646 s/iter. Eval: 0.0175 s/iter. Total: 0.2841 s/iter. ETA=0:19:25\n",
            "\u001b[32m[04/30 18:26:57 d2.evaluation.evaluator]: \u001b[0mInference done 916/5000. Dataloading: 0.0020 s/iter. Inference: 0.2646 s/iter. Eval: 0.0174 s/iter. Total: 0.2841 s/iter. ETA=0:19:20\n",
            "\u001b[32m[04/30 18:27:02 d2.evaluation.evaluator]: \u001b[0mInference done 933/5000. Dataloading: 0.0020 s/iter. Inference: 0.2648 s/iter. Eval: 0.0174 s/iter. Total: 0.2843 s/iter. ETA=0:19:16\n",
            "\u001b[32m[04/30 18:27:07 d2.evaluation.evaluator]: \u001b[0mInference done 951/5000. Dataloading: 0.0020 s/iter. Inference: 0.2651 s/iter. Eval: 0.0173 s/iter. Total: 0.2845 s/iter. ETA=0:19:11\n",
            "\u001b[32m[04/30 18:27:12 d2.evaluation.evaluator]: \u001b[0mInference done 968/5000. Dataloading: 0.0020 s/iter. Inference: 0.2653 s/iter. Eval: 0.0173 s/iter. Total: 0.2847 s/iter. ETA=0:19:07\n",
            "\u001b[32m[04/30 18:27:17 d2.evaluation.evaluator]: \u001b[0mInference done 985/5000. Dataloading: 0.0020 s/iter. Inference: 0.2655 s/iter. Eval: 0.0174 s/iter. Total: 0.2850 s/iter. ETA=0:19:04\n",
            "\u001b[32m[04/30 18:27:22 d2.evaluation.evaluator]: \u001b[0mInference done 1003/5000. Dataloading: 0.0020 s/iter. Inference: 0.2656 s/iter. Eval: 0.0172 s/iter. Total: 0.2849 s/iter. ETA=0:18:58\n",
            "\u001b[32m[04/30 18:27:27 d2.evaluation.evaluator]: \u001b[0mInference done 1021/5000. Dataloading: 0.0020 s/iter. Inference: 0.2657 s/iter. Eval: 0.0173 s/iter. Total: 0.2851 s/iter. ETA=0:18:54\n",
            "\u001b[32m[04/30 18:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 1039/5000. Dataloading: 0.0020 s/iter. Inference: 0.2658 s/iter. Eval: 0.0174 s/iter. Total: 0.2853 s/iter. ETA=0:18:49\n",
            "\u001b[32m[04/30 18:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 1057/5000. Dataloading: 0.0020 s/iter. Inference: 0.2659 s/iter. Eval: 0.0173 s/iter. Total: 0.2853 s/iter. ETA=0:18:44\n",
            "\u001b[32m[04/30 18:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 1074/5000. Dataloading: 0.0020 s/iter. Inference: 0.2661 s/iter. Eval: 0.0174 s/iter. Total: 0.2856 s/iter. ETA=0:18:41\n",
            "\u001b[32m[04/30 18:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 1092/5000. Dataloading: 0.0020 s/iter. Inference: 0.2662 s/iter. Eval: 0.0174 s/iter. Total: 0.2857 s/iter. ETA=0:18:36\n",
            "\u001b[32m[04/30 18:27:54 d2.evaluation.evaluator]: \u001b[0mInference done 1110/5000. Dataloading: 0.0020 s/iter. Inference: 0.2663 s/iter. Eval: 0.0173 s/iter. Total: 0.2857 s/iter. ETA=0:18:31\n",
            "\u001b[32m[04/30 18:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 1128/5000. Dataloading: 0.0020 s/iter. Inference: 0.2663 s/iter. Eval: 0.0172 s/iter. Total: 0.2856 s/iter. ETA=0:18:25\n",
            "\u001b[32m[04/30 18:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 1145/5000. Dataloading: 0.0020 s/iter. Inference: 0.2665 s/iter. Eval: 0.0173 s/iter. Total: 0.2858 s/iter. ETA=0:18:21\n",
            "\u001b[32m[04/30 18:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 1163/5000. Dataloading: 0.0020 s/iter. Inference: 0.2666 s/iter. Eval: 0.0174 s/iter. Total: 0.2860 s/iter. ETA=0:18:17\n",
            "\u001b[32m[04/30 18:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 1181/5000. Dataloading: 0.0020 s/iter. Inference: 0.2667 s/iter. Eval: 0.0174 s/iter. Total: 0.2861 s/iter. ETA=0:18:12\n",
            "\u001b[32m[04/30 18:28:20 d2.evaluation.evaluator]: \u001b[0mInference done 1199/5000. Dataloading: 0.0020 s/iter. Inference: 0.2668 s/iter. Eval: 0.0174 s/iter. Total: 0.2863 s/iter. ETA=0:18:08\n",
            "\u001b[32m[04/30 18:28:25 d2.evaluation.evaluator]: \u001b[0mInference done 1216/5000. Dataloading: 0.0020 s/iter. Inference: 0.2669 s/iter. Eval: 0.0176 s/iter. Total: 0.2866 s/iter. ETA=0:18:04\n",
            "\u001b[32m[04/30 18:28:30 d2.evaluation.evaluator]: \u001b[0mInference done 1233/5000. Dataloading: 0.0020 s/iter. Inference: 0.2670 s/iter. Eval: 0.0176 s/iter. Total: 0.2868 s/iter. ETA=0:18:00\n",
            "\u001b[32m[04/30 18:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 1250/5000. Dataloading: 0.0020 s/iter. Inference: 0.2671 s/iter. Eval: 0.0178 s/iter. Total: 0.2870 s/iter. ETA=0:17:56\n",
            "\u001b[32m[04/30 18:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 1268/5000. Dataloading: 0.0020 s/iter. Inference: 0.2672 s/iter. Eval: 0.0178 s/iter. Total: 0.2870 s/iter. ETA=0:17:51\n",
            "\u001b[32m[04/30 18:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 1285/5000. Dataloading: 0.0020 s/iter. Inference: 0.2673 s/iter. Eval: 0.0178 s/iter. Total: 0.2872 s/iter. ETA=0:17:47\n",
            "\u001b[32m[04/30 18:28:51 d2.evaluation.evaluator]: \u001b[0mInference done 1303/5000. Dataloading: 0.0020 s/iter. Inference: 0.2673 s/iter. Eval: 0.0177 s/iter. Total: 0.2872 s/iter. ETA=0:17:41\n",
            "\u001b[32m[04/30 18:28:56 d2.evaluation.evaluator]: \u001b[0mInference done 1321/5000. Dataloading: 0.0020 s/iter. Inference: 0.2673 s/iter. Eval: 0.0177 s/iter. Total: 0.2871 s/iter. ETA=0:17:36\n",
            "\u001b[32m[04/30 18:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 1338/5000. Dataloading: 0.0020 s/iter. Inference: 0.2675 s/iter. Eval: 0.0177 s/iter. Total: 0.2873 s/iter. ETA=0:17:32\n",
            "\u001b[32m[04/30 18:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 1355/5000. Dataloading: 0.0020 s/iter. Inference: 0.2675 s/iter. Eval: 0.0178 s/iter. Total: 0.2874 s/iter. ETA=0:17:27\n",
            "\u001b[32m[04/30 18:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 1373/5000. Dataloading: 0.0020 s/iter. Inference: 0.2676 s/iter. Eval: 0.0178 s/iter. Total: 0.2875 s/iter. ETA=0:17:22\n",
            "\u001b[32m[04/30 18:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 1391/5000. Dataloading: 0.0020 s/iter. Inference: 0.2676 s/iter. Eval: 0.0177 s/iter. Total: 0.2874 s/iter. ETA=0:17:17\n",
            "\u001b[32m[04/30 18:29:21 d2.evaluation.evaluator]: \u001b[0mInference done 1409/5000. Dataloading: 0.0020 s/iter. Inference: 0.2676 s/iter. Eval: 0.0177 s/iter. Total: 0.2874 s/iter. ETA=0:17:11\n",
            "\u001b[32m[04/30 18:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 1427/5000. Dataloading: 0.0020 s/iter. Inference: 0.2676 s/iter. Eval: 0.0177 s/iter. Total: 0.2874 s/iter. ETA=0:17:06\n",
            "\u001b[32m[04/30 18:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 1444/5000. Dataloading: 0.0020 s/iter. Inference: 0.2677 s/iter. Eval: 0.0177 s/iter. Total: 0.2875 s/iter. ETA=0:17:02\n",
            "\u001b[32m[04/30 18:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 1462/5000. Dataloading: 0.0020 s/iter. Inference: 0.2677 s/iter. Eval: 0.0177 s/iter. Total: 0.2874 s/iter. ETA=0:16:56\n",
            "\u001b[32m[04/30 18:29:42 d2.evaluation.evaluator]: \u001b[0mInference done 1480/5000. Dataloading: 0.0020 s/iter. Inference: 0.2677 s/iter. Eval: 0.0178 s/iter. Total: 0.2875 s/iter. ETA=0:16:51\n",
            "\u001b[32m[04/30 18:29:47 d2.evaluation.evaluator]: \u001b[0mInference done 1498/5000. Dataloading: 0.0020 s/iter. Inference: 0.2677 s/iter. Eval: 0.0177 s/iter. Total: 0.2875 s/iter. ETA=0:16:46\n",
            "\u001b[32m[04/30 18:29:52 d2.evaluation.evaluator]: \u001b[0mInference done 1516/5000. Dataloading: 0.0020 s/iter. Inference: 0.2676 s/iter. Eval: 0.0177 s/iter. Total: 0.2874 s/iter. ETA=0:16:41\n",
            "\u001b[32m[04/30 18:29:57 d2.evaluation.evaluator]: \u001b[0mInference done 1534/5000. Dataloading: 0.0020 s/iter. Inference: 0.2677 s/iter. Eval: 0.0177 s/iter. Total: 0.2874 s/iter. ETA=0:16:36\n",
            "\u001b[32m[04/30 18:30:02 d2.evaluation.evaluator]: \u001b[0mInference done 1551/5000. Dataloading: 0.0020 s/iter. Inference: 0.2678 s/iter. Eval: 0.0178 s/iter. Total: 0.2876 s/iter. ETA=0:16:32\n",
            "\u001b[32m[04/30 18:30:08 d2.evaluation.evaluator]: \u001b[0mInference done 1569/5000. Dataloading: 0.0020 s/iter. Inference: 0.2678 s/iter. Eval: 0.0178 s/iter. Total: 0.2877 s/iter. ETA=0:16:26\n",
            "\u001b[32m[04/30 18:30:13 d2.evaluation.evaluator]: \u001b[0mInference done 1586/5000. Dataloading: 0.0020 s/iter. Inference: 0.2679 s/iter. Eval: 0.0178 s/iter. Total: 0.2878 s/iter. ETA=0:16:22\n",
            "\u001b[32m[04/30 18:30:18 d2.evaluation.evaluator]: \u001b[0mInference done 1603/5000. Dataloading: 0.0020 s/iter. Inference: 0.2680 s/iter. Eval: 0.0178 s/iter. Total: 0.2880 s/iter. ETA=0:16:18\n",
            "\u001b[32m[04/30 18:30:23 d2.evaluation.evaluator]: \u001b[0mInference done 1621/5000. Dataloading: 0.0020 s/iter. Inference: 0.2681 s/iter. Eval: 0.0178 s/iter. Total: 0.2880 s/iter. ETA=0:16:13\n",
            "\u001b[32m[04/30 18:30:28 d2.evaluation.evaluator]: \u001b[0mInference done 1639/5000. Dataloading: 0.0020 s/iter. Inference: 0.2681 s/iter. Eval: 0.0178 s/iter. Total: 0.2880 s/iter. ETA=0:16:07\n",
            "\u001b[32m[04/30 18:30:34 d2.evaluation.evaluator]: \u001b[0mInference done 1657/5000. Dataloading: 0.0020 s/iter. Inference: 0.2681 s/iter. Eval: 0.0178 s/iter. Total: 0.2880 s/iter. ETA=0:16:02\n",
            "\u001b[32m[04/30 18:30:39 d2.evaluation.evaluator]: \u001b[0mInference done 1674/5000. Dataloading: 0.0020 s/iter. Inference: 0.2682 s/iter. Eval: 0.0178 s/iter. Total: 0.2881 s/iter. ETA=0:15:58\n",
            "\u001b[32m[04/30 18:30:44 d2.evaluation.evaluator]: \u001b[0mInference done 1692/5000. Dataloading: 0.0020 s/iter. Inference: 0.2682 s/iter. Eval: 0.0178 s/iter. Total: 0.2881 s/iter. ETA=0:15:52\n",
            "\u001b[32m[04/30 18:30:49 d2.evaluation.evaluator]: \u001b[0mInference done 1710/5000. Dataloading: 0.0020 s/iter. Inference: 0.2683 s/iter. Eval: 0.0177 s/iter. Total: 0.2881 s/iter. ETA=0:15:47\n",
            "\u001b[32m[04/30 18:30:54 d2.evaluation.evaluator]: \u001b[0mInference done 1727/5000. Dataloading: 0.0020 s/iter. Inference: 0.2683 s/iter. Eval: 0.0178 s/iter. Total: 0.2882 s/iter. ETA=0:15:43\n",
            "\u001b[32m[04/30 18:30:59 d2.evaluation.evaluator]: \u001b[0mInference done 1745/5000. Dataloading: 0.0020 s/iter. Inference: 0.2684 s/iter. Eval: 0.0177 s/iter. Total: 0.2881 s/iter. ETA=0:15:37\n",
            "\u001b[32m[04/30 18:31:04 d2.evaluation.evaluator]: \u001b[0mInference done 1763/5000. Dataloading: 0.0020 s/iter. Inference: 0.2684 s/iter. Eval: 0.0176 s/iter. Total: 0.2881 s/iter. ETA=0:15:32\n",
            "\u001b[32m[04/30 18:31:09 d2.evaluation.evaluator]: \u001b[0mInference done 1781/5000. Dataloading: 0.0020 s/iter. Inference: 0.2684 s/iter. Eval: 0.0176 s/iter. Total: 0.2881 s/iter. ETA=0:15:27\n",
            "\u001b[32m[04/30 18:31:15 d2.evaluation.evaluator]: \u001b[0mInference done 1799/5000. Dataloading: 0.0020 s/iter. Inference: 0.2684 s/iter. Eval: 0.0176 s/iter. Total: 0.2880 s/iter. ETA=0:15:21\n",
            "\u001b[32m[04/30 18:31:20 d2.evaluation.evaluator]: \u001b[0mInference done 1816/5000. Dataloading: 0.0020 s/iter. Inference: 0.2684 s/iter. Eval: 0.0176 s/iter. Total: 0.2882 s/iter. ETA=0:15:17\n",
            "\u001b[32m[04/30 18:31:25 d2.evaluation.evaluator]: \u001b[0mInference done 1834/5000. Dataloading: 0.0020 s/iter. Inference: 0.2684 s/iter. Eval: 0.0177 s/iter. Total: 0.2882 s/iter. ETA=0:15:12\n",
            "\u001b[32m[04/30 18:31:30 d2.evaluation.evaluator]: \u001b[0mInference done 1852/5000. Dataloading: 0.0020 s/iter. Inference: 0.2684 s/iter. Eval: 0.0176 s/iter. Total: 0.2882 s/iter. ETA=0:15:07\n",
            "\u001b[32m[04/30 18:31:35 d2.evaluation.evaluator]: \u001b[0mInference done 1869/5000. Dataloading: 0.0020 s/iter. Inference: 0.2685 s/iter. Eval: 0.0176 s/iter. Total: 0.2882 s/iter. ETA=0:15:02\n",
            "\u001b[32m[04/30 18:31:40 d2.evaluation.evaluator]: \u001b[0mInference done 1887/5000. Dataloading: 0.0020 s/iter. Inference: 0.2685 s/iter. Eval: 0.0176 s/iter. Total: 0.2882 s/iter. ETA=0:14:57\n",
            "\u001b[32m[04/30 18:31:45 d2.evaluation.evaluator]: \u001b[0mInference done 1904/5000. Dataloading: 0.0020 s/iter. Inference: 0.2686 s/iter. Eval: 0.0177 s/iter. Total: 0.2884 s/iter. ETA=0:14:52\n",
            "\u001b[32m[04/30 18:31:51 d2.evaluation.evaluator]: \u001b[0mInference done 1922/5000. Dataloading: 0.0020 s/iter. Inference: 0.2686 s/iter. Eval: 0.0176 s/iter. Total: 0.2883 s/iter. ETA=0:14:47\n",
            "\u001b[32m[04/30 18:31:56 d2.evaluation.evaluator]: \u001b[0mInference done 1940/5000. Dataloading: 0.0020 s/iter. Inference: 0.2686 s/iter. Eval: 0.0176 s/iter. Total: 0.2883 s/iter. ETA=0:14:42\n",
            "\u001b[32m[04/30 18:32:01 d2.evaluation.evaluator]: \u001b[0mInference done 1958/5000. Dataloading: 0.0020 s/iter. Inference: 0.2686 s/iter. Eval: 0.0175 s/iter. Total: 0.2883 s/iter. ETA=0:14:36\n",
            "\u001b[32m[04/30 18:32:06 d2.evaluation.evaluator]: \u001b[0mInference done 1975/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0176 s/iter. Total: 0.2883 s/iter. ETA=0:14:32\n",
            "\u001b[32m[04/30 18:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 1993/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0176 s/iter. Total: 0.2884 s/iter. ETA=0:14:27\n",
            "\u001b[32m[04/30 18:32:16 d2.evaluation.evaluator]: \u001b[0mInference done 2010/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0176 s/iter. Total: 0.2885 s/iter. ETA=0:14:22\n",
            "\u001b[32m[04/30 18:32:21 d2.evaluation.evaluator]: \u001b[0mInference done 2027/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0176 s/iter. Total: 0.2885 s/iter. ETA=0:14:17\n",
            "\u001b[32m[04/30 18:32:26 d2.evaluation.evaluator]: \u001b[0mInference done 2044/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0177 s/iter. Total: 0.2886 s/iter. ETA=0:14:13\n",
            "\u001b[32m[04/30 18:32:32 d2.evaluation.evaluator]: \u001b[0mInference done 2063/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0176 s/iter. Total: 0.2885 s/iter. ETA=0:14:07\n",
            "\u001b[32m[04/30 18:32:37 d2.evaluation.evaluator]: \u001b[0mInference done 2081/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0175 s/iter. Total: 0.2885 s/iter. ETA=0:14:01\n",
            "\u001b[32m[04/30 18:32:42 d2.evaluation.evaluator]: \u001b[0mInference done 2098/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0176 s/iter. Total: 0.2885 s/iter. ETA=0:13:57\n",
            "\u001b[32m[04/30 18:32:47 d2.evaluation.evaluator]: \u001b[0mInference done 2116/5000. Dataloading: 0.0020 s/iter. Inference: 0.2689 s/iter. Eval: 0.0176 s/iter. Total: 0.2886 s/iter. ETA=0:13:52\n",
            "\u001b[32m[04/30 18:32:52 d2.evaluation.evaluator]: \u001b[0mInference done 2134/5000. Dataloading: 0.0020 s/iter. Inference: 0.2689 s/iter. Eval: 0.0175 s/iter. Total: 0.2885 s/iter. ETA=0:13:46\n",
            "\u001b[32m[04/30 18:32:57 d2.evaluation.evaluator]: \u001b[0mInference done 2152/5000. Dataloading: 0.0020 s/iter. Inference: 0.2689 s/iter. Eval: 0.0175 s/iter. Total: 0.2885 s/iter. ETA=0:13:41\n",
            "\u001b[32m[04/30 18:33:02 d2.evaluation.evaluator]: \u001b[0mInference done 2170/5000. Dataloading: 0.0020 s/iter. Inference: 0.2689 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:13:36\n",
            "\u001b[32m[04/30 18:33:07 d2.evaluation.evaluator]: \u001b[0mInference done 2188/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:13:31\n",
            "\u001b[32m[04/30 18:33:13 d2.evaluation.evaluator]: \u001b[0mInference done 2205/5000. Dataloading: 0.0020 s/iter. Inference: 0.2689 s/iter. Eval: 0.0175 s/iter. Total: 0.2885 s/iter. ETA=0:13:26\n",
            "\u001b[32m[04/30 18:33:18 d2.evaluation.evaluator]: \u001b[0mInference done 2223/5000. Dataloading: 0.0020 s/iter. Inference: 0.2689 s/iter. Eval: 0.0175 s/iter. Total: 0.2885 s/iter. ETA=0:13:21\n",
            "\u001b[32m[04/30 18:33:23 d2.evaluation.evaluator]: \u001b[0mInference done 2241/5000. Dataloading: 0.0020 s/iter. Inference: 0.2690 s/iter. Eval: 0.0175 s/iter. Total: 0.2885 s/iter. ETA=0:13:16\n",
            "\u001b[32m[04/30 18:33:28 d2.evaluation.evaluator]: \u001b[0mInference done 2258/5000. Dataloading: 0.0020 s/iter. Inference: 0.2691 s/iter. Eval: 0.0176 s/iter. Total: 0.2887 s/iter. ETA=0:13:11\n",
            "\u001b[32m[04/30 18:33:33 d2.evaluation.evaluator]: \u001b[0mInference done 2276/5000. Dataloading: 0.0020 s/iter. Inference: 0.2691 s/iter. Eval: 0.0175 s/iter. Total: 0.2887 s/iter. ETA=0:13:06\n",
            "\u001b[32m[04/30 18:33:38 d2.evaluation.evaluator]: \u001b[0mInference done 2294/5000. Dataloading: 0.0020 s/iter. Inference: 0.2691 s/iter. Eval: 0.0175 s/iter. Total: 0.2886 s/iter. ETA=0:13:00\n",
            "\u001b[32m[04/30 18:33:44 d2.evaluation.evaluator]: \u001b[0mInference done 2312/5000. Dataloading: 0.0020 s/iter. Inference: 0.2691 s/iter. Eval: 0.0175 s/iter. Total: 0.2886 s/iter. ETA=0:12:55\n",
            "\u001b[32m[04/30 18:33:49 d2.evaluation.evaluator]: \u001b[0mInference done 2330/5000. Dataloading: 0.0020 s/iter. Inference: 0.2691 s/iter. Eval: 0.0174 s/iter. Total: 0.2886 s/iter. ETA=0:12:50\n",
            "\u001b[32m[04/30 18:33:54 d2.evaluation.evaluator]: \u001b[0mInference done 2348/5000. Dataloading: 0.0020 s/iter. Inference: 0.2691 s/iter. Eval: 0.0174 s/iter. Total: 0.2886 s/iter. ETA=0:12:45\n",
            "\u001b[32m[04/30 18:33:59 d2.evaluation.evaluator]: \u001b[0mInference done 2366/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0174 s/iter. Total: 0.2886 s/iter. ETA=0:12:40\n",
            "\u001b[32m[04/30 18:34:04 d2.evaluation.evaluator]: \u001b[0mInference done 2384/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0174 s/iter. Total: 0.2886 s/iter. ETA=0:12:35\n",
            "\u001b[32m[04/30 18:34:10 d2.evaluation.evaluator]: \u001b[0mInference done 2401/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0175 s/iter. Total: 0.2887 s/iter. ETA=0:12:30\n",
            "\u001b[32m[04/30 18:34:15 d2.evaluation.evaluator]: \u001b[0mInference done 2418/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0175 s/iter. Total: 0.2888 s/iter. ETA=0:12:25\n",
            "\u001b[32m[04/30 18:34:20 d2.evaluation.evaluator]: \u001b[0mInference done 2435/5000. Dataloading: 0.0020 s/iter. Inference: 0.2693 s/iter. Eval: 0.0175 s/iter. Total: 0.2889 s/iter. ETA=0:12:21\n",
            "\u001b[32m[04/30 18:34:25 d2.evaluation.evaluator]: \u001b[0mInference done 2453/5000. Dataloading: 0.0020 s/iter. Inference: 0.2693 s/iter. Eval: 0.0175 s/iter. Total: 0.2889 s/iter. ETA=0:12:15\n",
            "\u001b[32m[04/30 18:34:30 d2.evaluation.evaluator]: \u001b[0mInference done 2471/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0175 s/iter. Total: 0.2889 s/iter. ETA=0:12:10\n",
            "\u001b[32m[04/30 18:34:36 d2.evaluation.evaluator]: \u001b[0mInference done 2489/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0175 s/iter. Total: 0.2890 s/iter. ETA=0:12:05\n",
            "\u001b[32m[04/30 18:34:41 d2.evaluation.evaluator]: \u001b[0mInference done 2507/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0175 s/iter. Total: 0.2890 s/iter. ETA=0:12:00\n",
            "\u001b[32m[04/30 18:34:46 d2.evaluation.evaluator]: \u001b[0mInference done 2524/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0176 s/iter. Total: 0.2890 s/iter. ETA=0:11:55\n",
            "\u001b[32m[04/30 18:34:51 d2.evaluation.evaluator]: \u001b[0mInference done 2542/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0175 s/iter. Total: 0.2890 s/iter. ETA=0:11:50\n",
            "\u001b[32m[04/30 18:34:56 d2.evaluation.evaluator]: \u001b[0mInference done 2559/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0176 s/iter. Total: 0.2891 s/iter. ETA=0:11:45\n",
            "\u001b[32m[04/30 18:35:01 d2.evaluation.evaluator]: \u001b[0mInference done 2576/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0176 s/iter. Total: 0.2891 s/iter. ETA=0:11:40\n",
            "\u001b[32m[04/30 18:35:06 d2.evaluation.evaluator]: \u001b[0mInference done 2594/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0176 s/iter. Total: 0.2891 s/iter. ETA=0:11:35\n",
            "\u001b[32m[04/30 18:35:11 d2.evaluation.evaluator]: \u001b[0mInference done 2611/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0176 s/iter. Total: 0.2891 s/iter. ETA=0:11:30\n",
            "\u001b[32m[04/30 18:35:17 d2.evaluation.evaluator]: \u001b[0mInference done 2629/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0176 s/iter. Total: 0.2892 s/iter. ETA=0:11:25\n",
            "\u001b[32m[04/30 18:35:22 d2.evaluation.evaluator]: \u001b[0mInference done 2647/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0176 s/iter. Total: 0.2892 s/iter. ETA=0:11:20\n",
            "\u001b[32m[04/30 18:35:27 d2.evaluation.evaluator]: \u001b[0mInference done 2665/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0176 s/iter. Total: 0.2892 s/iter. ETA=0:11:15\n",
            "\u001b[32m[04/30 18:35:32 d2.evaluation.evaluator]: \u001b[0mInference done 2682/5000. Dataloading: 0.0020 s/iter. Inference: 0.2696 s/iter. Eval: 0.0176 s/iter. Total: 0.2892 s/iter. ETA=0:11:10\n",
            "\u001b[32m[04/30 18:35:37 d2.evaluation.evaluator]: \u001b[0mInference done 2700/5000. Dataloading: 0.0020 s/iter. Inference: 0.2696 s/iter. Eval: 0.0175 s/iter. Total: 0.2892 s/iter. ETA=0:11:05\n",
            "\u001b[32m[04/30 18:35:42 d2.evaluation.evaluator]: \u001b[0mInference done 2718/5000. Dataloading: 0.0020 s/iter. Inference: 0.2696 s/iter. Eval: 0.0175 s/iter. Total: 0.2892 s/iter. ETA=0:10:59\n",
            "\u001b[32m[04/30 18:35:47 d2.evaluation.evaluator]: \u001b[0mInference done 2735/5000. Dataloading: 0.0020 s/iter. Inference: 0.2696 s/iter. Eval: 0.0175 s/iter. Total: 0.2892 s/iter. ETA=0:10:55\n",
            "\u001b[32m[04/30 18:35:53 d2.evaluation.evaluator]: \u001b[0mInference done 2754/5000. Dataloading: 0.0020 s/iter. Inference: 0.2696 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:10:49\n",
            "\u001b[32m[04/30 18:35:58 d2.evaluation.evaluator]: \u001b[0mInference done 2772/5000. Dataloading: 0.0020 s/iter. Inference: 0.2696 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:10:44\n",
            "\u001b[32m[04/30 18:36:03 d2.evaluation.evaluator]: \u001b[0mInference done 2790/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:10:38\n",
            "\u001b[32m[04/30 18:36:08 d2.evaluation.evaluator]: \u001b[0mInference done 2808/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:10:33\n",
            "\u001b[32m[04/30 18:36:13 d2.evaluation.evaluator]: \u001b[0mInference done 2825/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:10:28\n",
            "\u001b[32m[04/30 18:36:18 d2.evaluation.evaluator]: \u001b[0mInference done 2843/5000. Dataloading: 0.0020 s/iter. Inference: 0.2696 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:10:23\n",
            "\u001b[32m[04/30 18:36:23 d2.evaluation.evaluator]: \u001b[0mInference done 2861/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:10:18\n",
            "\u001b[32m[04/30 18:36:29 d2.evaluation.evaluator]: \u001b[0mInference done 2879/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:10:13\n",
            "\u001b[32m[04/30 18:36:34 d2.evaluation.evaluator]: \u001b[0mInference done 2897/5000. Dataloading: 0.0020 s/iter. Inference: 0.2696 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:10:07\n",
            "\u001b[32m[04/30 18:36:39 d2.evaluation.evaluator]: \u001b[0mInference done 2915/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:10:02\n",
            "\u001b[32m[04/30 18:36:44 d2.evaluation.evaluator]: \u001b[0mInference done 2932/5000. Dataloading: 0.0020 s/iter. Inference: 0.2696 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:09:57\n",
            "\u001b[32m[04/30 18:36:49 d2.evaluation.evaluator]: \u001b[0mInference done 2950/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:09:52\n",
            "\u001b[32m[04/30 18:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 2968/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:09:47\n",
            "\u001b[32m[04/30 18:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 2986/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0175 s/iter. Total: 0.2890 s/iter. ETA=0:09:42\n",
            "\u001b[32m[04/30 18:37:05 d2.evaluation.evaluator]: \u001b[0mInference done 3004/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0174 s/iter. Total: 0.2890 s/iter. ETA=0:09:36\n",
            "\u001b[32m[04/30 18:37:10 d2.evaluation.evaluator]: \u001b[0mInference done 3022/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0174 s/iter. Total: 0.2890 s/iter. ETA=0:09:31\n",
            "\u001b[32m[04/30 18:37:15 d2.evaluation.evaluator]: \u001b[0mInference done 3039/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0174 s/iter. Total: 0.2890 s/iter. ETA=0:09:26\n",
            "\u001b[32m[04/30 18:37:20 d2.evaluation.evaluator]: \u001b[0mInference done 3057/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0174 s/iter. Total: 0.2890 s/iter. ETA=0:09:21\n",
            "\u001b[32m[04/30 18:37:25 d2.evaluation.evaluator]: \u001b[0mInference done 3075/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0174 s/iter. Total: 0.2890 s/iter. ETA=0:09:16\n",
            "\u001b[32m[04/30 18:37:30 d2.evaluation.evaluator]: \u001b[0mInference done 3093/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0174 s/iter. Total: 0.2890 s/iter. ETA=0:09:11\n",
            "\u001b[32m[04/30 18:37:35 d2.evaluation.evaluator]: \u001b[0mInference done 3111/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0174 s/iter. Total: 0.2889 s/iter. ETA=0:09:05\n",
            "\u001b[32m[04/30 18:37:40 d2.evaluation.evaluator]: \u001b[0mInference done 3129/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0174 s/iter. Total: 0.2889 s/iter. ETA=0:09:00\n",
            "\u001b[32m[04/30 18:37:46 d2.evaluation.evaluator]: \u001b[0mInference done 3146/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0174 s/iter. Total: 0.2890 s/iter. ETA=0:08:55\n",
            "\u001b[32m[04/30 18:37:51 d2.evaluation.evaluator]: \u001b[0mInference done 3164/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0174 s/iter. Total: 0.2889 s/iter. ETA=0:08:50\n",
            "\u001b[32m[04/30 18:37:56 d2.evaluation.evaluator]: \u001b[0mInference done 3182/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0173 s/iter. Total: 0.2889 s/iter. ETA=0:08:45\n",
            "\u001b[32m[04/30 18:38:01 d2.evaluation.evaluator]: \u001b[0mInference done 3200/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0173 s/iter. Total: 0.2889 s/iter. ETA=0:08:39\n",
            "\u001b[32m[04/30 18:38:06 d2.evaluation.evaluator]: \u001b[0mInference done 3217/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0174 s/iter. Total: 0.2889 s/iter. ETA=0:08:35\n",
            "\u001b[32m[04/30 18:38:11 d2.evaluation.evaluator]: \u001b[0mInference done 3235/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0174 s/iter. Total: 0.2890 s/iter. ETA=0:08:30\n",
            "\u001b[32m[04/30 18:38:16 d2.evaluation.evaluator]: \u001b[0mInference done 3253/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0174 s/iter. Total: 0.2890 s/iter. ETA=0:08:24\n",
            "\u001b[32m[04/30 18:38:22 d2.evaluation.evaluator]: \u001b[0mInference done 3271/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0174 s/iter. Total: 0.2890 s/iter. ETA=0:08:19\n",
            "\u001b[32m[04/30 18:38:27 d2.evaluation.evaluator]: \u001b[0mInference done 3289/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0174 s/iter. Total: 0.2890 s/iter. ETA=0:08:14\n",
            "\u001b[32m[04/30 18:38:32 d2.evaluation.evaluator]: \u001b[0mInference done 3306/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:08:09\n",
            "\u001b[32m[04/30 18:38:37 d2.evaluation.evaluator]: \u001b[0mInference done 3324/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:08:04\n",
            "\u001b[32m[04/30 18:38:42 d2.evaluation.evaluator]: \u001b[0mInference done 3342/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0175 s/iter. Total: 0.2890 s/iter. ETA=0:07:59\n",
            "\u001b[32m[04/30 18:38:47 d2.evaluation.evaluator]: \u001b[0mInference done 3359/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:07:54\n",
            "\u001b[32m[04/30 18:38:53 d2.evaluation.evaluator]: \u001b[0mInference done 3377/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0175 s/iter. Total: 0.2891 s/iter. ETA=0:07:49\n",
            "\u001b[32m[04/30 18:38:58 d2.evaluation.evaluator]: \u001b[0mInference done 3395/5000. Dataloading: 0.0020 s/iter. Inference: 0.2695 s/iter. Eval: 0.0175 s/iter. Total: 0.2890 s/iter. ETA=0:07:43\n",
            "\u001b[32m[04/30 18:39:03 d2.evaluation.evaluator]: \u001b[0mInference done 3413/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0175 s/iter. Total: 0.2890 s/iter. ETA=0:07:38\n",
            "\u001b[32m[04/30 18:39:08 d2.evaluation.evaluator]: \u001b[0mInference done 3431/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0175 s/iter. Total: 0.2890 s/iter. ETA=0:07:33\n",
            "\u001b[32m[04/30 18:39:13 d2.evaluation.evaluator]: \u001b[0mInference done 3448/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0176 s/iter. Total: 0.2891 s/iter. ETA=0:07:28\n",
            "\u001b[32m[04/30 18:39:18 d2.evaluation.evaluator]: \u001b[0mInference done 3466/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0175 s/iter. Total: 0.2890 s/iter. ETA=0:07:23\n",
            "\u001b[32m[04/30 18:39:23 d2.evaluation.evaluator]: \u001b[0mInference done 3484/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0175 s/iter. Total: 0.2890 s/iter. ETA=0:07:18\n",
            "\u001b[32m[04/30 18:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 3502/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0175 s/iter. Total: 0.2890 s/iter. ETA=0:07:12\n",
            "\u001b[32m[04/30 18:39:33 d2.evaluation.evaluator]: \u001b[0mInference done 3520/5000. Dataloading: 0.0020 s/iter. Inference: 0.2694 s/iter. Eval: 0.0175 s/iter. Total: 0.2890 s/iter. ETA=0:07:07\n",
            "\u001b[32m[04/30 18:39:39 d2.evaluation.evaluator]: \u001b[0mInference done 3539/5000. Dataloading: 0.0020 s/iter. Inference: 0.2693 s/iter. Eval: 0.0175 s/iter. Total: 0.2889 s/iter. ETA=0:07:02\n",
            "\u001b[32m[04/30 18:39:44 d2.evaluation.evaluator]: \u001b[0mInference done 3557/5000. Dataloading: 0.0020 s/iter. Inference: 0.2693 s/iter. Eval: 0.0175 s/iter. Total: 0.2889 s/iter. ETA=0:06:56\n",
            "\u001b[32m[04/30 18:39:49 d2.evaluation.evaluator]: \u001b[0mInference done 3575/5000. Dataloading: 0.0020 s/iter. Inference: 0.2693 s/iter. Eval: 0.0175 s/iter. Total: 0.2889 s/iter. ETA=0:06:51\n",
            "\u001b[32m[04/30 18:39:54 d2.evaluation.evaluator]: \u001b[0mInference done 3593/5000. Dataloading: 0.0020 s/iter. Inference: 0.2693 s/iter. Eval: 0.0175 s/iter. Total: 0.2889 s/iter. ETA=0:06:46\n",
            "\u001b[32m[04/30 18:40:00 d2.evaluation.evaluator]: \u001b[0mInference done 3611/5000. Dataloading: 0.0020 s/iter. Inference: 0.2693 s/iter. Eval: 0.0175 s/iter. Total: 0.2889 s/iter. ETA=0:06:41\n",
            "\u001b[32m[04/30 18:40:05 d2.evaluation.evaluator]: \u001b[0mInference done 3629/5000. Dataloading: 0.0020 s/iter. Inference: 0.2693 s/iter. Eval: 0.0175 s/iter. Total: 0.2889 s/iter. ETA=0:06:36\n",
            "\u001b[32m[04/30 18:40:10 d2.evaluation.evaluator]: \u001b[0mInference done 3647/5000. Dataloading: 0.0020 s/iter. Inference: 0.2693 s/iter. Eval: 0.0175 s/iter. Total: 0.2888 s/iter. ETA=0:06:30\n",
            "\u001b[32m[04/30 18:40:15 d2.evaluation.evaluator]: \u001b[0mInference done 3665/5000. Dataloading: 0.0020 s/iter. Inference: 0.2693 s/iter. Eval: 0.0175 s/iter. Total: 0.2888 s/iter. ETA=0:06:25\n",
            "\u001b[32m[04/30 18:40:20 d2.evaluation.evaluator]: \u001b[0mInference done 3683/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0175 s/iter. Total: 0.2888 s/iter. ETA=0:06:20\n",
            "\u001b[32m[04/30 18:40:25 d2.evaluation.evaluator]: \u001b[0mInference done 3701/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0175 s/iter. Total: 0.2888 s/iter. ETA=0:06:15\n",
            "\u001b[32m[04/30 18:40:30 d2.evaluation.evaluator]: \u001b[0mInference done 3720/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0175 s/iter. Total: 0.2887 s/iter. ETA=0:06:09\n",
            "\u001b[32m[04/30 18:40:36 d2.evaluation.evaluator]: \u001b[0mInference done 3738/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0174 s/iter. Total: 0.2887 s/iter. ETA=0:06:04\n",
            "\u001b[32m[04/30 18:40:41 d2.evaluation.evaluator]: \u001b[0mInference done 3756/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0175 s/iter. Total: 0.2887 s/iter. ETA=0:05:59\n",
            "\u001b[32m[04/30 18:40:46 d2.evaluation.evaluator]: \u001b[0mInference done 3773/5000. Dataloading: 0.0020 s/iter. Inference: 0.2693 s/iter. Eval: 0.0175 s/iter. Total: 0.2888 s/iter. ETA=0:05:54\n",
            "\u001b[32m[04/30 18:40:51 d2.evaluation.evaluator]: \u001b[0mInference done 3790/5000. Dataloading: 0.0020 s/iter. Inference: 0.2693 s/iter. Eval: 0.0175 s/iter. Total: 0.2888 s/iter. ETA=0:05:49\n",
            "\u001b[32m[04/30 18:40:56 d2.evaluation.evaluator]: \u001b[0mInference done 3808/5000. Dataloading: 0.0020 s/iter. Inference: 0.2693 s/iter. Eval: 0.0175 s/iter. Total: 0.2888 s/iter. ETA=0:05:44\n",
            "\u001b[32m[04/30 18:41:02 d2.evaluation.evaluator]: \u001b[0mInference done 3827/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0175 s/iter. Total: 0.2888 s/iter. ETA=0:05:38\n",
            "\u001b[32m[04/30 18:41:07 d2.evaluation.evaluator]: \u001b[0mInference done 3845/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0174 s/iter. Total: 0.2887 s/iter. ETA=0:05:33\n",
            "\u001b[32m[04/30 18:41:12 d2.evaluation.evaluator]: \u001b[0mInference done 3863/5000. Dataloading: 0.0020 s/iter. Inference: 0.2693 s/iter. Eval: 0.0174 s/iter. Total: 0.2888 s/iter. ETA=0:05:28\n",
            "\u001b[32m[04/30 18:41:17 d2.evaluation.evaluator]: \u001b[0mInference done 3881/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0174 s/iter. Total: 0.2887 s/iter. ETA=0:05:23\n",
            "\u001b[32m[04/30 18:41:22 d2.evaluation.evaluator]: \u001b[0mInference done 3900/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0174 s/iter. Total: 0.2887 s/iter. ETA=0:05:17\n",
            "\u001b[32m[04/30 18:41:27 d2.evaluation.evaluator]: \u001b[0mInference done 3918/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0174 s/iter. Total: 0.2887 s/iter. ETA=0:05:12\n",
            "\u001b[32m[04/30 18:41:32 d2.evaluation.evaluator]: \u001b[0mInference done 3936/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0174 s/iter. Total: 0.2886 s/iter. ETA=0:05:07\n",
            "\u001b[32m[04/30 18:41:38 d2.evaluation.evaluator]: \u001b[0mInference done 3954/5000. Dataloading: 0.0020 s/iter. Inference: 0.2692 s/iter. Eval: 0.0174 s/iter. Total: 0.2886 s/iter. ETA=0:05:01\n",
            "\u001b[32m[04/30 18:41:43 d2.evaluation.evaluator]: \u001b[0mInference done 3972/5000. Dataloading: 0.0020 s/iter. Inference: 0.2691 s/iter. Eval: 0.0174 s/iter. Total: 0.2886 s/iter. ETA=0:04:56\n",
            "\u001b[32m[04/30 18:41:48 d2.evaluation.evaluator]: \u001b[0mInference done 3991/5000. Dataloading: 0.0020 s/iter. Inference: 0.2691 s/iter. Eval: 0.0174 s/iter. Total: 0.2885 s/iter. ETA=0:04:51\n",
            "\u001b[32m[04/30 18:41:53 d2.evaluation.evaluator]: \u001b[0mInference done 4009/5000. Dataloading: 0.0020 s/iter. Inference: 0.2691 s/iter. Eval: 0.0174 s/iter. Total: 0.2885 s/iter. ETA=0:04:45\n",
            "\u001b[32m[04/30 18:41:58 d2.evaluation.evaluator]: \u001b[0mInference done 4027/5000. Dataloading: 0.0020 s/iter. Inference: 0.2690 s/iter. Eval: 0.0174 s/iter. Total: 0.2885 s/iter. ETA=0:04:40\n",
            "\u001b[32m[04/30 18:42:04 d2.evaluation.evaluator]: \u001b[0mInference done 4045/5000. Dataloading: 0.0020 s/iter. Inference: 0.2690 s/iter. Eval: 0.0174 s/iter. Total: 0.2885 s/iter. ETA=0:04:35\n",
            "\u001b[32m[04/30 18:42:09 d2.evaluation.evaluator]: \u001b[0mInference done 4063/5000. Dataloading: 0.0020 s/iter. Inference: 0.2690 s/iter. Eval: 0.0174 s/iter. Total: 0.2885 s/iter. ETA=0:04:30\n",
            "\u001b[32m[04/30 18:42:14 d2.evaluation.evaluator]: \u001b[0mInference done 4081/5000. Dataloading: 0.0020 s/iter. Inference: 0.2690 s/iter. Eval: 0.0175 s/iter. Total: 0.2886 s/iter. ETA=0:04:25\n",
            "\u001b[32m[04/30 18:42:19 d2.evaluation.evaluator]: \u001b[0mInference done 4099/5000. Dataloading: 0.0020 s/iter. Inference: 0.2691 s/iter. Eval: 0.0175 s/iter. Total: 0.2886 s/iter. ETA=0:04:20\n",
            "\u001b[32m[04/30 18:42:24 d2.evaluation.evaluator]: \u001b[0mInference done 4117/5000. Dataloading: 0.0020 s/iter. Inference: 0.2690 s/iter. Eval: 0.0175 s/iter. Total: 0.2886 s/iter. ETA=0:04:14\n",
            "\u001b[32m[04/30 18:42:30 d2.evaluation.evaluator]: \u001b[0mInference done 4135/5000. Dataloading: 0.0020 s/iter. Inference: 0.2691 s/iter. Eval: 0.0175 s/iter. Total: 0.2886 s/iter. ETA=0:04:09\n",
            "\u001b[32m[04/30 18:42:35 d2.evaluation.evaluator]: \u001b[0mInference done 4153/5000. Dataloading: 0.0020 s/iter. Inference: 0.2690 s/iter. Eval: 0.0175 s/iter. Total: 0.2886 s/iter. ETA=0:04:04\n",
            "\u001b[32m[04/30 18:42:40 d2.evaluation.evaluator]: \u001b[0mInference done 4170/5000. Dataloading: 0.0020 s/iter. Inference: 0.2690 s/iter. Eval: 0.0175 s/iter. Total: 0.2886 s/iter. ETA=0:03:59\n",
            "\u001b[32m[04/30 18:42:45 d2.evaluation.evaluator]: \u001b[0mInference done 4188/5000. Dataloading: 0.0020 s/iter. Inference: 0.2690 s/iter. Eval: 0.0175 s/iter. Total: 0.2886 s/iter. ETA=0:03:54\n",
            "\u001b[32m[04/30 18:42:50 d2.evaluation.evaluator]: \u001b[0mInference done 4206/5000. Dataloading: 0.0020 s/iter. Inference: 0.2690 s/iter. Eval: 0.0175 s/iter. Total: 0.2886 s/iter. ETA=0:03:49\n",
            "\u001b[32m[04/30 18:42:55 d2.evaluation.evaluator]: \u001b[0mInference done 4224/5000. Dataloading: 0.0020 s/iter. Inference: 0.2690 s/iter. Eval: 0.0175 s/iter. Total: 0.2886 s/iter. ETA=0:03:43\n",
            "\u001b[32m[04/30 18:43:01 d2.evaluation.evaluator]: \u001b[0mInference done 4243/5000. Dataloading: 0.0020 s/iter. Inference: 0.2690 s/iter. Eval: 0.0175 s/iter. Total: 0.2885 s/iter. ETA=0:03:38\n",
            "\u001b[32m[04/30 18:43:06 d2.evaluation.evaluator]: \u001b[0mInference done 4260/5000. Dataloading: 0.0020 s/iter. Inference: 0.2690 s/iter. Eval: 0.0175 s/iter. Total: 0.2886 s/iter. ETA=0:03:33\n",
            "\u001b[32m[04/30 18:43:11 d2.evaluation.evaluator]: \u001b[0mInference done 4278/5000. Dataloading: 0.0020 s/iter. Inference: 0.2690 s/iter. Eval: 0.0175 s/iter. Total: 0.2885 s/iter. ETA=0:03:28\n",
            "\u001b[32m[04/30 18:43:16 d2.evaluation.evaluator]: \u001b[0mInference done 4295/5000. Dataloading: 0.0020 s/iter. Inference: 0.2690 s/iter. Eval: 0.0176 s/iter. Total: 0.2886 s/iter. ETA=0:03:23\n",
            "\u001b[32m[04/30 18:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 4313/5000. Dataloading: 0.0020 s/iter. Inference: 0.2689 s/iter. Eval: 0.0175 s/iter. Total: 0.2886 s/iter. ETA=0:03:18\n",
            "\u001b[32m[04/30 18:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 4331/5000. Dataloading: 0.0020 s/iter. Inference: 0.2689 s/iter. Eval: 0.0175 s/iter. Total: 0.2885 s/iter. ETA=0:03:13\n",
            "\u001b[32m[04/30 18:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 4350/5000. Dataloading: 0.0020 s/iter. Inference: 0.2689 s/iter. Eval: 0.0175 s/iter. Total: 0.2885 s/iter. ETA=0:03:07\n",
            "\u001b[32m[04/30 18:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 4368/5000. Dataloading: 0.0020 s/iter. Inference: 0.2689 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:03:02\n",
            "\u001b[32m[04/30 18:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 4386/5000. Dataloading: 0.0020 s/iter. Inference: 0.2689 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:02:57\n",
            "\u001b[32m[04/30 18:43:47 d2.evaluation.evaluator]: \u001b[0mInference done 4404/5000. Dataloading: 0.0020 s/iter. Inference: 0.2689 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:02:51\n",
            "\u001b[32m[04/30 18:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 4422/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:02:46\n",
            "\u001b[32m[04/30 18:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 4440/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:02:41\n",
            "\u001b[32m[04/30 18:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 4458/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:02:36\n",
            "\u001b[32m[04/30 18:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 4476/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:02:31\n",
            "\u001b[32m[04/30 18:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 4494/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:02:25\n",
            "\u001b[32m[04/30 18:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 4512/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:02:20\n",
            "\u001b[32m[04/30 18:44:23 d2.evaluation.evaluator]: \u001b[0mInference done 4530/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0175 s/iter. Total: 0.2883 s/iter. ETA=0:02:15\n",
            "\u001b[32m[04/30 18:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 4548/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0175 s/iter. Total: 0.2883 s/iter. ETA=0:02:10\n",
            "\u001b[32m[04/30 18:44:33 d2.evaluation.evaluator]: \u001b[0mInference done 4565/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:02:05\n",
            "\u001b[32m[04/30 18:44:38 d2.evaluation.evaluator]: \u001b[0mInference done 4583/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0176 s/iter. Total: 0.2884 s/iter. ETA=0:02:00\n",
            "\u001b[32m[04/30 18:44:43 d2.evaluation.evaluator]: \u001b[0mInference done 4601/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:01:55\n",
            "\u001b[32m[04/30 18:44:48 d2.evaluation.evaluator]: \u001b[0mInference done 4619/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:01:49\n",
            "\u001b[32m[04/30 18:44:53 d2.evaluation.evaluator]: \u001b[0mInference done 4637/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0175 s/iter. Total: 0.2883 s/iter. ETA=0:01:44\n",
            "\u001b[32m[04/30 18:44:59 d2.evaluation.evaluator]: \u001b[0mInference done 4654/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:01:39\n",
            "\u001b[32m[04/30 18:45:04 d2.evaluation.evaluator]: \u001b[0mInference done 4672/5000. Dataloading: 0.0020 s/iter. Inference: 0.2688 s/iter. Eval: 0.0176 s/iter. Total: 0.2884 s/iter. ETA=0:01:34\n",
            "\u001b[32m[04/30 18:45:09 d2.evaluation.evaluator]: \u001b[0mInference done 4690/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2883 s/iter. ETA=0:01:29\n",
            "\u001b[32m[04/30 18:45:14 d2.evaluation.evaluator]: \u001b[0mInference done 4708/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2883 s/iter. ETA=0:01:24\n",
            "\u001b[32m[04/30 18:45:19 d2.evaluation.evaluator]: \u001b[0mInference done 4725/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0176 s/iter. Total: 0.2884 s/iter. ETA=0:01:19\n",
            "\u001b[32m[04/30 18:45:24 d2.evaluation.evaluator]: \u001b[0mInference done 4743/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:01:14\n",
            "\u001b[32m[04/30 18:45:29 d2.evaluation.evaluator]: \u001b[0mInference done 4761/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:01:08\n",
            "\u001b[32m[04/30 18:45:34 d2.evaluation.evaluator]: \u001b[0mInference done 4779/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2883 s/iter. ETA=0:01:03\n",
            "\u001b[32m[04/30 18:45:39 d2.evaluation.evaluator]: \u001b[0mInference done 4797/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2883 s/iter. ETA=0:00:58\n",
            "\u001b[32m[04/30 18:45:45 d2.evaluation.evaluator]: \u001b[0mInference done 4815/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2883 s/iter. ETA=0:00:53\n",
            "\u001b[32m[04/30 18:45:50 d2.evaluation.evaluator]: \u001b[0mInference done 4834/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2883 s/iter. ETA=0:00:47\n",
            "\u001b[32m[04/30 18:45:55 d2.evaluation.evaluator]: \u001b[0mInference done 4852/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2883 s/iter. ETA=0:00:42\n",
            "\u001b[32m[04/30 18:46:00 d2.evaluation.evaluator]: \u001b[0mInference done 4870/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2882 s/iter. ETA=0:00:37\n",
            "\u001b[32m[04/30 18:46:05 d2.evaluation.evaluator]: \u001b[0mInference done 4888/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2882 s/iter. ETA=0:00:32\n",
            "\u001b[32m[04/30 18:46:10 d2.evaluation.evaluator]: \u001b[0mInference done 4906/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2882 s/iter. ETA=0:00:27\n",
            "\u001b[32m[04/30 18:46:16 d2.evaluation.evaluator]: \u001b[0mInference done 4923/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2883 s/iter. ETA=0:00:22\n",
            "\u001b[32m[04/30 18:46:21 d2.evaluation.evaluator]: \u001b[0mInference done 4939/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:00:17\n",
            "\u001b[32m[04/30 18:46:26 d2.evaluation.evaluator]: \u001b[0mInference done 4957/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:00:12\n",
            "\u001b[32m[04/30 18:46:31 d2.evaluation.evaluator]: \u001b[0mInference done 4975/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:00:07\n",
            "\u001b[32m[04/30 18:46:36 d2.evaluation.evaluator]: \u001b[0mInference done 4993/5000. Dataloading: 0.0020 s/iter. Inference: 0.2687 s/iter. Eval: 0.0175 s/iter. Total: 0.2884 s/iter. ETA=0:00:02\n",
            "\u001b[32m[04/30 18:46:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:24:00.540980 (0.288397 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 18:46:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:22:22 (0.268670 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 18:46:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/30 18:46:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/30 18:46:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.12s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 18:46:41 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/30 18:46:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 8.62 seconds.\n",
            "\u001b[32m[04/30 18:46:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 18:46:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.86 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.669\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.498\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.290\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.351\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.556\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.584\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.406\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            "\u001b[32m[04/30 18:46:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 45.749 | 66.884 | 49.755 | 28.985 | 49.488 | 58.613 |\n",
            "\u001b[32m[04/30 18:46:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 57.283 | bicycle      | 34.357 | car            | 47.825 |\n",
            "| motorcycle    | 48.088 | airplane     | 69.249 | bus            | 68.335 |\n",
            "| train         | 67.644 | truck        | 38.309 | boat           | 30.409 |\n",
            "| traffic light | 30.033 | fire hydrant | 71.003 | stop sign      | 68.704 |\n",
            "| parking meter | 46.320 | bench        | 28.612 | bird           | 40.049 |\n",
            "| cat           | 72.345 | dog          | 67.710 | horse          | 61.042 |\n",
            "| sheep         | 56.013 | cow          | 60.600 | elephant       | 66.213 |\n",
            "| bear          | 73.690 | zebra        | 69.083 | giraffe        | 68.854 |\n",
            "| backpack      | 19.274 | umbrella     | 42.803 | handbag        | 18.599 |\n",
            "| tie           | 40.992 | suitcase     | 46.717 | frisbee        | 67.728 |\n",
            "| skis          | 29.609 | snowboard    | 44.559 | sports ball    | 50.991 |\n",
            "| kite          | 48.331 | baseball bat | 39.406 | baseball glove | 43.193 |\n",
            "| skateboard    | 59.621 | surfboard    | 44.426 | tennis racket  | 56.118 |\n",
            "| bottle        | 42.826 | wine glass   | 40.282 | cup            | 47.269 |\n",
            "| fork          | 42.907 | knife        | 25.864 | spoon          | 20.942 |\n",
            "| bowl          | 44.374 | banana       | 28.332 | apple          | 22.880 |\n",
            "| sandwich      | 39.428 | orange       | 32.997 | broccoli       | 25.754 |\n",
            "| carrot        | 26.157 | hot dog      | 39.354 | pizza          | 54.974 |\n",
            "| donut         | 52.149 | cake         | 40.538 | chair          | 31.313 |\n",
            "| couch         | 45.549 | potted plant | 28.145 | bed            | 46.045 |\n",
            "| dining table  | 30.775 | toilet       | 64.104 | tv             | 58.264 |\n",
            "| laptop        | 64.479 | mouse        | 63.586 | remote         | 40.544 |\n",
            "| keyboard      | 53.625 | cell phone   | 40.658 | microwave      | 56.596 |\n",
            "| oven          | 37.106 | toaster      | 38.997 | sink           | 40.678 |\n",
            "| refrigerator  | 59.219 | book         | 17.628 | clock          | 52.903 |\n",
            "| vase          | 42.149 | scissors     | 34.915 | teddy bear     | 51.358 |\n",
            "| hair drier    | 7.550  | toothbrush   | 32.560 |                |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=1.09s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 18:46:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
            "\u001b[32m[04/30 18:47:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 10.21 seconds.\n",
            "\u001b[32m[04/30 18:47:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 18:47:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.87 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.406\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.638\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.437\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.221\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.569\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.323\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.501\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.559\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665\n",
            "\u001b[32m[04/30 18:47:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 40.650 | 63.761 | 43.680 | 22.059 | 43.700 | 56.880 |\n",
            "\u001b[32m[04/30 18:47:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 49.226 | bicycle      | 20.306 | car            | 44.131 |\n",
            "| motorcycle    | 36.867 | airplane     | 54.219 | bus            | 66.020 |\n",
            "| train         | 66.086 | truck        | 37.167 | boat           | 26.343 |\n",
            "| traffic light | 29.017 | fire hydrant | 66.555 | stop sign      | 67.643 |\n",
            "| parking meter | 45.699 | bench        | 20.595 | bird           | 34.010 |\n",
            "| cat           | 70.443 | dog          | 62.688 | horse          | 43.931 |\n",
            "| sheep         | 49.965 | cow          | 51.345 | elephant       | 59.315 |\n",
            "| bear          | 72.069 | zebra        | 57.954 | giraffe        | 52.489 |\n",
            "| backpack      | 18.616 | umbrella     | 48.207 | handbag        | 17.184 |\n",
            "| tie           | 35.736 | suitcase     | 47.594 | frisbee        | 65.778 |\n",
            "| skis          | 4.153  | snowboard    | 27.672 | sports ball    | 51.155 |\n",
            "| kite          | 35.051 | baseball bat | 28.780 | baseball glove | 44.152 |\n",
            "| skateboard    | 36.545 | surfboard    | 38.157 | tennis racket  | 58.388 |\n",
            "| bottle        | 40.911 | wine glass   | 35.949 | cup            | 46.905 |\n",
            "| fork          | 20.302 | knife        | 16.370 | spoon          | 14.450 |\n",
            "| bowl          | 40.524 | banana       | 21.702 | apple          | 22.377 |\n",
            "| sandwich      | 41.555 | orange       | 31.975 | broccoli       | 24.206 |\n",
            "| carrot        | 21.992 | hot dog      | 32.207 | pizza          | 52.011 |\n",
            "| donut         | 51.558 | cake         | 40.475 | chair          | 21.199 |\n",
            "| couch         | 37.502 | potted plant | 23.781 | bed            | 37.235 |\n",
            "| dining table  | 17.686 | toilet       | 61.702 | tv             | 60.312 |\n",
            "| laptop        | 63.626 | mouse        | 63.698 | remote         | 36.764 |\n",
            "| keyboard      | 51.830 | cell phone   | 38.374 | microwave      | 58.572 |\n",
            "| oven          | 32.627 | toaster      | 40.317 | sink           | 37.731 |\n",
            "| refrigerator  | 59.783 | book         | 12.007 | clock          | 54.221 |\n",
            "| vase          | 41.610 | scissors     | 25.515 | teddy bear     | 48.684 |\n",
            "| hair drier    | 6.856  | toothbrush   | 23.619 |                |        |\n",
            "\u001b[32m[04/30 18:47:11 d2.engine.defaults]: \u001b[0mEvaluation results for coco_2017_val in csv format:\n",
            "\u001b[32m[04/30 18:47:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/30 18:47:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 18:47:11 d2.evaluation.testing]: \u001b[0mcopypaste: 45.7489,66.8836,49.7550,28.9849,49.4880,58.6127\n",
            "\u001b[32m[04/30 18:47:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[04/30 18:47:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 18:47:11 d2.evaluation.testing]: \u001b[0mcopypaste: 40.6496,63.7607,43.6799,22.0590,43.7004,56.8800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mask_rcnn_ResNeSt_101 - evaluation results for coco_2017_val in csv format:\n",
        "\n",
        "Task\\metrics  | AP | AP50 | AP75 | APs | APm | APl |\n",
        "--------------|----|------|------|-----|-----|-----|\n",
        "**bbox**    | 45.7489 | 66.8836 | 47.7550 | 28.9849 | 49.4880 | 58.6127\n",
        "**segm**   | 40.6496 | 63.7607 | 43.6799 | 22.0590 | 43.7004 | 56.8800\n",
        "\n",
        "Overall, the final results match those found in the original paper, the pretrained models thus perform as expected _(in the table mAP% = AP)_. \n",
        "\n",
        "Method | Backbone  | box mAP% | mask mAP% |\n",
        "------------------|--------------|------------------|------------------|\n",
        "**Mask-RCNN**    | ResNeSt50 | 42.81 |  38.14\n",
        "**Mask-RCNN**   | ResNeSt101 | 45.75 |  40.65\n",
        "**Cascade-RCNN**   | ResNeSt50 | 46.24 |  39.64\n",
        "**Cascade-RCNN** | ResNeSt101 | 48.44 | 41.52 \n",
        "\n",
        "Please consult the final report for additional comments."
      ],
      "metadata": {
        "id": "U_uyv1XbF9Fl"
      },
      "id": "U_uyv1XbF9Fl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Object Detection\n",
        "\n",
        "The object detection task closely ressembles the instance segmentation task, in both cases the dataset evaluated on is COCO and the models are based on a Detectron2 wrapper\n",
        "\n",
        "Like before we will access the necessary files from the drive and run the experiments with Colab and the ResNeSt repository has to be loaded in the drive. We assume that the dataset has already been prepared in the above section and the repository and detectron2 were successfully installed.\n",
        "\n",
        "In the wrapper subsection you will also find both the configuration files as and the weights, for this experiment. Once again the weights need to be downloaded manually and added to the repository, the path should be the following:\n",
        "* ResNeSt-master/d2/checkpoints/COCO-ObjectDetection/someweights.pth\n",
        "\n",
        "The configuration files are available by default when cloning the repository, it is not needed to download them."
      ],
      "metadata": {
        "id": "ZjJ8NEdL5bWJ"
      },
      "id": "ZjJ8NEdL5bWJ"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2/checkpoints/COCO-ObjectDetection/ && ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnQw-ENr_Jj6",
        "outputId": "55908d1a-01e2-4925-92de-a9bc9bfd5f3c"
      },
      "id": "OnQw-ENr_Jj6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x-e9955232.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-ObjectDetection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x-e9955232.pth"
      ],
      "metadata": {
        "id": "B3Mw2iv07qEc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421d6a33-cd38-4fd6-fadb-a5a72c2e15d6"
      },
      "id": "B3Mw2iv07qEc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command Line Args: Namespace(config_file='./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-ObjectDetection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x-e9955232.pth'], resume=False)\n",
            "\u001b[32m[04/30 15:22:38 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[04/30 15:22:38 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ----------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "numpy                   1.21.6\n",
            "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.5\n",
            "CUDA compiler           CUDA 11.1\n",
            "detectron2 arch flags   7.5\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.11.0+cu113 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           Yes\n",
            "GPU 0                   Tesla T4 (arch=7.5)\n",
            "Driver version          460.32.03\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.12.0+cu113 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
            "fvcore                  0.1.5.post20220414\n",
            "iopath                  0.1.9\n",
            "cv2                     4.1.2\n",
            "----------------------  ----------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.3\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.2\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "\u001b[32m[04/30 15:22:38 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-ObjectDetection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x-e9955232.pth'], resume=False)\n",
            "\u001b[32m[04/30 15:22:38 detectron2]: \u001b[0mContents of args.config_file=./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x.yaml:\n",
            "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186m../ResNest-Base-RCNN-FPN.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mhttps://s3.us-west-1.wasabisys.com/resnest/detectron/resnest50_detectron-255b5649.pth\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mFastRCNNConvFCHead\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m123.68\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m116.779\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m103.939\u001b[39m]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m58.393\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.12\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.375\u001b[39m]\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\u001b[38;5;15m    \u001b[39m\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m(640, 800)\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mrange\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mRGB\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\n",
            "\u001b[32m[04/30 15:22:39 detectron2]: \u001b[0mRunning with full config:\n",
            "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRGB\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mpolygon\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrange\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnest_fpn_backbone\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGeneralizedRCNN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.68\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.779\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.939\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m58.393\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.12\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.375\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRPN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVG_DOWN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOTTLENECK_WIDTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEEP_STEM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_NUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFastRCNNConvFCHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_FED_LOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_SIGMOID_CE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./checkpoints/COCO-ObjectDetection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x-e9955232.pth\n",
            "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./output\n",
            "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR_END\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m90000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m60000\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m80000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\n",
            "\u001b[32m[04/30 15:22:39 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[04/30 15:22:39 d2.utils.env]: \u001b[0mUsing a generated random seed 39170675\n",
            "\u001b[32m[04/30 15:22:44 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(\n",
            "      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output2): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral3): Conv2d(\n",
            "      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output3): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral4): Conv2d(\n",
            "      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output4): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral5): Conv2d(\n",
            "      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output5): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNeSt(\n",
            "      (stem): BasicStem(\n",
            "        (conv1_1): Conv2d(\n",
            "          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "        )\n",
            "        (conv1_2): Conv2d(\n",
            "          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "        )\n",
            "        (conv1_3): Conv2d(\n",
            "          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): CascadeROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): ModuleList(\n",
            "      (0): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (1): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (2): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): ModuleList(\n",
            "      (0): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (1): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (2): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/30 15:22:44 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from ./checkpoints/COCO-ObjectDetection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x-e9955232.pth ...\n",
            "\u001b[32m[04/30 15:22:46 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
            "| Names in Model                                  | Names in Checkpoint                                                                                                           | Shapes                                             |\n",
            "|:------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------|\n",
            "| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,1,1)                |\n",
            "| backbone.bottom_up.res2.0.conv2.bn0.*           | backbone.bottom_up.res2.0.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.0.conv2.bn1.*           | backbone.bottom_up.res2.0.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.0.conv2.conv.weight     | backbone.bottom_up.res2.0.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.0.conv2.fc1.*           | backbone.bottom_up.res2.0.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.0.conv2.fc2.*           | backbone.bottom_up.res2.0.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.1.conv2.bn0.*           | backbone.bottom_up.res2.1.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.1.conv2.bn1.*           | backbone.bottom_up.res2.1.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.1.conv2.conv.weight     | backbone.bottom_up.res2.1.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.1.conv2.fc1.*           | backbone.bottom_up.res2.1.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.1.conv2.fc2.*           | backbone.bottom_up.res2.1.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.2.conv2.bn0.*           | backbone.bottom_up.res2.2.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.2.conv2.bn1.*           | backbone.bottom_up.res2.2.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.2.conv2.conv.weight     | backbone.bottom_up.res2.2.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.2.conv2.fc1.*           | backbone.bottom_up.res2.2.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.2.conv2.fc2.*           | backbone.bottom_up.res2.2.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv2.bn0.*           | backbone.bottom_up.res3.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.0.conv2.bn1.*           | backbone.bottom_up.res3.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.0.conv2.conv.weight     | backbone.bottom_up.res3.0.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.0.conv2.fc1.*           | backbone.bottom_up.res3.0.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.0.conv2.fc2.*           | backbone.bottom_up.res3.0.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv2.bn0.*           | backbone.bottom_up.res3.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.1.conv2.bn1.*           | backbone.bottom_up.res3.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.1.conv2.conv.weight     | backbone.bottom_up.res3.1.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.1.conv2.fc1.*           | backbone.bottom_up.res3.1.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.1.conv2.fc2.*           | backbone.bottom_up.res3.1.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv2.bn0.*           | backbone.bottom_up.res3.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.2.conv2.bn1.*           | backbone.bottom_up.res3.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.2.conv2.conv.weight     | backbone.bottom_up.res3.2.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.2.conv2.fc1.*           | backbone.bottom_up.res3.2.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.2.conv2.fc2.*           | backbone.bottom_up.res3.2.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv2.bn0.*           | backbone.bottom_up.res3.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.3.conv2.bn1.*           | backbone.bottom_up.res3.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.3.conv2.conv.weight     | backbone.bottom_up.res3.3.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.3.conv2.fc1.*           | backbone.bottom_up.res3.3.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.3.conv2.fc2.*           | backbone.bottom_up.res3.3.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv2.bn0.*           | backbone.bottom_up.res4.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.bn1.*           | backbone.bottom_up.res4.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.conv.weight     | backbone.bottom_up.res4.0.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.0.conv2.fc1.*           | backbone.bottom_up.res4.0.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv2.fc2.*           | backbone.bottom_up.res4.0.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.1.conv2.bn0.*           | backbone.bottom_up.res4.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.bn1.*           | backbone.bottom_up.res4.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.conv.weight     | backbone.bottom_up.res4.1.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.1.conv2.fc1.*           | backbone.bottom_up.res4.1.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv2.fc2.*           | backbone.bottom_up.res4.1.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.2.conv2.bn0.*           | backbone.bottom_up.res4.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.bn1.*           | backbone.bottom_up.res4.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.conv.weight     | backbone.bottom_up.res4.2.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.2.conv2.fc1.*           | backbone.bottom_up.res4.2.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv2.fc2.*           | backbone.bottom_up.res4.2.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.3.conv2.bn0.*           | backbone.bottom_up.res4.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.bn1.*           | backbone.bottom_up.res4.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.conv.weight     | backbone.bottom_up.res4.3.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.3.conv2.fc1.*           | backbone.bottom_up.res4.3.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv2.fc2.*           | backbone.bottom_up.res4.3.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.4.conv2.bn0.*           | backbone.bottom_up.res4.4.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.bn1.*           | backbone.bottom_up.res4.4.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.conv.weight     | backbone.bottom_up.res4.4.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.4.conv2.fc1.*           | backbone.bottom_up.res4.4.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv2.fc2.*           | backbone.bottom_up.res4.4.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.5.conv2.bn0.*           | backbone.bottom_up.res4.5.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.bn1.*           | backbone.bottom_up.res4.5.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.conv.weight     | backbone.bottom_up.res4.5.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.5.conv2.fc1.*           | backbone.bottom_up.res4.5.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv2.fc2.*           | backbone.bottom_up.res4.5.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| backbone.bottom_up.res5.0.conv2.bn0.*           | backbone.bottom_up.res5.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.0.conv2.bn1.*           | backbone.bottom_up.res5.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.0.conv2.conv.weight     | backbone.bottom_up.res5.0.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.0.conv2.fc1.*           | backbone.bottom_up.res5.0.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.0.conv2.fc2.*           | backbone.bottom_up.res5.0.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.1.conv2.bn0.*           | backbone.bottom_up.res5.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.1.conv2.bn1.*           | backbone.bottom_up.res5.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.1.conv2.conv.weight     | backbone.bottom_up.res5.1.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.1.conv2.fc1.*           | backbone.bottom_up.res5.1.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.1.conv2.fc2.*           | backbone.bottom_up.res5.1.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.2.conv2.bn0.*           | backbone.bottom_up.res5.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.2.conv2.bn1.*           | backbone.bottom_up.res5.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.2.conv2.conv.weight     | backbone.bottom_up.res5.2.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.2.conv2.fc1.*           | backbone.bottom_up.res5.2.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.2.conv2.fc2.*           | backbone.bottom_up.res5.2.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.stem.conv1_1.*               | backbone.bottom_up.stem.conv1_1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (32,) (32,) (32,) (32,) (32,3,3,3)                 |\n",
            "| backbone.bottom_up.stem.conv1_2.*               | backbone.bottom_up.stem.conv1_2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (32,) (32,) (32,) (32,) (32,32,3,3)                |\n",
            "| backbone.bottom_up.stem.conv1_3.*               | backbone.bottom_up.stem.conv1_3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,32,3,3)                |\n",
            "| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,2048,1,1)      |\n",
            "| backbone.fpn_output2.*                          | backbone.fpn_output2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output3.*                          | backbone.fpn_output3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output4.*                          | backbone.fpn_output4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output5.*                          | backbone.fpn_output5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                                                       | (12,) (12,256,1,1)                                 |\n",
            "| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                                                | (256,) (256,256,3,3)                               |\n",
            "| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                                                   | (3,) (3,256,1,1)                                   |\n",
            "| roi_heads.box_head.0.conv1.*                    | roi_heads.box_head.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv2.*                    | roi_heads.box_head.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv3.*                    | roi_heads.box_head.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv4.*                    | roi_heads.box_head.0.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.fc1.*                      | roi_heads.box_head.0.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_head.1.conv1.*                    | roi_heads.box_head.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv2.*                    | roi_heads.box_head.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv3.*                    | roi_heads.box_head.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv4.*                    | roi_heads.box_head.1.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.fc1.*                      | roi_heads.box_head.1.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_head.2.conv1.*                    | roi_heads.box_head.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv2.*                    | roi_heads.box_head.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv3.*                    | roi_heads.box_head.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv4.*                    | roi_heads.box_head.2.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.fc1.*                      | roi_heads.box_head.2.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_predictor.0.bbox_pred.*           | roi_heads.box_predictor.0.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.0.cls_score.*           | roi_heads.box_predictor.0.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.box_predictor.1.bbox_pred.*           | roi_heads.box_predictor.1.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.1.cls_score.*           | roi_heads.box_predictor.1.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.box_predictor.2.bbox_pred.*           | roi_heads.box_predictor.2.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.2.cls_score.*           | roi_heads.box_predictor.2.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "\u001b[32m[04/30 15:22:47 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json\n",
            "\u001b[32m[04/30 15:22:48 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n",
            "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
            "|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\n",
            "|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\n",
            "|     train     | 190          |    truck     | 414          |     boat      | 424          |\n",
            "| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\n",
            "| parking meter | 60           |    bench     | 411          |     bird      | 427          |\n",
            "|      cat      | 202          |     dog      | 218          |     horse     | 272          |\n",
            "|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\n",
            "|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\n",
            "|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\n",
            "|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\n",
            "|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\n",
            "|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\n",
            "|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\n",
            "|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\n",
            "|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\n",
            "|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\n",
            "|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\n",
            "|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\n",
            "|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\n",
            "|     couch     | 261          | potted plant | 342          |      bed      | 163          |\n",
            "| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\n",
            "|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\n",
            "|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\n",
            "|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\n",
            "| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\n",
            "|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\n",
            "|  hair drier   | 11           |  toothbrush  | 57           |               |              |\n",
            "|     total     | 36335        |              |              |               |              |\u001b[0m\n",
            "\u001b[32m[04/30 15:22:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/30 15:22:48 d2.data.common]: \u001b[0mSerializing 5000 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/30 15:22:48 d2.data.common]: \u001b[0mSerialized dataset takes 19.10 MiB\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[32m[04/30 15:22:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 5000 batches\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m[04/30 15:22:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/5000. Dataloading: 0.0030 s/iter. Inference: 0.3551 s/iter. Eval: 0.0003 s/iter. Total: 0.3583 s/iter. ETA=0:29:47\n",
            "\u001b[32m[04/30 15:22:59 d2.evaluation.evaluator]: \u001b[0mInference done 26/5000. Dataloading: 0.0021 s/iter. Inference: 0.3519 s/iter. Eval: 0.0006 s/iter. Total: 0.3547 s/iter. ETA=0:29:24\n",
            "\u001b[32m[04/30 15:23:04 d2.evaluation.evaluator]: \u001b[0mInference done 40/5000. Dataloading: 0.0020 s/iter. Inference: 0.3534 s/iter. Eval: 0.0005 s/iter. Total: 0.3560 s/iter. ETA=0:29:25\n",
            "\u001b[32m[04/30 15:23:09 d2.evaluation.evaluator]: \u001b[0mInference done 54/5000. Dataloading: 0.0020 s/iter. Inference: 0.3540 s/iter. Eval: 0.0004 s/iter. Total: 0.3565 s/iter. ETA=0:29:23\n",
            "\u001b[32m[04/30 15:23:14 d2.evaluation.evaluator]: \u001b[0mInference done 68/5000. Dataloading: 0.0020 s/iter. Inference: 0.3552 s/iter. Eval: 0.0004 s/iter. Total: 0.3576 s/iter. ETA=0:29:23\n",
            "\u001b[32m[04/30 15:23:19 d2.evaluation.evaluator]: \u001b[0mInference done 82/5000. Dataloading: 0.0020 s/iter. Inference: 0.3556 s/iter. Eval: 0.0003 s/iter. Total: 0.3580 s/iter. ETA=0:29:20\n",
            "\u001b[32m[04/30 15:23:24 d2.evaluation.evaluator]: \u001b[0mInference done 97/5000. Dataloading: 0.0020 s/iter. Inference: 0.3555 s/iter. Eval: 0.0003 s/iter. Total: 0.3579 s/iter. ETA=0:29:14\n",
            "\u001b[32m[04/30 15:23:29 d2.evaluation.evaluator]: \u001b[0mInference done 112/5000. Dataloading: 0.0020 s/iter. Inference: 0.3554 s/iter. Eval: 0.0003 s/iter. Total: 0.3578 s/iter. ETA=0:29:08\n",
            "\u001b[32m[04/30 15:23:35 d2.evaluation.evaluator]: \u001b[0mInference done 126/5000. Dataloading: 0.0020 s/iter. Inference: 0.3561 s/iter. Eval: 0.0003 s/iter. Total: 0.3585 s/iter. ETA=0:29:07\n",
            "\u001b[32m[04/30 15:23:40 d2.evaluation.evaluator]: \u001b[0mInference done 140/5000. Dataloading: 0.0020 s/iter. Inference: 0.3570 s/iter. Eval: 0.0003 s/iter. Total: 0.3594 s/iter. ETA=0:29:06\n",
            "\u001b[32m[04/30 15:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 154/5000. Dataloading: 0.0020 s/iter. Inference: 0.3580 s/iter. Eval: 0.0003 s/iter. Total: 0.3604 s/iter. ETA=0:29:06\n",
            "\u001b[32m[04/30 15:23:50 d2.evaluation.evaluator]: \u001b[0mInference done 168/5000. Dataloading: 0.0020 s/iter. Inference: 0.3584 s/iter. Eval: 0.0003 s/iter. Total: 0.3608 s/iter. ETA=0:29:03\n",
            "\u001b[32m[04/30 15:23:55 d2.evaluation.evaluator]: \u001b[0mInference done 182/5000. Dataloading: 0.0020 s/iter. Inference: 0.3590 s/iter. Eval: 0.0003 s/iter. Total: 0.3614 s/iter. ETA=0:29:01\n",
            "\u001b[32m[04/30 15:24:00 d2.evaluation.evaluator]: \u001b[0mInference done 196/5000. Dataloading: 0.0020 s/iter. Inference: 0.3598 s/iter. Eval: 0.0003 s/iter. Total: 0.3622 s/iter. ETA=0:29:00\n",
            "\u001b[32m[04/30 15:24:06 d2.evaluation.evaluator]: \u001b[0mInference done 210/5000. Dataloading: 0.0020 s/iter. Inference: 0.3605 s/iter. Eval: 0.0003 s/iter. Total: 0.3629 s/iter. ETA=0:28:58\n",
            "\u001b[32m[04/30 15:24:11 d2.evaluation.evaluator]: \u001b[0mInference done 224/5000. Dataloading: 0.0020 s/iter. Inference: 0.3608 s/iter. Eval: 0.0003 s/iter. Total: 0.3632 s/iter. ETA=0:28:54\n",
            "\u001b[32m[04/30 15:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 238/5000. Dataloading: 0.0020 s/iter. Inference: 0.3617 s/iter. Eval: 0.0003 s/iter. Total: 0.3641 s/iter. ETA=0:28:53\n",
            "\u001b[32m[04/30 15:24:21 d2.evaluation.evaluator]: \u001b[0mInference done 252/5000. Dataloading: 0.0020 s/iter. Inference: 0.3624 s/iter. Eval: 0.0003 s/iter. Total: 0.3647 s/iter. ETA=0:28:51\n",
            "\u001b[32m[04/30 15:24:27 d2.evaluation.evaluator]: \u001b[0mInference done 266/5000. Dataloading: 0.0020 s/iter. Inference: 0.3630 s/iter. Eval: 0.0003 s/iter. Total: 0.3654 s/iter. ETA=0:28:49\n",
            "\u001b[32m[04/30 15:24:32 d2.evaluation.evaluator]: \u001b[0mInference done 280/5000. Dataloading: 0.0020 s/iter. Inference: 0.3634 s/iter. Eval: 0.0003 s/iter. Total: 0.3658 s/iter. ETA=0:28:46\n",
            "\u001b[32m[04/30 15:24:37 d2.evaluation.evaluator]: \u001b[0mInference done 294/5000. Dataloading: 0.0020 s/iter. Inference: 0.3642 s/iter. Eval: 0.0003 s/iter. Total: 0.3665 s/iter. ETA=0:28:44\n",
            "\u001b[32m[04/30 15:24:42 d2.evaluation.evaluator]: \u001b[0mInference done 308/5000. Dataloading: 0.0020 s/iter. Inference: 0.3647 s/iter. Eval: 0.0003 s/iter. Total: 0.3671 s/iter. ETA=0:28:42\n",
            "\u001b[32m[04/30 15:24:48 d2.evaluation.evaluator]: \u001b[0mInference done 322/5000. Dataloading: 0.0020 s/iter. Inference: 0.3653 s/iter. Eval: 0.0003 s/iter. Total: 0.3676 s/iter. ETA=0:28:39\n",
            "\u001b[32m[04/30 15:24:53 d2.evaluation.evaluator]: \u001b[0mInference done 336/5000. Dataloading: 0.0020 s/iter. Inference: 0.3660 s/iter. Eval: 0.0003 s/iter. Total: 0.3683 s/iter. ETA=0:28:37\n",
            "\u001b[32m[04/30 15:24:58 d2.evaluation.evaluator]: \u001b[0mInference done 350/5000. Dataloading: 0.0020 s/iter. Inference: 0.3666 s/iter. Eval: 0.0003 s/iter. Total: 0.3690 s/iter. ETA=0:28:35\n",
            "\u001b[32m[04/30 15:25:04 d2.evaluation.evaluator]: \u001b[0mInference done 364/5000. Dataloading: 0.0020 s/iter. Inference: 0.3672 s/iter. Eval: 0.0003 s/iter. Total: 0.3695 s/iter. ETA=0:28:33\n",
            "\u001b[32m[04/30 15:25:09 d2.evaluation.evaluator]: \u001b[0mInference done 377/5000. Dataloading: 0.0020 s/iter. Inference: 0.3678 s/iter. Eval: 0.0003 s/iter. Total: 0.3702 s/iter. ETA=0:28:31\n",
            "\u001b[32m[04/30 15:25:14 d2.evaluation.evaluator]: \u001b[0mInference done 391/5000. Dataloading: 0.0020 s/iter. Inference: 0.3682 s/iter. Eval: 0.0003 s/iter. Total: 0.3705 s/iter. ETA=0:28:27\n",
            "\u001b[32m[04/30 15:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 404/5000. Dataloading: 0.0020 s/iter. Inference: 0.3686 s/iter. Eval: 0.0003 s/iter. Total: 0.3710 s/iter. ETA=0:28:24\n",
            "\u001b[32m[04/30 15:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 417/5000. Dataloading: 0.0020 s/iter. Inference: 0.3692 s/iter. Eval: 0.0003 s/iter. Total: 0.3715 s/iter. ETA=0:28:22\n",
            "\u001b[32m[04/30 15:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 430/5000. Dataloading: 0.0020 s/iter. Inference: 0.3697 s/iter. Eval: 0.0003 s/iter. Total: 0.3720 s/iter. ETA=0:28:19\n",
            "\u001b[32m[04/30 15:25:34 d2.evaluation.evaluator]: \u001b[0mInference done 443/5000. Dataloading: 0.0020 s/iter. Inference: 0.3703 s/iter. Eval: 0.0003 s/iter. Total: 0.3726 s/iter. ETA=0:28:17\n",
            "\u001b[32m[04/30 15:25:39 d2.evaluation.evaluator]: \u001b[0mInference done 456/5000. Dataloading: 0.0020 s/iter. Inference: 0.3708 s/iter. Eval: 0.0003 s/iter. Total: 0.3731 s/iter. ETA=0:28:15\n",
            "\u001b[32m[04/30 15:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 469/5000. Dataloading: 0.0020 s/iter. Inference: 0.3713 s/iter. Eval: 0.0003 s/iter. Total: 0.3737 s/iter. ETA=0:28:13\n",
            "\u001b[32m[04/30 15:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 482/5000. Dataloading: 0.0020 s/iter. Inference: 0.3719 s/iter. Eval: 0.0003 s/iter. Total: 0.3743 s/iter. ETA=0:28:10\n",
            "\u001b[32m[04/30 15:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 495/5000. Dataloading: 0.0020 s/iter. Inference: 0.3724 s/iter. Eval: 0.0003 s/iter. Total: 0.3747 s/iter. ETA=0:28:08\n",
            "\u001b[32m[04/30 15:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 508/5000. Dataloading: 0.0020 s/iter. Inference: 0.3727 s/iter. Eval: 0.0003 s/iter. Total: 0.3750 s/iter. ETA=0:28:04\n",
            "\u001b[32m[04/30 15:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 521/5000. Dataloading: 0.0020 s/iter. Inference: 0.3730 s/iter. Eval: 0.0003 s/iter. Total: 0.3753 s/iter. ETA=0:28:01\n",
            "\u001b[32m[04/30 15:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 534/5000. Dataloading: 0.0020 s/iter. Inference: 0.3734 s/iter. Eval: 0.0003 s/iter. Total: 0.3758 s/iter. ETA=0:27:58\n",
            "\u001b[32m[04/30 15:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 547/5000. Dataloading: 0.0020 s/iter. Inference: 0.3738 s/iter. Eval: 0.0003 s/iter. Total: 0.3761 s/iter. ETA=0:27:54\n",
            "\u001b[32m[04/30 15:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 560/5000. Dataloading: 0.0020 s/iter. Inference: 0.3742 s/iter. Eval: 0.0003 s/iter. Total: 0.3765 s/iter. ETA=0:27:51\n",
            "\u001b[32m[04/30 15:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 573/5000. Dataloading: 0.0020 s/iter. Inference: 0.3746 s/iter. Eval: 0.0003 s/iter. Total: 0.3770 s/iter. ETA=0:27:48\n",
            "\u001b[32m[04/30 15:26:30 d2.evaluation.evaluator]: \u001b[0mInference done 586/5000. Dataloading: 0.0020 s/iter. Inference: 0.3749 s/iter. Eval: 0.0003 s/iter. Total: 0.3772 s/iter. ETA=0:27:45\n",
            "\u001b[32m[04/30 15:26:35 d2.evaluation.evaluator]: \u001b[0mInference done 599/5000. Dataloading: 0.0020 s/iter. Inference: 0.3752 s/iter. Eval: 0.0003 s/iter. Total: 0.3776 s/iter. ETA=0:27:41\n",
            "\u001b[32m[04/30 15:26:41 d2.evaluation.evaluator]: \u001b[0mInference done 612/5000. Dataloading: 0.0020 s/iter. Inference: 0.3756 s/iter. Eval: 0.0003 s/iter. Total: 0.3780 s/iter. ETA=0:27:38\n",
            "\u001b[32m[04/30 15:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 625/5000. Dataloading: 0.0020 s/iter. Inference: 0.3761 s/iter. Eval: 0.0003 s/iter. Total: 0.3784 s/iter. ETA=0:27:35\n",
            "\u001b[32m[04/30 15:26:51 d2.evaluation.evaluator]: \u001b[0mInference done 638/5000. Dataloading: 0.0020 s/iter. Inference: 0.3764 s/iter. Eval: 0.0003 s/iter. Total: 0.3788 s/iter. ETA=0:27:32\n",
            "\u001b[32m[04/30 15:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 651/5000. Dataloading: 0.0020 s/iter. Inference: 0.3767 s/iter. Eval: 0.0003 s/iter. Total: 0.3790 s/iter. ETA=0:27:28\n",
            "\u001b[32m[04/30 15:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 664/5000. Dataloading: 0.0020 s/iter. Inference: 0.3770 s/iter. Eval: 0.0003 s/iter. Total: 0.3794 s/iter. ETA=0:27:24\n",
            "\u001b[32m[04/30 15:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 677/5000. Dataloading: 0.0020 s/iter. Inference: 0.3774 s/iter. Eval: 0.0003 s/iter. Total: 0.3797 s/iter. ETA=0:27:21\n",
            "\u001b[32m[04/30 15:27:11 d2.evaluation.evaluator]: \u001b[0mInference done 690/5000. Dataloading: 0.0020 s/iter. Inference: 0.3777 s/iter. Eval: 0.0003 s/iter. Total: 0.3801 s/iter. ETA=0:27:18\n",
            "\u001b[32m[04/30 15:27:17 d2.evaluation.evaluator]: \u001b[0mInference done 703/5000. Dataloading: 0.0020 s/iter. Inference: 0.3781 s/iter. Eval: 0.0003 s/iter. Total: 0.3804 s/iter. ETA=0:27:14\n",
            "\u001b[32m[04/30 15:27:22 d2.evaluation.evaluator]: \u001b[0mInference done 716/5000. Dataloading: 0.0020 s/iter. Inference: 0.3785 s/iter. Eval: 0.0002 s/iter. Total: 0.3808 s/iter. ETA=0:27:11\n",
            "\u001b[32m[04/30 15:27:27 d2.evaluation.evaluator]: \u001b[0mInference done 729/5000. Dataloading: 0.0020 s/iter. Inference: 0.3788 s/iter. Eval: 0.0002 s/iter. Total: 0.3811 s/iter. ETA=0:27:07\n",
            "\u001b[32m[04/30 15:27:32 d2.evaluation.evaluator]: \u001b[0mInference done 742/5000. Dataloading: 0.0020 s/iter. Inference: 0.3793 s/iter. Eval: 0.0002 s/iter. Total: 0.3816 s/iter. ETA=0:27:05\n",
            "\u001b[32m[04/30 15:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 755/5000. Dataloading: 0.0020 s/iter. Inference: 0.3796 s/iter. Eval: 0.0003 s/iter. Total: 0.3819 s/iter. ETA=0:27:01\n",
            "\u001b[32m[04/30 15:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 768/5000. Dataloading: 0.0020 s/iter. Inference: 0.3798 s/iter. Eval: 0.0003 s/iter. Total: 0.3822 s/iter. ETA=0:26:57\n",
            "\u001b[32m[04/30 15:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 781/5000. Dataloading: 0.0020 s/iter. Inference: 0.3802 s/iter. Eval: 0.0003 s/iter. Total: 0.3825 s/iter. ETA=0:26:53\n",
            "\u001b[32m[04/30 15:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 794/5000. Dataloading: 0.0020 s/iter. Inference: 0.3805 s/iter. Eval: 0.0003 s/iter. Total: 0.3828 s/iter. ETA=0:26:50\n",
            "\u001b[32m[04/30 15:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 807/5000. Dataloading: 0.0020 s/iter. Inference: 0.3808 s/iter. Eval: 0.0003 s/iter. Total: 0.3832 s/iter. ETA=0:26:46\n",
            "\u001b[32m[04/30 15:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 820/5000. Dataloading: 0.0020 s/iter. Inference: 0.3811 s/iter. Eval: 0.0003 s/iter. Total: 0.3835 s/iter. ETA=0:26:42\n",
            "\u001b[32m[04/30 15:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 833/5000. Dataloading: 0.0020 s/iter. Inference: 0.3812 s/iter. Eval: 0.0003 s/iter. Total: 0.3836 s/iter. ETA=0:26:38\n",
            "\u001b[32m[04/30 15:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 846/5000. Dataloading: 0.0020 s/iter. Inference: 0.3815 s/iter. Eval: 0.0003 s/iter. Total: 0.3839 s/iter. ETA=0:26:34\n",
            "\u001b[32m[04/30 15:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 859/5000. Dataloading: 0.0020 s/iter. Inference: 0.3818 s/iter. Eval: 0.0003 s/iter. Total: 0.3842 s/iter. ETA=0:26:30\n",
            "\u001b[32m[04/30 15:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 872/5000. Dataloading: 0.0020 s/iter. Inference: 0.3821 s/iter. Eval: 0.0003 s/iter. Total: 0.3845 s/iter. ETA=0:26:27\n",
            "\u001b[32m[04/30 15:28:30 d2.evaluation.evaluator]: \u001b[0mInference done 885/5000. Dataloading: 0.0020 s/iter. Inference: 0.3823 s/iter. Eval: 0.0003 s/iter. Total: 0.3847 s/iter. ETA=0:26:23\n",
            "\u001b[32m[04/30 15:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 898/5000. Dataloading: 0.0020 s/iter. Inference: 0.3826 s/iter. Eval: 0.0003 s/iter. Total: 0.3849 s/iter. ETA=0:26:19\n",
            "\u001b[32m[04/30 15:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 911/5000. Dataloading: 0.0020 s/iter. Inference: 0.3827 s/iter. Eval: 0.0003 s/iter. Total: 0.3851 s/iter. ETA=0:26:14\n",
            "\u001b[32m[04/30 15:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 924/5000. Dataloading: 0.0020 s/iter. Inference: 0.3830 s/iter. Eval: 0.0003 s/iter. Total: 0.3853 s/iter. ETA=0:26:10\n",
            "\u001b[32m[04/30 15:28:51 d2.evaluation.evaluator]: \u001b[0mInference done 937/5000. Dataloading: 0.0020 s/iter. Inference: 0.3832 s/iter. Eval: 0.0003 s/iter. Total: 0.3856 s/iter. ETA=0:26:06\n",
            "\u001b[32m[04/30 15:28:56 d2.evaluation.evaluator]: \u001b[0mInference done 950/5000. Dataloading: 0.0020 s/iter. Inference: 0.3835 s/iter. Eval: 0.0003 s/iter. Total: 0.3858 s/iter. ETA=0:26:02\n",
            "\u001b[32m[04/30 15:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 963/5000. Dataloading: 0.0020 s/iter. Inference: 0.3837 s/iter. Eval: 0.0003 s/iter. Total: 0.3860 s/iter. ETA=0:25:58\n",
            "\u001b[32m[04/30 15:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 976/5000. Dataloading: 0.0020 s/iter. Inference: 0.3838 s/iter. Eval: 0.0003 s/iter. Total: 0.3862 s/iter. ETA=0:25:54\n",
            "\u001b[32m[04/30 15:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 989/5000. Dataloading: 0.0020 s/iter. Inference: 0.3841 s/iter. Eval: 0.0003 s/iter. Total: 0.3864 s/iter. ETA=0:25:49\n",
            "\u001b[32m[04/30 15:29:17 d2.evaluation.evaluator]: \u001b[0mInference done 1002/5000. Dataloading: 0.0020 s/iter. Inference: 0.3842 s/iter. Eval: 0.0003 s/iter. Total: 0.3866 s/iter. ETA=0:25:45\n",
            "\u001b[32m[04/30 15:29:22 d2.evaluation.evaluator]: \u001b[0mInference done 1015/5000. Dataloading: 0.0020 s/iter. Inference: 0.3844 s/iter. Eval: 0.0003 s/iter. Total: 0.3868 s/iter. ETA=0:25:41\n",
            "\u001b[32m[04/30 15:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 1028/5000. Dataloading: 0.0020 s/iter. Inference: 0.3845 s/iter. Eval: 0.0003 s/iter. Total: 0.3869 s/iter. ETA=0:25:36\n",
            "\u001b[32m[04/30 15:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 1041/5000. Dataloading: 0.0020 s/iter. Inference: 0.3847 s/iter. Eval: 0.0003 s/iter. Total: 0.3870 s/iter. ETA=0:25:32\n",
            "\u001b[32m[04/30 15:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 1054/5000. Dataloading: 0.0020 s/iter. Inference: 0.3849 s/iter. Eval: 0.0003 s/iter. Total: 0.3872 s/iter. ETA=0:25:28\n",
            "\u001b[32m[04/30 15:29:43 d2.evaluation.evaluator]: \u001b[0mInference done 1067/5000. Dataloading: 0.0020 s/iter. Inference: 0.3851 s/iter. Eval: 0.0003 s/iter. Total: 0.3874 s/iter. ETA=0:25:23\n",
            "\u001b[32m[04/30 15:29:48 d2.evaluation.evaluator]: \u001b[0mInference done 1080/5000. Dataloading: 0.0020 s/iter. Inference: 0.3853 s/iter. Eval: 0.0003 s/iter. Total: 0.3876 s/iter. ETA=0:25:19\n",
            "\u001b[32m[04/30 15:29:53 d2.evaluation.evaluator]: \u001b[0mInference done 1093/5000. Dataloading: 0.0020 s/iter. Inference: 0.3854 s/iter. Eval: 0.0003 s/iter. Total: 0.3878 s/iter. ETA=0:25:15\n",
            "\u001b[32m[04/30 15:29:58 d2.evaluation.evaluator]: \u001b[0mInference done 1106/5000. Dataloading: 0.0020 s/iter. Inference: 0.3856 s/iter. Eval: 0.0003 s/iter. Total: 0.3879 s/iter. ETA=0:25:10\n",
            "\u001b[32m[04/30 15:30:03 d2.evaluation.evaluator]: \u001b[0mInference done 1119/5000. Dataloading: 0.0020 s/iter. Inference: 0.3857 s/iter. Eval: 0.0003 s/iter. Total: 0.3881 s/iter. ETA=0:25:06\n",
            "\u001b[32m[04/30 15:30:09 d2.evaluation.evaluator]: \u001b[0mInference done 1132/5000. Dataloading: 0.0020 s/iter. Inference: 0.3859 s/iter. Eval: 0.0003 s/iter. Total: 0.3883 s/iter. ETA=0:25:01\n",
            "\u001b[32m[04/30 15:30:14 d2.evaluation.evaluator]: \u001b[0mInference done 1145/5000. Dataloading: 0.0020 s/iter. Inference: 0.3861 s/iter. Eval: 0.0003 s/iter. Total: 0.3884 s/iter. ETA=0:24:57\n",
            "\u001b[32m[04/30 15:30:19 d2.evaluation.evaluator]: \u001b[0mInference done 1158/5000. Dataloading: 0.0020 s/iter. Inference: 0.3862 s/iter. Eval: 0.0003 s/iter. Total: 0.3885 s/iter. ETA=0:24:52\n",
            "\u001b[32m[04/30 15:30:24 d2.evaluation.evaluator]: \u001b[0mInference done 1171/5000. Dataloading: 0.0020 s/iter. Inference: 0.3864 s/iter. Eval: 0.0003 s/iter. Total: 0.3887 s/iter. ETA=0:24:48\n",
            "\u001b[32m[04/30 15:30:30 d2.evaluation.evaluator]: \u001b[0mInference done 1184/5000. Dataloading: 0.0020 s/iter. Inference: 0.3865 s/iter. Eval: 0.0003 s/iter. Total: 0.3888 s/iter. ETA=0:24:43\n",
            "\u001b[32m[04/30 15:30:35 d2.evaluation.evaluator]: \u001b[0mInference done 1197/5000. Dataloading: 0.0020 s/iter. Inference: 0.3866 s/iter. Eval: 0.0003 s/iter. Total: 0.3889 s/iter. ETA=0:24:39\n",
            "\u001b[32m[04/30 15:30:40 d2.evaluation.evaluator]: \u001b[0mInference done 1210/5000. Dataloading: 0.0020 s/iter. Inference: 0.3868 s/iter. Eval: 0.0003 s/iter. Total: 0.3891 s/iter. ETA=0:24:34\n",
            "\u001b[32m[04/30 15:30:45 d2.evaluation.evaluator]: \u001b[0mInference done 1223/5000. Dataloading: 0.0020 s/iter. Inference: 0.3869 s/iter. Eval: 0.0003 s/iter. Total: 0.3892 s/iter. ETA=0:24:29\n",
            "\u001b[32m[04/30 15:30:50 d2.evaluation.evaluator]: \u001b[0mInference done 1236/5000. Dataloading: 0.0020 s/iter. Inference: 0.3870 s/iter. Eval: 0.0003 s/iter. Total: 0.3893 s/iter. ETA=0:24:25\n",
            "\u001b[32m[04/30 15:30:56 d2.evaluation.evaluator]: \u001b[0mInference done 1249/5000. Dataloading: 0.0020 s/iter. Inference: 0.3871 s/iter. Eval: 0.0003 s/iter. Total: 0.3894 s/iter. ETA=0:24:20\n",
            "\u001b[32m[04/30 15:31:01 d2.evaluation.evaluator]: \u001b[0mInference done 1262/5000. Dataloading: 0.0020 s/iter. Inference: 0.3872 s/iter. Eval: 0.0003 s/iter. Total: 0.3895 s/iter. ETA=0:24:15\n",
            "\u001b[32m[04/30 15:31:06 d2.evaluation.evaluator]: \u001b[0mInference done 1275/5000. Dataloading: 0.0020 s/iter. Inference: 0.3873 s/iter. Eval: 0.0003 s/iter. Total: 0.3896 s/iter. ETA=0:24:11\n",
            "\u001b[32m[04/30 15:31:11 d2.evaluation.evaluator]: \u001b[0mInference done 1288/5000. Dataloading: 0.0020 s/iter. Inference: 0.3874 s/iter. Eval: 0.0003 s/iter. Total: 0.3897 s/iter. ETA=0:24:06\n",
            "\u001b[32m[04/30 15:31:16 d2.evaluation.evaluator]: \u001b[0mInference done 1301/5000. Dataloading: 0.0020 s/iter. Inference: 0.3875 s/iter. Eval: 0.0003 s/iter. Total: 0.3898 s/iter. ETA=0:24:01\n",
            "\u001b[32m[04/30 15:31:22 d2.evaluation.evaluator]: \u001b[0mInference done 1314/5000. Dataloading: 0.0020 s/iter. Inference: 0.3876 s/iter. Eval: 0.0003 s/iter. Total: 0.3899 s/iter. ETA=0:23:57\n",
            "\u001b[32m[04/30 15:31:27 d2.evaluation.evaluator]: \u001b[0mInference done 1327/5000. Dataloading: 0.0020 s/iter. Inference: 0.3876 s/iter. Eval: 0.0003 s/iter. Total: 0.3900 s/iter. ETA=0:23:52\n",
            "\u001b[32m[04/30 15:31:32 d2.evaluation.evaluator]: \u001b[0mInference done 1340/5000. Dataloading: 0.0020 s/iter. Inference: 0.3878 s/iter. Eval: 0.0003 s/iter. Total: 0.3901 s/iter. ETA=0:23:47\n",
            "\u001b[32m[04/30 15:31:37 d2.evaluation.evaluator]: \u001b[0mInference done 1353/5000. Dataloading: 0.0020 s/iter. Inference: 0.3879 s/iter. Eval: 0.0003 s/iter. Total: 0.3902 s/iter. ETA=0:23:43\n",
            "\u001b[32m[04/30 15:31:42 d2.evaluation.evaluator]: \u001b[0mInference done 1366/5000. Dataloading: 0.0020 s/iter. Inference: 0.3880 s/iter. Eval: 0.0003 s/iter. Total: 0.3903 s/iter. ETA=0:23:38\n",
            "\u001b[32m[04/30 15:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 1379/5000. Dataloading: 0.0020 s/iter. Inference: 0.3881 s/iter. Eval: 0.0003 s/iter. Total: 0.3904 s/iter. ETA=0:23:33\n",
            "\u001b[32m[04/30 15:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 1392/5000. Dataloading: 0.0020 s/iter. Inference: 0.3882 s/iter. Eval: 0.0003 s/iter. Total: 0.3905 s/iter. ETA=0:23:28\n",
            "\u001b[32m[04/30 15:31:58 d2.evaluation.evaluator]: \u001b[0mInference done 1405/5000. Dataloading: 0.0020 s/iter. Inference: 0.3883 s/iter. Eval: 0.0003 s/iter. Total: 0.3906 s/iter. ETA=0:23:24\n",
            "\u001b[32m[04/30 15:32:03 d2.evaluation.evaluator]: \u001b[0mInference done 1418/5000. Dataloading: 0.0020 s/iter. Inference: 0.3883 s/iter. Eval: 0.0003 s/iter. Total: 0.3906 s/iter. ETA=0:23:19\n",
            "\u001b[32m[04/30 15:32:08 d2.evaluation.evaluator]: \u001b[0mInference done 1431/5000. Dataloading: 0.0020 s/iter. Inference: 0.3884 s/iter. Eval: 0.0003 s/iter. Total: 0.3907 s/iter. ETA=0:23:14\n",
            "\u001b[32m[04/30 15:32:14 d2.evaluation.evaluator]: \u001b[0mInference done 1444/5000. Dataloading: 0.0020 s/iter. Inference: 0.3885 s/iter. Eval: 0.0003 s/iter. Total: 0.3908 s/iter. ETA=0:23:09\n",
            "\u001b[32m[04/30 15:32:19 d2.evaluation.evaluator]: \u001b[0mInference done 1457/5000. Dataloading: 0.0020 s/iter. Inference: 0.3886 s/iter. Eval: 0.0003 s/iter. Total: 0.3909 s/iter. ETA=0:23:05\n",
            "\u001b[32m[04/30 15:32:24 d2.evaluation.evaluator]: \u001b[0mInference done 1470/5000. Dataloading: 0.0020 s/iter. Inference: 0.3886 s/iter. Eval: 0.0003 s/iter. Total: 0.3909 s/iter. ETA=0:23:00\n",
            "\u001b[32m[04/30 15:32:29 d2.evaluation.evaluator]: \u001b[0mInference done 1483/5000. Dataloading: 0.0020 s/iter. Inference: 0.3887 s/iter. Eval: 0.0003 s/iter. Total: 0.3910 s/iter. ETA=0:22:55\n",
            "\u001b[32m[04/30 15:32:34 d2.evaluation.evaluator]: \u001b[0mInference done 1496/5000. Dataloading: 0.0020 s/iter. Inference: 0.3888 s/iter. Eval: 0.0003 s/iter. Total: 0.3911 s/iter. ETA=0:22:50\n",
            "\u001b[32m[04/30 15:32:39 d2.evaluation.evaluator]: \u001b[0mInference done 1509/5000. Dataloading: 0.0020 s/iter. Inference: 0.3889 s/iter. Eval: 0.0003 s/iter. Total: 0.3912 s/iter. ETA=0:22:45\n",
            "\u001b[32m[04/30 15:32:45 d2.evaluation.evaluator]: \u001b[0mInference done 1522/5000. Dataloading: 0.0020 s/iter. Inference: 0.3889 s/iter. Eval: 0.0003 s/iter. Total: 0.3912 s/iter. ETA=0:22:40\n",
            "\u001b[32m[04/30 15:32:50 d2.evaluation.evaluator]: \u001b[0mInference done 1535/5000. Dataloading: 0.0020 s/iter. Inference: 0.3890 s/iter. Eval: 0.0003 s/iter. Total: 0.3913 s/iter. ETA=0:22:35\n",
            "\u001b[32m[04/30 15:32:55 d2.evaluation.evaluator]: \u001b[0mInference done 1548/5000. Dataloading: 0.0020 s/iter. Inference: 0.3891 s/iter. Eval: 0.0003 s/iter. Total: 0.3914 s/iter. ETA=0:22:31\n",
            "\u001b[32m[04/30 15:33:00 d2.evaluation.evaluator]: \u001b[0mInference done 1561/5000. Dataloading: 0.0020 s/iter. Inference: 0.3892 s/iter. Eval: 0.0003 s/iter. Total: 0.3915 s/iter. ETA=0:22:26\n",
            "\u001b[32m[04/30 15:33:06 d2.evaluation.evaluator]: \u001b[0mInference done 1574/5000. Dataloading: 0.0020 s/iter. Inference: 0.3893 s/iter. Eval: 0.0003 s/iter. Total: 0.3916 s/iter. ETA=0:22:21\n",
            "\u001b[32m[04/30 15:33:11 d2.evaluation.evaluator]: \u001b[0mInference done 1587/5000. Dataloading: 0.0020 s/iter. Inference: 0.3894 s/iter. Eval: 0.0003 s/iter. Total: 0.3917 s/iter. ETA=0:22:16\n",
            "\u001b[32m[04/30 15:33:16 d2.evaluation.evaluator]: \u001b[0mInference done 1600/5000. Dataloading: 0.0020 s/iter. Inference: 0.3895 s/iter. Eval: 0.0003 s/iter. Total: 0.3918 s/iter. ETA=0:22:12\n",
            "\u001b[32m[04/30 15:33:21 d2.evaluation.evaluator]: \u001b[0mInference done 1613/5000. Dataloading: 0.0020 s/iter. Inference: 0.3896 s/iter. Eval: 0.0003 s/iter. Total: 0.3919 s/iter. ETA=0:22:07\n",
            "\u001b[32m[04/30 15:33:27 d2.evaluation.evaluator]: \u001b[0mInference done 1626/5000. Dataloading: 0.0020 s/iter. Inference: 0.3896 s/iter. Eval: 0.0003 s/iter. Total: 0.3920 s/iter. ETA=0:22:02\n",
            "\u001b[32m[04/30 15:33:32 d2.evaluation.evaluator]: \u001b[0mInference done 1639/5000. Dataloading: 0.0020 s/iter. Inference: 0.3897 s/iter. Eval: 0.0003 s/iter. Total: 0.3920 s/iter. ETA=0:21:57\n",
            "\u001b[32m[04/30 15:33:37 d2.evaluation.evaluator]: \u001b[0mInference done 1652/5000. Dataloading: 0.0020 s/iter. Inference: 0.3898 s/iter. Eval: 0.0003 s/iter. Total: 0.3921 s/iter. ETA=0:21:52\n",
            "\u001b[32m[04/30 15:33:42 d2.evaluation.evaluator]: \u001b[0mInference done 1665/5000. Dataloading: 0.0020 s/iter. Inference: 0.3898 s/iter. Eval: 0.0003 s/iter. Total: 0.3921 s/iter. ETA=0:21:47\n",
            "\u001b[32m[04/30 15:33:47 d2.evaluation.evaluator]: \u001b[0mInference done 1678/5000. Dataloading: 0.0020 s/iter. Inference: 0.3899 s/iter. Eval: 0.0003 s/iter. Total: 0.3922 s/iter. ETA=0:21:43\n",
            "\u001b[32m[04/30 15:33:53 d2.evaluation.evaluator]: \u001b[0mInference done 1691/5000. Dataloading: 0.0020 s/iter. Inference: 0.3900 s/iter. Eval: 0.0003 s/iter. Total: 0.3923 s/iter. ETA=0:21:38\n",
            "\u001b[32m[04/30 15:33:58 d2.evaluation.evaluator]: \u001b[0mInference done 1704/5000. Dataloading: 0.0020 s/iter. Inference: 0.3901 s/iter. Eval: 0.0003 s/iter. Total: 0.3924 s/iter. ETA=0:21:33\n",
            "\u001b[32m[04/30 15:34:03 d2.evaluation.evaluator]: \u001b[0mInference done 1717/5000. Dataloading: 0.0020 s/iter. Inference: 0.3901 s/iter. Eval: 0.0003 s/iter. Total: 0.3925 s/iter. ETA=0:21:28\n",
            "\u001b[32m[04/30 15:34:08 d2.evaluation.evaluator]: \u001b[0mInference done 1730/5000. Dataloading: 0.0020 s/iter. Inference: 0.3902 s/iter. Eval: 0.0002 s/iter. Total: 0.3925 s/iter. ETA=0:21:23\n",
            "\u001b[32m[04/30 15:34:13 d2.evaluation.evaluator]: \u001b[0mInference done 1743/5000. Dataloading: 0.0020 s/iter. Inference: 0.3903 s/iter. Eval: 0.0002 s/iter. Total: 0.3926 s/iter. ETA=0:21:18\n",
            "\u001b[32m[04/30 15:34:19 d2.evaluation.evaluator]: \u001b[0mInference done 1756/5000. Dataloading: 0.0020 s/iter. Inference: 0.3903 s/iter. Eval: 0.0002 s/iter. Total: 0.3927 s/iter. ETA=0:21:13\n",
            "\u001b[32m[04/30 15:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 1769/5000. Dataloading: 0.0020 s/iter. Inference: 0.3904 s/iter. Eval: 0.0002 s/iter. Total: 0.3927 s/iter. ETA=0:21:08\n",
            "\u001b[32m[04/30 15:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 1782/5000. Dataloading: 0.0020 s/iter. Inference: 0.3904 s/iter. Eval: 0.0002 s/iter. Total: 0.3927 s/iter. ETA=0:21:03\n",
            "\u001b[32m[04/30 15:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 1795/5000. Dataloading: 0.0020 s/iter. Inference: 0.3905 s/iter. Eval: 0.0002 s/iter. Total: 0.3928 s/iter. ETA=0:20:58\n",
            "\u001b[32m[04/30 15:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 1808/5000. Dataloading: 0.0020 s/iter. Inference: 0.3905 s/iter. Eval: 0.0002 s/iter. Total: 0.3928 s/iter. ETA=0:20:53\n",
            "\u001b[32m[04/30 15:34:45 d2.evaluation.evaluator]: \u001b[0mInference done 1821/5000. Dataloading: 0.0020 s/iter. Inference: 0.3906 s/iter. Eval: 0.0002 s/iter. Total: 0.3929 s/iter. ETA=0:20:49\n",
            "\u001b[32m[04/30 15:34:50 d2.evaluation.evaluator]: \u001b[0mInference done 1834/5000. Dataloading: 0.0020 s/iter. Inference: 0.3906 s/iter. Eval: 0.0002 s/iter. Total: 0.3930 s/iter. ETA=0:20:44\n",
            "\u001b[32m[04/30 15:34:55 d2.evaluation.evaluator]: \u001b[0mInference done 1847/5000. Dataloading: 0.0020 s/iter. Inference: 0.3907 s/iter. Eval: 0.0002 s/iter. Total: 0.3930 s/iter. ETA=0:20:39\n",
            "\u001b[32m[04/30 15:35:00 d2.evaluation.evaluator]: \u001b[0mInference done 1860/5000. Dataloading: 0.0020 s/iter. Inference: 0.3907 s/iter. Eval: 0.0002 s/iter. Total: 0.3931 s/iter. ETA=0:20:34\n",
            "\u001b[32m[04/30 15:35:06 d2.evaluation.evaluator]: \u001b[0mInference done 1873/5000. Dataloading: 0.0020 s/iter. Inference: 0.3908 s/iter. Eval: 0.0002 s/iter. Total: 0.3931 s/iter. ETA=0:20:29\n",
            "\u001b[32m[04/30 15:35:11 d2.evaluation.evaluator]: \u001b[0mInference done 1886/5000. Dataloading: 0.0020 s/iter. Inference: 0.3909 s/iter. Eval: 0.0002 s/iter. Total: 0.3932 s/iter. ETA=0:20:24\n",
            "\u001b[32m[04/30 15:35:16 d2.evaluation.evaluator]: \u001b[0mInference done 1899/5000. Dataloading: 0.0020 s/iter. Inference: 0.3909 s/iter. Eval: 0.0002 s/iter. Total: 0.3933 s/iter. ETA=0:20:19\n",
            "\u001b[32m[04/30 15:35:21 d2.evaluation.evaluator]: \u001b[0mInference done 1912/5000. Dataloading: 0.0020 s/iter. Inference: 0.3910 s/iter. Eval: 0.0002 s/iter. Total: 0.3933 s/iter. ETA=0:20:14\n",
            "\u001b[32m[04/30 15:35:26 d2.evaluation.evaluator]: \u001b[0mInference done 1925/5000. Dataloading: 0.0020 s/iter. Inference: 0.3910 s/iter. Eval: 0.0002 s/iter. Total: 0.3934 s/iter. ETA=0:20:09\n",
            "\u001b[32m[04/30 15:35:32 d2.evaluation.evaluator]: \u001b[0mInference done 1938/5000. Dataloading: 0.0020 s/iter. Inference: 0.3911 s/iter. Eval: 0.0002 s/iter. Total: 0.3934 s/iter. ETA=0:20:04\n",
            "\u001b[32m[04/30 15:35:37 d2.evaluation.evaluator]: \u001b[0mInference done 1951/5000. Dataloading: 0.0020 s/iter. Inference: 0.3911 s/iter. Eval: 0.0002 s/iter. Total: 0.3934 s/iter. ETA=0:19:59\n",
            "\u001b[32m[04/30 15:35:42 d2.evaluation.evaluator]: \u001b[0mInference done 1964/5000. Dataloading: 0.0020 s/iter. Inference: 0.3912 s/iter. Eval: 0.0002 s/iter. Total: 0.3935 s/iter. ETA=0:19:54\n",
            "\u001b[32m[04/30 15:35:47 d2.evaluation.evaluator]: \u001b[0mInference done 1977/5000. Dataloading: 0.0020 s/iter. Inference: 0.3912 s/iter. Eval: 0.0002 s/iter. Total: 0.3935 s/iter. ETA=0:19:49\n",
            "\u001b[32m[04/30 15:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 1990/5000. Dataloading: 0.0020 s/iter. Inference: 0.3913 s/iter. Eval: 0.0002 s/iter. Total: 0.3936 s/iter. ETA=0:19:44\n",
            "\u001b[32m[04/30 15:35:58 d2.evaluation.evaluator]: \u001b[0mInference done 2003/5000. Dataloading: 0.0020 s/iter. Inference: 0.3913 s/iter. Eval: 0.0002 s/iter. Total: 0.3936 s/iter. ETA=0:19:39\n",
            "\u001b[32m[04/30 15:36:03 d2.evaluation.evaluator]: \u001b[0mInference done 2016/5000. Dataloading: 0.0020 s/iter. Inference: 0.3914 s/iter. Eval: 0.0002 s/iter. Total: 0.3937 s/iter. ETA=0:19:34\n",
            "\u001b[32m[04/30 15:36:08 d2.evaluation.evaluator]: \u001b[0mInference done 2029/5000. Dataloading: 0.0020 s/iter. Inference: 0.3914 s/iter. Eval: 0.0002 s/iter. Total: 0.3937 s/iter. ETA=0:19:29\n",
            "\u001b[32m[04/30 15:36:13 d2.evaluation.evaluator]: \u001b[0mInference done 2042/5000. Dataloading: 0.0020 s/iter. Inference: 0.3914 s/iter. Eval: 0.0002 s/iter. Total: 0.3938 s/iter. ETA=0:19:24\n",
            "\u001b[32m[04/30 15:36:18 d2.evaluation.evaluator]: \u001b[0mInference done 2055/5000. Dataloading: 0.0020 s/iter. Inference: 0.3914 s/iter. Eval: 0.0002 s/iter. Total: 0.3938 s/iter. ETA=0:19:19\n",
            "\u001b[32m[04/30 15:36:24 d2.evaluation.evaluator]: \u001b[0mInference done 2068/5000. Dataloading: 0.0020 s/iter. Inference: 0.3915 s/iter. Eval: 0.0002 s/iter. Total: 0.3939 s/iter. ETA=0:19:14\n",
            "\u001b[32m[04/30 15:36:29 d2.evaluation.evaluator]: \u001b[0mInference done 2081/5000. Dataloading: 0.0020 s/iter. Inference: 0.3916 s/iter. Eval: 0.0002 s/iter. Total: 0.3939 s/iter. ETA=0:19:09\n",
            "\u001b[32m[04/30 15:36:34 d2.evaluation.evaluator]: \u001b[0mInference done 2094/5000. Dataloading: 0.0020 s/iter. Inference: 0.3916 s/iter. Eval: 0.0002 s/iter. Total: 0.3939 s/iter. ETA=0:19:04\n",
            "\u001b[32m[04/30 15:36:39 d2.evaluation.evaluator]: \u001b[0mInference done 2107/5000. Dataloading: 0.0020 s/iter. Inference: 0.3916 s/iter. Eval: 0.0002 s/iter. Total: 0.3940 s/iter. ETA=0:18:59\n",
            "\u001b[32m[04/30 15:36:44 d2.evaluation.evaluator]: \u001b[0mInference done 2120/5000. Dataloading: 0.0020 s/iter. Inference: 0.3917 s/iter. Eval: 0.0002 s/iter. Total: 0.3940 s/iter. ETA=0:18:54\n",
            "\u001b[32m[04/30 15:36:50 d2.evaluation.evaluator]: \u001b[0mInference done 2133/5000. Dataloading: 0.0020 s/iter. Inference: 0.3917 s/iter. Eval: 0.0002 s/iter. Total: 0.3940 s/iter. ETA=0:18:49\n",
            "\u001b[32m[04/30 15:36:55 d2.evaluation.evaluator]: \u001b[0mInference done 2146/5000. Dataloading: 0.0020 s/iter. Inference: 0.3917 s/iter. Eval: 0.0002 s/iter. Total: 0.3940 s/iter. ETA=0:18:44\n",
            "\u001b[32m[04/30 15:37:00 d2.evaluation.evaluator]: \u001b[0mInference done 2159/5000. Dataloading: 0.0020 s/iter. Inference: 0.3917 s/iter. Eval: 0.0002 s/iter. Total: 0.3941 s/iter. ETA=0:18:39\n",
            "\u001b[32m[04/30 15:37:05 d2.evaluation.evaluator]: \u001b[0mInference done 2172/5000. Dataloading: 0.0020 s/iter. Inference: 0.3917 s/iter. Eval: 0.0002 s/iter. Total: 0.3941 s/iter. ETA=0:18:34\n",
            "\u001b[32m[04/30 15:37:10 d2.evaluation.evaluator]: \u001b[0mInference done 2185/5000. Dataloading: 0.0020 s/iter. Inference: 0.3918 s/iter. Eval: 0.0002 s/iter. Total: 0.3941 s/iter. ETA=0:18:29\n",
            "\u001b[32m[04/30 15:37:16 d2.evaluation.evaluator]: \u001b[0mInference done 2198/5000. Dataloading: 0.0020 s/iter. Inference: 0.3918 s/iter. Eval: 0.0002 s/iter. Total: 0.3941 s/iter. ETA=0:18:24\n",
            "\u001b[32m[04/30 15:37:21 d2.evaluation.evaluator]: \u001b[0mInference done 2211/5000. Dataloading: 0.0020 s/iter. Inference: 0.3918 s/iter. Eval: 0.0002 s/iter. Total: 0.3942 s/iter. ETA=0:18:19\n",
            "\u001b[32m[04/30 15:37:26 d2.evaluation.evaluator]: \u001b[0mInference done 2224/5000. Dataloading: 0.0020 s/iter. Inference: 0.3919 s/iter. Eval: 0.0002 s/iter. Total: 0.3942 s/iter. ETA=0:18:14\n",
            "\u001b[32m[04/30 15:37:31 d2.evaluation.evaluator]: \u001b[0mInference done 2237/5000. Dataloading: 0.0020 s/iter. Inference: 0.3919 s/iter. Eval: 0.0002 s/iter. Total: 0.3942 s/iter. ETA=0:18:09\n",
            "\u001b[32m[04/30 15:37:36 d2.evaluation.evaluator]: \u001b[0mInference done 2250/5000. Dataloading: 0.0020 s/iter. Inference: 0.3919 s/iter. Eval: 0.0002 s/iter. Total: 0.3943 s/iter. ETA=0:18:04\n",
            "\u001b[32m[04/30 15:37:42 d2.evaluation.evaluator]: \u001b[0mInference done 2263/5000. Dataloading: 0.0020 s/iter. Inference: 0.3920 s/iter. Eval: 0.0002 s/iter. Total: 0.3943 s/iter. ETA=0:17:59\n",
            "\u001b[32m[04/30 15:37:47 d2.evaluation.evaluator]: \u001b[0mInference done 2276/5000. Dataloading: 0.0020 s/iter. Inference: 0.3920 s/iter. Eval: 0.0002 s/iter. Total: 0.3943 s/iter. ETA=0:17:54\n",
            "\u001b[32m[04/30 15:37:52 d2.evaluation.evaluator]: \u001b[0mInference done 2289/5000. Dataloading: 0.0020 s/iter. Inference: 0.3921 s/iter. Eval: 0.0002 s/iter. Total: 0.3944 s/iter. ETA=0:17:49\n",
            "\u001b[32m[04/30 15:37:57 d2.evaluation.evaluator]: \u001b[0mInference done 2302/5000. Dataloading: 0.0020 s/iter. Inference: 0.3921 s/iter. Eval: 0.0002 s/iter. Total: 0.3944 s/iter. ETA=0:17:44\n",
            "\u001b[32m[04/30 15:38:02 d2.evaluation.evaluator]: \u001b[0mInference done 2315/5000. Dataloading: 0.0020 s/iter. Inference: 0.3921 s/iter. Eval: 0.0002 s/iter. Total: 0.3944 s/iter. ETA=0:17:39\n",
            "\u001b[32m[04/30 15:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 2328/5000. Dataloading: 0.0020 s/iter. Inference: 0.3921 s/iter. Eval: 0.0002 s/iter. Total: 0.3945 s/iter. ETA=0:17:33\n",
            "\u001b[32m[04/30 15:38:13 d2.evaluation.evaluator]: \u001b[0mInference done 2341/5000. Dataloading: 0.0020 s/iter. Inference: 0.3921 s/iter. Eval: 0.0002 s/iter. Total: 0.3945 s/iter. ETA=0:17:28\n",
            "\u001b[32m[04/30 15:38:18 d2.evaluation.evaluator]: \u001b[0mInference done 2354/5000. Dataloading: 0.0020 s/iter. Inference: 0.3922 s/iter. Eval: 0.0002 s/iter. Total: 0.3946 s/iter. ETA=0:17:23\n",
            "\u001b[32m[04/30 15:38:23 d2.evaluation.evaluator]: \u001b[0mInference done 2367/5000. Dataloading: 0.0020 s/iter. Inference: 0.3923 s/iter. Eval: 0.0002 s/iter. Total: 0.3946 s/iter. ETA=0:17:19\n",
            "\u001b[32m[04/30 15:38:28 d2.evaluation.evaluator]: \u001b[0mInference done 2380/5000. Dataloading: 0.0020 s/iter. Inference: 0.3923 s/iter. Eval: 0.0002 s/iter. Total: 0.3946 s/iter. ETA=0:17:13\n",
            "\u001b[32m[04/30 15:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 2393/5000. Dataloading: 0.0020 s/iter. Inference: 0.3924 s/iter. Eval: 0.0002 s/iter. Total: 0.3947 s/iter. ETA=0:17:08\n",
            "\u001b[32m[04/30 15:38:39 d2.evaluation.evaluator]: \u001b[0mInference done 2406/5000. Dataloading: 0.0020 s/iter. Inference: 0.3924 s/iter. Eval: 0.0002 s/iter. Total: 0.3947 s/iter. ETA=0:17:03\n",
            "\u001b[32m[04/30 15:38:44 d2.evaluation.evaluator]: \u001b[0mInference done 2419/5000. Dataloading: 0.0020 s/iter. Inference: 0.3924 s/iter. Eval: 0.0002 s/iter. Total: 0.3947 s/iter. ETA=0:16:58\n",
            "\u001b[32m[04/30 15:38:49 d2.evaluation.evaluator]: \u001b[0mInference done 2432/5000. Dataloading: 0.0020 s/iter. Inference: 0.3925 s/iter. Eval: 0.0002 s/iter. Total: 0.3948 s/iter. ETA=0:16:53\n",
            "\u001b[32m[04/30 15:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 2445/5000. Dataloading: 0.0020 s/iter. Inference: 0.3925 s/iter. Eval: 0.0002 s/iter. Total: 0.3948 s/iter. ETA=0:16:48\n",
            "\u001b[32m[04/30 15:39:00 d2.evaluation.evaluator]: \u001b[0mInference done 2458/5000. Dataloading: 0.0020 s/iter. Inference: 0.3925 s/iter. Eval: 0.0002 s/iter. Total: 0.3949 s/iter. ETA=0:16:43\n",
            "\u001b[32m[04/30 15:39:05 d2.evaluation.evaluator]: \u001b[0mInference done 2471/5000. Dataloading: 0.0020 s/iter. Inference: 0.3926 s/iter. Eval: 0.0002 s/iter. Total: 0.3949 s/iter. ETA=0:16:38\n",
            "\u001b[32m[04/30 15:39:10 d2.evaluation.evaluator]: \u001b[0mInference done 2484/5000. Dataloading: 0.0020 s/iter. Inference: 0.3926 s/iter. Eval: 0.0002 s/iter. Total: 0.3949 s/iter. ETA=0:16:33\n",
            "\u001b[32m[04/30 15:39:15 d2.evaluation.evaluator]: \u001b[0mInference done 2497/5000. Dataloading: 0.0020 s/iter. Inference: 0.3926 s/iter. Eval: 0.0002 s/iter. Total: 0.3949 s/iter. ETA=0:16:28\n",
            "\u001b[32m[04/30 15:39:20 d2.evaluation.evaluator]: \u001b[0mInference done 2510/5000. Dataloading: 0.0020 s/iter. Inference: 0.3926 s/iter. Eval: 0.0002 s/iter. Total: 0.3950 s/iter. ETA=0:16:23\n",
            "\u001b[32m[04/30 15:39:26 d2.evaluation.evaluator]: \u001b[0mInference done 2523/5000. Dataloading: 0.0020 s/iter. Inference: 0.3926 s/iter. Eval: 0.0002 s/iter. Total: 0.3950 s/iter. ETA=0:16:18\n",
            "\u001b[32m[04/30 15:39:31 d2.evaluation.evaluator]: \u001b[0mInference done 2536/5000. Dataloading: 0.0020 s/iter. Inference: 0.3926 s/iter. Eval: 0.0002 s/iter. Total: 0.3950 s/iter. ETA=0:16:13\n",
            "\u001b[32m[04/30 15:39:36 d2.evaluation.evaluator]: \u001b[0mInference done 2549/5000. Dataloading: 0.0020 s/iter. Inference: 0.3927 s/iter. Eval: 0.0002 s/iter. Total: 0.3950 s/iter. ETA=0:16:08\n",
            "\u001b[32m[04/30 15:39:41 d2.evaluation.evaluator]: \u001b[0mInference done 2562/5000. Dataloading: 0.0020 s/iter. Inference: 0.3927 s/iter. Eval: 0.0002 s/iter. Total: 0.3951 s/iter. ETA=0:16:03\n",
            "\u001b[32m[04/30 15:39:47 d2.evaluation.evaluator]: \u001b[0mInference done 2575/5000. Dataloading: 0.0020 s/iter. Inference: 0.3928 s/iter. Eval: 0.0002 s/iter. Total: 0.3951 s/iter. ETA=0:15:58\n",
            "\u001b[32m[04/30 15:39:52 d2.evaluation.evaluator]: \u001b[0mInference done 2588/5000. Dataloading: 0.0020 s/iter. Inference: 0.3927 s/iter. Eval: 0.0002 s/iter. Total: 0.3951 s/iter. ETA=0:15:52\n",
            "\u001b[32m[04/30 15:39:57 d2.evaluation.evaluator]: \u001b[0mInference done 2601/5000. Dataloading: 0.0020 s/iter. Inference: 0.3928 s/iter. Eval: 0.0002 s/iter. Total: 0.3951 s/iter. ETA=0:15:47\n",
            "\u001b[32m[04/30 15:40:02 d2.evaluation.evaluator]: \u001b[0mInference done 2614/5000. Dataloading: 0.0020 s/iter. Inference: 0.3928 s/iter. Eval: 0.0002 s/iter. Total: 0.3951 s/iter. ETA=0:15:42\n",
            "\u001b[32m[04/30 15:40:07 d2.evaluation.evaluator]: \u001b[0mInference done 2627/5000. Dataloading: 0.0020 s/iter. Inference: 0.3928 s/iter. Eval: 0.0002 s/iter. Total: 0.3952 s/iter. ETA=0:15:37\n",
            "\u001b[32m[04/30 15:40:13 d2.evaluation.evaluator]: \u001b[0mInference done 2640/5000. Dataloading: 0.0020 s/iter. Inference: 0.3929 s/iter. Eval: 0.0002 s/iter. Total: 0.3952 s/iter. ETA=0:15:32\n",
            "\u001b[32m[04/30 15:40:18 d2.evaluation.evaluator]: \u001b[0mInference done 2653/5000. Dataloading: 0.0020 s/iter. Inference: 0.3929 s/iter. Eval: 0.0002 s/iter. Total: 0.3952 s/iter. ETA=0:15:27\n",
            "\u001b[32m[04/30 15:40:23 d2.evaluation.evaluator]: \u001b[0mInference done 2666/5000. Dataloading: 0.0020 s/iter. Inference: 0.3929 s/iter. Eval: 0.0002 s/iter. Total: 0.3953 s/iter. ETA=0:15:22\n",
            "\u001b[32m[04/30 15:40:28 d2.evaluation.evaluator]: \u001b[0mInference done 2679/5000. Dataloading: 0.0020 s/iter. Inference: 0.3930 s/iter. Eval: 0.0002 s/iter. Total: 0.3953 s/iter. ETA=0:15:17\n",
            "\u001b[32m[04/30 15:40:33 d2.evaluation.evaluator]: \u001b[0mInference done 2692/5000. Dataloading: 0.0020 s/iter. Inference: 0.3930 s/iter. Eval: 0.0002 s/iter. Total: 0.3954 s/iter. ETA=0:15:12\n",
            "\u001b[32m[04/30 15:40:39 d2.evaluation.evaluator]: \u001b[0mInference done 2705/5000. Dataloading: 0.0020 s/iter. Inference: 0.3931 s/iter. Eval: 0.0002 s/iter. Total: 0.3954 s/iter. ETA=0:15:07\n",
            "\u001b[32m[04/30 15:40:44 d2.evaluation.evaluator]: \u001b[0mInference done 2718/5000. Dataloading: 0.0020 s/iter. Inference: 0.3931 s/iter. Eval: 0.0002 s/iter. Total: 0.3954 s/iter. ETA=0:15:02\n",
            "\u001b[32m[04/30 15:40:49 d2.evaluation.evaluator]: \u001b[0mInference done 2731/5000. Dataloading: 0.0020 s/iter. Inference: 0.3931 s/iter. Eval: 0.0002 s/iter. Total: 0.3955 s/iter. ETA=0:14:57\n",
            "\u001b[32m[04/30 15:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 2744/5000. Dataloading: 0.0020 s/iter. Inference: 0.3931 s/iter. Eval: 0.0002 s/iter. Total: 0.3955 s/iter. ETA=0:14:52\n",
            "\u001b[32m[04/30 15:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 2757/5000. Dataloading: 0.0020 s/iter. Inference: 0.3931 s/iter. Eval: 0.0002 s/iter. Total: 0.3955 s/iter. ETA=0:14:47\n",
            "\u001b[32m[04/30 15:41:05 d2.evaluation.evaluator]: \u001b[0mInference done 2770/5000. Dataloading: 0.0020 s/iter. Inference: 0.3932 s/iter. Eval: 0.0002 s/iter. Total: 0.3955 s/iter. ETA=0:14:41\n",
            "\u001b[32m[04/30 15:41:10 d2.evaluation.evaluator]: \u001b[0mInference done 2783/5000. Dataloading: 0.0020 s/iter. Inference: 0.3932 s/iter. Eval: 0.0002 s/iter. Total: 0.3955 s/iter. ETA=0:14:36\n",
            "\u001b[32m[04/30 15:41:15 d2.evaluation.evaluator]: \u001b[0mInference done 2796/5000. Dataloading: 0.0020 s/iter. Inference: 0.3932 s/iter. Eval: 0.0002 s/iter. Total: 0.3955 s/iter. ETA=0:14:31\n",
            "\u001b[32m[04/30 15:41:20 d2.evaluation.evaluator]: \u001b[0mInference done 2809/5000. Dataloading: 0.0020 s/iter. Inference: 0.3932 s/iter. Eval: 0.0002 s/iter. Total: 0.3956 s/iter. ETA=0:14:26\n",
            "\u001b[32m[04/30 15:41:25 d2.evaluation.evaluator]: \u001b[0mInference done 2822/5000. Dataloading: 0.0020 s/iter. Inference: 0.3932 s/iter. Eval: 0.0002 s/iter. Total: 0.3956 s/iter. ETA=0:14:21\n",
            "\u001b[32m[04/30 15:41:31 d2.evaluation.evaluator]: \u001b[0mInference done 2835/5000. Dataloading: 0.0020 s/iter. Inference: 0.3933 s/iter. Eval: 0.0002 s/iter. Total: 0.3956 s/iter. ETA=0:14:16\n",
            "\u001b[32m[04/30 15:41:36 d2.evaluation.evaluator]: \u001b[0mInference done 2848/5000. Dataloading: 0.0020 s/iter. Inference: 0.3933 s/iter. Eval: 0.0002 s/iter. Total: 0.3957 s/iter. ETA=0:14:11\n",
            "\u001b[32m[04/30 15:41:41 d2.evaluation.evaluator]: \u001b[0mInference done 2861/5000. Dataloading: 0.0020 s/iter. Inference: 0.3933 s/iter. Eval: 0.0002 s/iter. Total: 0.3957 s/iter. ETA=0:14:06\n",
            "\u001b[32m[04/30 15:41:46 d2.evaluation.evaluator]: \u001b[0mInference done 2874/5000. Dataloading: 0.0020 s/iter. Inference: 0.3934 s/iter. Eval: 0.0002 s/iter. Total: 0.3957 s/iter. ETA=0:14:01\n",
            "\u001b[32m[04/30 15:41:52 d2.evaluation.evaluator]: \u001b[0mInference done 2887/5000. Dataloading: 0.0020 s/iter. Inference: 0.3934 s/iter. Eval: 0.0002 s/iter. Total: 0.3957 s/iter. ETA=0:13:56\n",
            "\u001b[32m[04/30 15:41:57 d2.evaluation.evaluator]: \u001b[0mInference done 2900/5000. Dataloading: 0.0020 s/iter. Inference: 0.3934 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:51\n",
            "\u001b[32m[04/30 15:42:02 d2.evaluation.evaluator]: \u001b[0mInference done 2913/5000. Dataloading: 0.0020 s/iter. Inference: 0.3934 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:45\n",
            "\u001b[32m[04/30 15:42:07 d2.evaluation.evaluator]: \u001b[0mInference done 2926/5000. Dataloading: 0.0020 s/iter. Inference: 0.3934 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:40\n",
            "\u001b[32m[04/30 15:42:12 d2.evaluation.evaluator]: \u001b[0mInference done 2939/5000. Dataloading: 0.0020 s/iter. Inference: 0.3935 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:35\n",
            "\u001b[32m[04/30 15:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 2952/5000. Dataloading: 0.0020 s/iter. Inference: 0.3935 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:30\n",
            "\u001b[32m[04/30 15:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 2965/5000. Dataloading: 0.0020 s/iter. Inference: 0.3935 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:25\n",
            "\u001b[32m[04/30 15:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 2978/5000. Dataloading: 0.0020 s/iter. Inference: 0.3935 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:20\n",
            "\u001b[32m[04/30 15:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 2991/5000. Dataloading: 0.0020 s/iter. Inference: 0.3935 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:15\n",
            "\u001b[32m[04/30 15:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 3004/5000. Dataloading: 0.0020 s/iter. Inference: 0.3935 s/iter. Eval: 0.0002 s/iter. Total: 0.3959 s/iter. ETA=0:13:10\n",
            "\u001b[32m[04/30 15:42:44 d2.evaluation.evaluator]: \u001b[0mInference done 3017/5000. Dataloading: 0.0020 s/iter. Inference: 0.3936 s/iter. Eval: 0.0002 s/iter. Total: 0.3959 s/iter. ETA=0:13:05\n",
            "\u001b[32m[04/30 15:42:49 d2.evaluation.evaluator]: \u001b[0mInference done 3030/5000. Dataloading: 0.0020 s/iter. Inference: 0.3936 s/iter. Eval: 0.0002 s/iter. Total: 0.3959 s/iter. ETA=0:12:59\n",
            "\u001b[32m[04/30 15:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 3043/5000. Dataloading: 0.0020 s/iter. Inference: 0.3936 s/iter. Eval: 0.0002 s/iter. Total: 0.3960 s/iter. ETA=0:12:54\n",
            "\u001b[32m[04/30 15:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 3056/5000. Dataloading: 0.0020 s/iter. Inference: 0.3937 s/iter. Eval: 0.0002 s/iter. Total: 0.3960 s/iter. ETA=0:12:49\n",
            "\u001b[32m[04/30 15:43:05 d2.evaluation.evaluator]: \u001b[0mInference done 3069/5000. Dataloading: 0.0020 s/iter. Inference: 0.3937 s/iter. Eval: 0.0002 s/iter. Total: 0.3960 s/iter. ETA=0:12:44\n",
            "\u001b[32m[04/30 15:43:10 d2.evaluation.evaluator]: \u001b[0mInference done 3082/5000. Dataloading: 0.0020 s/iter. Inference: 0.3937 s/iter. Eval: 0.0002 s/iter. Total: 0.3961 s/iter. ETA=0:12:39\n",
            "\u001b[32m[04/30 15:43:15 d2.evaluation.evaluator]: \u001b[0mInference done 3095/5000. Dataloading: 0.0020 s/iter. Inference: 0.3937 s/iter. Eval: 0.0002 s/iter. Total: 0.3961 s/iter. ETA=0:12:34\n",
            "\u001b[32m[04/30 15:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 3108/5000. Dataloading: 0.0020 s/iter. Inference: 0.3938 s/iter. Eval: 0.0002 s/iter. Total: 0.3961 s/iter. ETA=0:12:29\n",
            "\u001b[32m[04/30 15:43:25 d2.evaluation.evaluator]: \u001b[0mInference done 3121/5000. Dataloading: 0.0020 s/iter. Inference: 0.3938 s/iter. Eval: 0.0002 s/iter. Total: 0.3961 s/iter. ETA=0:12:24\n",
            "\u001b[32m[04/30 15:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 3134/5000. Dataloading: 0.0020 s/iter. Inference: 0.3938 s/iter. Eval: 0.0002 s/iter. Total: 0.3961 s/iter. ETA=0:12:19\n",
            "\u001b[32m[04/30 15:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 3147/5000. Dataloading: 0.0020 s/iter. Inference: 0.3938 s/iter. Eval: 0.0002 s/iter. Total: 0.3962 s/iter. ETA=0:12:14\n",
            "\u001b[32m[04/30 15:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 3160/5000. Dataloading: 0.0020 s/iter. Inference: 0.3938 s/iter. Eval: 0.0002 s/iter. Total: 0.3962 s/iter. ETA=0:12:08\n",
            "\u001b[32m[04/30 15:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 3173/5000. Dataloading: 0.0020 s/iter. Inference: 0.3939 s/iter. Eval: 0.0002 s/iter. Total: 0.3962 s/iter. ETA=0:12:03\n",
            "\u001b[32m[04/30 15:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 3186/5000. Dataloading: 0.0020 s/iter. Inference: 0.3939 s/iter. Eval: 0.0002 s/iter. Total: 0.3962 s/iter. ETA=0:11:58\n",
            "\u001b[32m[04/30 15:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 3199/5000. Dataloading: 0.0020 s/iter. Inference: 0.3939 s/iter. Eval: 0.0002 s/iter. Total: 0.3962 s/iter. ETA=0:11:53\n",
            "\u001b[32m[04/30 15:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 3212/5000. Dataloading: 0.0020 s/iter. Inference: 0.3939 s/iter. Eval: 0.0002 s/iter. Total: 0.3963 s/iter. ETA=0:11:48\n",
            "\u001b[32m[04/30 15:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 3225/5000. Dataloading: 0.0020 s/iter. Inference: 0.3939 s/iter. Eval: 0.0002 s/iter. Total: 0.3963 s/iter. ETA=0:11:43\n",
            "\u001b[32m[04/30 15:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 3238/5000. Dataloading: 0.0020 s/iter. Inference: 0.3940 s/iter. Eval: 0.0002 s/iter. Total: 0.3963 s/iter. ETA=0:11:38\n",
            "\u001b[32m[04/30 15:44:18 d2.evaluation.evaluator]: \u001b[0mInference done 3251/5000. Dataloading: 0.0020 s/iter. Inference: 0.3940 s/iter. Eval: 0.0002 s/iter. Total: 0.3963 s/iter. ETA=0:11:33\n",
            "\u001b[32m[04/30 15:44:23 d2.evaluation.evaluator]: \u001b[0mInference done 3264/5000. Dataloading: 0.0020 s/iter. Inference: 0.3940 s/iter. Eval: 0.0002 s/iter. Total: 0.3963 s/iter. ETA=0:11:28\n",
            "\u001b[32m[04/30 15:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 3277/5000. Dataloading: 0.0020 s/iter. Inference: 0.3940 s/iter. Eval: 0.0002 s/iter. Total: 0.3964 s/iter. ETA=0:11:22\n",
            "\u001b[32m[04/30 15:44:33 d2.evaluation.evaluator]: \u001b[0mInference done 3290/5000. Dataloading: 0.0020 s/iter. Inference: 0.3941 s/iter. Eval: 0.0002 s/iter. Total: 0.3964 s/iter. ETA=0:11:17\n",
            "\u001b[32m[04/30 15:44:39 d2.evaluation.evaluator]: \u001b[0mInference done 3303/5000. Dataloading: 0.0020 s/iter. Inference: 0.3941 s/iter. Eval: 0.0002 s/iter. Total: 0.3964 s/iter. ETA=0:11:12\n",
            "\u001b[32m[04/30 15:44:44 d2.evaluation.evaluator]: \u001b[0mInference done 3316/5000. Dataloading: 0.0020 s/iter. Inference: 0.3941 s/iter. Eval: 0.0002 s/iter. Total: 0.3964 s/iter. ETA=0:11:07\n",
            "\u001b[32m[04/30 15:44:49 d2.evaluation.evaluator]: \u001b[0mInference done 3329/5000. Dataloading: 0.0020 s/iter. Inference: 0.3941 s/iter. Eval: 0.0002 s/iter. Total: 0.3965 s/iter. ETA=0:11:02\n",
            "\u001b[32m[04/30 15:44:54 d2.evaluation.evaluator]: \u001b[0mInference done 3342/5000. Dataloading: 0.0020 s/iter. Inference: 0.3941 s/iter. Eval: 0.0002 s/iter. Total: 0.3965 s/iter. ETA=0:10:57\n",
            "\u001b[32m[04/30 15:44:59 d2.evaluation.evaluator]: \u001b[0mInference done 3355/5000. Dataloading: 0.0020 s/iter. Inference: 0.3941 s/iter. Eval: 0.0002 s/iter. Total: 0.3965 s/iter. ETA=0:10:52\n",
            "\u001b[32m[04/30 15:45:05 d2.evaluation.evaluator]: \u001b[0mInference done 3368/5000. Dataloading: 0.0020 s/iter. Inference: 0.3942 s/iter. Eval: 0.0002 s/iter. Total: 0.3965 s/iter. ETA=0:10:47\n",
            "\u001b[32m[04/30 15:45:10 d2.evaluation.evaluator]: \u001b[0mInference done 3381/5000. Dataloading: 0.0020 s/iter. Inference: 0.3942 s/iter. Eval: 0.0002 s/iter. Total: 0.3965 s/iter. ETA=0:10:42\n",
            "\u001b[32m[04/30 15:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 3394/5000. Dataloading: 0.0020 s/iter. Inference: 0.3942 s/iter. Eval: 0.0002 s/iter. Total: 0.3966 s/iter. ETA=0:10:36\n",
            "\u001b[32m[04/30 15:45:20 d2.evaluation.evaluator]: \u001b[0mInference done 3407/5000. Dataloading: 0.0020 s/iter. Inference: 0.3942 s/iter. Eval: 0.0002 s/iter. Total: 0.3966 s/iter. ETA=0:10:31\n",
            "\u001b[32m[04/30 15:45:25 d2.evaluation.evaluator]: \u001b[0mInference done 3420/5000. Dataloading: 0.0020 s/iter. Inference: 0.3942 s/iter. Eval: 0.0002 s/iter. Total: 0.3966 s/iter. ETA=0:10:26\n",
            "\u001b[32m[04/30 15:45:31 d2.evaluation.evaluator]: \u001b[0mInference done 3433/5000. Dataloading: 0.0020 s/iter. Inference: 0.3943 s/iter. Eval: 0.0002 s/iter. Total: 0.3966 s/iter. ETA=0:10:21\n",
            "\u001b[32m[04/30 15:45:36 d2.evaluation.evaluator]: \u001b[0mInference done 3446/5000. Dataloading: 0.0020 s/iter. Inference: 0.3943 s/iter. Eval: 0.0002 s/iter. Total: 0.3966 s/iter. ETA=0:10:16\n",
            "\u001b[32m[04/30 15:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 3459/5000. Dataloading: 0.0020 s/iter. Inference: 0.3943 s/iter. Eval: 0.0002 s/iter. Total: 0.3966 s/iter. ETA=0:10:11\n",
            "\u001b[32m[04/30 15:45:46 d2.evaluation.evaluator]: \u001b[0mInference done 3472/5000. Dataloading: 0.0020 s/iter. Inference: 0.3943 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:10:06\n",
            "\u001b[32m[04/30 15:45:52 d2.evaluation.evaluator]: \u001b[0mInference done 3485/5000. Dataloading: 0.0020 s/iter. Inference: 0.3943 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:10:00\n",
            "\u001b[32m[04/30 15:45:57 d2.evaluation.evaluator]: \u001b[0mInference done 3498/5000. Dataloading: 0.0020 s/iter. Inference: 0.3943 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:09:55\n",
            "\u001b[32m[04/30 15:46:02 d2.evaluation.evaluator]: \u001b[0mInference done 3511/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:09:50\n",
            "\u001b[32m[04/30 15:46:07 d2.evaluation.evaluator]: \u001b[0mInference done 3524/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:09:45\n",
            "\u001b[32m[04/30 15:46:12 d2.evaluation.evaluator]: \u001b[0mInference done 3537/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:09:40\n",
            "\u001b[32m[04/30 15:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 3550/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:09:35\n",
            "\u001b[32m[04/30 15:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 3563/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:09:30\n",
            "\u001b[32m[04/30 15:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 3576/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:09:24\n",
            "\u001b[32m[04/30 15:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 3589/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:09:19\n",
            "\u001b[32m[04/30 15:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 3602/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:09:14\n",
            "\u001b[32m[04/30 15:46:44 d2.evaluation.evaluator]: \u001b[0mInference done 3615/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:09:09\n",
            "\u001b[32m[04/30 15:46:49 d2.evaluation.evaluator]: \u001b[0mInference done 3628/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:09:04\n",
            "\u001b[32m[04/30 15:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 3641/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:08:59\n",
            "\u001b[32m[04/30 15:46:59 d2.evaluation.evaluator]: \u001b[0mInference done 3654/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:08:54\n",
            "\u001b[32m[04/30 15:47:04 d2.evaluation.evaluator]: \u001b[0mInference done 3667/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:08:48\n",
            "\u001b[32m[04/30 15:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 3680/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:08:43\n",
            "\u001b[32m[04/30 15:47:15 d2.evaluation.evaluator]: \u001b[0mInference done 3693/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:08:38\n",
            "\u001b[32m[04/30 15:47:20 d2.evaluation.evaluator]: \u001b[0mInference done 3706/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:08:33\n",
            "\u001b[32m[04/30 15:47:25 d2.evaluation.evaluator]: \u001b[0mInference done 3719/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:08:28\n",
            "\u001b[32m[04/30 15:47:30 d2.evaluation.evaluator]: \u001b[0mInference done 3732/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:08:23\n",
            "\u001b[32m[04/30 15:47:36 d2.evaluation.evaluator]: \u001b[0mInference done 3745/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:08:18\n",
            "\u001b[32m[04/30 15:47:41 d2.evaluation.evaluator]: \u001b[0mInference done 3758/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:08:12\n",
            "\u001b[32m[04/30 15:47:46 d2.evaluation.evaluator]: \u001b[0mInference done 3771/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:08:07\n",
            "\u001b[32m[04/30 15:47:51 d2.evaluation.evaluator]: \u001b[0mInference done 3784/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:08:02\n",
            "\u001b[32m[04/30 15:47:56 d2.evaluation.evaluator]: \u001b[0mInference done 3797/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:07:57\n",
            "\u001b[32m[04/30 15:48:01 d2.evaluation.evaluator]: \u001b[0mInference done 3810/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:07:52\n",
            "\u001b[32m[04/30 15:48:07 d2.evaluation.evaluator]: \u001b[0mInference done 3823/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:07:47\n",
            "\u001b[32m[04/30 15:48:12 d2.evaluation.evaluator]: \u001b[0mInference done 3836/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:42\n",
            "\u001b[32m[04/30 15:48:17 d2.evaluation.evaluator]: \u001b[0mInference done 3849/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:36\n",
            "\u001b[32m[04/30 15:48:22 d2.evaluation.evaluator]: \u001b[0mInference done 3862/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:31\n",
            "\u001b[32m[04/30 15:48:28 d2.evaluation.evaluator]: \u001b[0mInference done 3875/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:26\n",
            "\u001b[32m[04/30 15:48:33 d2.evaluation.evaluator]: \u001b[0mInference done 3888/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:21\n",
            "\u001b[32m[04/30 15:48:38 d2.evaluation.evaluator]: \u001b[0mInference done 3901/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:16\n",
            "\u001b[32m[04/30 15:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 3914/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:11\n",
            "\u001b[32m[04/30 15:48:48 d2.evaluation.evaluator]: \u001b[0mInference done 3927/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:06\n",
            "\u001b[32m[04/30 15:48:53 d2.evaluation.evaluator]: \u001b[0mInference done 3940/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:00\n",
            "\u001b[32m[04/30 15:48:59 d2.evaluation.evaluator]: \u001b[0mInference done 3953/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:06:55\n",
            "\u001b[32m[04/30 15:49:04 d2.evaluation.evaluator]: \u001b[0mInference done 3966/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:06:50\n",
            "\u001b[32m[04/30 15:49:09 d2.evaluation.evaluator]: \u001b[0mInference done 3979/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:45\n",
            "\u001b[32m[04/30 15:49:14 d2.evaluation.evaluator]: \u001b[0mInference done 3992/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:40\n",
            "\u001b[32m[04/30 15:49:19 d2.evaluation.evaluator]: \u001b[0mInference done 4005/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:35\n",
            "\u001b[32m[04/30 15:49:25 d2.evaluation.evaluator]: \u001b[0mInference done 4018/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:29\n",
            "\u001b[32m[04/30 15:49:30 d2.evaluation.evaluator]: \u001b[0mInference done 4031/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:24\n",
            "\u001b[32m[04/30 15:49:35 d2.evaluation.evaluator]: \u001b[0mInference done 4044/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:19\n",
            "\u001b[32m[04/30 15:49:40 d2.evaluation.evaluator]: \u001b[0mInference done 4057/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:14\n",
            "\u001b[32m[04/30 15:49:45 d2.evaluation.evaluator]: \u001b[0mInference done 4070/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:09\n",
            "\u001b[32m[04/30 15:49:51 d2.evaluation.evaluator]: \u001b[0mInference done 4083/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:04\n",
            "\u001b[32m[04/30 15:49:56 d2.evaluation.evaluator]: \u001b[0mInference done 4096/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:05:59\n",
            "\u001b[32m[04/30 15:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 4109/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:05:53\n",
            "\u001b[32m[04/30 15:50:06 d2.evaluation.evaluator]: \u001b[0mInference done 4122/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:48\n",
            "\u001b[32m[04/30 15:50:12 d2.evaluation.evaluator]: \u001b[0mInference done 4135/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:43\n",
            "\u001b[32m[04/30 15:50:17 d2.evaluation.evaluator]: \u001b[0mInference done 4148/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:38\n",
            "\u001b[32m[04/30 15:50:22 d2.evaluation.evaluator]: \u001b[0mInference done 4161/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:33\n",
            "\u001b[32m[04/30 15:50:27 d2.evaluation.evaluator]: \u001b[0mInference done 4174/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:28\n",
            "\u001b[32m[04/30 15:50:32 d2.evaluation.evaluator]: \u001b[0mInference done 4187/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:22\n",
            "\u001b[32m[04/30 15:50:38 d2.evaluation.evaluator]: \u001b[0mInference done 4200/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:17\n",
            "\u001b[32m[04/30 15:50:43 d2.evaluation.evaluator]: \u001b[0mInference done 4213/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:12\n",
            "\u001b[32m[04/30 15:50:48 d2.evaluation.evaluator]: \u001b[0mInference done 4226/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:05:07\n",
            "\u001b[32m[04/30 15:50:53 d2.evaluation.evaluator]: \u001b[0mInference done 4239/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:02\n",
            "\u001b[32m[04/30 15:50:58 d2.evaluation.evaluator]: \u001b[0mInference done 4252/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:04:57\n",
            "\u001b[32m[04/30 15:51:03 d2.evaluation.evaluator]: \u001b[0mInference done 4265/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:04:51\n",
            "\u001b[32m[04/30 15:51:09 d2.evaluation.evaluator]: \u001b[0mInference done 4278/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:46\n",
            "\u001b[32m[04/30 15:51:14 d2.evaluation.evaluator]: \u001b[0mInference done 4291/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:41\n",
            "\u001b[32m[04/30 15:51:19 d2.evaluation.evaluator]: \u001b[0mInference done 4304/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:36\n",
            "\u001b[32m[04/30 15:51:24 d2.evaluation.evaluator]: \u001b[0mInference done 4317/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:31\n",
            "\u001b[32m[04/30 15:51:29 d2.evaluation.evaluator]: \u001b[0mInference done 4330/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:26\n",
            "\u001b[32m[04/30 15:51:35 d2.evaluation.evaluator]: \u001b[0mInference done 4343/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:21\n",
            "\u001b[32m[04/30 15:51:40 d2.evaluation.evaluator]: \u001b[0mInference done 4356/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:15\n",
            "\u001b[32m[04/30 15:51:45 d2.evaluation.evaluator]: \u001b[0mInference done 4369/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:04:10\n",
            "\u001b[32m[04/30 15:51:50 d2.evaluation.evaluator]: \u001b[0mInference done 4382/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:05\n",
            "\u001b[32m[04/30 15:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 4395/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:04:00\n",
            "\u001b[32m[04/30 15:52:01 d2.evaluation.evaluator]: \u001b[0mInference done 4408/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:55\n",
            "\u001b[32m[04/30 15:52:06 d2.evaluation.evaluator]: \u001b[0mInference done 4421/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:50\n",
            "\u001b[32m[04/30 15:52:11 d2.evaluation.evaluator]: \u001b[0mInference done 4434/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:44\n",
            "\u001b[32m[04/30 15:52:16 d2.evaluation.evaluator]: \u001b[0mInference done 4447/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:39\n",
            "\u001b[32m[04/30 15:52:22 d2.evaluation.evaluator]: \u001b[0mInference done 4460/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:34\n",
            "\u001b[32m[04/30 15:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 4473/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:29\n",
            "\u001b[32m[04/30 15:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 4486/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:24\n",
            "\u001b[32m[04/30 15:52:37 d2.evaluation.evaluator]: \u001b[0mInference done 4499/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:19\n",
            "\u001b[32m[04/30 15:52:42 d2.evaluation.evaluator]: \u001b[0mInference done 4512/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:13\n",
            "\u001b[32m[04/30 15:52:48 d2.evaluation.evaluator]: \u001b[0mInference done 4525/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:08\n",
            "\u001b[32m[04/30 15:52:53 d2.evaluation.evaluator]: \u001b[0mInference done 4538/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:03\n",
            "\u001b[32m[04/30 15:52:58 d2.evaluation.evaluator]: \u001b[0mInference done 4551/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:02:58\n",
            "\u001b[32m[04/30 15:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 4564/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:53\n",
            "\u001b[32m[04/30 15:53:08 d2.evaluation.evaluator]: \u001b[0mInference done 4577/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:48\n",
            "\u001b[32m[04/30 15:53:14 d2.evaluation.evaluator]: \u001b[0mInference done 4590/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:42\n",
            "\u001b[32m[04/30 15:53:19 d2.evaluation.evaluator]: \u001b[0mInference done 4603/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:37\n",
            "\u001b[32m[04/30 15:53:24 d2.evaluation.evaluator]: \u001b[0mInference done 4616/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:32\n",
            "\u001b[32m[04/30 15:53:29 d2.evaluation.evaluator]: \u001b[0mInference done 4629/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:27\n",
            "\u001b[32m[04/30 15:53:34 d2.evaluation.evaluator]: \u001b[0mInference done 4642/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:22\n",
            "\u001b[32m[04/30 15:53:40 d2.evaluation.evaluator]: \u001b[0mInference done 4655/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:17\n",
            "\u001b[32m[04/30 15:53:45 d2.evaluation.evaluator]: \u001b[0mInference done 4668/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:11\n",
            "\u001b[32m[04/30 15:53:50 d2.evaluation.evaluator]: \u001b[0mInference done 4681/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:06\n",
            "\u001b[32m[04/30 15:53:55 d2.evaluation.evaluator]: \u001b[0mInference done 4694/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:01\n",
            "\u001b[32m[04/30 15:54:00 d2.evaluation.evaluator]: \u001b[0mInference done 4707/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:01:56\n",
            "\u001b[32m[04/30 15:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 4720/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:01:51\n",
            "\u001b[32m[04/30 15:54:11 d2.evaluation.evaluator]: \u001b[0mInference done 4733/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:01:46\n",
            "\u001b[32m[04/30 15:54:16 d2.evaluation.evaluator]: \u001b[0mInference done 4746/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:01:40\n",
            "\u001b[32m[04/30 15:54:21 d2.evaluation.evaluator]: \u001b[0mInference done 4759/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:01:35\n",
            "\u001b[32m[04/30 15:54:26 d2.evaluation.evaluator]: \u001b[0mInference done 4772/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:01:30\n",
            "\u001b[32m[04/30 15:54:31 d2.evaluation.evaluator]: \u001b[0mInference done 4785/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:01:25\n",
            "\u001b[32m[04/30 15:54:37 d2.evaluation.evaluator]: \u001b[0mInference done 4798/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:01:20\n",
            "\u001b[32m[04/30 15:54:42 d2.evaluation.evaluator]: \u001b[0mInference done 4811/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:01:15\n",
            "\u001b[32m[04/30 15:54:47 d2.evaluation.evaluator]: \u001b[0mInference done 4824/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:01:09\n",
            "\u001b[32m[04/30 15:54:52 d2.evaluation.evaluator]: \u001b[0mInference done 4837/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:01:04\n",
            "\u001b[32m[04/30 15:54:57 d2.evaluation.evaluator]: \u001b[0mInference done 4850/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:59\n",
            "\u001b[32m[04/30 15:55:03 d2.evaluation.evaluator]: \u001b[0mInference done 4863/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:54\n",
            "\u001b[32m[04/30 15:55:08 d2.evaluation.evaluator]: \u001b[0mInference done 4876/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:49\n",
            "\u001b[32m[04/30 15:55:13 d2.evaluation.evaluator]: \u001b[0mInference done 4889/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:44\n",
            "\u001b[32m[04/30 15:55:18 d2.evaluation.evaluator]: \u001b[0mInference done 4902/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:38\n",
            "\u001b[32m[04/30 15:55:23 d2.evaluation.evaluator]: \u001b[0mInference done 4915/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:33\n",
            "\u001b[32m[04/30 15:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 4928/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:28\n",
            "\u001b[32m[04/30 15:55:34 d2.evaluation.evaluator]: \u001b[0mInference done 4941/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:23\n",
            "\u001b[32m[04/30 15:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 4954/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:18\n",
            "\u001b[32m[04/30 15:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 4967/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3977 s/iter. ETA=0:00:13\n",
            "\u001b[32m[04/30 15:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 4980/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3977 s/iter. ETA=0:00:07\n",
            "\u001b[32m[04/30 15:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 4993/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3977 s/iter. ETA=0:00:02\n",
            "\u001b[32m[04/30 15:55:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:33:06.530207 (0.397704 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 15:55:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:32:54 (0.395342 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 15:55:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/30 15:55:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/30 15:55:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.44s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 15:56:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/30 15:56:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 8.06 seconds.\n",
            "\u001b[32m[04/30 15:56:08 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 15:56:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.95 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.639\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.487\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.487\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.566\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.594\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738\n",
            "\u001b[32m[04/30 15:56:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 45.408 | 63.923 | 48.701 | 28.767 | 48.693 | 58.429 |\n",
            "\u001b[32m[04/30 15:56:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 58.624 | bicycle      | 32.908 | car            | 48.271 |\n",
            "| motorcycle    | 46.440 | airplane     | 68.067 | bus            | 68.425 |\n",
            "| train         | 66.699 | truck        | 38.693 | boat           | 30.799 |\n",
            "| traffic light | 31.221 | fire hydrant | 71.224 | stop sign      | 70.503 |\n",
            "| parking meter | 49.486 | bench        | 27.713 | bird           | 38.792 |\n",
            "| cat           | 74.579 | dog          | 67.272 | horse          | 60.823 |\n",
            "| sheep         | 55.491 | cow          | 61.081 | elephant       | 67.356 |\n",
            "| bear          | 73.520 | zebra        | 69.968 | giraffe        | 71.867 |\n",
            "| backpack      | 15.444 | umbrella     | 42.920 | handbag        | 17.071 |\n",
            "| tie           | 38.259 | suitcase     | 44.097 | frisbee        | 70.688 |\n",
            "| skis          | 28.861 | snowboard    | 41.994 | sports ball    | 51.488 |\n",
            "| kite          | 48.666 | baseball bat | 38.565 | baseball glove | 40.780 |\n",
            "| skateboard    | 58.474 | surfboard    | 43.512 | tennis racket  | 52.613 |\n",
            "| bottle        | 44.289 | wine glass   | 39.766 | cup            | 47.769 |\n",
            "| fork          | 41.927 | knife        | 26.748 | spoon          | 21.343 |\n",
            "| bowl          | 44.505 | banana       | 27.732 | apple          | 21.735 |\n",
            "| sandwich      | 36.654 | orange       | 30.908 | broccoli       | 24.763 |\n",
            "| carrot        | 25.473 | hot dog      | 34.539 | pizza          | 54.644 |\n",
            "| donut         | 51.431 | cake         | 40.581 | chair          | 30.304 |\n",
            "| couch         | 42.850 | potted plant | 28.514 | bed            | 47.883 |\n",
            "| dining table  | 31.143 | toilet       | 65.346 | tv             | 60.449 |\n",
            "| laptop        | 63.218 | mouse        | 63.567 | remote         | 40.392 |\n",
            "| keyboard      | 52.342 | cell phone   | 39.867 | microwave      | 61.073 |\n",
            "| oven          | 36.082 | toaster      | 34.250 | sink           | 40.465 |\n",
            "| refrigerator  | 59.283 | book         | 16.998 | clock          | 54.235 |\n",
            "| vase          | 41.118 | scissors     | 35.154 | teddy bear     | 52.487 |\n",
            "| hair drier    | 4.950  | toothbrush   | 32.600 |                |        |\n",
            "\u001b[32m[04/30 15:56:11 d2.engine.defaults]: \u001b[0mEvaluation results for coco_2017_val in csv format:\n",
            "\u001b[32m[04/30 15:56:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/30 15:56:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 15:56:11 d2.evaluation.testing]: \u001b[0mcopypaste: 45.4079,63.9231,48.7010,28.7674,48.6927,58.4289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "faster_cascade_rcnn_ResNeSt_50 - evaluation results for coco_2017_val in csv format:\n",
        "\n",
        "Task\\metrics  | AP | AP50 | AP75 | APs | APm | APl |\n",
        "--------------|----|------|------|-----|-----|-----|\n",
        "**bbox**    | 45.4079 | 63.9231 | 48.7010 |28.7674 | 48.6927 | 58.4289"
      ],
      "metadata": {
        "id": "9FWvXdAsL_y4"
      },
      "id": "9FWvXdAsL_y4"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-ObjectDetection/faster_cascade_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x-3627ef78.pth"
      ],
      "metadata": {
        "id": "aYoEROmw9GYl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b382e78-0da3-47cd-a178-0110b265bdaa"
      },
      "id": "aYoEROmw9GYl",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command Line Args: Namespace(config_file='./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-ObjectDetection1/faster_cascade_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x-3627ef78.pth'], resume=False)\n",
            "\u001b[32m[04/30 18:51:58 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[04/30 18:51:59 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ----------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "numpy                   1.21.6\n",
            "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.5\n",
            "CUDA compiler           CUDA 11.1\n",
            "detectron2 arch flags   7.5\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.11.0+cu113 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           Yes\n",
            "GPU 0                   Tesla T4 (arch=7.5)\n",
            "Driver version          460.32.03\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.12.0+cu113 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
            "fvcore                  0.1.5.post20220414\n",
            "iopath                  0.1.9\n",
            "cv2                     4.1.2\n",
            "----------------------  ----------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.3\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.2\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "\u001b[32m[04/30 18:51:59 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-ObjectDetection1/faster_cascade_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x-3627ef78.pth'], resume=False)\n",
            "\u001b[32m[04/30 18:51:59 detectron2]: \u001b[0mContents of args.config_file=./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x.yaml:\n",
            "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186m../ResNest-Base-RCNN-FPN.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mhttps://s3.us-west-1.wasabisys.com/resnest/detectron/resnest101_detectron-486f69a8.pth\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m101\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mFastRCNNConvFCHead\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m123.68\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m116.779\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m103.939\u001b[39m]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m58.393\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.12\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.375\u001b[39m]\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\u001b[38;5;15m    \u001b[39m\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m(640, 800)\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mrange\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mRGB\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\n",
            "\u001b[32m[04/30 18:51:59 detectron2]: \u001b[0mRunning with full config:\n",
            "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRGB\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mpolygon\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrange\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnest_fpn_backbone\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGeneralizedRCNN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.68\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.779\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.939\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m58.393\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.12\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.375\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRPN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVG_DOWN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOTTLENECK_WIDTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEEP_STEM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m101\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_NUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFastRCNNConvFCHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_FED_LOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_SIGMOID_CE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./checkpoints/COCO-ObjectDetection1/faster_cascade_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x-3627ef78.pth\n",
            "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./output\n",
            "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR_END\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m90000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m60000\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m80000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\n",
            "\u001b[32m[04/30 18:51:59 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[04/30 18:51:59 d2.utils.env]: \u001b[0mUsing a generated random seed 59276840\n",
            "\u001b[32m[04/30 18:52:04 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(\n",
            "      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output2): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral3): Conv2d(\n",
            "      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output3): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral4): Conv2d(\n",
            "      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output4): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral5): Conv2d(\n",
            "      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output5): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNeSt(\n",
            "      (stem): BasicStem(\n",
            "        (conv1_1): Conv2d(\n",
            "          3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv1_2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv1_3): Conv2d(\n",
            "          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): CascadeROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): ModuleList(\n",
            "      (0): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (1): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (2): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): ModuleList(\n",
            "      (0): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (1): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (2): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/30 18:52:04 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from ./checkpoints/COCO-ObjectDetection1/faster_cascade_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x-3627ef78.pth ...\n",
            "\u001b[32m[04/30 18:52:11 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
            "| Names in Model                                  | Names in Checkpoint                                                                                                           | Shapes                                             |\n",
            "|:------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------|\n",
            "| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,128,1,1)               |\n",
            "| backbone.bottom_up.res2.0.conv2.bn0.*           | backbone.bottom_up.res2.0.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.0.conv2.bn1.*           | backbone.bottom_up.res2.0.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.0.conv2.conv.weight     | backbone.bottom_up.res2.0.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.0.conv2.fc1.*           | backbone.bottom_up.res2.0.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.0.conv2.fc2.*           | backbone.bottom_up.res2.0.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,128,1,1)          |\n",
            "| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.1.conv2.bn0.*           | backbone.bottom_up.res2.1.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.1.conv2.bn1.*           | backbone.bottom_up.res2.1.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.1.conv2.conv.weight     | backbone.bottom_up.res2.1.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.1.conv2.fc1.*           | backbone.bottom_up.res2.1.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.1.conv2.fc2.*           | backbone.bottom_up.res2.1.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.2.conv2.bn0.*           | backbone.bottom_up.res2.2.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.2.conv2.bn1.*           | backbone.bottom_up.res2.2.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.2.conv2.conv.weight     | backbone.bottom_up.res2.2.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.2.conv2.fc1.*           | backbone.bottom_up.res2.2.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.2.conv2.fc2.*           | backbone.bottom_up.res2.2.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv2.bn0.*           | backbone.bottom_up.res3.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.0.conv2.bn1.*           | backbone.bottom_up.res3.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.0.conv2.conv.weight     | backbone.bottom_up.res3.0.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.0.conv2.fc1.*           | backbone.bottom_up.res3.0.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.0.conv2.fc2.*           | backbone.bottom_up.res3.0.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv2.bn0.*           | backbone.bottom_up.res3.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.1.conv2.bn1.*           | backbone.bottom_up.res3.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.1.conv2.conv.weight     | backbone.bottom_up.res3.1.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.1.conv2.fc1.*           | backbone.bottom_up.res3.1.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.1.conv2.fc2.*           | backbone.bottom_up.res3.1.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv2.bn0.*           | backbone.bottom_up.res3.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.2.conv2.bn1.*           | backbone.bottom_up.res3.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.2.conv2.conv.weight     | backbone.bottom_up.res3.2.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.2.conv2.fc1.*           | backbone.bottom_up.res3.2.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.2.conv2.fc2.*           | backbone.bottom_up.res3.2.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv2.bn0.*           | backbone.bottom_up.res3.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.3.conv2.bn1.*           | backbone.bottom_up.res3.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.3.conv2.conv.weight     | backbone.bottom_up.res3.3.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.3.conv2.fc1.*           | backbone.bottom_up.res3.3.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.3.conv2.fc2.*           | backbone.bottom_up.res3.3.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv2.bn0.*           | backbone.bottom_up.res4.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.bn1.*           | backbone.bottom_up.res4.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.conv.weight     | backbone.bottom_up.res4.0.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.0.conv2.fc1.*           | backbone.bottom_up.res4.0.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv2.fc2.*           | backbone.bottom_up.res4.0.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.1.conv2.bn0.*           | backbone.bottom_up.res4.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.bn1.*           | backbone.bottom_up.res4.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.conv.weight     | backbone.bottom_up.res4.1.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.1.conv2.fc1.*           | backbone.bottom_up.res4.1.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv2.fc2.*           | backbone.bottom_up.res4.1.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.10.conv1.*              | backbone.bottom_up.res4.10.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.10.conv2.bn0.*          | backbone.bottom_up.res4.10.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.10.conv2.bn1.*          | backbone.bottom_up.res4.10.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.10.conv2.conv.weight    | backbone.bottom_up.res4.10.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.10.conv2.fc1.*          | backbone.bottom_up.res4.10.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.10.conv2.fc2.*          | backbone.bottom_up.res4.10.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.10.conv3.*              | backbone.bottom_up.res4.10.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.11.conv1.*              | backbone.bottom_up.res4.11.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.11.conv2.bn0.*          | backbone.bottom_up.res4.11.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.11.conv2.bn1.*          | backbone.bottom_up.res4.11.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.11.conv2.conv.weight    | backbone.bottom_up.res4.11.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.11.conv2.fc1.*          | backbone.bottom_up.res4.11.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.11.conv2.fc2.*          | backbone.bottom_up.res4.11.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.11.conv3.*              | backbone.bottom_up.res4.11.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.12.conv1.*              | backbone.bottom_up.res4.12.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.12.conv2.bn0.*          | backbone.bottom_up.res4.12.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.12.conv2.bn1.*          | backbone.bottom_up.res4.12.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.12.conv2.conv.weight    | backbone.bottom_up.res4.12.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.12.conv2.fc1.*          | backbone.bottom_up.res4.12.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.12.conv2.fc2.*          | backbone.bottom_up.res4.12.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.12.conv3.*              | backbone.bottom_up.res4.12.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.13.conv1.*              | backbone.bottom_up.res4.13.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.13.conv2.bn0.*          | backbone.bottom_up.res4.13.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.13.conv2.bn1.*          | backbone.bottom_up.res4.13.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.13.conv2.conv.weight    | backbone.bottom_up.res4.13.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.13.conv2.fc1.*          | backbone.bottom_up.res4.13.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.13.conv2.fc2.*          | backbone.bottom_up.res4.13.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.13.conv3.*              | backbone.bottom_up.res4.13.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.14.conv1.*              | backbone.bottom_up.res4.14.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.14.conv2.bn0.*          | backbone.bottom_up.res4.14.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.14.conv2.bn1.*          | backbone.bottom_up.res4.14.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.14.conv2.conv.weight    | backbone.bottom_up.res4.14.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.14.conv2.fc1.*          | backbone.bottom_up.res4.14.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.14.conv2.fc2.*          | backbone.bottom_up.res4.14.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.14.conv3.*              | backbone.bottom_up.res4.14.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.15.conv1.*              | backbone.bottom_up.res4.15.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.15.conv2.bn0.*          | backbone.bottom_up.res4.15.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.15.conv2.bn1.*          | backbone.bottom_up.res4.15.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.15.conv2.conv.weight    | backbone.bottom_up.res4.15.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.15.conv2.fc1.*          | backbone.bottom_up.res4.15.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.15.conv2.fc2.*          | backbone.bottom_up.res4.15.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.15.conv3.*              | backbone.bottom_up.res4.15.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.16.conv1.*              | backbone.bottom_up.res4.16.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.16.conv2.bn0.*          | backbone.bottom_up.res4.16.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.16.conv2.bn1.*          | backbone.bottom_up.res4.16.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.16.conv2.conv.weight    | backbone.bottom_up.res4.16.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.16.conv2.fc1.*          | backbone.bottom_up.res4.16.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.16.conv2.fc2.*          | backbone.bottom_up.res4.16.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.16.conv3.*              | backbone.bottom_up.res4.16.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.17.conv1.*              | backbone.bottom_up.res4.17.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.17.conv2.bn0.*          | backbone.bottom_up.res4.17.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.17.conv2.bn1.*          | backbone.bottom_up.res4.17.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.17.conv2.conv.weight    | backbone.bottom_up.res4.17.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.17.conv2.fc1.*          | backbone.bottom_up.res4.17.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.17.conv2.fc2.*          | backbone.bottom_up.res4.17.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.17.conv3.*              | backbone.bottom_up.res4.17.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.18.conv1.*              | backbone.bottom_up.res4.18.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.18.conv2.bn0.*          | backbone.bottom_up.res4.18.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.18.conv2.bn1.*          | backbone.bottom_up.res4.18.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.18.conv2.conv.weight    | backbone.bottom_up.res4.18.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.18.conv2.fc1.*          | backbone.bottom_up.res4.18.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.18.conv2.fc2.*          | backbone.bottom_up.res4.18.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.18.conv3.*              | backbone.bottom_up.res4.18.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.19.conv1.*              | backbone.bottom_up.res4.19.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.19.conv2.bn0.*          | backbone.bottom_up.res4.19.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.19.conv2.bn1.*          | backbone.bottom_up.res4.19.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.19.conv2.conv.weight    | backbone.bottom_up.res4.19.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.19.conv2.fc1.*          | backbone.bottom_up.res4.19.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.19.conv2.fc2.*          | backbone.bottom_up.res4.19.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.19.conv3.*              | backbone.bottom_up.res4.19.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.2.conv2.bn0.*           | backbone.bottom_up.res4.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.bn1.*           | backbone.bottom_up.res4.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.conv.weight     | backbone.bottom_up.res4.2.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.2.conv2.fc1.*           | backbone.bottom_up.res4.2.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv2.fc2.*           | backbone.bottom_up.res4.2.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.20.conv1.*              | backbone.bottom_up.res4.20.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.20.conv2.bn0.*          | backbone.bottom_up.res4.20.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.20.conv2.bn1.*          | backbone.bottom_up.res4.20.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.20.conv2.conv.weight    | backbone.bottom_up.res4.20.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.20.conv2.fc1.*          | backbone.bottom_up.res4.20.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.20.conv2.fc2.*          | backbone.bottom_up.res4.20.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.20.conv3.*              | backbone.bottom_up.res4.20.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.21.conv1.*              | backbone.bottom_up.res4.21.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.21.conv2.bn0.*          | backbone.bottom_up.res4.21.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.21.conv2.bn1.*          | backbone.bottom_up.res4.21.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.21.conv2.conv.weight    | backbone.bottom_up.res4.21.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.21.conv2.fc1.*          | backbone.bottom_up.res4.21.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.21.conv2.fc2.*          | backbone.bottom_up.res4.21.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.21.conv3.*              | backbone.bottom_up.res4.21.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.22.conv1.*              | backbone.bottom_up.res4.22.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.22.conv2.bn0.*          | backbone.bottom_up.res4.22.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.22.conv2.bn1.*          | backbone.bottom_up.res4.22.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.22.conv2.conv.weight    | backbone.bottom_up.res4.22.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.22.conv2.fc1.*          | backbone.bottom_up.res4.22.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.22.conv2.fc2.*          | backbone.bottom_up.res4.22.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.22.conv3.*              | backbone.bottom_up.res4.22.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.3.conv2.bn0.*           | backbone.bottom_up.res4.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.bn1.*           | backbone.bottom_up.res4.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.conv.weight     | backbone.bottom_up.res4.3.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.3.conv2.fc1.*           | backbone.bottom_up.res4.3.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv2.fc2.*           | backbone.bottom_up.res4.3.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.4.conv2.bn0.*           | backbone.bottom_up.res4.4.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.bn1.*           | backbone.bottom_up.res4.4.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.conv.weight     | backbone.bottom_up.res4.4.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.4.conv2.fc1.*           | backbone.bottom_up.res4.4.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv2.fc2.*           | backbone.bottom_up.res4.4.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.5.conv2.bn0.*           | backbone.bottom_up.res4.5.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.bn1.*           | backbone.bottom_up.res4.5.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.conv.weight     | backbone.bottom_up.res4.5.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.5.conv2.fc1.*           | backbone.bottom_up.res4.5.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv2.fc2.*           | backbone.bottom_up.res4.5.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.6.conv1.*               | backbone.bottom_up.res4.6.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.6.conv2.bn0.*           | backbone.bottom_up.res4.6.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.6.conv2.bn1.*           | backbone.bottom_up.res4.6.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.6.conv2.conv.weight     | backbone.bottom_up.res4.6.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.6.conv2.fc1.*           | backbone.bottom_up.res4.6.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.6.conv2.fc2.*           | backbone.bottom_up.res4.6.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.6.conv3.*               | backbone.bottom_up.res4.6.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.7.conv1.*               | backbone.bottom_up.res4.7.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.7.conv2.bn0.*           | backbone.bottom_up.res4.7.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.7.conv2.bn1.*           | backbone.bottom_up.res4.7.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.7.conv2.conv.weight     | backbone.bottom_up.res4.7.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.7.conv2.fc1.*           | backbone.bottom_up.res4.7.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.7.conv2.fc2.*           | backbone.bottom_up.res4.7.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.7.conv3.*               | backbone.bottom_up.res4.7.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.8.conv1.*               | backbone.bottom_up.res4.8.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.8.conv2.bn0.*           | backbone.bottom_up.res4.8.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.8.conv2.bn1.*           | backbone.bottom_up.res4.8.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.8.conv2.conv.weight     | backbone.bottom_up.res4.8.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.8.conv2.fc1.*           | backbone.bottom_up.res4.8.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.8.conv2.fc2.*           | backbone.bottom_up.res4.8.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.8.conv3.*               | backbone.bottom_up.res4.8.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.9.conv1.*               | backbone.bottom_up.res4.9.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.9.conv2.bn0.*           | backbone.bottom_up.res4.9.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.9.conv2.bn1.*           | backbone.bottom_up.res4.9.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.9.conv2.conv.weight     | backbone.bottom_up.res4.9.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.9.conv2.fc1.*           | backbone.bottom_up.res4.9.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.9.conv2.fc2.*           | backbone.bottom_up.res4.9.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.9.conv3.*               | backbone.bottom_up.res4.9.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| backbone.bottom_up.res5.0.conv2.bn0.*           | backbone.bottom_up.res5.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.0.conv2.bn1.*           | backbone.bottom_up.res5.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.0.conv2.conv.weight     | backbone.bottom_up.res5.0.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.0.conv2.fc1.*           | backbone.bottom_up.res5.0.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.0.conv2.fc2.*           | backbone.bottom_up.res5.0.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.1.conv2.bn0.*           | backbone.bottom_up.res5.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.1.conv2.bn1.*           | backbone.bottom_up.res5.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.1.conv2.conv.weight     | backbone.bottom_up.res5.1.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.1.conv2.fc1.*           | backbone.bottom_up.res5.1.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.1.conv2.fc2.*           | backbone.bottom_up.res5.1.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.2.conv2.bn0.*           | backbone.bottom_up.res5.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.2.conv2.bn1.*           | backbone.bottom_up.res5.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.2.conv2.conv.weight     | backbone.bottom_up.res5.2.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.2.conv2.fc1.*           | backbone.bottom_up.res5.2.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.2.conv2.fc2.*           | backbone.bottom_up.res5.2.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.stem.conv1_1.*               | backbone.bottom_up.stem.conv1_1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,3,3,3)                 |\n",
            "| backbone.bottom_up.stem.conv1_2.*               | backbone.bottom_up.stem.conv1_2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |\n",
            "| backbone.bottom_up.stem.conv1_3.*               | backbone.bottom_up.stem.conv1_3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,64,3,3)           |\n",
            "| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,2048,1,1)      |\n",
            "| backbone.fpn_output2.*                          | backbone.fpn_output2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output3.*                          | backbone.fpn_output3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output4.*                          | backbone.fpn_output4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output5.*                          | backbone.fpn_output5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                                                       | (12,) (12,256,1,1)                                 |\n",
            "| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                                                | (256,) (256,256,3,3)                               |\n",
            "| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                                                   | (3,) (3,256,1,1)                                   |\n",
            "| roi_heads.box_head.0.conv1.*                    | roi_heads.box_head.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv2.*                    | roi_heads.box_head.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv3.*                    | roi_heads.box_head.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv4.*                    | roi_heads.box_head.0.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.fc1.*                      | roi_heads.box_head.0.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_head.1.conv1.*                    | roi_heads.box_head.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv2.*                    | roi_heads.box_head.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv3.*                    | roi_heads.box_head.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv4.*                    | roi_heads.box_head.1.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.fc1.*                      | roi_heads.box_head.1.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_head.2.conv1.*                    | roi_heads.box_head.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv2.*                    | roi_heads.box_head.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv3.*                    | roi_heads.box_head.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv4.*                    | roi_heads.box_head.2.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.fc1.*                      | roi_heads.box_head.2.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_predictor.0.bbox_pred.*           | roi_heads.box_predictor.0.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.0.cls_score.*           | roi_heads.box_predictor.0.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.box_predictor.1.bbox_pred.*           | roi_heads.box_predictor.1.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.1.cls_score.*           | roi_heads.box_predictor.1.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.box_predictor.2.bbox_pred.*           | roi_heads.box_predictor.2.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.2.cls_score.*           | roi_heads.box_predictor.2.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "\u001b[32m[04/30 18:52:12 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json\n",
            "\u001b[32m[04/30 18:52:12 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n",
            "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
            "|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\n",
            "|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\n",
            "|     train     | 190          |    truck     | 414          |     boat      | 424          |\n",
            "| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\n",
            "| parking meter | 60           |    bench     | 411          |     bird      | 427          |\n",
            "|      cat      | 202          |     dog      | 218          |     horse     | 272          |\n",
            "|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\n",
            "|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\n",
            "|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\n",
            "|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\n",
            "|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\n",
            "|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\n",
            "|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\n",
            "|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\n",
            "|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\n",
            "|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\n",
            "|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\n",
            "|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\n",
            "|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\n",
            "|     couch     | 261          | potted plant | 342          |      bed      | 163          |\n",
            "| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\n",
            "|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\n",
            "|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\n",
            "|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\n",
            "| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\n",
            "|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\n",
            "|  hair drier   | 11           |  toothbrush  | 57           |               |              |\n",
            "|     total     | 36335        |              |              |               |              |\u001b[0m\n",
            "\u001b[32m[04/30 18:52:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/30 18:52:12 d2.data.common]: \u001b[0mSerializing 5000 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/30 18:52:13 d2.data.common]: \u001b[0mSerialized dataset takes 19.10 MiB\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[32m[04/30 18:52:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 5000 batches\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m[04/30 18:52:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/5000. Dataloading: 0.0014 s/iter. Inference: 0.3991 s/iter. Eval: 0.0002 s/iter. Total: 0.4007 s/iter. ETA=0:33:19\n",
            "\u001b[32m[04/30 18:52:24 d2.evaluation.evaluator]: \u001b[0mInference done 24/5000. Dataloading: 0.0016 s/iter. Inference: 0.3990 s/iter. Eval: 0.0002 s/iter. Total: 0.4009 s/iter. ETA=0:33:15\n",
            "\u001b[32m[04/30 18:52:29 d2.evaluation.evaluator]: \u001b[0mInference done 37/5000. Dataloading: 0.0017 s/iter. Inference: 0.4023 s/iter. Eval: 0.0002 s/iter. Total: 0.4043 s/iter. ETA=0:33:26\n",
            "\u001b[32m[04/30 18:52:34 d2.evaluation.evaluator]: \u001b[0mInference done 50/5000. Dataloading: 0.0018 s/iter. Inference: 0.4019 s/iter. Eval: 0.0002 s/iter. Total: 0.4040 s/iter. ETA=0:33:19\n",
            "\u001b[32m[04/30 18:52:39 d2.evaluation.evaluator]: \u001b[0mInference done 62/5000. Dataloading: 0.0018 s/iter. Inference: 0.4046 s/iter. Eval: 0.0002 s/iter. Total: 0.4067 s/iter. ETA=0:33:28\n",
            "\u001b[32m[04/30 18:52:44 d2.evaluation.evaluator]: \u001b[0mInference done 75/5000. Dataloading: 0.0019 s/iter. Inference: 0.4056 s/iter. Eval: 0.0002 s/iter. Total: 0.4077 s/iter. ETA=0:33:28\n",
            "\u001b[32m[04/30 18:52:50 d2.evaluation.evaluator]: \u001b[0mInference done 88/5000. Dataloading: 0.0018 s/iter. Inference: 0.4051 s/iter. Eval: 0.0002 s/iter. Total: 0.4073 s/iter. ETA=0:33:20\n",
            "\u001b[32m[04/30 18:52:55 d2.evaluation.evaluator]: \u001b[0mInference done 101/5000. Dataloading: 0.0019 s/iter. Inference: 0.4050 s/iter. Eval: 0.0002 s/iter. Total: 0.4071 s/iter. ETA=0:33:14\n",
            "\u001b[32m[04/30 18:53:00 d2.evaluation.evaluator]: \u001b[0mInference done 114/5000. Dataloading: 0.0019 s/iter. Inference: 0.4051 s/iter. Eval: 0.0002 s/iter. Total: 0.4073 s/iter. ETA=0:33:09\n",
            "\u001b[32m[04/30 18:53:05 d2.evaluation.evaluator]: \u001b[0mInference done 126/5000. Dataloading: 0.0019 s/iter. Inference: 0.4060 s/iter. Eval: 0.0002 s/iter. Total: 0.4082 s/iter. ETA=0:33:09\n",
            "\u001b[32m[04/30 18:53:10 d2.evaluation.evaluator]: \u001b[0mInference done 138/5000. Dataloading: 0.0019 s/iter. Inference: 0.4072 s/iter. Eval: 0.0002 s/iter. Total: 0.4094 s/iter. ETA=0:33:10\n",
            "\u001b[32m[04/30 18:53:15 d2.evaluation.evaluator]: \u001b[0mInference done 150/5000. Dataloading: 0.0019 s/iter. Inference: 0.4081 s/iter. Eval: 0.0002 s/iter. Total: 0.4104 s/iter. ETA=0:33:10\n",
            "\u001b[32m[04/30 18:53:20 d2.evaluation.evaluator]: \u001b[0mInference done 162/5000. Dataloading: 0.0019 s/iter. Inference: 0.4090 s/iter. Eval: 0.0002 s/iter. Total: 0.4112 s/iter. ETA=0:33:09\n",
            "\u001b[32m[04/30 18:53:26 d2.evaluation.evaluator]: \u001b[0mInference done 175/5000. Dataloading: 0.0019 s/iter. Inference: 0.4091 s/iter. Eval: 0.0002 s/iter. Total: 0.4114 s/iter. ETA=0:33:04\n",
            "\u001b[32m[04/30 18:53:31 d2.evaluation.evaluator]: \u001b[0mInference done 187/5000. Dataloading: 0.0019 s/iter. Inference: 0.4097 s/iter. Eval: 0.0002 s/iter. Total: 0.4119 s/iter. ETA=0:33:02\n",
            "\u001b[32m[04/30 18:53:36 d2.evaluation.evaluator]: \u001b[0mInference done 199/5000. Dataloading: 0.0019 s/iter. Inference: 0.4103 s/iter. Eval: 0.0002 s/iter. Total: 0.4126 s/iter. ETA=0:33:00\n",
            "\u001b[32m[04/30 18:53:41 d2.evaluation.evaluator]: \u001b[0mInference done 211/5000. Dataloading: 0.0019 s/iter. Inference: 0.4110 s/iter. Eval: 0.0002 s/iter. Total: 0.4132 s/iter. ETA=0:32:58\n",
            "\u001b[32m[04/30 18:53:46 d2.evaluation.evaluator]: \u001b[0mInference done 224/5000. Dataloading: 0.0019 s/iter. Inference: 0.4113 s/iter. Eval: 0.0002 s/iter. Total: 0.4135 s/iter. ETA=0:32:54\n",
            "\u001b[32m[04/30 18:53:52 d2.evaluation.evaluator]: \u001b[0mInference done 236/5000. Dataloading: 0.0019 s/iter. Inference: 0.4120 s/iter. Eval: 0.0002 s/iter. Total: 0.4143 s/iter. ETA=0:32:53\n",
            "\u001b[32m[04/30 18:53:57 d2.evaluation.evaluator]: \u001b[0mInference done 248/5000. Dataloading: 0.0019 s/iter. Inference: 0.4127 s/iter. Eval: 0.0002 s/iter. Total: 0.4150 s/iter. ETA=0:32:51\n",
            "\u001b[32m[04/30 18:54:02 d2.evaluation.evaluator]: \u001b[0mInference done 260/5000. Dataloading: 0.0019 s/iter. Inference: 0.4134 s/iter. Eval: 0.0002 s/iter. Total: 0.4156 s/iter. ETA=0:32:50\n",
            "\u001b[32m[04/30 18:54:07 d2.evaluation.evaluator]: \u001b[0mInference done 272/5000. Dataloading: 0.0019 s/iter. Inference: 0.4135 s/iter. Eval: 0.0002 s/iter. Total: 0.4157 s/iter. ETA=0:32:45\n",
            "\u001b[32m[04/30 18:54:12 d2.evaluation.evaluator]: \u001b[0mInference done 284/5000. Dataloading: 0.0019 s/iter. Inference: 0.4140 s/iter. Eval: 0.0002 s/iter. Total: 0.4163 s/iter. ETA=0:32:43\n",
            "\u001b[32m[04/30 18:54:17 d2.evaluation.evaluator]: \u001b[0mInference done 296/5000. Dataloading: 0.0019 s/iter. Inference: 0.4146 s/iter. Eval: 0.0002 s/iter. Total: 0.4168 s/iter. ETA=0:32:40\n",
            "\u001b[32m[04/30 18:54:22 d2.evaluation.evaluator]: \u001b[0mInference done 308/5000. Dataloading: 0.0019 s/iter. Inference: 0.4151 s/iter. Eval: 0.0002 s/iter. Total: 0.4174 s/iter. ETA=0:32:38\n",
            "\u001b[32m[04/30 18:54:28 d2.evaluation.evaluator]: \u001b[0mInference done 320/5000. Dataloading: 0.0019 s/iter. Inference: 0.4156 s/iter. Eval: 0.0002 s/iter. Total: 0.4178 s/iter. ETA=0:32:35\n",
            "\u001b[32m[04/30 18:54:33 d2.evaluation.evaluator]: \u001b[0mInference done 332/5000. Dataloading: 0.0019 s/iter. Inference: 0.4162 s/iter. Eval: 0.0002 s/iter. Total: 0.4184 s/iter. ETA=0:32:33\n",
            "\u001b[32m[04/30 18:54:38 d2.evaluation.evaluator]: \u001b[0mInference done 344/5000. Dataloading: 0.0019 s/iter. Inference: 0.4167 s/iter. Eval: 0.0002 s/iter. Total: 0.4190 s/iter. ETA=0:32:30\n",
            "\u001b[32m[04/30 18:54:43 d2.evaluation.evaluator]: \u001b[0mInference done 356/5000. Dataloading: 0.0019 s/iter. Inference: 0.4174 s/iter. Eval: 0.0002 s/iter. Total: 0.4197 s/iter. ETA=0:32:28\n",
            "\u001b[32m[04/30 18:54:48 d2.evaluation.evaluator]: \u001b[0mInference done 368/5000. Dataloading: 0.0019 s/iter. Inference: 0.4178 s/iter. Eval: 0.0002 s/iter. Total: 0.4201 s/iter. ETA=0:32:25\n",
            "\u001b[32m[04/30 18:54:54 d2.evaluation.evaluator]: \u001b[0mInference done 380/5000. Dataloading: 0.0019 s/iter. Inference: 0.4182 s/iter. Eval: 0.0002 s/iter. Total: 0.4205 s/iter. ETA=0:32:22\n",
            "\u001b[32m[04/30 18:54:59 d2.evaluation.evaluator]: \u001b[0mInference done 392/5000. Dataloading: 0.0019 s/iter. Inference: 0.4185 s/iter. Eval: 0.0002 s/iter. Total: 0.4207 s/iter. ETA=0:32:18\n",
            "\u001b[32m[04/30 18:55:04 d2.evaluation.evaluator]: \u001b[0mInference done 404/5000. Dataloading: 0.0019 s/iter. Inference: 0.4189 s/iter. Eval: 0.0002 s/iter. Total: 0.4211 s/iter. ETA=0:32:15\n",
            "\u001b[32m[04/30 18:55:09 d2.evaluation.evaluator]: \u001b[0mInference done 416/5000. Dataloading: 0.0019 s/iter. Inference: 0.4197 s/iter. Eval: 0.0002 s/iter. Total: 0.4219 s/iter. ETA=0:32:14\n",
            "\u001b[32m[04/30 18:55:14 d2.evaluation.evaluator]: \u001b[0mInference done 428/5000. Dataloading: 0.0019 s/iter. Inference: 0.4199 s/iter. Eval: 0.0002 s/iter. Total: 0.4221 s/iter. ETA=0:32:09\n",
            "\u001b[32m[04/30 18:55:20 d2.evaluation.evaluator]: \u001b[0mInference done 440/5000. Dataloading: 0.0019 s/iter. Inference: 0.4204 s/iter. Eval: 0.0002 s/iter. Total: 0.4227 s/iter. ETA=0:32:07\n",
            "\u001b[32m[04/30 18:55:25 d2.evaluation.evaluator]: \u001b[0mInference done 452/5000. Dataloading: 0.0019 s/iter. Inference: 0.4207 s/iter. Eval: 0.0002 s/iter. Total: 0.4229 s/iter. ETA=0:32:03\n",
            "\u001b[32m[04/30 18:55:30 d2.evaluation.evaluator]: \u001b[0mInference done 464/5000. Dataloading: 0.0019 s/iter. Inference: 0.4212 s/iter. Eval: 0.0002 s/iter. Total: 0.4235 s/iter. ETA=0:32:00\n",
            "\u001b[32m[04/30 18:55:36 d2.evaluation.evaluator]: \u001b[0mInference done 476/5000. Dataloading: 0.0019 s/iter. Inference: 0.4217 s/iter. Eval: 0.0002 s/iter. Total: 0.4240 s/iter. ETA=0:31:58\n",
            "\u001b[32m[04/30 18:55:41 d2.evaluation.evaluator]: \u001b[0mInference done 488/5000. Dataloading: 0.0019 s/iter. Inference: 0.4221 s/iter. Eval: 0.0002 s/iter. Total: 0.4244 s/iter. ETA=0:31:54\n",
            "\u001b[32m[04/30 18:55:46 d2.evaluation.evaluator]: \u001b[0mInference done 500/5000. Dataloading: 0.0019 s/iter. Inference: 0.4224 s/iter. Eval: 0.0002 s/iter. Total: 0.4246 s/iter. ETA=0:31:50\n",
            "\u001b[32m[04/30 18:55:51 d2.evaluation.evaluator]: \u001b[0mInference done 512/5000. Dataloading: 0.0019 s/iter. Inference: 0.4226 s/iter. Eval: 0.0002 s/iter. Total: 0.4248 s/iter. ETA=0:31:46\n",
            "\u001b[32m[04/30 18:55:57 d2.evaluation.evaluator]: \u001b[0mInference done 524/5000. Dataloading: 0.0019 s/iter. Inference: 0.4229 s/iter. Eval: 0.0002 s/iter. Total: 0.4251 s/iter. ETA=0:31:42\n",
            "\u001b[32m[04/30 18:56:02 d2.evaluation.evaluator]: \u001b[0mInference done 536/5000. Dataloading: 0.0019 s/iter. Inference: 0.4232 s/iter. Eval: 0.0002 s/iter. Total: 0.4255 s/iter. ETA=0:31:39\n",
            "\u001b[32m[04/30 18:56:07 d2.evaluation.evaluator]: \u001b[0mInference done 548/5000. Dataloading: 0.0019 s/iter. Inference: 0.4236 s/iter. Eval: 0.0002 s/iter. Total: 0.4258 s/iter. ETA=0:31:35\n",
            "\u001b[32m[04/30 18:56:12 d2.evaluation.evaluator]: \u001b[0mInference done 560/5000. Dataloading: 0.0019 s/iter. Inference: 0.4238 s/iter. Eval: 0.0002 s/iter. Total: 0.4261 s/iter. ETA=0:31:31\n",
            "\u001b[32m[04/30 18:56:18 d2.evaluation.evaluator]: \u001b[0mInference done 572/5000. Dataloading: 0.0019 s/iter. Inference: 0.4242 s/iter. Eval: 0.0002 s/iter. Total: 0.4265 s/iter. ETA=0:31:28\n",
            "\u001b[32m[04/30 18:56:23 d2.evaluation.evaluator]: \u001b[0mInference done 584/5000. Dataloading: 0.0019 s/iter. Inference: 0.4245 s/iter. Eval: 0.0002 s/iter. Total: 0.4267 s/iter. ETA=0:31:24\n",
            "\u001b[32m[04/30 18:56:28 d2.evaluation.evaluator]: \u001b[0mInference done 596/5000. Dataloading: 0.0019 s/iter. Inference: 0.4247 s/iter. Eval: 0.0002 s/iter. Total: 0.4269 s/iter. ETA=0:31:20\n",
            "\u001b[32m[04/30 18:56:34 d2.evaluation.evaluator]: \u001b[0mInference done 608/5000. Dataloading: 0.0019 s/iter. Inference: 0.4250 s/iter. Eval: 0.0002 s/iter. Total: 0.4273 s/iter. ETA=0:31:16\n",
            "\u001b[32m[04/30 18:56:39 d2.evaluation.evaluator]: \u001b[0mInference done 620/5000. Dataloading: 0.0019 s/iter. Inference: 0.4254 s/iter. Eval: 0.0002 s/iter. Total: 0.4277 s/iter. ETA=0:31:13\n",
            "\u001b[32m[04/30 18:56:44 d2.evaluation.evaluator]: \u001b[0mInference done 632/5000. Dataloading: 0.0019 s/iter. Inference: 0.4256 s/iter. Eval: 0.0002 s/iter. Total: 0.4279 s/iter. ETA=0:31:08\n",
            "\u001b[32m[04/30 18:56:49 d2.evaluation.evaluator]: \u001b[0mInference done 644/5000. Dataloading: 0.0019 s/iter. Inference: 0.4259 s/iter. Eval: 0.0002 s/iter. Total: 0.4281 s/iter. ETA=0:31:04\n",
            "\u001b[32m[04/30 18:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 656/5000. Dataloading: 0.0019 s/iter. Inference: 0.4261 s/iter. Eval: 0.0002 s/iter. Total: 0.4284 s/iter. ETA=0:31:00\n",
            "\u001b[32m[04/30 18:57:00 d2.evaluation.evaluator]: \u001b[0mInference done 668/5000. Dataloading: 0.0019 s/iter. Inference: 0.4263 s/iter. Eval: 0.0002 s/iter. Total: 0.4286 s/iter. ETA=0:30:56\n",
            "\u001b[32m[04/30 18:57:05 d2.evaluation.evaluator]: \u001b[0mInference done 680/5000. Dataloading: 0.0019 s/iter. Inference: 0.4267 s/iter. Eval: 0.0002 s/iter. Total: 0.4289 s/iter. ETA=0:30:53\n",
            "\u001b[32m[04/30 18:57:11 d2.evaluation.evaluator]: \u001b[0mInference done 692/5000. Dataloading: 0.0019 s/iter. Inference: 0.4270 s/iter. Eval: 0.0002 s/iter. Total: 0.4292 s/iter. ETA=0:30:49\n",
            "\u001b[32m[04/30 18:57:16 d2.evaluation.evaluator]: \u001b[0mInference done 704/5000. Dataloading: 0.0019 s/iter. Inference: 0.4273 s/iter. Eval: 0.0002 s/iter. Total: 0.4295 s/iter. ETA=0:30:45\n",
            "\u001b[32m[04/30 18:57:22 d2.evaluation.evaluator]: \u001b[0mInference done 716/5000. Dataloading: 0.0019 s/iter. Inference: 0.4276 s/iter. Eval: 0.0002 s/iter. Total: 0.4298 s/iter. ETA=0:30:41\n",
            "\u001b[32m[04/30 18:57:27 d2.evaluation.evaluator]: \u001b[0mInference done 728/5000. Dataloading: 0.0019 s/iter. Inference: 0.4278 s/iter. Eval: 0.0002 s/iter. Total: 0.4301 s/iter. ETA=0:30:37\n",
            "\u001b[32m[04/30 18:57:32 d2.evaluation.evaluator]: \u001b[0mInference done 740/5000. Dataloading: 0.0019 s/iter. Inference: 0.4281 s/iter. Eval: 0.0002 s/iter. Total: 0.4303 s/iter. ETA=0:30:33\n",
            "\u001b[32m[04/30 18:57:37 d2.evaluation.evaluator]: \u001b[0mInference done 752/5000. Dataloading: 0.0019 s/iter. Inference: 0.4283 s/iter. Eval: 0.0002 s/iter. Total: 0.4305 s/iter. ETA=0:30:28\n",
            "\u001b[32m[04/30 18:57:43 d2.evaluation.evaluator]: \u001b[0mInference done 764/5000. Dataloading: 0.0019 s/iter. Inference: 0.4285 s/iter. Eval: 0.0002 s/iter. Total: 0.4307 s/iter. ETA=0:30:24\n",
            "\u001b[32m[04/30 18:57:48 d2.evaluation.evaluator]: \u001b[0mInference done 776/5000. Dataloading: 0.0019 s/iter. Inference: 0.4288 s/iter. Eval: 0.0002 s/iter. Total: 0.4310 s/iter. ETA=0:30:20\n",
            "\u001b[32m[04/30 18:57:54 d2.evaluation.evaluator]: \u001b[0mInference done 788/5000. Dataloading: 0.0019 s/iter. Inference: 0.4290 s/iter. Eval: 0.0002 s/iter. Total: 0.4312 s/iter. ETA=0:30:16\n",
            "\u001b[32m[04/30 18:57:59 d2.evaluation.evaluator]: \u001b[0mInference done 800/5000. Dataloading: 0.0019 s/iter. Inference: 0.4292 s/iter. Eval: 0.0002 s/iter. Total: 0.4314 s/iter. ETA=0:30:11\n",
            "\u001b[32m[04/30 18:58:04 d2.evaluation.evaluator]: \u001b[0mInference done 812/5000. Dataloading: 0.0019 s/iter. Inference: 0.4294 s/iter. Eval: 0.0002 s/iter. Total: 0.4317 s/iter. ETA=0:30:07\n",
            "\u001b[32m[04/30 18:58:10 d2.evaluation.evaluator]: \u001b[0mInference done 824/5000. Dataloading: 0.0019 s/iter. Inference: 0.4296 s/iter. Eval: 0.0002 s/iter. Total: 0.4318 s/iter. ETA=0:30:03\n",
            "\u001b[32m[04/30 18:58:15 d2.evaluation.evaluator]: \u001b[0mInference done 836/5000. Dataloading: 0.0019 s/iter. Inference: 0.4297 s/iter. Eval: 0.0002 s/iter. Total: 0.4320 s/iter. ETA=0:29:58\n",
            "\u001b[32m[04/30 18:58:20 d2.evaluation.evaluator]: \u001b[0mInference done 848/5000. Dataloading: 0.0019 s/iter. Inference: 0.4300 s/iter. Eval: 0.0002 s/iter. Total: 0.4322 s/iter. ETA=0:29:54\n",
            "\u001b[32m[04/30 18:58:26 d2.evaluation.evaluator]: \u001b[0mInference done 860/5000. Dataloading: 0.0019 s/iter. Inference: 0.4302 s/iter. Eval: 0.0002 s/iter. Total: 0.4324 s/iter. ETA=0:29:50\n",
            "\u001b[32m[04/30 18:58:31 d2.evaluation.evaluator]: \u001b[0mInference done 872/5000. Dataloading: 0.0019 s/iter. Inference: 0.4304 s/iter. Eval: 0.0002 s/iter. Total: 0.4327 s/iter. ETA=0:29:46\n",
            "\u001b[32m[04/30 18:58:36 d2.evaluation.evaluator]: \u001b[0mInference done 884/5000. Dataloading: 0.0019 s/iter. Inference: 0.4306 s/iter. Eval: 0.0002 s/iter. Total: 0.4328 s/iter. ETA=0:29:41\n",
            "\u001b[32m[04/30 18:58:42 d2.evaluation.evaluator]: \u001b[0mInference done 896/5000. Dataloading: 0.0019 s/iter. Inference: 0.4307 s/iter. Eval: 0.0002 s/iter. Total: 0.4330 s/iter. ETA=0:29:36\n",
            "\u001b[32m[04/30 18:58:47 d2.evaluation.evaluator]: \u001b[0mInference done 908/5000. Dataloading: 0.0019 s/iter. Inference: 0.4308 s/iter. Eval: 0.0002 s/iter. Total: 0.4330 s/iter. ETA=0:29:31\n",
            "\u001b[32m[04/30 18:58:52 d2.evaluation.evaluator]: \u001b[0mInference done 920/5000. Dataloading: 0.0019 s/iter. Inference: 0.4310 s/iter. Eval: 0.0002 s/iter. Total: 0.4332 s/iter. ETA=0:29:27\n",
            "\u001b[32m[04/30 18:58:58 d2.evaluation.evaluator]: \u001b[0mInference done 932/5000. Dataloading: 0.0019 s/iter. Inference: 0.4311 s/iter. Eval: 0.0002 s/iter. Total: 0.4334 s/iter. ETA=0:29:22\n",
            "\u001b[32m[04/30 18:59:03 d2.evaluation.evaluator]: \u001b[0mInference done 944/5000. Dataloading: 0.0019 s/iter. Inference: 0.4314 s/iter. Eval: 0.0002 s/iter. Total: 0.4336 s/iter. ETA=0:29:18\n",
            "\u001b[32m[04/30 18:59:08 d2.evaluation.evaluator]: \u001b[0mInference done 956/5000. Dataloading: 0.0019 s/iter. Inference: 0.4315 s/iter. Eval: 0.0002 s/iter. Total: 0.4338 s/iter. ETA=0:29:14\n",
            "\u001b[32m[04/30 18:59:14 d2.evaluation.evaluator]: \u001b[0mInference done 968/5000. Dataloading: 0.0019 s/iter. Inference: 0.4317 s/iter. Eval: 0.0002 s/iter. Total: 0.4340 s/iter. ETA=0:29:09\n",
            "\u001b[32m[04/30 18:59:19 d2.evaluation.evaluator]: \u001b[0mInference done 980/5000. Dataloading: 0.0019 s/iter. Inference: 0.4318 s/iter. Eval: 0.0002 s/iter. Total: 0.4340 s/iter. ETA=0:29:04\n",
            "\u001b[32m[04/30 18:59:24 d2.evaluation.evaluator]: \u001b[0mInference done 992/5000. Dataloading: 0.0019 s/iter. Inference: 0.4320 s/iter. Eval: 0.0002 s/iter. Total: 0.4342 s/iter. ETA=0:29:00\n",
            "\u001b[32m[04/30 18:59:30 d2.evaluation.evaluator]: \u001b[0mInference done 1004/5000. Dataloading: 0.0019 s/iter. Inference: 0.4321 s/iter. Eval: 0.0002 s/iter. Total: 0.4344 s/iter. ETA=0:28:55\n",
            "\u001b[32m[04/30 18:59:35 d2.evaluation.evaluator]: \u001b[0mInference done 1016/5000. Dataloading: 0.0019 s/iter. Inference: 0.4322 s/iter. Eval: 0.0002 s/iter. Total: 0.4345 s/iter. ETA=0:28:50\n",
            "\u001b[32m[04/30 18:59:40 d2.evaluation.evaluator]: \u001b[0mInference done 1028/5000. Dataloading: 0.0019 s/iter. Inference: 0.4323 s/iter. Eval: 0.0002 s/iter. Total: 0.4346 s/iter. ETA=0:28:46\n",
            "\u001b[32m[04/30 18:59:46 d2.evaluation.evaluator]: \u001b[0mInference done 1040/5000. Dataloading: 0.0019 s/iter. Inference: 0.4324 s/iter. Eval: 0.0002 s/iter. Total: 0.4347 s/iter. ETA=0:28:41\n",
            "\u001b[32m[04/30 18:59:51 d2.evaluation.evaluator]: \u001b[0mInference done 1052/5000. Dataloading: 0.0019 s/iter. Inference: 0.4326 s/iter. Eval: 0.0002 s/iter. Total: 0.4348 s/iter. ETA=0:28:36\n",
            "\u001b[32m[04/30 18:59:57 d2.evaluation.evaluator]: \u001b[0mInference done 1064/5000. Dataloading: 0.0019 s/iter. Inference: 0.4328 s/iter. Eval: 0.0002 s/iter. Total: 0.4350 s/iter. ETA=0:28:32\n",
            "\u001b[32m[04/30 19:00:02 d2.evaluation.evaluator]: \u001b[0mInference done 1076/5000. Dataloading: 0.0019 s/iter. Inference: 0.4329 s/iter. Eval: 0.0002 s/iter. Total: 0.4352 s/iter. ETA=0:28:27\n",
            "\u001b[32m[04/30 19:00:07 d2.evaluation.evaluator]: \u001b[0mInference done 1088/5000. Dataloading: 0.0019 s/iter. Inference: 0.4331 s/iter. Eval: 0.0002 s/iter. Total: 0.4354 s/iter. ETA=0:28:23\n",
            "\u001b[32m[04/30 19:00:13 d2.evaluation.evaluator]: \u001b[0mInference done 1100/5000. Dataloading: 0.0019 s/iter. Inference: 0.4332 s/iter. Eval: 0.0002 s/iter. Total: 0.4354 s/iter. ETA=0:28:18\n",
            "\u001b[32m[04/30 19:00:18 d2.evaluation.evaluator]: \u001b[0mInference done 1112/5000. Dataloading: 0.0019 s/iter. Inference: 0.4333 s/iter. Eval: 0.0002 s/iter. Total: 0.4356 s/iter. ETA=0:28:13\n",
            "\u001b[32m[04/30 19:00:24 d2.evaluation.evaluator]: \u001b[0mInference done 1124/5000. Dataloading: 0.0019 s/iter. Inference: 0.4335 s/iter. Eval: 0.0002 s/iter. Total: 0.4358 s/iter. ETA=0:28:08\n",
            "\u001b[32m[04/30 19:00:29 d2.evaluation.evaluator]: \u001b[0mInference done 1135/5000. Dataloading: 0.0019 s/iter. Inference: 0.4337 s/iter. Eval: 0.0002 s/iter. Total: 0.4359 s/iter. ETA=0:28:04\n",
            "\u001b[32m[04/30 19:00:34 d2.evaluation.evaluator]: \u001b[0mInference done 1147/5000. Dataloading: 0.0020 s/iter. Inference: 0.4338 s/iter. Eval: 0.0002 s/iter. Total: 0.4360 s/iter. ETA=0:28:00\n",
            "\u001b[32m[04/30 19:00:39 d2.evaluation.evaluator]: \u001b[0mInference done 1159/5000. Dataloading: 0.0020 s/iter. Inference: 0.4339 s/iter. Eval: 0.0002 s/iter. Total: 0.4361 s/iter. ETA=0:27:55\n",
            "\u001b[32m[04/30 19:00:45 d2.evaluation.evaluator]: \u001b[0mInference done 1171/5000. Dataloading: 0.0020 s/iter. Inference: 0.4340 s/iter. Eval: 0.0002 s/iter. Total: 0.4363 s/iter. ETA=0:27:50\n",
            "\u001b[32m[04/30 19:00:50 d2.evaluation.evaluator]: \u001b[0mInference done 1183/5000. Dataloading: 0.0020 s/iter. Inference: 0.4341 s/iter. Eval: 0.0002 s/iter. Total: 0.4364 s/iter. ETA=0:27:45\n",
            "\u001b[32m[04/30 19:00:55 d2.evaluation.evaluator]: \u001b[0mInference done 1195/5000. Dataloading: 0.0020 s/iter. Inference: 0.4343 s/iter. Eval: 0.0002 s/iter. Total: 0.4365 s/iter. ETA=0:27:41\n",
            "\u001b[32m[04/30 19:01:01 d2.evaluation.evaluator]: \u001b[0mInference done 1207/5000. Dataloading: 0.0020 s/iter. Inference: 0.4344 s/iter. Eval: 0.0002 s/iter. Total: 0.4367 s/iter. ETA=0:27:36\n",
            "\u001b[32m[04/30 19:01:06 d2.evaluation.evaluator]: \u001b[0mInference done 1219/5000. Dataloading: 0.0020 s/iter. Inference: 0.4345 s/iter. Eval: 0.0002 s/iter. Total: 0.4367 s/iter. ETA=0:27:31\n",
            "\u001b[32m[04/30 19:01:12 d2.evaluation.evaluator]: \u001b[0mInference done 1231/5000. Dataloading: 0.0020 s/iter. Inference: 0.4346 s/iter. Eval: 0.0002 s/iter. Total: 0.4369 s/iter. ETA=0:27:26\n",
            "\u001b[32m[04/30 19:01:17 d2.evaluation.evaluator]: \u001b[0mInference done 1243/5000. Dataloading: 0.0020 s/iter. Inference: 0.4347 s/iter. Eval: 0.0002 s/iter. Total: 0.4369 s/iter. ETA=0:27:21\n",
            "\u001b[32m[04/30 19:01:22 d2.evaluation.evaluator]: \u001b[0mInference done 1255/5000. Dataloading: 0.0020 s/iter. Inference: 0.4348 s/iter. Eval: 0.0002 s/iter. Total: 0.4370 s/iter. ETA=0:27:16\n",
            "\u001b[32m[04/30 19:01:27 d2.evaluation.evaluator]: \u001b[0mInference done 1267/5000. Dataloading: 0.0020 s/iter. Inference: 0.4348 s/iter. Eval: 0.0002 s/iter. Total: 0.4371 s/iter. ETA=0:27:11\n",
            "\u001b[32m[04/30 19:01:33 d2.evaluation.evaluator]: \u001b[0mInference done 1279/5000. Dataloading: 0.0020 s/iter. Inference: 0.4349 s/iter. Eval: 0.0002 s/iter. Total: 0.4372 s/iter. ETA=0:27:06\n",
            "\u001b[32m[04/30 19:01:38 d2.evaluation.evaluator]: \u001b[0mInference done 1291/5000. Dataloading: 0.0020 s/iter. Inference: 0.4350 s/iter. Eval: 0.0002 s/iter. Total: 0.4373 s/iter. ETA=0:27:02\n",
            "\u001b[32m[04/30 19:01:44 d2.evaluation.evaluator]: \u001b[0mInference done 1303/5000. Dataloading: 0.0020 s/iter. Inference: 0.4351 s/iter. Eval: 0.0002 s/iter. Total: 0.4373 s/iter. ETA=0:26:56\n",
            "\u001b[32m[04/30 19:01:49 d2.evaluation.evaluator]: \u001b[0mInference done 1315/5000. Dataloading: 0.0019 s/iter. Inference: 0.4352 s/iter. Eval: 0.0002 s/iter. Total: 0.4374 s/iter. ETA=0:26:51\n",
            "\u001b[32m[04/30 19:01:54 d2.evaluation.evaluator]: \u001b[0mInference done 1327/5000. Dataloading: 0.0019 s/iter. Inference: 0.4351 s/iter. Eval: 0.0002 s/iter. Total: 0.4374 s/iter. ETA=0:26:46\n",
            "\u001b[32m[04/30 19:02:00 d2.evaluation.evaluator]: \u001b[0mInference done 1339/5000. Dataloading: 0.0020 s/iter. Inference: 0.4352 s/iter. Eval: 0.0002 s/iter. Total: 0.4375 s/iter. ETA=0:26:41\n",
            "\u001b[32m[04/30 19:02:05 d2.evaluation.evaluator]: \u001b[0mInference done 1351/5000. Dataloading: 0.0020 s/iter. Inference: 0.4353 s/iter. Eval: 0.0002 s/iter. Total: 0.4376 s/iter. ETA=0:26:36\n",
            "\u001b[32m[04/30 19:02:10 d2.evaluation.evaluator]: \u001b[0mInference done 1363/5000. Dataloading: 0.0020 s/iter. Inference: 0.4354 s/iter. Eval: 0.0002 s/iter. Total: 0.4376 s/iter. ETA=0:26:31\n",
            "\u001b[32m[04/30 19:02:15 d2.evaluation.evaluator]: \u001b[0mInference done 1375/5000. Dataloading: 0.0020 s/iter. Inference: 0.4354 s/iter. Eval: 0.0002 s/iter. Total: 0.4376 s/iter. ETA=0:26:26\n",
            "\u001b[32m[04/30 19:02:21 d2.evaluation.evaluator]: \u001b[0mInference done 1387/5000. Dataloading: 0.0020 s/iter. Inference: 0.4354 s/iter. Eval: 0.0002 s/iter. Total: 0.4377 s/iter. ETA=0:26:21\n",
            "\u001b[32m[04/30 19:02:26 d2.evaluation.evaluator]: \u001b[0mInference done 1399/5000. Dataloading: 0.0020 s/iter. Inference: 0.4355 s/iter. Eval: 0.0002 s/iter. Total: 0.4377 s/iter. ETA=0:26:16\n",
            "\u001b[32m[04/30 19:02:31 d2.evaluation.evaluator]: \u001b[0mInference done 1411/5000. Dataloading: 0.0020 s/iter. Inference: 0.4355 s/iter. Eval: 0.0002 s/iter. Total: 0.4378 s/iter. ETA=0:26:11\n",
            "\u001b[32m[04/30 19:02:37 d2.evaluation.evaluator]: \u001b[0mInference done 1423/5000. Dataloading: 0.0020 s/iter. Inference: 0.4355 s/iter. Eval: 0.0002 s/iter. Total: 0.4378 s/iter. ETA=0:26:05\n",
            "\u001b[32m[04/30 19:02:42 d2.evaluation.evaluator]: \u001b[0mInference done 1435/5000. Dataloading: 0.0020 s/iter. Inference: 0.4355 s/iter. Eval: 0.0002 s/iter. Total: 0.4378 s/iter. ETA=0:26:00\n",
            "\u001b[32m[04/30 19:02:47 d2.evaluation.evaluator]: \u001b[0mInference done 1447/5000. Dataloading: 0.0020 s/iter. Inference: 0.4356 s/iter. Eval: 0.0002 s/iter. Total: 0.4379 s/iter. ETA=0:25:55\n",
            "\u001b[32m[04/30 19:02:53 d2.evaluation.evaluator]: \u001b[0mInference done 1459/5000. Dataloading: 0.0020 s/iter. Inference: 0.4356 s/iter. Eval: 0.0002 s/iter. Total: 0.4379 s/iter. ETA=0:25:50\n",
            "\u001b[32m[04/30 19:02:58 d2.evaluation.evaluator]: \u001b[0mInference done 1471/5000. Dataloading: 0.0020 s/iter. Inference: 0.4356 s/iter. Eval: 0.0002 s/iter. Total: 0.4378 s/iter. ETA=0:25:45\n",
            "\u001b[32m[04/30 19:03:03 d2.evaluation.evaluator]: \u001b[0mInference done 1483/5000. Dataloading: 0.0020 s/iter. Inference: 0.4356 s/iter. Eval: 0.0002 s/iter. Total: 0.4379 s/iter. ETA=0:25:40\n",
            "\u001b[32m[04/30 19:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 1495/5000. Dataloading: 0.0020 s/iter. Inference: 0.4357 s/iter. Eval: 0.0002 s/iter. Total: 0.4380 s/iter. ETA=0:25:35\n",
            "\u001b[32m[04/30 19:03:14 d2.evaluation.evaluator]: \u001b[0mInference done 1507/5000. Dataloading: 0.0020 s/iter. Inference: 0.4357 s/iter. Eval: 0.0002 s/iter. Total: 0.4379 s/iter. ETA=0:25:29\n",
            "\u001b[32m[04/30 19:03:19 d2.evaluation.evaluator]: \u001b[0mInference done 1519/5000. Dataloading: 0.0020 s/iter. Inference: 0.4357 s/iter. Eval: 0.0002 s/iter. Total: 0.4379 s/iter. ETA=0:25:24\n",
            "\u001b[32m[04/30 19:03:24 d2.evaluation.evaluator]: \u001b[0mInference done 1531/5000. Dataloading: 0.0020 s/iter. Inference: 0.4357 s/iter. Eval: 0.0002 s/iter. Total: 0.4380 s/iter. ETA=0:25:19\n",
            "\u001b[32m[04/30 19:03:30 d2.evaluation.evaluator]: \u001b[0mInference done 1543/5000. Dataloading: 0.0020 s/iter. Inference: 0.4358 s/iter. Eval: 0.0002 s/iter. Total: 0.4380 s/iter. ETA=0:25:14\n",
            "\u001b[32m[04/30 19:03:35 d2.evaluation.evaluator]: \u001b[0mInference done 1555/5000. Dataloading: 0.0020 s/iter. Inference: 0.4358 s/iter. Eval: 0.0002 s/iter. Total: 0.4381 s/iter. ETA=0:25:09\n",
            "\u001b[32m[04/30 19:03:40 d2.evaluation.evaluator]: \u001b[0mInference done 1567/5000. Dataloading: 0.0020 s/iter. Inference: 0.4359 s/iter. Eval: 0.0002 s/iter. Total: 0.4382 s/iter. ETA=0:25:04\n",
            "\u001b[32m[04/30 19:03:46 d2.evaluation.evaluator]: \u001b[0mInference done 1579/5000. Dataloading: 0.0020 s/iter. Inference: 0.4359 s/iter. Eval: 0.0002 s/iter. Total: 0.4382 s/iter. ETA=0:24:59\n",
            "\u001b[32m[04/30 19:03:51 d2.evaluation.evaluator]: \u001b[0mInference done 1591/5000. Dataloading: 0.0020 s/iter. Inference: 0.4360 s/iter. Eval: 0.0002 s/iter. Total: 0.4383 s/iter. ETA=0:24:54\n",
            "\u001b[32m[04/30 19:03:56 d2.evaluation.evaluator]: \u001b[0mInference done 1603/5000. Dataloading: 0.0020 s/iter. Inference: 0.4361 s/iter. Eval: 0.0002 s/iter. Total: 0.4383 s/iter. ETA=0:24:49\n",
            "\u001b[32m[04/30 19:04:02 d2.evaluation.evaluator]: \u001b[0mInference done 1615/5000. Dataloading: 0.0020 s/iter. Inference: 0.4361 s/iter. Eval: 0.0002 s/iter. Total: 0.4384 s/iter. ETA=0:24:43\n",
            "\u001b[32m[04/30 19:04:07 d2.evaluation.evaluator]: \u001b[0mInference done 1627/5000. Dataloading: 0.0020 s/iter. Inference: 0.4361 s/iter. Eval: 0.0002 s/iter. Total: 0.4384 s/iter. ETA=0:24:38\n",
            "\u001b[32m[04/30 19:04:12 d2.evaluation.evaluator]: \u001b[0mInference done 1639/5000. Dataloading: 0.0020 s/iter. Inference: 0.4362 s/iter. Eval: 0.0002 s/iter. Total: 0.4384 s/iter. ETA=0:24:33\n",
            "\u001b[32m[04/30 19:04:18 d2.evaluation.evaluator]: \u001b[0mInference done 1651/5000. Dataloading: 0.0020 s/iter. Inference: 0.4362 s/iter. Eval: 0.0002 s/iter. Total: 0.4385 s/iter. ETA=0:24:28\n",
            "\u001b[32m[04/30 19:04:23 d2.evaluation.evaluator]: \u001b[0mInference done 1663/5000. Dataloading: 0.0020 s/iter. Inference: 0.4362 s/iter. Eval: 0.0002 s/iter. Total: 0.4385 s/iter. ETA=0:24:23\n",
            "\u001b[32m[04/30 19:04:28 d2.evaluation.evaluator]: \u001b[0mInference done 1675/5000. Dataloading: 0.0020 s/iter. Inference: 0.4363 s/iter. Eval: 0.0002 s/iter. Total: 0.4385 s/iter. ETA=0:24:18\n",
            "\u001b[32m[04/30 19:04:34 d2.evaluation.evaluator]: \u001b[0mInference done 1687/5000. Dataloading: 0.0020 s/iter. Inference: 0.4363 s/iter. Eval: 0.0002 s/iter. Total: 0.4386 s/iter. ETA=0:24:12\n",
            "\u001b[32m[04/30 19:04:39 d2.evaluation.evaluator]: \u001b[0mInference done 1699/5000. Dataloading: 0.0020 s/iter. Inference: 0.4364 s/iter. Eval: 0.0002 s/iter. Total: 0.4386 s/iter. ETA=0:24:07\n",
            "\u001b[32m[04/30 19:04:44 d2.evaluation.evaluator]: \u001b[0mInference done 1711/5000. Dataloading: 0.0020 s/iter. Inference: 0.4364 s/iter. Eval: 0.0002 s/iter. Total: 0.4387 s/iter. ETA=0:24:02\n",
            "\u001b[32m[04/30 19:04:50 d2.evaluation.evaluator]: \u001b[0mInference done 1723/5000. Dataloading: 0.0020 s/iter. Inference: 0.4364 s/iter. Eval: 0.0002 s/iter. Total: 0.4387 s/iter. ETA=0:23:57\n",
            "\u001b[32m[04/30 19:04:55 d2.evaluation.evaluator]: \u001b[0mInference done 1735/5000. Dataloading: 0.0020 s/iter. Inference: 0.4364 s/iter. Eval: 0.0002 s/iter. Total: 0.4387 s/iter. ETA=0:23:52\n",
            "\u001b[32m[04/30 19:05:00 d2.evaluation.evaluator]: \u001b[0mInference done 1747/5000. Dataloading: 0.0020 s/iter. Inference: 0.4365 s/iter. Eval: 0.0002 s/iter. Total: 0.4388 s/iter. ETA=0:23:47\n",
            "\u001b[32m[04/30 19:05:06 d2.evaluation.evaluator]: \u001b[0mInference done 1759/5000. Dataloading: 0.0020 s/iter. Inference: 0.4366 s/iter. Eval: 0.0002 s/iter. Total: 0.4389 s/iter. ETA=0:23:42\n",
            "\u001b[32m[04/30 19:05:11 d2.evaluation.evaluator]: \u001b[0mInference done 1771/5000. Dataloading: 0.0020 s/iter. Inference: 0.4366 s/iter. Eval: 0.0002 s/iter. Total: 0.4388 s/iter. ETA=0:23:37\n",
            "\u001b[32m[04/30 19:05:16 d2.evaluation.evaluator]: \u001b[0mInference done 1783/5000. Dataloading: 0.0020 s/iter. Inference: 0.4366 s/iter. Eval: 0.0002 s/iter. Total: 0.4388 s/iter. ETA=0:23:31\n",
            "\u001b[32m[04/30 19:05:21 d2.evaluation.evaluator]: \u001b[0mInference done 1795/5000. Dataloading: 0.0020 s/iter. Inference: 0.4366 s/iter. Eval: 0.0002 s/iter. Total: 0.4389 s/iter. ETA=0:23:26\n",
            "\u001b[32m[04/30 19:05:27 d2.evaluation.evaluator]: \u001b[0mInference done 1807/5000. Dataloading: 0.0020 s/iter. Inference: 0.4366 s/iter. Eval: 0.0002 s/iter. Total: 0.4389 s/iter. ETA=0:23:21\n",
            "\u001b[32m[04/30 19:05:32 d2.evaluation.evaluator]: \u001b[0mInference done 1819/5000. Dataloading: 0.0020 s/iter. Inference: 0.4367 s/iter. Eval: 0.0002 s/iter. Total: 0.4389 s/iter. ETA=0:23:16\n",
            "\u001b[32m[04/30 19:05:37 d2.evaluation.evaluator]: \u001b[0mInference done 1831/5000. Dataloading: 0.0020 s/iter. Inference: 0.4367 s/iter. Eval: 0.0002 s/iter. Total: 0.4390 s/iter. ETA=0:23:11\n",
            "\u001b[32m[04/30 19:05:43 d2.evaluation.evaluator]: \u001b[0mInference done 1843/5000. Dataloading: 0.0020 s/iter. Inference: 0.4367 s/iter. Eval: 0.0002 s/iter. Total: 0.4390 s/iter. ETA=0:23:05\n",
            "\u001b[32m[04/30 19:05:48 d2.evaluation.evaluator]: \u001b[0mInference done 1855/5000. Dataloading: 0.0020 s/iter. Inference: 0.4367 s/iter. Eval: 0.0002 s/iter. Total: 0.4390 s/iter. ETA=0:23:00\n",
            "\u001b[32m[04/30 19:05:53 d2.evaluation.evaluator]: \u001b[0mInference done 1867/5000. Dataloading: 0.0020 s/iter. Inference: 0.4367 s/iter. Eval: 0.0002 s/iter. Total: 0.4390 s/iter. ETA=0:22:55\n",
            "\u001b[32m[04/30 19:05:59 d2.evaluation.evaluator]: \u001b[0mInference done 1879/5000. Dataloading: 0.0020 s/iter. Inference: 0.4368 s/iter. Eval: 0.0002 s/iter. Total: 0.4390 s/iter. ETA=0:22:50\n",
            "\u001b[32m[04/30 19:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 1891/5000. Dataloading: 0.0020 s/iter. Inference: 0.4368 s/iter. Eval: 0.0002 s/iter. Total: 0.4391 s/iter. ETA=0:22:45\n",
            "\u001b[32m[04/30 19:06:09 d2.evaluation.evaluator]: \u001b[0mInference done 1903/5000. Dataloading: 0.0020 s/iter. Inference: 0.4369 s/iter. Eval: 0.0002 s/iter. Total: 0.4391 s/iter. ETA=0:22:40\n",
            "\u001b[32m[04/30 19:06:15 d2.evaluation.evaluator]: \u001b[0mInference done 1915/5000. Dataloading: 0.0020 s/iter. Inference: 0.4369 s/iter. Eval: 0.0002 s/iter. Total: 0.4392 s/iter. ETA=0:22:34\n",
            "\u001b[32m[04/30 19:06:20 d2.evaluation.evaluator]: \u001b[0mInference done 1927/5000. Dataloading: 0.0020 s/iter. Inference: 0.4369 s/iter. Eval: 0.0002 s/iter. Total: 0.4392 s/iter. ETA=0:22:29\n",
            "\u001b[32m[04/30 19:06:25 d2.evaluation.evaluator]: \u001b[0mInference done 1939/5000. Dataloading: 0.0020 s/iter. Inference: 0.4369 s/iter. Eval: 0.0002 s/iter. Total: 0.4392 s/iter. ETA=0:22:24\n",
            "\u001b[32m[04/30 19:06:31 d2.evaluation.evaluator]: \u001b[0mInference done 1951/5000. Dataloading: 0.0020 s/iter. Inference: 0.4369 s/iter. Eval: 0.0002 s/iter. Total: 0.4392 s/iter. ETA=0:22:19\n",
            "\u001b[32m[04/30 19:06:36 d2.evaluation.evaluator]: \u001b[0mInference done 1963/5000. Dataloading: 0.0020 s/iter. Inference: 0.4370 s/iter. Eval: 0.0002 s/iter. Total: 0.4392 s/iter. ETA=0:22:13\n",
            "\u001b[32m[04/30 19:06:41 d2.evaluation.evaluator]: \u001b[0mInference done 1975/5000. Dataloading: 0.0020 s/iter. Inference: 0.4370 s/iter. Eval: 0.0002 s/iter. Total: 0.4393 s/iter. ETA=0:22:08\n",
            "\u001b[32m[04/30 19:06:47 d2.evaluation.evaluator]: \u001b[0mInference done 1987/5000. Dataloading: 0.0020 s/iter. Inference: 0.4370 s/iter. Eval: 0.0002 s/iter. Total: 0.4393 s/iter. ETA=0:22:03\n",
            "\u001b[32m[04/30 19:06:52 d2.evaluation.evaluator]: \u001b[0mInference done 1999/5000. Dataloading: 0.0020 s/iter. Inference: 0.4370 s/iter. Eval: 0.0002 s/iter. Total: 0.4393 s/iter. ETA=0:21:58\n",
            "\u001b[32m[04/30 19:06:57 d2.evaluation.evaluator]: \u001b[0mInference done 2011/5000. Dataloading: 0.0020 s/iter. Inference: 0.4371 s/iter. Eval: 0.0002 s/iter. Total: 0.4393 s/iter. ETA=0:21:53\n",
            "\u001b[32m[04/30 19:07:03 d2.evaluation.evaluator]: \u001b[0mInference done 2023/5000. Dataloading: 0.0020 s/iter. Inference: 0.4371 s/iter. Eval: 0.0002 s/iter. Total: 0.4394 s/iter. ETA=0:21:48\n",
            "\u001b[32m[04/30 19:07:08 d2.evaluation.evaluator]: \u001b[0mInference done 2035/5000. Dataloading: 0.0020 s/iter. Inference: 0.4371 s/iter. Eval: 0.0002 s/iter. Total: 0.4394 s/iter. ETA=0:21:42\n",
            "\u001b[32m[04/30 19:07:13 d2.evaluation.evaluator]: \u001b[0mInference done 2047/5000. Dataloading: 0.0020 s/iter. Inference: 0.4371 s/iter. Eval: 0.0002 s/iter. Total: 0.4394 s/iter. ETA=0:21:37\n",
            "\u001b[32m[04/30 19:07:18 d2.evaluation.evaluator]: \u001b[0mInference done 2059/5000. Dataloading: 0.0020 s/iter. Inference: 0.4371 s/iter. Eval: 0.0002 s/iter. Total: 0.4394 s/iter. ETA=0:21:32\n",
            "\u001b[32m[04/30 19:07:24 d2.evaluation.evaluator]: \u001b[0mInference done 2071/5000. Dataloading: 0.0020 s/iter. Inference: 0.4372 s/iter. Eval: 0.0002 s/iter. Total: 0.4394 s/iter. ETA=0:21:27\n",
            "\u001b[32m[04/30 19:07:29 d2.evaluation.evaluator]: \u001b[0mInference done 2083/5000. Dataloading: 0.0020 s/iter. Inference: 0.4372 s/iter. Eval: 0.0002 s/iter. Total: 0.4395 s/iter. ETA=0:21:21\n",
            "\u001b[32m[04/30 19:07:34 d2.evaluation.evaluator]: \u001b[0mInference done 2095/5000. Dataloading: 0.0020 s/iter. Inference: 0.4372 s/iter. Eval: 0.0002 s/iter. Total: 0.4395 s/iter. ETA=0:21:16\n",
            "\u001b[32m[04/30 19:07:40 d2.evaluation.evaluator]: \u001b[0mInference done 2107/5000. Dataloading: 0.0020 s/iter. Inference: 0.4372 s/iter. Eval: 0.0002 s/iter. Total: 0.4395 s/iter. ETA=0:21:11\n",
            "\u001b[32m[04/30 19:07:45 d2.evaluation.evaluator]: \u001b[0mInference done 2119/5000. Dataloading: 0.0020 s/iter. Inference: 0.4372 s/iter. Eval: 0.0002 s/iter. Total: 0.4395 s/iter. ETA=0:21:06\n",
            "\u001b[32m[04/30 19:07:50 d2.evaluation.evaluator]: \u001b[0mInference done 2131/5000. Dataloading: 0.0020 s/iter. Inference: 0.4372 s/iter. Eval: 0.0002 s/iter. Total: 0.4395 s/iter. ETA=0:21:00\n",
            "\u001b[32m[04/30 19:07:56 d2.evaluation.evaluator]: \u001b[0mInference done 2143/5000. Dataloading: 0.0020 s/iter. Inference: 0.4373 s/iter. Eval: 0.0002 s/iter. Total: 0.4395 s/iter. ETA=0:20:55\n",
            "\u001b[32m[04/30 19:08:01 d2.evaluation.evaluator]: \u001b[0mInference done 2155/5000. Dataloading: 0.0020 s/iter. Inference: 0.4373 s/iter. Eval: 0.0002 s/iter. Total: 0.4396 s/iter. ETA=0:20:50\n",
            "\u001b[32m[04/30 19:08:06 d2.evaluation.evaluator]: \u001b[0mInference done 2167/5000. Dataloading: 0.0020 s/iter. Inference: 0.4373 s/iter. Eval: 0.0002 s/iter. Total: 0.4396 s/iter. ETA=0:20:45\n",
            "\u001b[32m[04/30 19:08:12 d2.evaluation.evaluator]: \u001b[0mInference done 2179/5000. Dataloading: 0.0020 s/iter. Inference: 0.4373 s/iter. Eval: 0.0002 s/iter. Total: 0.4396 s/iter. ETA=0:20:40\n",
            "\u001b[32m[04/30 19:08:17 d2.evaluation.evaluator]: \u001b[0mInference done 2191/5000. Dataloading: 0.0020 s/iter. Inference: 0.4373 s/iter. Eval: 0.0002 s/iter. Total: 0.4396 s/iter. ETA=0:20:34\n",
            "\u001b[32m[04/30 19:08:22 d2.evaluation.evaluator]: \u001b[0mInference done 2203/5000. Dataloading: 0.0020 s/iter. Inference: 0.4374 s/iter. Eval: 0.0002 s/iter. Total: 0.4397 s/iter. ETA=0:20:29\n",
            "\u001b[32m[04/30 19:08:28 d2.evaluation.evaluator]: \u001b[0mInference done 2215/5000. Dataloading: 0.0020 s/iter. Inference: 0.4374 s/iter. Eval: 0.0002 s/iter. Total: 0.4396 s/iter. ETA=0:20:24\n",
            "\u001b[32m[04/30 19:08:33 d2.evaluation.evaluator]: \u001b[0mInference done 2227/5000. Dataloading: 0.0020 s/iter. Inference: 0.4374 s/iter. Eval: 0.0002 s/iter. Total: 0.4397 s/iter. ETA=0:20:19\n",
            "\u001b[32m[04/30 19:08:38 d2.evaluation.evaluator]: \u001b[0mInference done 2239/5000. Dataloading: 0.0020 s/iter. Inference: 0.4374 s/iter. Eval: 0.0002 s/iter. Total: 0.4397 s/iter. ETA=0:20:14\n",
            "\u001b[32m[04/30 19:08:44 d2.evaluation.evaluator]: \u001b[0mInference done 2251/5000. Dataloading: 0.0020 s/iter. Inference: 0.4375 s/iter. Eval: 0.0002 s/iter. Total: 0.4398 s/iter. ETA=0:20:08\n",
            "\u001b[32m[04/30 19:08:49 d2.evaluation.evaluator]: \u001b[0mInference done 2263/5000. Dataloading: 0.0020 s/iter. Inference: 0.4375 s/iter. Eval: 0.0002 s/iter. Total: 0.4398 s/iter. ETA=0:20:03\n",
            "\u001b[32m[04/30 19:08:54 d2.evaluation.evaluator]: \u001b[0mInference done 2275/5000. Dataloading: 0.0020 s/iter. Inference: 0.4375 s/iter. Eval: 0.0002 s/iter. Total: 0.4398 s/iter. ETA=0:19:58\n",
            "\u001b[32m[04/30 19:09:00 d2.evaluation.evaluator]: \u001b[0mInference done 2287/5000. Dataloading: 0.0020 s/iter. Inference: 0.4376 s/iter. Eval: 0.0002 s/iter. Total: 0.4399 s/iter. ETA=0:19:53\n",
            "\u001b[32m[04/30 19:09:05 d2.evaluation.evaluator]: \u001b[0mInference done 2299/5000. Dataloading: 0.0020 s/iter. Inference: 0.4375 s/iter. Eval: 0.0002 s/iter. Total: 0.4398 s/iter. ETA=0:19:47\n",
            "\u001b[32m[04/30 19:09:10 d2.evaluation.evaluator]: \u001b[0mInference done 2311/5000. Dataloading: 0.0020 s/iter. Inference: 0.4376 s/iter. Eval: 0.0002 s/iter. Total: 0.4398 s/iter. ETA=0:19:42\n",
            "\u001b[32m[04/30 19:09:16 d2.evaluation.evaluator]: \u001b[0mInference done 2323/5000. Dataloading: 0.0020 s/iter. Inference: 0.4376 s/iter. Eval: 0.0002 s/iter. Total: 0.4399 s/iter. ETA=0:19:37\n",
            "\u001b[32m[04/30 19:09:21 d2.evaluation.evaluator]: \u001b[0mInference done 2335/5000. Dataloading: 0.0020 s/iter. Inference: 0.4376 s/iter. Eval: 0.0002 s/iter. Total: 0.4399 s/iter. ETA=0:19:32\n",
            "\u001b[32m[04/30 19:09:26 d2.evaluation.evaluator]: \u001b[0mInference done 2347/5000. Dataloading: 0.0020 s/iter. Inference: 0.4377 s/iter. Eval: 0.0002 s/iter. Total: 0.4399 s/iter. ETA=0:19:27\n",
            "\u001b[32m[04/30 19:09:32 d2.evaluation.evaluator]: \u001b[0mInference done 2359/5000. Dataloading: 0.0020 s/iter. Inference: 0.4377 s/iter. Eval: 0.0002 s/iter. Total: 0.4400 s/iter. ETA=0:19:21\n",
            "\u001b[32m[04/30 19:09:37 d2.evaluation.evaluator]: \u001b[0mInference done 2371/5000. Dataloading: 0.0020 s/iter. Inference: 0.4377 s/iter. Eval: 0.0002 s/iter. Total: 0.4400 s/iter. ETA=0:19:16\n",
            "\u001b[32m[04/30 19:09:42 d2.evaluation.evaluator]: \u001b[0mInference done 2383/5000. Dataloading: 0.0020 s/iter. Inference: 0.4377 s/iter. Eval: 0.0002 s/iter. Total: 0.4400 s/iter. ETA=0:19:11\n",
            "\u001b[32m[04/30 19:09:48 d2.evaluation.evaluator]: \u001b[0mInference done 2395/5000. Dataloading: 0.0020 s/iter. Inference: 0.4377 s/iter. Eval: 0.0002 s/iter. Total: 0.4400 s/iter. ETA=0:19:06\n",
            "\u001b[32m[04/30 19:09:53 d2.evaluation.evaluator]: \u001b[0mInference done 2407/5000. Dataloading: 0.0020 s/iter. Inference: 0.4378 s/iter. Eval: 0.0002 s/iter. Total: 0.4400 s/iter. ETA=0:19:01\n",
            "\u001b[32m[04/30 19:09:58 d2.evaluation.evaluator]: \u001b[0mInference done 2419/5000. Dataloading: 0.0020 s/iter. Inference: 0.4378 s/iter. Eval: 0.0002 s/iter. Total: 0.4401 s/iter. ETA=0:18:55\n",
            "\u001b[32m[04/30 19:10:04 d2.evaluation.evaluator]: \u001b[0mInference done 2431/5000. Dataloading: 0.0020 s/iter. Inference: 0.4378 s/iter. Eval: 0.0002 s/iter. Total: 0.4401 s/iter. ETA=0:18:50\n",
            "\u001b[32m[04/30 19:10:09 d2.evaluation.evaluator]: \u001b[0mInference done 2443/5000. Dataloading: 0.0020 s/iter. Inference: 0.4379 s/iter. Eval: 0.0002 s/iter. Total: 0.4401 s/iter. ETA=0:18:45\n",
            "\u001b[32m[04/30 19:10:14 d2.evaluation.evaluator]: \u001b[0mInference done 2455/5000. Dataloading: 0.0020 s/iter. Inference: 0.4379 s/iter. Eval: 0.0002 s/iter. Total: 0.4401 s/iter. ETA=0:18:40\n",
            "\u001b[32m[04/30 19:10:20 d2.evaluation.evaluator]: \u001b[0mInference done 2467/5000. Dataloading: 0.0020 s/iter. Inference: 0.4379 s/iter. Eval: 0.0002 s/iter. Total: 0.4402 s/iter. ETA=0:18:34\n",
            "\u001b[32m[04/30 19:10:25 d2.evaluation.evaluator]: \u001b[0mInference done 2479/5000. Dataloading: 0.0020 s/iter. Inference: 0.4379 s/iter. Eval: 0.0002 s/iter. Total: 0.4402 s/iter. ETA=0:18:29\n",
            "\u001b[32m[04/30 19:10:30 d2.evaluation.evaluator]: \u001b[0mInference done 2491/5000. Dataloading: 0.0020 s/iter. Inference: 0.4379 s/iter. Eval: 0.0002 s/iter. Total: 0.4402 s/iter. ETA=0:18:24\n",
            "\u001b[32m[04/30 19:10:35 d2.evaluation.evaluator]: \u001b[0mInference done 2503/5000. Dataloading: 0.0020 s/iter. Inference: 0.4379 s/iter. Eval: 0.0002 s/iter. Total: 0.4402 s/iter. ETA=0:18:19\n",
            "\u001b[32m[04/30 19:10:41 d2.evaluation.evaluator]: \u001b[0mInference done 2515/5000. Dataloading: 0.0020 s/iter. Inference: 0.4379 s/iter. Eval: 0.0002 s/iter. Total: 0.4402 s/iter. ETA=0:18:13\n",
            "\u001b[32m[04/30 19:10:46 d2.evaluation.evaluator]: \u001b[0mInference done 2527/5000. Dataloading: 0.0020 s/iter. Inference: 0.4379 s/iter. Eval: 0.0002 s/iter. Total: 0.4402 s/iter. ETA=0:18:08\n",
            "\u001b[32m[04/30 19:10:51 d2.evaluation.evaluator]: \u001b[0mInference done 2539/5000. Dataloading: 0.0020 s/iter. Inference: 0.4379 s/iter. Eval: 0.0002 s/iter. Total: 0.4402 s/iter. ETA=0:18:03\n",
            "\u001b[32m[04/30 19:10:57 d2.evaluation.evaluator]: \u001b[0mInference done 2551/5000. Dataloading: 0.0020 s/iter. Inference: 0.4379 s/iter. Eval: 0.0002 s/iter. Total: 0.4402 s/iter. ETA=0:17:58\n",
            "\u001b[32m[04/30 19:11:02 d2.evaluation.evaluator]: \u001b[0mInference done 2563/5000. Dataloading: 0.0020 s/iter. Inference: 0.4380 s/iter. Eval: 0.0002 s/iter. Total: 0.4402 s/iter. ETA=0:17:52\n",
            "\u001b[32m[04/30 19:11:07 d2.evaluation.evaluator]: \u001b[0mInference done 2575/5000. Dataloading: 0.0020 s/iter. Inference: 0.4380 s/iter. Eval: 0.0002 s/iter. Total: 0.4402 s/iter. ETA=0:17:47\n",
            "\u001b[32m[04/30 19:11:13 d2.evaluation.evaluator]: \u001b[0mInference done 2587/5000. Dataloading: 0.0020 s/iter. Inference: 0.4379 s/iter. Eval: 0.0002 s/iter. Total: 0.4402 s/iter. ETA=0:17:42\n",
            "\u001b[32m[04/30 19:11:18 d2.evaluation.evaluator]: \u001b[0mInference done 2599/5000. Dataloading: 0.0020 s/iter. Inference: 0.4379 s/iter. Eval: 0.0002 s/iter. Total: 0.4402 s/iter. ETA=0:17:36\n",
            "\u001b[32m[04/30 19:11:23 d2.evaluation.evaluator]: \u001b[0mInference done 2611/5000. Dataloading: 0.0020 s/iter. Inference: 0.4380 s/iter. Eval: 0.0002 s/iter. Total: 0.4402 s/iter. ETA=0:17:31\n",
            "\u001b[32m[04/30 19:11:28 d2.evaluation.evaluator]: \u001b[0mInference done 2623/5000. Dataloading: 0.0020 s/iter. Inference: 0.4380 s/iter. Eval: 0.0002 s/iter. Total: 0.4402 s/iter. ETA=0:17:26\n",
            "\u001b[32m[04/30 19:11:34 d2.evaluation.evaluator]: \u001b[0mInference done 2635/5000. Dataloading: 0.0020 s/iter. Inference: 0.4380 s/iter. Eval: 0.0002 s/iter. Total: 0.4403 s/iter. ETA=0:17:21\n",
            "\u001b[32m[04/30 19:11:39 d2.evaluation.evaluator]: \u001b[0mInference done 2647/5000. Dataloading: 0.0020 s/iter. Inference: 0.4380 s/iter. Eval: 0.0002 s/iter. Total: 0.4403 s/iter. ETA=0:17:16\n",
            "\u001b[32m[04/30 19:11:45 d2.evaluation.evaluator]: \u001b[0mInference done 2659/5000. Dataloading: 0.0020 s/iter. Inference: 0.4381 s/iter. Eval: 0.0002 s/iter. Total: 0.4403 s/iter. ETA=0:17:10\n",
            "\u001b[32m[04/30 19:11:50 d2.evaluation.evaluator]: \u001b[0mInference done 2671/5000. Dataloading: 0.0020 s/iter. Inference: 0.4381 s/iter. Eval: 0.0002 s/iter. Total: 0.4403 s/iter. ETA=0:17:05\n",
            "\u001b[32m[04/30 19:11:55 d2.evaluation.evaluator]: \u001b[0mInference done 2683/5000. Dataloading: 0.0020 s/iter. Inference: 0.4381 s/iter. Eval: 0.0002 s/iter. Total: 0.4404 s/iter. ETA=0:17:00\n",
            "\u001b[32m[04/30 19:12:01 d2.evaluation.evaluator]: \u001b[0mInference done 2695/5000. Dataloading: 0.0020 s/iter. Inference: 0.4381 s/iter. Eval: 0.0002 s/iter. Total: 0.4404 s/iter. ETA=0:16:55\n",
            "\u001b[32m[04/30 19:12:06 d2.evaluation.evaluator]: \u001b[0mInference done 2707/5000. Dataloading: 0.0020 s/iter. Inference: 0.4381 s/iter. Eval: 0.0002 s/iter. Total: 0.4404 s/iter. ETA=0:16:49\n",
            "\u001b[32m[04/30 19:12:11 d2.evaluation.evaluator]: \u001b[0mInference done 2719/5000. Dataloading: 0.0020 s/iter. Inference: 0.4382 s/iter. Eval: 0.0002 s/iter. Total: 0.4404 s/iter. ETA=0:16:44\n",
            "\u001b[32m[04/30 19:12:17 d2.evaluation.evaluator]: \u001b[0mInference done 2731/5000. Dataloading: 0.0020 s/iter. Inference: 0.4382 s/iter. Eval: 0.0002 s/iter. Total: 0.4405 s/iter. ETA=0:16:39\n",
            "\u001b[32m[04/30 19:12:22 d2.evaluation.evaluator]: \u001b[0mInference done 2743/5000. Dataloading: 0.0020 s/iter. Inference: 0.4382 s/iter. Eval: 0.0002 s/iter. Total: 0.4404 s/iter. ETA=0:16:34\n",
            "\u001b[32m[04/30 19:12:27 d2.evaluation.evaluator]: \u001b[0mInference done 2755/5000. Dataloading: 0.0020 s/iter. Inference: 0.4382 s/iter. Eval: 0.0002 s/iter. Total: 0.4404 s/iter. ETA=0:16:28\n",
            "\u001b[32m[04/30 19:12:32 d2.evaluation.evaluator]: \u001b[0mInference done 2767/5000. Dataloading: 0.0020 s/iter. Inference: 0.4382 s/iter. Eval: 0.0002 s/iter. Total: 0.4404 s/iter. ETA=0:16:23\n",
            "\u001b[32m[04/30 19:12:38 d2.evaluation.evaluator]: \u001b[0mInference done 2779/5000. Dataloading: 0.0019 s/iter. Inference: 0.4382 s/iter. Eval: 0.0002 s/iter. Total: 0.4405 s/iter. ETA=0:16:18\n",
            "\u001b[32m[04/30 19:12:43 d2.evaluation.evaluator]: \u001b[0mInference done 2791/5000. Dataloading: 0.0019 s/iter. Inference: 0.4382 s/iter. Eval: 0.0002 s/iter. Total: 0.4405 s/iter. ETA=0:16:12\n",
            "\u001b[32m[04/30 19:12:48 d2.evaluation.evaluator]: \u001b[0mInference done 2803/5000. Dataloading: 0.0020 s/iter. Inference: 0.4382 s/iter. Eval: 0.0002 s/iter. Total: 0.4405 s/iter. ETA=0:16:07\n",
            "\u001b[32m[04/30 19:12:54 d2.evaluation.evaluator]: \u001b[0mInference done 2815/5000. Dataloading: 0.0020 s/iter. Inference: 0.4382 s/iter. Eval: 0.0002 s/iter. Total: 0.4405 s/iter. ETA=0:16:02\n",
            "\u001b[32m[04/30 19:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 2827/5000. Dataloading: 0.0020 s/iter. Inference: 0.4382 s/iter. Eval: 0.0002 s/iter. Total: 0.4405 s/iter. ETA=0:15:57\n",
            "\u001b[32m[04/30 19:13:04 d2.evaluation.evaluator]: \u001b[0mInference done 2839/5000. Dataloading: 0.0020 s/iter. Inference: 0.4383 s/iter. Eval: 0.0002 s/iter. Total: 0.4405 s/iter. ETA=0:15:51\n",
            "\u001b[32m[04/30 19:13:10 d2.evaluation.evaluator]: \u001b[0mInference done 2851/5000. Dataloading: 0.0020 s/iter. Inference: 0.4383 s/iter. Eval: 0.0002 s/iter. Total: 0.4406 s/iter. ETA=0:15:46\n",
            "\u001b[32m[04/30 19:13:15 d2.evaluation.evaluator]: \u001b[0mInference done 2863/5000. Dataloading: 0.0020 s/iter. Inference: 0.4383 s/iter. Eval: 0.0002 s/iter. Total: 0.4405 s/iter. ETA=0:15:41\n",
            "\u001b[32m[04/30 19:13:20 d2.evaluation.evaluator]: \u001b[0mInference done 2875/5000. Dataloading: 0.0020 s/iter. Inference: 0.4383 s/iter. Eval: 0.0002 s/iter. Total: 0.4406 s/iter. ETA=0:15:36\n",
            "\u001b[32m[04/30 19:13:26 d2.evaluation.evaluator]: \u001b[0mInference done 2887/5000. Dataloading: 0.0019 s/iter. Inference: 0.4383 s/iter. Eval: 0.0002 s/iter. Total: 0.4406 s/iter. ETA=0:15:30\n",
            "\u001b[32m[04/30 19:13:31 d2.evaluation.evaluator]: \u001b[0mInference done 2899/5000. Dataloading: 0.0019 s/iter. Inference: 0.4384 s/iter. Eval: 0.0002 s/iter. Total: 0.4406 s/iter. ETA=0:15:25\n",
            "\u001b[32m[04/30 19:13:36 d2.evaluation.evaluator]: \u001b[0mInference done 2911/5000. Dataloading: 0.0019 s/iter. Inference: 0.4384 s/iter. Eval: 0.0002 s/iter. Total: 0.4406 s/iter. ETA=0:15:20\n",
            "\u001b[32m[04/30 19:13:42 d2.evaluation.evaluator]: \u001b[0mInference done 2923/5000. Dataloading: 0.0019 s/iter. Inference: 0.4384 s/iter. Eval: 0.0002 s/iter. Total: 0.4406 s/iter. ETA=0:15:15\n",
            "\u001b[32m[04/30 19:13:47 d2.evaluation.evaluator]: \u001b[0mInference done 2935/5000. Dataloading: 0.0019 s/iter. Inference: 0.4384 s/iter. Eval: 0.0002 s/iter. Total: 0.4406 s/iter. ETA=0:15:09\n",
            "\u001b[32m[04/30 19:13:52 d2.evaluation.evaluator]: \u001b[0mInference done 2947/5000. Dataloading: 0.0019 s/iter. Inference: 0.4384 s/iter. Eval: 0.0002 s/iter. Total: 0.4406 s/iter. ETA=0:15:04\n",
            "\u001b[32m[04/30 19:13:58 d2.evaluation.evaluator]: \u001b[0mInference done 2959/5000. Dataloading: 0.0019 s/iter. Inference: 0.4384 s/iter. Eval: 0.0002 s/iter. Total: 0.4407 s/iter. ETA=0:14:59\n",
            "\u001b[32m[04/30 19:14:03 d2.evaluation.evaluator]: \u001b[0mInference done 2971/5000. Dataloading: 0.0019 s/iter. Inference: 0.4384 s/iter. Eval: 0.0002 s/iter. Total: 0.4407 s/iter. ETA=0:14:54\n",
            "\u001b[32m[04/30 19:14:08 d2.evaluation.evaluator]: \u001b[0mInference done 2983/5000. Dataloading: 0.0019 s/iter. Inference: 0.4384 s/iter. Eval: 0.0002 s/iter. Total: 0.4407 s/iter. ETA=0:14:48\n",
            "\u001b[32m[04/30 19:14:14 d2.evaluation.evaluator]: \u001b[0mInference done 2995/5000. Dataloading: 0.0019 s/iter. Inference: 0.4384 s/iter. Eval: 0.0002 s/iter. Total: 0.4407 s/iter. ETA=0:14:43\n",
            "\u001b[32m[04/30 19:14:19 d2.evaluation.evaluator]: \u001b[0mInference done 3007/5000. Dataloading: 0.0019 s/iter. Inference: 0.4384 s/iter. Eval: 0.0002 s/iter. Total: 0.4407 s/iter. ETA=0:14:38\n",
            "\u001b[32m[04/30 19:14:24 d2.evaluation.evaluator]: \u001b[0mInference done 3019/5000. Dataloading: 0.0019 s/iter. Inference: 0.4385 s/iter. Eval: 0.0002 s/iter. Total: 0.4407 s/iter. ETA=0:14:33\n",
            "\u001b[32m[04/30 19:14:30 d2.evaluation.evaluator]: \u001b[0mInference done 3031/5000. Dataloading: 0.0019 s/iter. Inference: 0.4385 s/iter. Eval: 0.0002 s/iter. Total: 0.4408 s/iter. ETA=0:14:27\n",
            "\u001b[32m[04/30 19:14:35 d2.evaluation.evaluator]: \u001b[0mInference done 3043/5000. Dataloading: 0.0019 s/iter. Inference: 0.4385 s/iter. Eval: 0.0002 s/iter. Total: 0.4408 s/iter. ETA=0:14:22\n",
            "\u001b[32m[04/30 19:14:40 d2.evaluation.evaluator]: \u001b[0mInference done 3055/5000. Dataloading: 0.0019 s/iter. Inference: 0.4386 s/iter. Eval: 0.0002 s/iter. Total: 0.4408 s/iter. ETA=0:14:17\n",
            "\u001b[32m[04/30 19:14:46 d2.evaluation.evaluator]: \u001b[0mInference done 3067/5000. Dataloading: 0.0019 s/iter. Inference: 0.4386 s/iter. Eval: 0.0002 s/iter. Total: 0.4409 s/iter. ETA=0:14:12\n",
            "\u001b[32m[04/30 19:14:51 d2.evaluation.evaluator]: \u001b[0mInference done 3079/5000. Dataloading: 0.0019 s/iter. Inference: 0.4386 s/iter. Eval: 0.0002 s/iter. Total: 0.4409 s/iter. ETA=0:14:06\n",
            "\u001b[32m[04/30 19:14:57 d2.evaluation.evaluator]: \u001b[0mInference done 3091/5000. Dataloading: 0.0019 s/iter. Inference: 0.4386 s/iter. Eval: 0.0002 s/iter. Total: 0.4409 s/iter. ETA=0:14:01\n",
            "\u001b[32m[04/30 19:15:02 d2.evaluation.evaluator]: \u001b[0mInference done 3103/5000. Dataloading: 0.0019 s/iter. Inference: 0.4386 s/iter. Eval: 0.0002 s/iter. Total: 0.4409 s/iter. ETA=0:13:56\n",
            "\u001b[32m[04/30 19:15:07 d2.evaluation.evaluator]: \u001b[0mInference done 3115/5000. Dataloading: 0.0019 s/iter. Inference: 0.4386 s/iter. Eval: 0.0002 s/iter. Total: 0.4409 s/iter. ETA=0:13:51\n",
            "\u001b[32m[04/30 19:15:12 d2.evaluation.evaluator]: \u001b[0mInference done 3127/5000. Dataloading: 0.0019 s/iter. Inference: 0.4387 s/iter. Eval: 0.0002 s/iter. Total: 0.4409 s/iter. ETA=0:13:45\n",
            "\u001b[32m[04/30 19:15:18 d2.evaluation.evaluator]: \u001b[0mInference done 3139/5000. Dataloading: 0.0019 s/iter. Inference: 0.4387 s/iter. Eval: 0.0002 s/iter. Total: 0.4409 s/iter. ETA=0:13:40\n",
            "\u001b[32m[04/30 19:15:23 d2.evaluation.evaluator]: \u001b[0mInference done 3151/5000. Dataloading: 0.0019 s/iter. Inference: 0.4387 s/iter. Eval: 0.0002 s/iter. Total: 0.4410 s/iter. ETA=0:13:35\n",
            "\u001b[32m[04/30 19:15:28 d2.evaluation.evaluator]: \u001b[0mInference done 3163/5000. Dataloading: 0.0019 s/iter. Inference: 0.4387 s/iter. Eval: 0.0002 s/iter. Total: 0.4410 s/iter. ETA=0:13:30\n",
            "\u001b[32m[04/30 19:15:34 d2.evaluation.evaluator]: \u001b[0mInference done 3175/5000. Dataloading: 0.0019 s/iter. Inference: 0.4387 s/iter. Eval: 0.0002 s/iter. Total: 0.4410 s/iter. ETA=0:13:24\n",
            "\u001b[32m[04/30 19:15:39 d2.evaluation.evaluator]: \u001b[0mInference done 3187/5000. Dataloading: 0.0019 s/iter. Inference: 0.4387 s/iter. Eval: 0.0002 s/iter. Total: 0.4410 s/iter. ETA=0:13:19\n",
            "\u001b[32m[04/30 19:15:44 d2.evaluation.evaluator]: \u001b[0mInference done 3199/5000. Dataloading: 0.0019 s/iter. Inference: 0.4387 s/iter. Eval: 0.0002 s/iter. Total: 0.4410 s/iter. ETA=0:13:14\n",
            "\u001b[32m[04/30 19:15:50 d2.evaluation.evaluator]: \u001b[0mInference done 3211/5000. Dataloading: 0.0019 s/iter. Inference: 0.4387 s/iter. Eval: 0.0002 s/iter. Total: 0.4410 s/iter. ETA=0:13:08\n",
            "\u001b[32m[04/30 19:15:55 d2.evaluation.evaluator]: \u001b[0mInference done 3223/5000. Dataloading: 0.0019 s/iter. Inference: 0.4387 s/iter. Eval: 0.0002 s/iter. Total: 0.4410 s/iter. ETA=0:13:03\n",
            "\u001b[32m[04/30 19:16:00 d2.evaluation.evaluator]: \u001b[0mInference done 3235/5000. Dataloading: 0.0019 s/iter. Inference: 0.4388 s/iter. Eval: 0.0002 s/iter. Total: 0.4410 s/iter. ETA=0:12:58\n",
            "\u001b[32m[04/30 19:16:06 d2.evaluation.evaluator]: \u001b[0mInference done 3247/5000. Dataloading: 0.0019 s/iter. Inference: 0.4388 s/iter. Eval: 0.0002 s/iter. Total: 0.4411 s/iter. ETA=0:12:53\n",
            "\u001b[32m[04/30 19:16:11 d2.evaluation.evaluator]: \u001b[0mInference done 3259/5000. Dataloading: 0.0019 s/iter. Inference: 0.4388 s/iter. Eval: 0.0002 s/iter. Total: 0.4410 s/iter. ETA=0:12:47\n",
            "\u001b[32m[04/30 19:16:16 d2.evaluation.evaluator]: \u001b[0mInference done 3271/5000. Dataloading: 0.0019 s/iter. Inference: 0.4388 s/iter. Eval: 0.0002 s/iter. Total: 0.4411 s/iter. ETA=0:12:42\n",
            "\u001b[32m[04/30 19:16:22 d2.evaluation.evaluator]: \u001b[0mInference done 3283/5000. Dataloading: 0.0019 s/iter. Inference: 0.4388 s/iter. Eval: 0.0002 s/iter. Total: 0.4411 s/iter. ETA=0:12:37\n",
            "\u001b[32m[04/30 19:16:27 d2.evaluation.evaluator]: \u001b[0mInference done 3295/5000. Dataloading: 0.0019 s/iter. Inference: 0.4389 s/iter. Eval: 0.0002 s/iter. Total: 0.4411 s/iter. ETA=0:12:32\n",
            "\u001b[32m[04/30 19:16:32 d2.evaluation.evaluator]: \u001b[0mInference done 3307/5000. Dataloading: 0.0020 s/iter. Inference: 0.4389 s/iter. Eval: 0.0002 s/iter. Total: 0.4411 s/iter. ETA=0:12:26\n",
            "\u001b[32m[04/30 19:16:38 d2.evaluation.evaluator]: \u001b[0mInference done 3319/5000. Dataloading: 0.0020 s/iter. Inference: 0.4389 s/iter. Eval: 0.0002 s/iter. Total: 0.4411 s/iter. ETA=0:12:21\n",
            "\u001b[32m[04/30 19:16:43 d2.evaluation.evaluator]: \u001b[0mInference done 3331/5000. Dataloading: 0.0020 s/iter. Inference: 0.4389 s/iter. Eval: 0.0002 s/iter. Total: 0.4411 s/iter. ETA=0:12:16\n",
            "\u001b[32m[04/30 19:16:48 d2.evaluation.evaluator]: \u001b[0mInference done 3343/5000. Dataloading: 0.0020 s/iter. Inference: 0.4389 s/iter. Eval: 0.0002 s/iter. Total: 0.4411 s/iter. ETA=0:12:10\n",
            "\u001b[32m[04/30 19:16:54 d2.evaluation.evaluator]: \u001b[0mInference done 3355/5000. Dataloading: 0.0020 s/iter. Inference: 0.4389 s/iter. Eval: 0.0002 s/iter. Total: 0.4412 s/iter. ETA=0:12:05\n",
            "\u001b[32m[04/30 19:16:59 d2.evaluation.evaluator]: \u001b[0mInference done 3367/5000. Dataloading: 0.0020 s/iter. Inference: 0.4389 s/iter. Eval: 0.0002 s/iter. Total: 0.4412 s/iter. ETA=0:12:00\n",
            "\u001b[32m[04/30 19:17:04 d2.evaluation.evaluator]: \u001b[0mInference done 3379/5000. Dataloading: 0.0020 s/iter. Inference: 0.4389 s/iter. Eval: 0.0002 s/iter. Total: 0.4412 s/iter. ETA=0:11:55\n",
            "\u001b[32m[04/30 19:17:10 d2.evaluation.evaluator]: \u001b[0mInference done 3391/5000. Dataloading: 0.0020 s/iter. Inference: 0.4389 s/iter. Eval: 0.0002 s/iter. Total: 0.4412 s/iter. ETA=0:11:49\n",
            "\u001b[32m[04/30 19:17:15 d2.evaluation.evaluator]: \u001b[0mInference done 3403/5000. Dataloading: 0.0020 s/iter. Inference: 0.4389 s/iter. Eval: 0.0002 s/iter. Total: 0.4412 s/iter. ETA=0:11:44\n",
            "\u001b[32m[04/30 19:17:20 d2.evaluation.evaluator]: \u001b[0mInference done 3415/5000. Dataloading: 0.0019 s/iter. Inference: 0.4389 s/iter. Eval: 0.0002 s/iter. Total: 0.4412 s/iter. ETA=0:11:39\n",
            "\u001b[32m[04/30 19:17:26 d2.evaluation.evaluator]: \u001b[0mInference done 3427/5000. Dataloading: 0.0019 s/iter. Inference: 0.4389 s/iter. Eval: 0.0002 s/iter. Total: 0.4412 s/iter. ETA=0:11:33\n",
            "\u001b[32m[04/30 19:17:31 d2.evaluation.evaluator]: \u001b[0mInference done 3439/5000. Dataloading: 0.0019 s/iter. Inference: 0.4389 s/iter. Eval: 0.0002 s/iter. Total: 0.4412 s/iter. ETA=0:11:28\n",
            "\u001b[32m[04/30 19:17:36 d2.evaluation.evaluator]: \u001b[0mInference done 3451/5000. Dataloading: 0.0019 s/iter. Inference: 0.4389 s/iter. Eval: 0.0002 s/iter. Total: 0.4412 s/iter. ETA=0:11:23\n",
            "\u001b[32m[04/30 19:17:42 d2.evaluation.evaluator]: \u001b[0mInference done 3463/5000. Dataloading: 0.0019 s/iter. Inference: 0.4390 s/iter. Eval: 0.0002 s/iter. Total: 0.4412 s/iter. ETA=0:11:18\n",
            "\u001b[32m[04/30 19:17:47 d2.evaluation.evaluator]: \u001b[0mInference done 3475/5000. Dataloading: 0.0019 s/iter. Inference: 0.4390 s/iter. Eval: 0.0002 s/iter. Total: 0.4412 s/iter. ETA=0:11:12\n",
            "\u001b[32m[04/30 19:17:52 d2.evaluation.evaluator]: \u001b[0mInference done 3487/5000. Dataloading: 0.0019 s/iter. Inference: 0.4390 s/iter. Eval: 0.0002 s/iter. Total: 0.4412 s/iter. ETA=0:11:07\n",
            "\u001b[32m[04/30 19:17:58 d2.evaluation.evaluator]: \u001b[0mInference done 3499/5000. Dataloading: 0.0019 s/iter. Inference: 0.4390 s/iter. Eval: 0.0002 s/iter. Total: 0.4413 s/iter. ETA=0:11:02\n",
            "\u001b[32m[04/30 19:18:03 d2.evaluation.evaluator]: \u001b[0mInference done 3511/5000. Dataloading: 0.0019 s/iter. Inference: 0.4390 s/iter. Eval: 0.0002 s/iter. Total: 0.4413 s/iter. ETA=0:10:57\n",
            "\u001b[32m[04/30 19:18:08 d2.evaluation.evaluator]: \u001b[0mInference done 3523/5000. Dataloading: 0.0019 s/iter. Inference: 0.4390 s/iter. Eval: 0.0002 s/iter. Total: 0.4413 s/iter. ETA=0:10:51\n",
            "\u001b[32m[04/30 19:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 3535/5000. Dataloading: 0.0019 s/iter. Inference: 0.4390 s/iter. Eval: 0.0002 s/iter. Total: 0.4413 s/iter. ETA=0:10:46\n",
            "\u001b[32m[04/30 19:18:19 d2.evaluation.evaluator]: \u001b[0mInference done 3547/5000. Dataloading: 0.0019 s/iter. Inference: 0.4390 s/iter. Eval: 0.0002 s/iter. Total: 0.4413 s/iter. ETA=0:10:41\n",
            "\u001b[32m[04/30 19:18:24 d2.evaluation.evaluator]: \u001b[0mInference done 3559/5000. Dataloading: 0.0019 s/iter. Inference: 0.4390 s/iter. Eval: 0.0002 s/iter. Total: 0.4413 s/iter. ETA=0:10:35\n",
            "\u001b[32m[04/30 19:18:30 d2.evaluation.evaluator]: \u001b[0mInference done 3571/5000. Dataloading: 0.0019 s/iter. Inference: 0.4390 s/iter. Eval: 0.0002 s/iter. Total: 0.4413 s/iter. ETA=0:10:30\n",
            "\u001b[32m[04/30 19:18:35 d2.evaluation.evaluator]: \u001b[0mInference done 3583/5000. Dataloading: 0.0019 s/iter. Inference: 0.4390 s/iter. Eval: 0.0002 s/iter. Total: 0.4413 s/iter. ETA=0:10:25\n",
            "\u001b[32m[04/30 19:18:40 d2.evaluation.evaluator]: \u001b[0mInference done 3595/5000. Dataloading: 0.0019 s/iter. Inference: 0.4390 s/iter. Eval: 0.0002 s/iter. Total: 0.4413 s/iter. ETA=0:10:20\n",
            "\u001b[32m[04/30 19:18:46 d2.evaluation.evaluator]: \u001b[0mInference done 3607/5000. Dataloading: 0.0019 s/iter. Inference: 0.4390 s/iter. Eval: 0.0002 s/iter. Total: 0.4413 s/iter. ETA=0:10:14\n",
            "\u001b[32m[04/30 19:18:51 d2.evaluation.evaluator]: \u001b[0mInference done 3619/5000. Dataloading: 0.0019 s/iter. Inference: 0.4391 s/iter. Eval: 0.0002 s/iter. Total: 0.4413 s/iter. ETA=0:10:09\n",
            "\u001b[32m[04/30 19:18:56 d2.evaluation.evaluator]: \u001b[0mInference done 3631/5000. Dataloading: 0.0019 s/iter. Inference: 0.4391 s/iter. Eval: 0.0002 s/iter. Total: 0.4413 s/iter. ETA=0:10:04\n",
            "\u001b[32m[04/30 19:19:02 d2.evaluation.evaluator]: \u001b[0mInference done 3643/5000. Dataloading: 0.0020 s/iter. Inference: 0.4391 s/iter. Eval: 0.0002 s/iter. Total: 0.4414 s/iter. ETA=0:09:58\n",
            "\u001b[32m[04/30 19:19:07 d2.evaluation.evaluator]: \u001b[0mInference done 3655/5000. Dataloading: 0.0019 s/iter. Inference: 0.4391 s/iter. Eval: 0.0002 s/iter. Total: 0.4414 s/iter. ETA=0:09:53\n",
            "\u001b[32m[04/30 19:19:12 d2.evaluation.evaluator]: \u001b[0mInference done 3667/5000. Dataloading: 0.0019 s/iter. Inference: 0.4391 s/iter. Eval: 0.0002 s/iter. Total: 0.4414 s/iter. ETA=0:09:48\n",
            "\u001b[32m[04/30 19:19:18 d2.evaluation.evaluator]: \u001b[0mInference done 3679/5000. Dataloading: 0.0019 s/iter. Inference: 0.4391 s/iter. Eval: 0.0002 s/iter. Total: 0.4414 s/iter. ETA=0:09:43\n",
            "\u001b[32m[04/30 19:19:23 d2.evaluation.evaluator]: \u001b[0mInference done 3691/5000. Dataloading: 0.0020 s/iter. Inference: 0.4391 s/iter. Eval: 0.0002 s/iter. Total: 0.4414 s/iter. ETA=0:09:37\n",
            "\u001b[32m[04/30 19:19:28 d2.evaluation.evaluator]: \u001b[0mInference done 3703/5000. Dataloading: 0.0020 s/iter. Inference: 0.4391 s/iter. Eval: 0.0002 s/iter. Total: 0.4414 s/iter. ETA=0:09:32\n",
            "\u001b[32m[04/30 19:19:33 d2.evaluation.evaluator]: \u001b[0mInference done 3715/5000. Dataloading: 0.0020 s/iter. Inference: 0.4391 s/iter. Eval: 0.0002 s/iter. Total: 0.4414 s/iter. ETA=0:09:27\n",
            "\u001b[32m[04/30 19:19:39 d2.evaluation.evaluator]: \u001b[0mInference done 3727/5000. Dataloading: 0.0020 s/iter. Inference: 0.4392 s/iter. Eval: 0.0002 s/iter. Total: 0.4414 s/iter. ETA=0:09:21\n",
            "\u001b[32m[04/30 19:19:44 d2.evaluation.evaluator]: \u001b[0mInference done 3739/5000. Dataloading: 0.0020 s/iter. Inference: 0.4392 s/iter. Eval: 0.0002 s/iter. Total: 0.4414 s/iter. ETA=0:09:16\n",
            "\u001b[32m[04/30 19:19:50 d2.evaluation.evaluator]: \u001b[0mInference done 3751/5000. Dataloading: 0.0020 s/iter. Inference: 0.4392 s/iter. Eval: 0.0002 s/iter. Total: 0.4414 s/iter. ETA=0:09:11\n",
            "\u001b[32m[04/30 19:19:55 d2.evaluation.evaluator]: \u001b[0mInference done 3763/5000. Dataloading: 0.0020 s/iter. Inference: 0.4392 s/iter. Eval: 0.0002 s/iter. Total: 0.4414 s/iter. ETA=0:09:06\n",
            "\u001b[32m[04/30 19:20:00 d2.evaluation.evaluator]: \u001b[0mInference done 3775/5000. Dataloading: 0.0020 s/iter. Inference: 0.4392 s/iter. Eval: 0.0002 s/iter. Total: 0.4414 s/iter. ETA=0:09:00\n",
            "\u001b[32m[04/30 19:20:06 d2.evaluation.evaluator]: \u001b[0mInference done 3787/5000. Dataloading: 0.0020 s/iter. Inference: 0.4392 s/iter. Eval: 0.0002 s/iter. Total: 0.4415 s/iter. ETA=0:08:55\n",
            "\u001b[32m[04/30 19:20:11 d2.evaluation.evaluator]: \u001b[0mInference done 3799/5000. Dataloading: 0.0020 s/iter. Inference: 0.4392 s/iter. Eval: 0.0002 s/iter. Total: 0.4415 s/iter. ETA=0:08:50\n",
            "\u001b[32m[04/30 19:20:16 d2.evaluation.evaluator]: \u001b[0mInference done 3811/5000. Dataloading: 0.0020 s/iter. Inference: 0.4392 s/iter. Eval: 0.0002 s/iter. Total: 0.4415 s/iter. ETA=0:08:44\n",
            "\u001b[32m[04/30 19:20:21 d2.evaluation.evaluator]: \u001b[0mInference done 3823/5000. Dataloading: 0.0020 s/iter. Inference: 0.4392 s/iter. Eval: 0.0002 s/iter. Total: 0.4415 s/iter. ETA=0:08:39\n",
            "\u001b[32m[04/30 19:20:27 d2.evaluation.evaluator]: \u001b[0mInference done 3835/5000. Dataloading: 0.0020 s/iter. Inference: 0.4392 s/iter. Eval: 0.0002 s/iter. Total: 0.4415 s/iter. ETA=0:08:34\n",
            "\u001b[32m[04/30 19:20:32 d2.evaluation.evaluator]: \u001b[0mInference done 3847/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4415 s/iter. ETA=0:08:29\n",
            "\u001b[32m[04/30 19:20:38 d2.evaluation.evaluator]: \u001b[0mInference done 3859/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:08:23\n",
            "\u001b[32m[04/30 19:20:43 d2.evaluation.evaluator]: \u001b[0mInference done 3871/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:08:18\n",
            "\u001b[32m[04/30 19:20:48 d2.evaluation.evaluator]: \u001b[0mInference done 3883/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:08:13\n",
            "\u001b[32m[04/30 19:20:54 d2.evaluation.evaluator]: \u001b[0mInference done 3895/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:08:07\n",
            "\u001b[32m[04/30 19:20:59 d2.evaluation.evaluator]: \u001b[0mInference done 3907/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:08:02\n",
            "\u001b[32m[04/30 19:21:04 d2.evaluation.evaluator]: \u001b[0mInference done 3919/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:07:57\n",
            "\u001b[32m[04/30 19:21:09 d2.evaluation.evaluator]: \u001b[0mInference done 3931/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:07:52\n",
            "\u001b[32m[04/30 19:21:15 d2.evaluation.evaluator]: \u001b[0mInference done 3943/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4415 s/iter. ETA=0:07:46\n",
            "\u001b[32m[04/30 19:21:20 d2.evaluation.evaluator]: \u001b[0mInference done 3955/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:07:41\n",
            "\u001b[32m[04/30 19:21:25 d2.evaluation.evaluator]: \u001b[0mInference done 3967/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:07:36\n",
            "\u001b[32m[04/30 19:21:31 d2.evaluation.evaluator]: \u001b[0mInference done 3979/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:07:30\n",
            "\u001b[32m[04/30 19:21:36 d2.evaluation.evaluator]: \u001b[0mInference done 3991/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:07:25\n",
            "\u001b[32m[04/30 19:21:41 d2.evaluation.evaluator]: \u001b[0mInference done 4003/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:07:20\n",
            "\u001b[32m[04/30 19:21:47 d2.evaluation.evaluator]: \u001b[0mInference done 4015/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:07:14\n",
            "\u001b[32m[04/30 19:21:52 d2.evaluation.evaluator]: \u001b[0mInference done 4027/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:07:09\n",
            "\u001b[32m[04/30 19:21:57 d2.evaluation.evaluator]: \u001b[0mInference done 4039/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:07:04\n",
            "\u001b[32m[04/30 19:22:03 d2.evaluation.evaluator]: \u001b[0mInference done 4051/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:06:59\n",
            "\u001b[32m[04/30 19:22:08 d2.evaluation.evaluator]: \u001b[0mInference done 4063/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:06:53\n",
            "\u001b[32m[04/30 19:22:13 d2.evaluation.evaluator]: \u001b[0mInference done 4075/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:06:48\n",
            "\u001b[32m[04/30 19:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 4087/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:06:43\n",
            "\u001b[32m[04/30 19:22:24 d2.evaluation.evaluator]: \u001b[0mInference done 4099/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:06:37\n",
            "\u001b[32m[04/30 19:22:29 d2.evaluation.evaluator]: \u001b[0mInference done 4111/5000. Dataloading: 0.0020 s/iter. Inference: 0.4393 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:06:32\n",
            "\u001b[32m[04/30 19:22:35 d2.evaluation.evaluator]: \u001b[0mInference done 4123/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4416 s/iter. ETA=0:06:27\n",
            "\u001b[32m[04/30 19:22:40 d2.evaluation.evaluator]: \u001b[0mInference done 4135/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:06:22\n",
            "\u001b[32m[04/30 19:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 4147/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:06:16\n",
            "\u001b[32m[04/30 19:22:51 d2.evaluation.evaluator]: \u001b[0mInference done 4159/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:06:11\n",
            "\u001b[32m[04/30 19:22:56 d2.evaluation.evaluator]: \u001b[0mInference done 4171/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:06:06\n",
            "\u001b[32m[04/30 19:23:01 d2.evaluation.evaluator]: \u001b[0mInference done 4183/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:06:00\n",
            "\u001b[32m[04/30 19:23:07 d2.evaluation.evaluator]: \u001b[0mInference done 4195/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:05:55\n",
            "\u001b[32m[04/30 19:23:12 d2.evaluation.evaluator]: \u001b[0mInference done 4207/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:05:50\n",
            "\u001b[32m[04/30 19:23:17 d2.evaluation.evaluator]: \u001b[0mInference done 4219/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:05:44\n",
            "\u001b[32m[04/30 19:23:22 d2.evaluation.evaluator]: \u001b[0mInference done 4231/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:05:39\n",
            "\u001b[32m[04/30 19:23:28 d2.evaluation.evaluator]: \u001b[0mInference done 4243/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:05:34\n",
            "\u001b[32m[04/30 19:23:33 d2.evaluation.evaluator]: \u001b[0mInference done 4255/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:05:29\n",
            "\u001b[32m[04/30 19:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 4267/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:05:23\n",
            "\u001b[32m[04/30 19:23:44 d2.evaluation.evaluator]: \u001b[0mInference done 4279/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:05:18\n",
            "\u001b[32m[04/30 19:23:49 d2.evaluation.evaluator]: \u001b[0mInference done 4291/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:05:13\n",
            "\u001b[32m[04/30 19:23:54 d2.evaluation.evaluator]: \u001b[0mInference done 4302/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:05:08\n",
            "\u001b[32m[04/30 19:23:59 d2.evaluation.evaluator]: \u001b[0mInference done 4314/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:05:03\n",
            "\u001b[32m[04/30 19:24:05 d2.evaluation.evaluator]: \u001b[0mInference done 4326/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:04:57\n",
            "\u001b[32m[04/30 19:24:10 d2.evaluation.evaluator]: \u001b[0mInference done 4338/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:04:52\n",
            "\u001b[32m[04/30 19:24:15 d2.evaluation.evaluator]: \u001b[0mInference done 4350/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:04:47\n",
            "\u001b[32m[04/30 19:24:21 d2.evaluation.evaluator]: \u001b[0mInference done 4362/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:04:41\n",
            "\u001b[32m[04/30 19:24:26 d2.evaluation.evaluator]: \u001b[0mInference done 4374/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:04:36\n",
            "\u001b[32m[04/30 19:24:31 d2.evaluation.evaluator]: \u001b[0mInference done 4386/5000. Dataloading: 0.0020 s/iter. Inference: 0.4394 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:04:31\n",
            "\u001b[32m[04/30 19:24:36 d2.evaluation.evaluator]: \u001b[0mInference done 4398/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:04:25\n",
            "\u001b[32m[04/30 19:24:42 d2.evaluation.evaluator]: \u001b[0mInference done 4410/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:04:20\n",
            "\u001b[32m[04/30 19:24:47 d2.evaluation.evaluator]: \u001b[0mInference done 4422/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:04:15\n",
            "\u001b[32m[04/30 19:24:52 d2.evaluation.evaluator]: \u001b[0mInference done 4434/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:04:10\n",
            "\u001b[32m[04/30 19:24:58 d2.evaluation.evaluator]: \u001b[0mInference done 4446/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4417 s/iter. ETA=0:04:04\n",
            "\u001b[32m[04/30 19:25:03 d2.evaluation.evaluator]: \u001b[0mInference done 4458/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:03:59\n",
            "\u001b[32m[04/30 19:25:08 d2.evaluation.evaluator]: \u001b[0mInference done 4470/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:03:54\n",
            "\u001b[32m[04/30 19:25:14 d2.evaluation.evaluator]: \u001b[0mInference done 4482/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:03:48\n",
            "\u001b[32m[04/30 19:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 4494/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:03:43\n",
            "\u001b[32m[04/30 19:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 4506/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:03:38\n",
            "\u001b[32m[04/30 19:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 4518/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:03:32\n",
            "\u001b[32m[04/30 19:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 4530/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:03:27\n",
            "\u001b[32m[04/30 19:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 4542/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:03:22\n",
            "\u001b[32m[04/30 19:25:46 d2.evaluation.evaluator]: \u001b[0mInference done 4554/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:03:17\n",
            "\u001b[32m[04/30 19:25:51 d2.evaluation.evaluator]: \u001b[0mInference done 4566/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:03:11\n",
            "\u001b[32m[04/30 19:25:56 d2.evaluation.evaluator]: \u001b[0mInference done 4578/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:03:06\n",
            "\u001b[32m[04/30 19:26:02 d2.evaluation.evaluator]: \u001b[0mInference done 4590/5000. Dataloading: 0.0020 s/iter. Inference: 0.4395 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:03:01\n",
            "\u001b[32m[04/30 19:26:07 d2.evaluation.evaluator]: \u001b[0mInference done 4602/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:02:55\n",
            "\u001b[32m[04/30 19:26:12 d2.evaluation.evaluator]: \u001b[0mInference done 4614/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:02:50\n",
            "\u001b[32m[04/30 19:26:18 d2.evaluation.evaluator]: \u001b[0mInference done 4626/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:02:45\n",
            "\u001b[32m[04/30 19:26:23 d2.evaluation.evaluator]: \u001b[0mInference done 4638/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:02:39\n",
            "\u001b[32m[04/30 19:26:28 d2.evaluation.evaluator]: \u001b[0mInference done 4650/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:02:34\n",
            "\u001b[32m[04/30 19:26:34 d2.evaluation.evaluator]: \u001b[0mInference done 4662/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:02:29\n",
            "\u001b[32m[04/30 19:26:39 d2.evaluation.evaluator]: \u001b[0mInference done 4674/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:02:24\n",
            "\u001b[32m[04/30 19:26:44 d2.evaluation.evaluator]: \u001b[0mInference done 4686/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4418 s/iter. ETA=0:02:18\n",
            "\u001b[32m[04/30 19:26:50 d2.evaluation.evaluator]: \u001b[0mInference done 4698/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:02:13\n",
            "\u001b[32m[04/30 19:26:55 d2.evaluation.evaluator]: \u001b[0mInference done 4710/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:02:08\n",
            "\u001b[32m[04/30 19:27:00 d2.evaluation.evaluator]: \u001b[0mInference done 4722/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:02:02\n",
            "\u001b[32m[04/30 19:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 4734/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:01:57\n",
            "\u001b[32m[04/30 19:27:11 d2.evaluation.evaluator]: \u001b[0mInference done 4746/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:01:52\n",
            "\u001b[32m[04/30 19:27:16 d2.evaluation.evaluator]: \u001b[0mInference done 4758/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:01:46\n",
            "\u001b[32m[04/30 19:27:22 d2.evaluation.evaluator]: \u001b[0mInference done 4770/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:01:41\n",
            "\u001b[32m[04/30 19:27:27 d2.evaluation.evaluator]: \u001b[0mInference done 4782/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:01:36\n",
            "\u001b[32m[04/30 19:27:32 d2.evaluation.evaluator]: \u001b[0mInference done 4794/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:01:31\n",
            "\u001b[32m[04/30 19:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 4806/5000. Dataloading: 0.0020 s/iter. Inference: 0.4397 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:01:25\n",
            "\u001b[32m[04/30 19:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 4818/5000. Dataloading: 0.0020 s/iter. Inference: 0.4397 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:01:20\n",
            "\u001b[32m[04/30 19:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 4830/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:01:15\n",
            "\u001b[32m[04/30 19:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 4842/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:01:09\n",
            "\u001b[32m[04/30 19:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 4854/5000. Dataloading: 0.0020 s/iter. Inference: 0.4396 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:01:04\n",
            "\u001b[32m[04/30 19:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 4866/5000. Dataloading: 0.0020 s/iter. Inference: 0.4397 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:00:59\n",
            "\u001b[32m[04/30 19:28:10 d2.evaluation.evaluator]: \u001b[0mInference done 4878/5000. Dataloading: 0.0020 s/iter. Inference: 0.4397 s/iter. Eval: 0.0002 s/iter. Total: 0.4419 s/iter. ETA=0:00:53\n",
            "\u001b[32m[04/30 19:28:15 d2.evaluation.evaluator]: \u001b[0mInference done 4890/5000. Dataloading: 0.0020 s/iter. Inference: 0.4397 s/iter. Eval: 0.0002 s/iter. Total: 0.4420 s/iter. ETA=0:00:48\n",
            "\u001b[32m[04/30 19:28:20 d2.evaluation.evaluator]: \u001b[0mInference done 4902/5000. Dataloading: 0.0020 s/iter. Inference: 0.4397 s/iter. Eval: 0.0002 s/iter. Total: 0.4420 s/iter. ETA=0:00:43\n",
            "\u001b[32m[04/30 19:28:26 d2.evaluation.evaluator]: \u001b[0mInference done 4914/5000. Dataloading: 0.0020 s/iter. Inference: 0.4397 s/iter. Eval: 0.0002 s/iter. Total: 0.4420 s/iter. ETA=0:00:38\n",
            "\u001b[32m[04/30 19:28:31 d2.evaluation.evaluator]: \u001b[0mInference done 4926/5000. Dataloading: 0.0020 s/iter. Inference: 0.4397 s/iter. Eval: 0.0002 s/iter. Total: 0.4420 s/iter. ETA=0:00:32\n",
            "\u001b[32m[04/30 19:28:36 d2.evaluation.evaluator]: \u001b[0mInference done 4938/5000. Dataloading: 0.0020 s/iter. Inference: 0.4397 s/iter. Eval: 0.0002 s/iter. Total: 0.4420 s/iter. ETA=0:00:27\n",
            "\u001b[32m[04/30 19:28:42 d2.evaluation.evaluator]: \u001b[0mInference done 4950/5000. Dataloading: 0.0020 s/iter. Inference: 0.4397 s/iter. Eval: 0.0002 s/iter. Total: 0.4420 s/iter. ETA=0:00:22\n",
            "\u001b[32m[04/30 19:28:47 d2.evaluation.evaluator]: \u001b[0mInference done 4962/5000. Dataloading: 0.0020 s/iter. Inference: 0.4397 s/iter. Eval: 0.0002 s/iter. Total: 0.4420 s/iter. ETA=0:00:16\n",
            "\u001b[32m[04/30 19:28:52 d2.evaluation.evaluator]: \u001b[0mInference done 4974/5000. Dataloading: 0.0020 s/iter. Inference: 0.4397 s/iter. Eval: 0.0002 s/iter. Total: 0.4420 s/iter. ETA=0:00:11\n",
            "\u001b[32m[04/30 19:28:58 d2.evaluation.evaluator]: \u001b[0mInference done 4986/5000. Dataloading: 0.0020 s/iter. Inference: 0.4397 s/iter. Eval: 0.0002 s/iter. Total: 0.4420 s/iter. ETA=0:00:06\n",
            "\u001b[32m[04/30 19:29:03 d2.evaluation.evaluator]: \u001b[0mInference done 4998/5000. Dataloading: 0.0020 s/iter. Inference: 0.4398 s/iter. Eval: 0.0002 s/iter. Total: 0.4420 s/iter. ETA=0:00:00\n",
            "\u001b[32m[04/30 19:29:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:36:48.094547 (0.442061 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 19:29:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:36:36 (0.439750 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 19:29:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/30 19:29:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/30 19:29:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.38s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 19:29:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/30 19:29:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 7.77 seconds.\n",
            "\u001b[32m[04/30 19:29:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 19:29:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.94 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.661\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.513\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.510\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.612\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.366\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.579\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.606\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.426\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.638\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.745\n",
            "\u001b[32m[04/30 19:29:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 47.508 | 66.056 | 51.349 | 30.249 | 50.962 | 61.231 |\n",
            "\u001b[32m[04/30 19:29:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 60.123 | bicycle      | 34.951 | car            | 49.954 |\n",
            "| motorcycle    | 49.136 | airplane     | 71.193 | bus            | 70.552 |\n",
            "| train         | 71.791 | truck        | 40.101 | boat           | 32.294 |\n",
            "| traffic light | 31.408 | fire hydrant | 72.222 | stop sign      | 70.298 |\n",
            "| parking meter | 49.809 | bench        | 29.185 | bird           | 42.066 |\n",
            "| cat           | 76.512 | dog          | 69.653 | horse          | 62.752 |\n",
            "| sheep         | 58.588 | cow          | 63.351 | elephant       | 69.908 |\n",
            "| bear          | 73.065 | zebra        | 71.753 | giraffe        | 74.048 |\n",
            "| backpack      | 17.218 | umbrella     | 45.412 | handbag        | 19.663 |\n",
            "| tie           | 40.615 | suitcase     | 47.777 | frisbee        | 73.548 |\n",
            "| skis          | 30.963 | snowboard    | 46.739 | sports ball    | 52.287 |\n",
            "| kite          | 49.964 | baseball bat | 39.410 | baseball glove | 43.322 |\n",
            "| skateboard    | 63.283 | surfboard    | 43.452 | tennis racket  | 57.301 |\n",
            "| bottle        | 45.317 | wine glass   | 42.004 | cup            | 49.041 |\n",
            "| fork          | 45.266 | knife        | 27.801 | spoon          | 26.628 |\n",
            "| bowl          | 45.113 | banana       | 28.656 | apple          | 25.312 |\n",
            "| sandwich      | 41.144 | orange       | 32.879 | broccoli       | 26.826 |\n",
            "| carrot        | 25.494 | hot dog      | 41.003 | pizza          | 55.735 |\n",
            "| donut         | 53.319 | cake         | 41.308 | chair          | 33.376 |\n",
            "| couch         | 44.593 | potted plant | 32.350 | bed            | 46.334 |\n",
            "| dining table  | 33.053 | toilet       | 64.892 | tv             | 60.737 |\n",
            "| laptop        | 66.446 | mouse        | 67.721 | remote         | 43.476 |\n",
            "| keyboard      | 55.992 | cell phone   | 45.062 | microwave      | 61.540 |\n",
            "| oven          | 37.397 | toaster      | 33.557 | sink           | 40.488 |\n",
            "| refrigerator  | 62.512 | book         | 18.981 | clock          | 57.020 |\n",
            "| vase          | 41.415 | scissors     | 39.691 | teddy bear     | 54.327 |\n",
            "| hair drier    | 6.238  | toothbrush   | 34.896 |                |        |\n",
            "\u001b[32m[04/30 19:29:16 d2.engine.defaults]: \u001b[0mEvaluation results for coco_2017_val in csv format:\n",
            "\u001b[32m[04/30 19:29:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/30 19:29:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 19:29:16 d2.evaluation.testing]: \u001b[0mcopypaste: 47.5076,66.0564,51.3485,30.2491,50.9618,61.2314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "faster_cascade_rcnn_ResNeSt_101 - evaluation results for coco_2017_val in csv format:\n",
        "\n",
        "Task\\metrics  | AP | AP50 | AP75 | APs | APm | APl |\n",
        "--------------|----|------|------|-----|-----|-----|\n",
        "**bbox**    | 47.5076 | 66.0564 | 51.3485 | 30.2491 | 50.9618 | 61.2314"
      ],
      "metadata": {
        "id": "i6Tox09I9dbJ"
      },
      "id": "i6Tox09I9dbJ"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_200_FPN_syncbn_range-scale_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-ObjectDetection/faster_cascade_rcnn_ResNeSt_200_FPN_syncbn_range-scale_1x-1be2a87e.pth"
      ],
      "metadata": {
        "id": "36W3Ai_J9MLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01562cf1-b0f5-45a8-ef6c-2e1b536e497f"
      },
      "id": "36W3Ai_J9MLw",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command Line Args: Namespace(config_file='./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_200_FPN_syncbn_range-scale_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-ObjectDetection1/faster_cascade_rcnn_ResNeSt_200_FPN_syncbn_range-scale_1x-1be2a87e.pth'], resume=False)\n",
            "\u001b[32m[04/30 19:30:35 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[04/30 19:30:36 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ----------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "numpy                   1.21.6\n",
            "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.5\n",
            "CUDA compiler           CUDA 11.1\n",
            "detectron2 arch flags   7.5\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.11.0+cu113 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           Yes\n",
            "GPU 0                   Tesla T4 (arch=7.5)\n",
            "Driver version          460.32.03\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.12.0+cu113 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
            "fvcore                  0.1.5.post20220414\n",
            "iopath                  0.1.9\n",
            "cv2                     4.1.2\n",
            "----------------------  ----------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.3\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.2\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "\u001b[32m[04/30 19:30:36 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_200_FPN_syncbn_range-scale_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-ObjectDetection1/faster_cascade_rcnn_ResNeSt_200_FPN_syncbn_range-scale_1x-1be2a87e.pth'], resume=False)\n",
            "\u001b[32m[04/30 19:30:36 detectron2]: \u001b[0mContents of args.config_file=./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_200_FPN_syncbn_range-scale_1x.yaml:\n",
            "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186m../ResNest-Base-RCNN-FPN.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mhttps://s3.us-west-1.wasabisys.com/resnest/detectron/resnest200_detectron-02644020.pth\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mFastRCNNConvFCHead\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m123.68\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m116.779\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m103.939\u001b[39m]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m58.393\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.12\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.375\u001b[39m]\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\u001b[38;5;15m  \u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\u001b[38;5;15m    \u001b[39m\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m(640, 800)\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mrange\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mRGB\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\n",
            "\u001b[32m[04/30 19:30:36 detectron2]: \u001b[0mRunning with full config:\n",
            "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRGB\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mpolygon\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrange\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnest_fpn_backbone\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGeneralizedRCNN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.68\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.779\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.939\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m58.393\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.12\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.375\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRPN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVG_DOWN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOTTLENECK_WIDTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEEP_STEM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_NUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFastRCNNConvFCHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_FED_LOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_SIGMOID_CE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./checkpoints/COCO-ObjectDetection1/faster_cascade_rcnn_ResNeSt_200_FPN_syncbn_range-scale_1x-1be2a87e.pth\n",
            "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./output\n",
            "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR_END\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m90000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m60000\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m80000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\n",
            "\u001b[32m[04/30 19:30:36 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[04/30 19:30:36 d2.utils.env]: \u001b[0mUsing a generated random seed 36773353\n",
            "\u001b[32m[04/30 19:30:42 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(\n",
            "      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output2): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral3): Conv2d(\n",
            "      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output3): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral4): Conv2d(\n",
            "      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output4): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral5): Conv2d(\n",
            "      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output5): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNeSt(\n",
            "      (stem): BasicStem(\n",
            "        (conv1_1): Conv2d(\n",
            "          3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv1_2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv1_3): Conv2d(\n",
            "          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (23): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (23): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (24): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (25): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (26): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (27): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (28): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (29): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (30): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (31): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (32): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (33): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (34): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (35): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): CascadeROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): ModuleList(\n",
            "      (0): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (1): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (2): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): ModuleList(\n",
            "      (0): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (1): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (2): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/30 19:30:42 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from ./checkpoints/COCO-ObjectDetection1/faster_cascade_rcnn_ResNeSt_200_FPN_syncbn_range-scale_1x-1be2a87e.pth ...\n",
            "\u001b[32m[04/30 19:30:53 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
            "| Names in Model                                  | Names in Checkpoint                                                                                                           | Shapes                                             |\n",
            "|:------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------|\n",
            "| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,128,1,1)               |\n",
            "| backbone.bottom_up.res2.0.conv2.bn0.*           | backbone.bottom_up.res2.0.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.0.conv2.bn1.*           | backbone.bottom_up.res2.0.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.0.conv2.conv.weight     | backbone.bottom_up.res2.0.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.0.conv2.fc1.*           | backbone.bottom_up.res2.0.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.0.conv2.fc2.*           | backbone.bottom_up.res2.0.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,128,1,1)          |\n",
            "| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.1.conv2.bn0.*           | backbone.bottom_up.res2.1.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.1.conv2.bn1.*           | backbone.bottom_up.res2.1.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.1.conv2.conv.weight     | backbone.bottom_up.res2.1.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.1.conv2.fc1.*           | backbone.bottom_up.res2.1.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.1.conv2.fc2.*           | backbone.bottom_up.res2.1.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.2.conv2.bn0.*           | backbone.bottom_up.res2.2.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.2.conv2.bn1.*           | backbone.bottom_up.res2.2.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.2.conv2.conv.weight     | backbone.bottom_up.res2.2.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.2.conv2.fc1.*           | backbone.bottom_up.res2.2.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.2.conv2.fc2.*           | backbone.bottom_up.res2.2.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv2.bn0.*           | backbone.bottom_up.res3.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.0.conv2.bn1.*           | backbone.bottom_up.res3.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.0.conv2.conv.weight     | backbone.bottom_up.res3.0.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.0.conv2.fc1.*           | backbone.bottom_up.res3.0.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.0.conv2.fc2.*           | backbone.bottom_up.res3.0.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv2.bn0.*           | backbone.bottom_up.res3.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.1.conv2.bn1.*           | backbone.bottom_up.res3.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.1.conv2.conv.weight     | backbone.bottom_up.res3.1.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.1.conv2.fc1.*           | backbone.bottom_up.res3.1.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.1.conv2.fc2.*           | backbone.bottom_up.res3.1.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.10.conv1.*              | backbone.bottom_up.res3.10.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.10.conv2.bn0.*          | backbone.bottom_up.res3.10.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.10.conv2.bn1.*          | backbone.bottom_up.res3.10.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.10.conv2.conv.weight    | backbone.bottom_up.res3.10.conv2.conv.weight                                                                                  | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.10.conv2.fc1.*          | backbone.bottom_up.res3.10.conv2.fc1.{bias,weight}                                                                            | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.10.conv2.fc2.*          | backbone.bottom_up.res3.10.conv2.fc2.{bias,weight}                                                                            | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.10.conv3.*              | backbone.bottom_up.res3.10.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.11.conv1.*              | backbone.bottom_up.res3.11.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.11.conv2.bn0.*          | backbone.bottom_up.res3.11.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.11.conv2.bn1.*          | backbone.bottom_up.res3.11.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.11.conv2.conv.weight    | backbone.bottom_up.res3.11.conv2.conv.weight                                                                                  | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.11.conv2.fc1.*          | backbone.bottom_up.res3.11.conv2.fc1.{bias,weight}                                                                            | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.11.conv2.fc2.*          | backbone.bottom_up.res3.11.conv2.fc2.{bias,weight}                                                                            | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.11.conv3.*              | backbone.bottom_up.res3.11.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.12.conv1.*              | backbone.bottom_up.res3.12.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.12.conv2.bn0.*          | backbone.bottom_up.res3.12.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.12.conv2.bn1.*          | backbone.bottom_up.res3.12.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.12.conv2.conv.weight    | backbone.bottom_up.res3.12.conv2.conv.weight                                                                                  | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.12.conv2.fc1.*          | backbone.bottom_up.res3.12.conv2.fc1.{bias,weight}                                                                            | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.12.conv2.fc2.*          | backbone.bottom_up.res3.12.conv2.fc2.{bias,weight}                                                                            | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.12.conv3.*              | backbone.bottom_up.res3.12.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.13.conv1.*              | backbone.bottom_up.res3.13.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.13.conv2.bn0.*          | backbone.bottom_up.res3.13.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.13.conv2.bn1.*          | backbone.bottom_up.res3.13.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.13.conv2.conv.weight    | backbone.bottom_up.res3.13.conv2.conv.weight                                                                                  | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.13.conv2.fc1.*          | backbone.bottom_up.res3.13.conv2.fc1.{bias,weight}                                                                            | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.13.conv2.fc2.*          | backbone.bottom_up.res3.13.conv2.fc2.{bias,weight}                                                                            | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.13.conv3.*              | backbone.bottom_up.res3.13.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.14.conv1.*              | backbone.bottom_up.res3.14.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.14.conv2.bn0.*          | backbone.bottom_up.res3.14.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.14.conv2.bn1.*          | backbone.bottom_up.res3.14.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.14.conv2.conv.weight    | backbone.bottom_up.res3.14.conv2.conv.weight                                                                                  | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.14.conv2.fc1.*          | backbone.bottom_up.res3.14.conv2.fc1.{bias,weight}                                                                            | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.14.conv2.fc2.*          | backbone.bottom_up.res3.14.conv2.fc2.{bias,weight}                                                                            | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.14.conv3.*              | backbone.bottom_up.res3.14.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.15.conv1.*              | backbone.bottom_up.res3.15.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.15.conv2.bn0.*          | backbone.bottom_up.res3.15.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.15.conv2.bn1.*          | backbone.bottom_up.res3.15.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.15.conv2.conv.weight    | backbone.bottom_up.res3.15.conv2.conv.weight                                                                                  | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.15.conv2.fc1.*          | backbone.bottom_up.res3.15.conv2.fc1.{bias,weight}                                                                            | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.15.conv2.fc2.*          | backbone.bottom_up.res3.15.conv2.fc2.{bias,weight}                                                                            | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.15.conv3.*              | backbone.bottom_up.res3.15.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.16.conv1.*              | backbone.bottom_up.res3.16.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.16.conv2.bn0.*          | backbone.bottom_up.res3.16.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.16.conv2.bn1.*          | backbone.bottom_up.res3.16.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.16.conv2.conv.weight    | backbone.bottom_up.res3.16.conv2.conv.weight                                                                                  | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.16.conv2.fc1.*          | backbone.bottom_up.res3.16.conv2.fc1.{bias,weight}                                                                            | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.16.conv2.fc2.*          | backbone.bottom_up.res3.16.conv2.fc2.{bias,weight}                                                                            | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.16.conv3.*              | backbone.bottom_up.res3.16.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.17.conv1.*              | backbone.bottom_up.res3.17.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.17.conv2.bn0.*          | backbone.bottom_up.res3.17.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.17.conv2.bn1.*          | backbone.bottom_up.res3.17.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.17.conv2.conv.weight    | backbone.bottom_up.res3.17.conv2.conv.weight                                                                                  | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.17.conv2.fc1.*          | backbone.bottom_up.res3.17.conv2.fc1.{bias,weight}                                                                            | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.17.conv2.fc2.*          | backbone.bottom_up.res3.17.conv2.fc2.{bias,weight}                                                                            | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.17.conv3.*              | backbone.bottom_up.res3.17.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.18.conv1.*              | backbone.bottom_up.res3.18.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.18.conv2.bn0.*          | backbone.bottom_up.res3.18.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.18.conv2.bn1.*          | backbone.bottom_up.res3.18.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.18.conv2.conv.weight    | backbone.bottom_up.res3.18.conv2.conv.weight                                                                                  | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.18.conv2.fc1.*          | backbone.bottom_up.res3.18.conv2.fc1.{bias,weight}                                                                            | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.18.conv2.fc2.*          | backbone.bottom_up.res3.18.conv2.fc2.{bias,weight}                                                                            | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.18.conv3.*              | backbone.bottom_up.res3.18.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.19.conv1.*              | backbone.bottom_up.res3.19.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.19.conv2.bn0.*          | backbone.bottom_up.res3.19.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.19.conv2.bn1.*          | backbone.bottom_up.res3.19.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.19.conv2.conv.weight    | backbone.bottom_up.res3.19.conv2.conv.weight                                                                                  | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.19.conv2.fc1.*          | backbone.bottom_up.res3.19.conv2.fc1.{bias,weight}                                                                            | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.19.conv2.fc2.*          | backbone.bottom_up.res3.19.conv2.fc2.{bias,weight}                                                                            | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.19.conv3.*              | backbone.bottom_up.res3.19.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv2.bn0.*           | backbone.bottom_up.res3.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.2.conv2.bn1.*           | backbone.bottom_up.res3.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.2.conv2.conv.weight     | backbone.bottom_up.res3.2.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.2.conv2.fc1.*           | backbone.bottom_up.res3.2.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.2.conv2.fc2.*           | backbone.bottom_up.res3.2.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.20.conv1.*              | backbone.bottom_up.res3.20.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.20.conv2.bn0.*          | backbone.bottom_up.res3.20.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.20.conv2.bn1.*          | backbone.bottom_up.res3.20.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.20.conv2.conv.weight    | backbone.bottom_up.res3.20.conv2.conv.weight                                                                                  | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.20.conv2.fc1.*          | backbone.bottom_up.res3.20.conv2.fc1.{bias,weight}                                                                            | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.20.conv2.fc2.*          | backbone.bottom_up.res3.20.conv2.fc2.{bias,weight}                                                                            | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.20.conv3.*              | backbone.bottom_up.res3.20.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.21.conv1.*              | backbone.bottom_up.res3.21.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.21.conv2.bn0.*          | backbone.bottom_up.res3.21.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.21.conv2.bn1.*          | backbone.bottom_up.res3.21.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.21.conv2.conv.weight    | backbone.bottom_up.res3.21.conv2.conv.weight                                                                                  | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.21.conv2.fc1.*          | backbone.bottom_up.res3.21.conv2.fc1.{bias,weight}                                                                            | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.21.conv2.fc2.*          | backbone.bottom_up.res3.21.conv2.fc2.{bias,weight}                                                                            | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.21.conv3.*              | backbone.bottom_up.res3.21.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.22.conv1.*              | backbone.bottom_up.res3.22.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.22.conv2.bn0.*          | backbone.bottom_up.res3.22.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.22.conv2.bn1.*          | backbone.bottom_up.res3.22.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.22.conv2.conv.weight    | backbone.bottom_up.res3.22.conv2.conv.weight                                                                                  | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.22.conv2.fc1.*          | backbone.bottom_up.res3.22.conv2.fc1.{bias,weight}                                                                            | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.22.conv2.fc2.*          | backbone.bottom_up.res3.22.conv2.fc2.{bias,weight}                                                                            | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.22.conv3.*              | backbone.bottom_up.res3.22.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.23.conv1.*              | backbone.bottom_up.res3.23.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.23.conv2.bn0.*          | backbone.bottom_up.res3.23.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.23.conv2.bn1.*          | backbone.bottom_up.res3.23.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.23.conv2.conv.weight    | backbone.bottom_up.res3.23.conv2.conv.weight                                                                                  | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.23.conv2.fc1.*          | backbone.bottom_up.res3.23.conv2.fc1.{bias,weight}                                                                            | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.23.conv2.fc2.*          | backbone.bottom_up.res3.23.conv2.fc2.{bias,weight}                                                                            | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.23.conv3.*              | backbone.bottom_up.res3.23.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv2.bn0.*           | backbone.bottom_up.res3.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.3.conv2.bn1.*           | backbone.bottom_up.res3.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.3.conv2.conv.weight     | backbone.bottom_up.res3.3.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.3.conv2.fc1.*           | backbone.bottom_up.res3.3.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.3.conv2.fc2.*           | backbone.bottom_up.res3.3.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.4.conv1.*               | backbone.bottom_up.res3.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.4.conv2.bn0.*           | backbone.bottom_up.res3.4.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.4.conv2.bn1.*           | backbone.bottom_up.res3.4.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.4.conv2.conv.weight     | backbone.bottom_up.res3.4.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.4.conv2.fc1.*           | backbone.bottom_up.res3.4.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.4.conv2.fc2.*           | backbone.bottom_up.res3.4.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.4.conv3.*               | backbone.bottom_up.res3.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.5.conv1.*               | backbone.bottom_up.res3.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.5.conv2.bn0.*           | backbone.bottom_up.res3.5.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.5.conv2.bn1.*           | backbone.bottom_up.res3.5.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.5.conv2.conv.weight     | backbone.bottom_up.res3.5.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.5.conv2.fc1.*           | backbone.bottom_up.res3.5.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.5.conv2.fc2.*           | backbone.bottom_up.res3.5.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.5.conv3.*               | backbone.bottom_up.res3.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.6.conv1.*               | backbone.bottom_up.res3.6.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.6.conv2.bn0.*           | backbone.bottom_up.res3.6.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.6.conv2.bn1.*           | backbone.bottom_up.res3.6.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.6.conv2.conv.weight     | backbone.bottom_up.res3.6.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.6.conv2.fc1.*           | backbone.bottom_up.res3.6.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.6.conv2.fc2.*           | backbone.bottom_up.res3.6.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.6.conv3.*               | backbone.bottom_up.res3.6.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.7.conv1.*               | backbone.bottom_up.res3.7.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.7.conv2.bn0.*           | backbone.bottom_up.res3.7.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.7.conv2.bn1.*           | backbone.bottom_up.res3.7.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.7.conv2.conv.weight     | backbone.bottom_up.res3.7.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.7.conv2.fc1.*           | backbone.bottom_up.res3.7.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.7.conv2.fc2.*           | backbone.bottom_up.res3.7.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.7.conv3.*               | backbone.bottom_up.res3.7.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.8.conv1.*               | backbone.bottom_up.res3.8.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.8.conv2.bn0.*           | backbone.bottom_up.res3.8.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.8.conv2.bn1.*           | backbone.bottom_up.res3.8.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.8.conv2.conv.weight     | backbone.bottom_up.res3.8.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.8.conv2.fc1.*           | backbone.bottom_up.res3.8.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.8.conv2.fc2.*           | backbone.bottom_up.res3.8.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.8.conv3.*               | backbone.bottom_up.res3.8.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.9.conv1.*               | backbone.bottom_up.res3.9.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.9.conv2.bn0.*           | backbone.bottom_up.res3.9.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.9.conv2.bn1.*           | backbone.bottom_up.res3.9.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.9.conv2.conv.weight     | backbone.bottom_up.res3.9.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.9.conv2.fc1.*           | backbone.bottom_up.res3.9.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.9.conv2.fc2.*           | backbone.bottom_up.res3.9.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.9.conv3.*               | backbone.bottom_up.res3.9.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv2.bn0.*           | backbone.bottom_up.res4.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.bn1.*           | backbone.bottom_up.res4.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.conv.weight     | backbone.bottom_up.res4.0.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.0.conv2.fc1.*           | backbone.bottom_up.res4.0.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv2.fc2.*           | backbone.bottom_up.res4.0.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.1.conv2.bn0.*           | backbone.bottom_up.res4.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.bn1.*           | backbone.bottom_up.res4.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.conv.weight     | backbone.bottom_up.res4.1.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.1.conv2.fc1.*           | backbone.bottom_up.res4.1.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv2.fc2.*           | backbone.bottom_up.res4.1.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.10.conv1.*              | backbone.bottom_up.res4.10.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.10.conv2.bn0.*          | backbone.bottom_up.res4.10.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.10.conv2.bn1.*          | backbone.bottom_up.res4.10.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.10.conv2.conv.weight    | backbone.bottom_up.res4.10.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.10.conv2.fc1.*          | backbone.bottom_up.res4.10.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.10.conv2.fc2.*          | backbone.bottom_up.res4.10.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.10.conv3.*              | backbone.bottom_up.res4.10.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.11.conv1.*              | backbone.bottom_up.res4.11.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.11.conv2.bn0.*          | backbone.bottom_up.res4.11.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.11.conv2.bn1.*          | backbone.bottom_up.res4.11.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.11.conv2.conv.weight    | backbone.bottom_up.res4.11.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.11.conv2.fc1.*          | backbone.bottom_up.res4.11.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.11.conv2.fc2.*          | backbone.bottom_up.res4.11.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.11.conv3.*              | backbone.bottom_up.res4.11.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.12.conv1.*              | backbone.bottom_up.res4.12.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.12.conv2.bn0.*          | backbone.bottom_up.res4.12.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.12.conv2.bn1.*          | backbone.bottom_up.res4.12.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.12.conv2.conv.weight    | backbone.bottom_up.res4.12.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.12.conv2.fc1.*          | backbone.bottom_up.res4.12.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.12.conv2.fc2.*          | backbone.bottom_up.res4.12.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.12.conv3.*              | backbone.bottom_up.res4.12.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.13.conv1.*              | backbone.bottom_up.res4.13.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.13.conv2.bn0.*          | backbone.bottom_up.res4.13.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.13.conv2.bn1.*          | backbone.bottom_up.res4.13.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.13.conv2.conv.weight    | backbone.bottom_up.res4.13.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.13.conv2.fc1.*          | backbone.bottom_up.res4.13.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.13.conv2.fc2.*          | backbone.bottom_up.res4.13.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.13.conv3.*              | backbone.bottom_up.res4.13.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.14.conv1.*              | backbone.bottom_up.res4.14.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.14.conv2.bn0.*          | backbone.bottom_up.res4.14.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.14.conv2.bn1.*          | backbone.bottom_up.res4.14.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.14.conv2.conv.weight    | backbone.bottom_up.res4.14.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.14.conv2.fc1.*          | backbone.bottom_up.res4.14.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.14.conv2.fc2.*          | backbone.bottom_up.res4.14.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.14.conv3.*              | backbone.bottom_up.res4.14.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.15.conv1.*              | backbone.bottom_up.res4.15.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.15.conv2.bn0.*          | backbone.bottom_up.res4.15.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.15.conv2.bn1.*          | backbone.bottom_up.res4.15.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.15.conv2.conv.weight    | backbone.bottom_up.res4.15.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.15.conv2.fc1.*          | backbone.bottom_up.res4.15.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.15.conv2.fc2.*          | backbone.bottom_up.res4.15.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.15.conv3.*              | backbone.bottom_up.res4.15.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.16.conv1.*              | backbone.bottom_up.res4.16.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.16.conv2.bn0.*          | backbone.bottom_up.res4.16.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.16.conv2.bn1.*          | backbone.bottom_up.res4.16.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.16.conv2.conv.weight    | backbone.bottom_up.res4.16.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.16.conv2.fc1.*          | backbone.bottom_up.res4.16.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.16.conv2.fc2.*          | backbone.bottom_up.res4.16.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.16.conv3.*              | backbone.bottom_up.res4.16.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.17.conv1.*              | backbone.bottom_up.res4.17.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.17.conv2.bn0.*          | backbone.bottom_up.res4.17.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.17.conv2.bn1.*          | backbone.bottom_up.res4.17.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.17.conv2.conv.weight    | backbone.bottom_up.res4.17.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.17.conv2.fc1.*          | backbone.bottom_up.res4.17.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.17.conv2.fc2.*          | backbone.bottom_up.res4.17.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.17.conv3.*              | backbone.bottom_up.res4.17.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.18.conv1.*              | backbone.bottom_up.res4.18.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.18.conv2.bn0.*          | backbone.bottom_up.res4.18.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.18.conv2.bn1.*          | backbone.bottom_up.res4.18.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.18.conv2.conv.weight    | backbone.bottom_up.res4.18.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.18.conv2.fc1.*          | backbone.bottom_up.res4.18.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.18.conv2.fc2.*          | backbone.bottom_up.res4.18.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.18.conv3.*              | backbone.bottom_up.res4.18.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.19.conv1.*              | backbone.bottom_up.res4.19.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.19.conv2.bn0.*          | backbone.bottom_up.res4.19.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.19.conv2.bn1.*          | backbone.bottom_up.res4.19.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.19.conv2.conv.weight    | backbone.bottom_up.res4.19.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.19.conv2.fc1.*          | backbone.bottom_up.res4.19.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.19.conv2.fc2.*          | backbone.bottom_up.res4.19.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.19.conv3.*              | backbone.bottom_up.res4.19.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.2.conv2.bn0.*           | backbone.bottom_up.res4.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.bn1.*           | backbone.bottom_up.res4.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.conv.weight     | backbone.bottom_up.res4.2.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.2.conv2.fc1.*           | backbone.bottom_up.res4.2.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv2.fc2.*           | backbone.bottom_up.res4.2.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.20.conv1.*              | backbone.bottom_up.res4.20.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.20.conv2.bn0.*          | backbone.bottom_up.res4.20.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.20.conv2.bn1.*          | backbone.bottom_up.res4.20.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.20.conv2.conv.weight    | backbone.bottom_up.res4.20.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.20.conv2.fc1.*          | backbone.bottom_up.res4.20.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.20.conv2.fc2.*          | backbone.bottom_up.res4.20.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.20.conv3.*              | backbone.bottom_up.res4.20.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.21.conv1.*              | backbone.bottom_up.res4.21.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.21.conv2.bn0.*          | backbone.bottom_up.res4.21.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.21.conv2.bn1.*          | backbone.bottom_up.res4.21.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.21.conv2.conv.weight    | backbone.bottom_up.res4.21.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.21.conv2.fc1.*          | backbone.bottom_up.res4.21.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.21.conv2.fc2.*          | backbone.bottom_up.res4.21.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.21.conv3.*              | backbone.bottom_up.res4.21.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.22.conv1.*              | backbone.bottom_up.res4.22.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.22.conv2.bn0.*          | backbone.bottom_up.res4.22.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.22.conv2.bn1.*          | backbone.bottom_up.res4.22.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.22.conv2.conv.weight    | backbone.bottom_up.res4.22.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.22.conv2.fc1.*          | backbone.bottom_up.res4.22.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.22.conv2.fc2.*          | backbone.bottom_up.res4.22.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.22.conv3.*              | backbone.bottom_up.res4.22.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.23.conv1.*              | backbone.bottom_up.res4.23.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.23.conv2.bn0.*          | backbone.bottom_up.res4.23.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.23.conv2.bn1.*          | backbone.bottom_up.res4.23.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.23.conv2.conv.weight    | backbone.bottom_up.res4.23.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.23.conv2.fc1.*          | backbone.bottom_up.res4.23.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.23.conv2.fc2.*          | backbone.bottom_up.res4.23.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.23.conv3.*              | backbone.bottom_up.res4.23.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.24.conv1.*              | backbone.bottom_up.res4.24.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.24.conv2.bn0.*          | backbone.bottom_up.res4.24.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.24.conv2.bn1.*          | backbone.bottom_up.res4.24.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.24.conv2.conv.weight    | backbone.bottom_up.res4.24.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.24.conv2.fc1.*          | backbone.bottom_up.res4.24.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.24.conv2.fc2.*          | backbone.bottom_up.res4.24.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.24.conv3.*              | backbone.bottom_up.res4.24.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.25.conv1.*              | backbone.bottom_up.res4.25.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.25.conv2.bn0.*          | backbone.bottom_up.res4.25.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.25.conv2.bn1.*          | backbone.bottom_up.res4.25.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.25.conv2.conv.weight    | backbone.bottom_up.res4.25.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.25.conv2.fc1.*          | backbone.bottom_up.res4.25.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.25.conv2.fc2.*          | backbone.bottom_up.res4.25.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.25.conv3.*              | backbone.bottom_up.res4.25.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.26.conv1.*              | backbone.bottom_up.res4.26.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.26.conv2.bn0.*          | backbone.bottom_up.res4.26.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.26.conv2.bn1.*          | backbone.bottom_up.res4.26.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.26.conv2.conv.weight    | backbone.bottom_up.res4.26.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.26.conv2.fc1.*          | backbone.bottom_up.res4.26.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.26.conv2.fc2.*          | backbone.bottom_up.res4.26.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.26.conv3.*              | backbone.bottom_up.res4.26.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.27.conv1.*              | backbone.bottom_up.res4.27.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.27.conv2.bn0.*          | backbone.bottom_up.res4.27.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.27.conv2.bn1.*          | backbone.bottom_up.res4.27.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.27.conv2.conv.weight    | backbone.bottom_up.res4.27.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.27.conv2.fc1.*          | backbone.bottom_up.res4.27.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.27.conv2.fc2.*          | backbone.bottom_up.res4.27.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.27.conv3.*              | backbone.bottom_up.res4.27.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.28.conv1.*              | backbone.bottom_up.res4.28.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.28.conv2.bn0.*          | backbone.bottom_up.res4.28.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.28.conv2.bn1.*          | backbone.bottom_up.res4.28.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.28.conv2.conv.weight    | backbone.bottom_up.res4.28.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.28.conv2.fc1.*          | backbone.bottom_up.res4.28.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.28.conv2.fc2.*          | backbone.bottom_up.res4.28.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.28.conv3.*              | backbone.bottom_up.res4.28.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.29.conv1.*              | backbone.bottom_up.res4.29.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.29.conv2.bn0.*          | backbone.bottom_up.res4.29.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.29.conv2.bn1.*          | backbone.bottom_up.res4.29.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.29.conv2.conv.weight    | backbone.bottom_up.res4.29.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.29.conv2.fc1.*          | backbone.bottom_up.res4.29.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.29.conv2.fc2.*          | backbone.bottom_up.res4.29.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.29.conv3.*              | backbone.bottom_up.res4.29.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.3.conv2.bn0.*           | backbone.bottom_up.res4.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.bn1.*           | backbone.bottom_up.res4.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.conv.weight     | backbone.bottom_up.res4.3.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.3.conv2.fc1.*           | backbone.bottom_up.res4.3.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv2.fc2.*           | backbone.bottom_up.res4.3.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.30.conv1.*              | backbone.bottom_up.res4.30.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.30.conv2.bn0.*          | backbone.bottom_up.res4.30.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.30.conv2.bn1.*          | backbone.bottom_up.res4.30.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.30.conv2.conv.weight    | backbone.bottom_up.res4.30.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.30.conv2.fc1.*          | backbone.bottom_up.res4.30.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.30.conv2.fc2.*          | backbone.bottom_up.res4.30.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.30.conv3.*              | backbone.bottom_up.res4.30.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.31.conv1.*              | backbone.bottom_up.res4.31.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.31.conv2.bn0.*          | backbone.bottom_up.res4.31.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.31.conv2.bn1.*          | backbone.bottom_up.res4.31.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.31.conv2.conv.weight    | backbone.bottom_up.res4.31.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.31.conv2.fc1.*          | backbone.bottom_up.res4.31.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.31.conv2.fc2.*          | backbone.bottom_up.res4.31.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.31.conv3.*              | backbone.bottom_up.res4.31.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.32.conv1.*              | backbone.bottom_up.res4.32.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.32.conv2.bn0.*          | backbone.bottom_up.res4.32.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.32.conv2.bn1.*          | backbone.bottom_up.res4.32.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.32.conv2.conv.weight    | backbone.bottom_up.res4.32.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.32.conv2.fc1.*          | backbone.bottom_up.res4.32.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.32.conv2.fc2.*          | backbone.bottom_up.res4.32.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.32.conv3.*              | backbone.bottom_up.res4.32.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.33.conv1.*              | backbone.bottom_up.res4.33.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.33.conv2.bn0.*          | backbone.bottom_up.res4.33.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.33.conv2.bn1.*          | backbone.bottom_up.res4.33.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.33.conv2.conv.weight    | backbone.bottom_up.res4.33.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.33.conv2.fc1.*          | backbone.bottom_up.res4.33.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.33.conv2.fc2.*          | backbone.bottom_up.res4.33.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.33.conv3.*              | backbone.bottom_up.res4.33.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.34.conv1.*              | backbone.bottom_up.res4.34.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.34.conv2.bn0.*          | backbone.bottom_up.res4.34.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.34.conv2.bn1.*          | backbone.bottom_up.res4.34.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.34.conv2.conv.weight    | backbone.bottom_up.res4.34.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.34.conv2.fc1.*          | backbone.bottom_up.res4.34.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.34.conv2.fc2.*          | backbone.bottom_up.res4.34.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.34.conv3.*              | backbone.bottom_up.res4.34.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.35.conv1.*              | backbone.bottom_up.res4.35.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.35.conv2.bn0.*          | backbone.bottom_up.res4.35.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.35.conv2.bn1.*          | backbone.bottom_up.res4.35.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.35.conv2.conv.weight    | backbone.bottom_up.res4.35.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.35.conv2.fc1.*          | backbone.bottom_up.res4.35.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.35.conv2.fc2.*          | backbone.bottom_up.res4.35.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.35.conv3.*              | backbone.bottom_up.res4.35.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.4.conv2.bn0.*           | backbone.bottom_up.res4.4.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.bn1.*           | backbone.bottom_up.res4.4.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.conv.weight     | backbone.bottom_up.res4.4.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.4.conv2.fc1.*           | backbone.bottom_up.res4.4.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv2.fc2.*           | backbone.bottom_up.res4.4.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.5.conv2.bn0.*           | backbone.bottom_up.res4.5.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.bn1.*           | backbone.bottom_up.res4.5.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.conv.weight     | backbone.bottom_up.res4.5.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.5.conv2.fc1.*           | backbone.bottom_up.res4.5.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv2.fc2.*           | backbone.bottom_up.res4.5.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.6.conv1.*               | backbone.bottom_up.res4.6.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.6.conv2.bn0.*           | backbone.bottom_up.res4.6.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.6.conv2.bn1.*           | backbone.bottom_up.res4.6.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.6.conv2.conv.weight     | backbone.bottom_up.res4.6.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.6.conv2.fc1.*           | backbone.bottom_up.res4.6.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.6.conv2.fc2.*           | backbone.bottom_up.res4.6.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.6.conv3.*               | backbone.bottom_up.res4.6.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.7.conv1.*               | backbone.bottom_up.res4.7.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.7.conv2.bn0.*           | backbone.bottom_up.res4.7.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.7.conv2.bn1.*           | backbone.bottom_up.res4.7.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.7.conv2.conv.weight     | backbone.bottom_up.res4.7.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.7.conv2.fc1.*           | backbone.bottom_up.res4.7.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.7.conv2.fc2.*           | backbone.bottom_up.res4.7.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.7.conv3.*               | backbone.bottom_up.res4.7.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.8.conv1.*               | backbone.bottom_up.res4.8.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.8.conv2.bn0.*           | backbone.bottom_up.res4.8.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.8.conv2.bn1.*           | backbone.bottom_up.res4.8.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.8.conv2.conv.weight     | backbone.bottom_up.res4.8.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.8.conv2.fc1.*           | backbone.bottom_up.res4.8.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.8.conv2.fc2.*           | backbone.bottom_up.res4.8.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.8.conv3.*               | backbone.bottom_up.res4.8.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.9.conv1.*               | backbone.bottom_up.res4.9.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.9.conv2.bn0.*           | backbone.bottom_up.res4.9.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.9.conv2.bn1.*           | backbone.bottom_up.res4.9.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.9.conv2.conv.weight     | backbone.bottom_up.res4.9.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.9.conv2.fc1.*           | backbone.bottom_up.res4.9.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.9.conv2.fc2.*           | backbone.bottom_up.res4.9.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.9.conv3.*               | backbone.bottom_up.res4.9.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| backbone.bottom_up.res5.0.conv2.bn0.*           | backbone.bottom_up.res5.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.0.conv2.bn1.*           | backbone.bottom_up.res5.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.0.conv2.conv.weight     | backbone.bottom_up.res5.0.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.0.conv2.fc1.*           | backbone.bottom_up.res5.0.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.0.conv2.fc2.*           | backbone.bottom_up.res5.0.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.1.conv2.bn0.*           | backbone.bottom_up.res5.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.1.conv2.bn1.*           | backbone.bottom_up.res5.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.1.conv2.conv.weight     | backbone.bottom_up.res5.1.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.1.conv2.fc1.*           | backbone.bottom_up.res5.1.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.1.conv2.fc2.*           | backbone.bottom_up.res5.1.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.2.conv2.bn0.*           | backbone.bottom_up.res5.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.2.conv2.bn1.*           | backbone.bottom_up.res5.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.2.conv2.conv.weight     | backbone.bottom_up.res5.2.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.2.conv2.fc1.*           | backbone.bottom_up.res5.2.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.2.conv2.fc2.*           | backbone.bottom_up.res5.2.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.stem.conv1_1.*               | backbone.bottom_up.stem.conv1_1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,3,3,3)                 |\n",
            "| backbone.bottom_up.stem.conv1_2.*               | backbone.bottom_up.stem.conv1_2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |\n",
            "| backbone.bottom_up.stem.conv1_3.*               | backbone.bottom_up.stem.conv1_3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,64,3,3)           |\n",
            "| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,2048,1,1)      |\n",
            "| backbone.fpn_output2.*                          | backbone.fpn_output2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output3.*                          | backbone.fpn_output3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output4.*                          | backbone.fpn_output4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output5.*                          | backbone.fpn_output5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                                                       | (12,) (12,256,1,1)                                 |\n",
            "| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                                                | (256,) (256,256,3,3)                               |\n",
            "| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                                                   | (3,) (3,256,1,1)                                   |\n",
            "| roi_heads.box_head.0.conv1.*                    | roi_heads.box_head.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv2.*                    | roi_heads.box_head.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv3.*                    | roi_heads.box_head.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv4.*                    | roi_heads.box_head.0.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.fc1.*                      | roi_heads.box_head.0.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_head.1.conv1.*                    | roi_heads.box_head.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv2.*                    | roi_heads.box_head.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv3.*                    | roi_heads.box_head.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv4.*                    | roi_heads.box_head.1.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.fc1.*                      | roi_heads.box_head.1.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_head.2.conv1.*                    | roi_heads.box_head.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv2.*                    | roi_heads.box_head.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv3.*                    | roi_heads.box_head.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv4.*                    | roi_heads.box_head.2.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.fc1.*                      | roi_heads.box_head.2.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_predictor.0.bbox_pred.*           | roi_heads.box_predictor.0.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.0.cls_score.*           | roi_heads.box_predictor.0.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.box_predictor.1.bbox_pred.*           | roi_heads.box_predictor.1.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.1.cls_score.*           | roi_heads.box_predictor.1.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.box_predictor.2.bbox_pred.*           | roi_heads.box_predictor.2.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.2.cls_score.*           | roi_heads.box_predictor.2.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "\u001b[32m[04/30 19:30:54 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json\n",
            "\u001b[32m[04/30 19:30:54 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n",
            "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
            "|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\n",
            "|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\n",
            "|     train     | 190          |    truck     | 414          |     boat      | 424          |\n",
            "| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\n",
            "| parking meter | 60           |    bench     | 411          |     bird      | 427          |\n",
            "|      cat      | 202          |     dog      | 218          |     horse     | 272          |\n",
            "|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\n",
            "|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\n",
            "|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\n",
            "|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\n",
            "|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\n",
            "|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\n",
            "|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\n",
            "|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\n",
            "|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\n",
            "|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\n",
            "|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\n",
            "|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\n",
            "|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\n",
            "|     couch     | 261          | potted plant | 342          |      bed      | 163          |\n",
            "| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\n",
            "|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\n",
            "|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\n",
            "|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\n",
            "| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\n",
            "|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\n",
            "|  hair drier   | 11           |  toothbrush  | 57           |               |              |\n",
            "|     total     | 36335        |              |              |               |              |\u001b[0m\n",
            "\u001b[32m[04/30 19:30:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/30 19:30:54 d2.data.common]: \u001b[0mSerializing 5000 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/30 19:30:55 d2.data.common]: \u001b[0mSerialized dataset takes 19.10 MiB\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[32m[04/30 19:30:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 5000 batches\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m[04/30 19:31:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/5000. Dataloading: 0.0011 s/iter. Inference: 0.5026 s/iter. Eval: 0.0002 s/iter. Total: 0.5039 s/iter. ETA=0:41:53\n",
            "\u001b[32m[04/30 19:31:06 d2.evaluation.evaluator]: \u001b[0mInference done 21/5000. Dataloading: 0.0015 s/iter. Inference: 0.4998 s/iter. Eval: 0.0002 s/iter. Total: 0.5016 s/iter. ETA=0:41:37\n",
            "\u001b[32m[04/30 19:31:12 d2.evaluation.evaluator]: \u001b[0mInference done 31/5000. Dataloading: 0.0016 s/iter. Inference: 0.5073 s/iter. Eval: 0.0002 s/iter. Total: 0.5092 s/iter. ETA=0:42:10\n",
            "\u001b[32m[04/30 19:31:17 d2.evaluation.evaluator]: \u001b[0mInference done 41/5000. Dataloading: 0.0017 s/iter. Inference: 0.5078 s/iter. Eval: 0.0002 s/iter. Total: 0.5098 s/iter. ETA=0:42:08\n",
            "\u001b[32m[04/30 19:31:22 d2.evaluation.evaluator]: \u001b[0mInference done 51/5000. Dataloading: 0.0017 s/iter. Inference: 0.5075 s/iter. Eval: 0.0002 s/iter. Total: 0.5096 s/iter. ETA=0:42:01\n",
            "\u001b[32m[04/30 19:31:27 d2.evaluation.evaluator]: \u001b[0mInference done 61/5000. Dataloading: 0.0018 s/iter. Inference: 0.5110 s/iter. Eval: 0.0002 s/iter. Total: 0.5131 s/iter. ETA=0:42:14\n",
            "\u001b[32m[04/30 19:31:32 d2.evaluation.evaluator]: \u001b[0mInference done 71/5000. Dataloading: 0.0018 s/iter. Inference: 0.5122 s/iter. Eval: 0.0002 s/iter. Total: 0.5143 s/iter. ETA=0:42:14\n",
            "\u001b[32m[04/30 19:31:38 d2.evaluation.evaluator]: \u001b[0mInference done 81/5000. Dataloading: 0.0018 s/iter. Inference: 0.5126 s/iter. Eval: 0.0002 s/iter. Total: 0.5148 s/iter. ETA=0:42:12\n",
            "\u001b[32m[04/30 19:31:43 d2.evaluation.evaluator]: \u001b[0mInference done 91/5000. Dataloading: 0.0019 s/iter. Inference: 0.5126 s/iter. Eval: 0.0002 s/iter. Total: 0.5148 s/iter. ETA=0:42:07\n",
            "\u001b[32m[04/30 19:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 101/5000. Dataloading: 0.0019 s/iter. Inference: 0.5121 s/iter. Eval: 0.0002 s/iter. Total: 0.5143 s/iter. ETA=0:41:59\n",
            "\u001b[32m[04/30 19:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 111/5000. Dataloading: 0.0019 s/iter. Inference: 0.5121 s/iter. Eval: 0.0002 s/iter. Total: 0.5142 s/iter. ETA=0:41:54\n",
            "\u001b[32m[04/30 19:31:58 d2.evaluation.evaluator]: \u001b[0mInference done 121/5000. Dataloading: 0.0019 s/iter. Inference: 0.5136 s/iter. Eval: 0.0002 s/iter. Total: 0.5158 s/iter. ETA=0:41:56\n",
            "\u001b[32m[04/30 19:32:04 d2.evaluation.evaluator]: \u001b[0mInference done 131/5000. Dataloading: 0.0019 s/iter. Inference: 0.5150 s/iter. Eval: 0.0002 s/iter. Total: 0.5173 s/iter. ETA=0:41:58\n",
            "\u001b[32m[04/30 19:32:09 d2.evaluation.evaluator]: \u001b[0mInference done 141/5000. Dataloading: 0.0019 s/iter. Inference: 0.5161 s/iter. Eval: 0.0002 s/iter. Total: 0.5183 s/iter. ETA=0:41:58\n",
            "\u001b[32m[04/30 19:32:14 d2.evaluation.evaluator]: \u001b[0mInference done 151/5000. Dataloading: 0.0019 s/iter. Inference: 0.5173 s/iter. Eval: 0.0002 s/iter. Total: 0.5195 s/iter. ETA=0:41:59\n",
            "\u001b[32m[04/30 19:32:20 d2.evaluation.evaluator]: \u001b[0mInference done 161/5000. Dataloading: 0.0019 s/iter. Inference: 0.5182 s/iter. Eval: 0.0002 s/iter. Total: 0.5204 s/iter. ETA=0:41:58\n",
            "\u001b[32m[04/30 19:32:25 d2.evaluation.evaluator]: \u001b[0mInference done 171/5000. Dataloading: 0.0019 s/iter. Inference: 0.5182 s/iter. Eval: 0.0002 s/iter. Total: 0.5204 s/iter. ETA=0:41:53\n",
            "\u001b[32m[04/30 19:32:30 d2.evaluation.evaluator]: \u001b[0mInference done 181/5000. Dataloading: 0.0019 s/iter. Inference: 0.5185 s/iter. Eval: 0.0002 s/iter. Total: 0.5208 s/iter. ETA=0:41:49\n",
            "\u001b[32m[04/30 19:32:36 d2.evaluation.evaluator]: \u001b[0mInference done 191/5000. Dataloading: 0.0019 s/iter. Inference: 0.5196 s/iter. Eval: 0.0002 s/iter. Total: 0.5218 s/iter. ETA=0:41:49\n",
            "\u001b[32m[04/30 19:32:41 d2.evaluation.evaluator]: \u001b[0mInference done 201/5000. Dataloading: 0.0019 s/iter. Inference: 0.5201 s/iter. Eval: 0.0002 s/iter. Total: 0.5223 s/iter. ETA=0:41:46\n",
            "\u001b[32m[04/30 19:32:46 d2.evaluation.evaluator]: \u001b[0mInference done 211/5000. Dataloading: 0.0019 s/iter. Inference: 0.5206 s/iter. Eval: 0.0002 s/iter. Total: 0.5228 s/iter. ETA=0:41:43\n",
            "\u001b[32m[04/30 19:32:51 d2.evaluation.evaluator]: \u001b[0mInference done 221/5000. Dataloading: 0.0019 s/iter. Inference: 0.5208 s/iter. Eval: 0.0002 s/iter. Total: 0.5230 s/iter. ETA=0:41:39\n",
            "\u001b[32m[04/30 19:32:57 d2.evaluation.evaluator]: \u001b[0mInference done 231/5000. Dataloading: 0.0019 s/iter. Inference: 0.5213 s/iter. Eval: 0.0002 s/iter. Total: 0.5235 s/iter. ETA=0:41:36\n",
            "\u001b[32m[04/30 19:33:02 d2.evaluation.evaluator]: \u001b[0mInference done 241/5000. Dataloading: 0.0019 s/iter. Inference: 0.5220 s/iter. Eval: 0.0002 s/iter. Total: 0.5242 s/iter. ETA=0:41:34\n",
            "\u001b[32m[04/30 19:33:08 d2.evaluation.evaluator]: \u001b[0mInference done 251/5000. Dataloading: 0.0019 s/iter. Inference: 0.5228 s/iter. Eval: 0.0002 s/iter. Total: 0.5250 s/iter. ETA=0:41:33\n",
            "\u001b[32m[04/30 19:33:13 d2.evaluation.evaluator]: \u001b[0mInference done 261/5000. Dataloading: 0.0019 s/iter. Inference: 0.5236 s/iter. Eval: 0.0002 s/iter. Total: 0.5258 s/iter. ETA=0:41:31\n",
            "\u001b[32m[04/30 19:33:18 d2.evaluation.evaluator]: \u001b[0mInference done 271/5000. Dataloading: 0.0019 s/iter. Inference: 0.5234 s/iter. Eval: 0.0002 s/iter. Total: 0.5257 s/iter. ETA=0:41:25\n",
            "\u001b[32m[04/30 19:33:24 d2.evaluation.evaluator]: \u001b[0mInference done 281/5000. Dataloading: 0.0019 s/iter. Inference: 0.5237 s/iter. Eval: 0.0002 s/iter. Total: 0.5260 s/iter. ETA=0:41:21\n",
            "\u001b[32m[04/30 19:33:29 d2.evaluation.evaluator]: \u001b[0mInference done 291/5000. Dataloading: 0.0019 s/iter. Inference: 0.5246 s/iter. Eval: 0.0002 s/iter. Total: 0.5268 s/iter. ETA=0:41:20\n",
            "\u001b[32m[04/30 19:33:34 d2.evaluation.evaluator]: \u001b[0mInference done 301/5000. Dataloading: 0.0019 s/iter. Inference: 0.5250 s/iter. Eval: 0.0002 s/iter. Total: 0.5272 s/iter. ETA=0:41:17\n",
            "\u001b[32m[04/30 19:33:40 d2.evaluation.evaluator]: \u001b[0mInference done 311/5000. Dataloading: 0.0019 s/iter. Inference: 0.5253 s/iter. Eval: 0.0002 s/iter. Total: 0.5275 s/iter. ETA=0:41:13\n",
            "\u001b[32m[04/30 19:33:45 d2.evaluation.evaluator]: \u001b[0mInference done 321/5000. Dataloading: 0.0019 s/iter. Inference: 0.5257 s/iter. Eval: 0.0002 s/iter. Total: 0.5279 s/iter. ETA=0:41:10\n",
            "\u001b[32m[04/30 19:33:51 d2.evaluation.evaluator]: \u001b[0mInference done 331/5000. Dataloading: 0.0019 s/iter. Inference: 0.5264 s/iter. Eval: 0.0002 s/iter. Total: 0.5286 s/iter. ETA=0:41:08\n",
            "\u001b[32m[04/30 19:33:56 d2.evaluation.evaluator]: \u001b[0mInference done 341/5000. Dataloading: 0.0019 s/iter. Inference: 0.5271 s/iter. Eval: 0.0002 s/iter. Total: 0.5294 s/iter. ETA=0:41:06\n",
            "\u001b[32m[04/30 19:34:02 d2.evaluation.evaluator]: \u001b[0mInference done 351/5000. Dataloading: 0.0019 s/iter. Inference: 0.5278 s/iter. Eval: 0.0002 s/iter. Total: 0.5300 s/iter. ETA=0:41:04\n",
            "\u001b[32m[04/30 19:34:07 d2.evaluation.evaluator]: \u001b[0mInference done 361/5000. Dataloading: 0.0019 s/iter. Inference: 0.5282 s/iter. Eval: 0.0002 s/iter. Total: 0.5305 s/iter. ETA=0:41:00\n",
            "\u001b[32m[04/30 19:34:13 d2.evaluation.evaluator]: \u001b[0mInference done 371/5000. Dataloading: 0.0019 s/iter. Inference: 0.5289 s/iter. Eval: 0.0002 s/iter. Total: 0.5312 s/iter. ETA=0:40:58\n",
            "\u001b[32m[04/30 19:34:18 d2.evaluation.evaluator]: \u001b[0mInference done 381/5000. Dataloading: 0.0019 s/iter. Inference: 0.5291 s/iter. Eval: 0.0002 s/iter. Total: 0.5313 s/iter. ETA=0:40:54\n",
            "\u001b[32m[04/30 19:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 391/5000. Dataloading: 0.0019 s/iter. Inference: 0.5291 s/iter. Eval: 0.0002 s/iter. Total: 0.5313 s/iter. ETA=0:40:48\n",
            "\u001b[32m[04/30 19:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 401/5000. Dataloading: 0.0019 s/iter. Inference: 0.5293 s/iter. Eval: 0.0002 s/iter. Total: 0.5316 s/iter. ETA=0:40:44\n",
            "\u001b[32m[04/30 19:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 411/5000. Dataloading: 0.0019 s/iter. Inference: 0.5297 s/iter. Eval: 0.0002 s/iter. Total: 0.5320 s/iter. ETA=0:40:41\n",
            "\u001b[32m[04/30 19:34:40 d2.evaluation.evaluator]: \u001b[0mInference done 421/5000. Dataloading: 0.0019 s/iter. Inference: 0.5301 s/iter. Eval: 0.0002 s/iter. Total: 0.5323 s/iter. ETA=0:40:37\n",
            "\u001b[32m[04/30 19:34:45 d2.evaluation.evaluator]: \u001b[0mInference done 431/5000. Dataloading: 0.0019 s/iter. Inference: 0.5304 s/iter. Eval: 0.0002 s/iter. Total: 0.5327 s/iter. ETA=0:40:33\n",
            "\u001b[32m[04/30 19:34:51 d2.evaluation.evaluator]: \u001b[0mInference done 441/5000. Dataloading: 0.0019 s/iter. Inference: 0.5309 s/iter. Eval: 0.0002 s/iter. Total: 0.5332 s/iter. ETA=0:40:30\n",
            "\u001b[32m[04/30 19:34:56 d2.evaluation.evaluator]: \u001b[0mInference done 451/5000. Dataloading: 0.0019 s/iter. Inference: 0.5311 s/iter. Eval: 0.0002 s/iter. Total: 0.5333 s/iter. ETA=0:40:26\n",
            "\u001b[32m[04/30 19:35:01 d2.evaluation.evaluator]: \u001b[0mInference done 460/5000. Dataloading: 0.0019 s/iter. Inference: 0.5316 s/iter. Eval: 0.0002 s/iter. Total: 0.5338 s/iter. ETA=0:40:23\n",
            "\u001b[32m[04/30 19:35:06 d2.evaluation.evaluator]: \u001b[0mInference done 469/5000. Dataloading: 0.0019 s/iter. Inference: 0.5320 s/iter. Eval: 0.0002 s/iter. Total: 0.5343 s/iter. ETA=0:40:20\n",
            "\u001b[32m[04/30 19:35:11 d2.evaluation.evaluator]: \u001b[0mInference done 478/5000. Dataloading: 0.0019 s/iter. Inference: 0.5324 s/iter. Eval: 0.0002 s/iter. Total: 0.5347 s/iter. ETA=0:40:17\n",
            "\u001b[32m[04/30 19:35:16 d2.evaluation.evaluator]: \u001b[0mInference done 487/5000. Dataloading: 0.0019 s/iter. Inference: 0.5328 s/iter. Eval: 0.0002 s/iter. Total: 0.5351 s/iter. ETA=0:40:14\n",
            "\u001b[32m[04/30 19:35:22 d2.evaluation.evaluator]: \u001b[0mInference done 497/5000. Dataloading: 0.0019 s/iter. Inference: 0.5332 s/iter. Eval: 0.0002 s/iter. Total: 0.5354 s/iter. ETA=0:40:10\n",
            "\u001b[32m[04/30 19:35:27 d2.evaluation.evaluator]: \u001b[0mInference done 507/5000. Dataloading: 0.0019 s/iter. Inference: 0.5332 s/iter. Eval: 0.0002 s/iter. Total: 0.5354 s/iter. ETA=0:40:05\n",
            "\u001b[32m[04/30 19:35:33 d2.evaluation.evaluator]: \u001b[0mInference done 517/5000. Dataloading: 0.0019 s/iter. Inference: 0.5331 s/iter. Eval: 0.0002 s/iter. Total: 0.5354 s/iter. ETA=0:40:00\n",
            "\u001b[32m[04/30 19:35:38 d2.evaluation.evaluator]: \u001b[0mInference done 526/5000. Dataloading: 0.0019 s/iter. Inference: 0.5335 s/iter. Eval: 0.0002 s/iter. Total: 0.5358 s/iter. ETA=0:39:57\n",
            "\u001b[32m[04/30 19:35:43 d2.evaluation.evaluator]: \u001b[0mInference done 536/5000. Dataloading: 0.0019 s/iter. Inference: 0.5338 s/iter. Eval: 0.0002 s/iter. Total: 0.5360 s/iter. ETA=0:39:52\n",
            "\u001b[32m[04/30 19:35:49 d2.evaluation.evaluator]: \u001b[0mInference done 546/5000. Dataloading: 0.0019 s/iter. Inference: 0.5340 s/iter. Eval: 0.0002 s/iter. Total: 0.5363 s/iter. ETA=0:39:48\n",
            "\u001b[32m[04/30 19:35:54 d2.evaluation.evaluator]: \u001b[0mInference done 556/5000. Dataloading: 0.0019 s/iter. Inference: 0.5343 s/iter. Eval: 0.0002 s/iter. Total: 0.5365 s/iter. ETA=0:39:44\n",
            "\u001b[32m[04/30 19:36:00 d2.evaluation.evaluator]: \u001b[0mInference done 566/5000. Dataloading: 0.0019 s/iter. Inference: 0.5345 s/iter. Eval: 0.0002 s/iter. Total: 0.5367 s/iter. ETA=0:39:39\n",
            "\u001b[32m[04/30 19:36:05 d2.evaluation.evaluator]: \u001b[0mInference done 575/5000. Dataloading: 0.0019 s/iter. Inference: 0.5348 s/iter. Eval: 0.0002 s/iter. Total: 0.5371 s/iter. ETA=0:39:36\n",
            "\u001b[32m[04/30 19:36:10 d2.evaluation.evaluator]: \u001b[0mInference done 585/5000. Dataloading: 0.0019 s/iter. Inference: 0.5349 s/iter. Eval: 0.0002 s/iter. Total: 0.5371 s/iter. ETA=0:39:31\n",
            "\u001b[32m[04/30 19:36:15 d2.evaluation.evaluator]: \u001b[0mInference done 595/5000. Dataloading: 0.0019 s/iter. Inference: 0.5350 s/iter. Eval: 0.0002 s/iter. Total: 0.5372 s/iter. ETA=0:39:26\n",
            "\u001b[32m[04/30 19:36:21 d2.evaluation.evaluator]: \u001b[0mInference done 605/5000. Dataloading: 0.0019 s/iter. Inference: 0.5352 s/iter. Eval: 0.0002 s/iter. Total: 0.5374 s/iter. ETA=0:39:21\n",
            "\u001b[32m[04/30 19:36:26 d2.evaluation.evaluator]: \u001b[0mInference done 614/5000. Dataloading: 0.0019 s/iter. Inference: 0.5355 s/iter. Eval: 0.0002 s/iter. Total: 0.5378 s/iter. ETA=0:39:18\n",
            "\u001b[32m[04/30 19:36:31 d2.evaluation.evaluator]: \u001b[0mInference done 623/5000. Dataloading: 0.0019 s/iter. Inference: 0.5359 s/iter. Eval: 0.0002 s/iter. Total: 0.5381 s/iter. ETA=0:39:15\n",
            "\u001b[32m[04/30 19:36:36 d2.evaluation.evaluator]: \u001b[0mInference done 633/5000. Dataloading: 0.0019 s/iter. Inference: 0.5360 s/iter. Eval: 0.0002 s/iter. Total: 0.5382 s/iter. ETA=0:39:10\n",
            "\u001b[32m[04/30 19:36:42 d2.evaluation.evaluator]: \u001b[0mInference done 643/5000. Dataloading: 0.0019 s/iter. Inference: 0.5362 s/iter. Eval: 0.0002 s/iter. Total: 0.5384 s/iter. ETA=0:39:05\n",
            "\u001b[32m[04/30 19:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 653/5000. Dataloading: 0.0019 s/iter. Inference: 0.5363 s/iter. Eval: 0.0002 s/iter. Total: 0.5385 s/iter. ETA=0:39:00\n",
            "\u001b[32m[04/30 19:36:53 d2.evaluation.evaluator]: \u001b[0mInference done 663/5000. Dataloading: 0.0019 s/iter. Inference: 0.5365 s/iter. Eval: 0.0002 s/iter. Total: 0.5388 s/iter. ETA=0:38:56\n",
            "\u001b[32m[04/30 19:36:58 d2.evaluation.evaluator]: \u001b[0mInference done 672/5000. Dataloading: 0.0019 s/iter. Inference: 0.5368 s/iter. Eval: 0.0002 s/iter. Total: 0.5390 s/iter. ETA=0:38:52\n",
            "\u001b[32m[04/30 19:37:03 d2.evaluation.evaluator]: \u001b[0mInference done 681/5000. Dataloading: 0.0019 s/iter. Inference: 0.5370 s/iter. Eval: 0.0002 s/iter. Total: 0.5392 s/iter. ETA=0:38:48\n",
            "\u001b[32m[04/30 19:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 691/5000. Dataloading: 0.0019 s/iter. Inference: 0.5372 s/iter. Eval: 0.0002 s/iter. Total: 0.5394 s/iter. ETA=0:38:44\n",
            "\u001b[32m[04/30 19:37:14 d2.evaluation.evaluator]: \u001b[0mInference done 701/5000. Dataloading: 0.0019 s/iter. Inference: 0.5374 s/iter. Eval: 0.0002 s/iter. Total: 0.5396 s/iter. ETA=0:38:39\n",
            "\u001b[32m[04/30 19:37:19 d2.evaluation.evaluator]: \u001b[0mInference done 710/5000. Dataloading: 0.0019 s/iter. Inference: 0.5376 s/iter. Eval: 0.0002 s/iter. Total: 0.5399 s/iter. ETA=0:38:36\n",
            "\u001b[32m[04/30 19:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 719/5000. Dataloading: 0.0019 s/iter. Inference: 0.5379 s/iter. Eval: 0.0002 s/iter. Total: 0.5401 s/iter. ETA=0:38:32\n",
            "\u001b[32m[04/30 19:37:30 d2.evaluation.evaluator]: \u001b[0mInference done 729/5000. Dataloading: 0.0019 s/iter. Inference: 0.5380 s/iter. Eval: 0.0002 s/iter. Total: 0.5403 s/iter. ETA=0:38:27\n",
            "\u001b[32m[04/30 19:37:35 d2.evaluation.evaluator]: \u001b[0mInference done 738/5000. Dataloading: 0.0019 s/iter. Inference: 0.5382 s/iter. Eval: 0.0002 s/iter. Total: 0.5405 s/iter. ETA=0:38:23\n",
            "\u001b[32m[04/30 19:37:40 d2.evaluation.evaluator]: \u001b[0mInference done 748/5000. Dataloading: 0.0019 s/iter. Inference: 0.5384 s/iter. Eval: 0.0002 s/iter. Total: 0.5406 s/iter. ETA=0:38:18\n",
            "\u001b[32m[04/30 19:37:46 d2.evaluation.evaluator]: \u001b[0mInference done 758/5000. Dataloading: 0.0019 s/iter. Inference: 0.5386 s/iter. Eval: 0.0002 s/iter. Total: 0.5408 s/iter. ETA=0:38:14\n",
            "\u001b[32m[04/30 19:37:51 d2.evaluation.evaluator]: \u001b[0mInference done 768/5000. Dataloading: 0.0019 s/iter. Inference: 0.5386 s/iter. Eval: 0.0002 s/iter. Total: 0.5409 s/iter. ETA=0:38:09\n",
            "\u001b[32m[04/30 19:37:56 d2.evaluation.evaluator]: \u001b[0mInference done 777/5000. Dataloading: 0.0019 s/iter. Inference: 0.5388 s/iter. Eval: 0.0002 s/iter. Total: 0.5411 s/iter. ETA=0:38:05\n",
            "\u001b[32m[04/30 19:38:01 d2.evaluation.evaluator]: \u001b[0mInference done 786/5000. Dataloading: 0.0019 s/iter. Inference: 0.5390 s/iter. Eval: 0.0002 s/iter. Total: 0.5413 s/iter. ETA=0:38:01\n",
            "\u001b[32m[04/30 19:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 796/5000. Dataloading: 0.0019 s/iter. Inference: 0.5391 s/iter. Eval: 0.0002 s/iter. Total: 0.5413 s/iter. ETA=0:37:55\n",
            "\u001b[32m[04/30 19:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 805/5000. Dataloading: 0.0019 s/iter. Inference: 0.5393 s/iter. Eval: 0.0002 s/iter. Total: 0.5416 s/iter. ETA=0:37:52\n",
            "\u001b[32m[04/30 19:38:17 d2.evaluation.evaluator]: \u001b[0mInference done 815/5000. Dataloading: 0.0019 s/iter. Inference: 0.5395 s/iter. Eval: 0.0002 s/iter. Total: 0.5418 s/iter. ETA=0:37:47\n",
            "\u001b[32m[04/30 19:38:23 d2.evaluation.evaluator]: \u001b[0mInference done 825/5000. Dataloading: 0.0019 s/iter. Inference: 0.5395 s/iter. Eval: 0.0002 s/iter. Total: 0.5418 s/iter. ETA=0:37:41\n",
            "\u001b[32m[04/30 19:38:28 d2.evaluation.evaluator]: \u001b[0mInference done 835/5000. Dataloading: 0.0019 s/iter. Inference: 0.5396 s/iter. Eval: 0.0002 s/iter. Total: 0.5418 s/iter. ETA=0:37:36\n",
            "\u001b[32m[04/30 19:38:33 d2.evaluation.evaluator]: \u001b[0mInference done 844/5000. Dataloading: 0.0019 s/iter. Inference: 0.5398 s/iter. Eval: 0.0002 s/iter. Total: 0.5421 s/iter. ETA=0:37:32\n",
            "\u001b[32m[04/30 19:38:39 d2.evaluation.evaluator]: \u001b[0mInference done 854/5000. Dataloading: 0.0019 s/iter. Inference: 0.5399 s/iter. Eval: 0.0002 s/iter. Total: 0.5422 s/iter. ETA=0:37:27\n",
            "\u001b[32m[04/30 19:38:44 d2.evaluation.evaluator]: \u001b[0mInference done 863/5000. Dataloading: 0.0019 s/iter. Inference: 0.5401 s/iter. Eval: 0.0002 s/iter. Total: 0.5423 s/iter. ETA=0:37:23\n",
            "\u001b[32m[04/30 19:38:49 d2.evaluation.evaluator]: \u001b[0mInference done 873/5000. Dataloading: 0.0019 s/iter. Inference: 0.5402 s/iter. Eval: 0.0002 s/iter. Total: 0.5425 s/iter. ETA=0:37:18\n",
            "\u001b[32m[04/30 19:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 883/5000. Dataloading: 0.0019 s/iter. Inference: 0.5403 s/iter. Eval: 0.0002 s/iter. Total: 0.5425 s/iter. ETA=0:37:13\n",
            "\u001b[32m[04/30 19:39:00 d2.evaluation.evaluator]: \u001b[0mInference done 892/5000. Dataloading: 0.0019 s/iter. Inference: 0.5404 s/iter. Eval: 0.0002 s/iter. Total: 0.5427 s/iter. ETA=0:37:09\n",
            "\u001b[32m[04/30 19:39:05 d2.evaluation.evaluator]: \u001b[0mInference done 902/5000. Dataloading: 0.0019 s/iter. Inference: 0.5405 s/iter. Eval: 0.0002 s/iter. Total: 0.5427 s/iter. ETA=0:37:04\n",
            "\u001b[32m[04/30 19:39:11 d2.evaluation.evaluator]: \u001b[0mInference done 912/5000. Dataloading: 0.0019 s/iter. Inference: 0.5404 s/iter. Eval: 0.0002 s/iter. Total: 0.5427 s/iter. ETA=0:36:58\n",
            "\u001b[32m[04/30 19:39:16 d2.evaluation.evaluator]: \u001b[0mInference done 922/5000. Dataloading: 0.0019 s/iter. Inference: 0.5405 s/iter. Eval: 0.0002 s/iter. Total: 0.5428 s/iter. ETA=0:36:53\n",
            "\u001b[32m[04/30 19:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 932/5000. Dataloading: 0.0019 s/iter. Inference: 0.5406 s/iter. Eval: 0.0002 s/iter. Total: 0.5429 s/iter. ETA=0:36:48\n",
            "\u001b[32m[04/30 19:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 941/5000. Dataloading: 0.0019 s/iter. Inference: 0.5408 s/iter. Eval: 0.0002 s/iter. Total: 0.5430 s/iter. ETA=0:36:44\n",
            "\u001b[32m[04/30 19:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 950/5000. Dataloading: 0.0019 s/iter. Inference: 0.5409 s/iter. Eval: 0.0002 s/iter. Total: 0.5432 s/iter. ETA=0:36:39\n",
            "\u001b[32m[04/30 19:39:37 d2.evaluation.evaluator]: \u001b[0mInference done 960/5000. Dataloading: 0.0019 s/iter. Inference: 0.5410 s/iter. Eval: 0.0002 s/iter. Total: 0.5433 s/iter. ETA=0:36:34\n",
            "\u001b[32m[04/30 19:39:43 d2.evaluation.evaluator]: \u001b[0mInference done 970/5000. Dataloading: 0.0019 s/iter. Inference: 0.5411 s/iter. Eval: 0.0002 s/iter. Total: 0.5433 s/iter. ETA=0:36:29\n",
            "\u001b[32m[04/30 19:39:48 d2.evaluation.evaluator]: \u001b[0mInference done 980/5000. Dataloading: 0.0019 s/iter. Inference: 0.5411 s/iter. Eval: 0.0002 s/iter. Total: 0.5434 s/iter. ETA=0:36:24\n",
            "\u001b[32m[04/30 19:39:53 d2.evaluation.evaluator]: \u001b[0mInference done 989/5000. Dataloading: 0.0019 s/iter. Inference: 0.5412 s/iter. Eval: 0.0002 s/iter. Total: 0.5435 s/iter. ETA=0:36:19\n",
            "\u001b[32m[04/30 19:39:59 d2.evaluation.evaluator]: \u001b[0mInference done 999/5000. Dataloading: 0.0019 s/iter. Inference: 0.5413 s/iter. Eval: 0.0002 s/iter. Total: 0.5436 s/iter. ETA=0:36:14\n",
            "\u001b[32m[04/30 19:40:04 d2.evaluation.evaluator]: \u001b[0mInference done 1009/5000. Dataloading: 0.0019 s/iter. Inference: 0.5414 s/iter. Eval: 0.0002 s/iter. Total: 0.5436 s/iter. ETA=0:36:09\n",
            "\u001b[32m[04/30 19:40:10 d2.evaluation.evaluator]: \u001b[0mInference done 1019/5000. Dataloading: 0.0019 s/iter. Inference: 0.5414 s/iter. Eval: 0.0002 s/iter. Total: 0.5437 s/iter. ETA=0:36:04\n",
            "\u001b[32m[04/30 19:40:15 d2.evaluation.evaluator]: \u001b[0mInference done 1029/5000. Dataloading: 0.0019 s/iter. Inference: 0.5414 s/iter. Eval: 0.0002 s/iter. Total: 0.5437 s/iter. ETA=0:35:58\n",
            "\u001b[32m[04/30 19:40:21 d2.evaluation.evaluator]: \u001b[0mInference done 1039/5000. Dataloading: 0.0019 s/iter. Inference: 0.5415 s/iter. Eval: 0.0002 s/iter. Total: 0.5438 s/iter. ETA=0:35:53\n",
            "\u001b[32m[04/30 19:40:26 d2.evaluation.evaluator]: \u001b[0mInference done 1049/5000. Dataloading: 0.0019 s/iter. Inference: 0.5416 s/iter. Eval: 0.0002 s/iter. Total: 0.5439 s/iter. ETA=0:35:48\n",
            "\u001b[32m[04/30 19:40:31 d2.evaluation.evaluator]: \u001b[0mInference done 1058/5000. Dataloading: 0.0019 s/iter. Inference: 0.5417 s/iter. Eval: 0.0002 s/iter. Total: 0.5440 s/iter. ETA=0:35:44\n",
            "\u001b[32m[04/30 19:40:36 d2.evaluation.evaluator]: \u001b[0mInference done 1067/5000. Dataloading: 0.0019 s/iter. Inference: 0.5419 s/iter. Eval: 0.0002 s/iter. Total: 0.5441 s/iter. ETA=0:35:40\n",
            "\u001b[32m[04/30 19:40:41 d2.evaluation.evaluator]: \u001b[0mInference done 1076/5000. Dataloading: 0.0019 s/iter. Inference: 0.5420 s/iter. Eval: 0.0002 s/iter. Total: 0.5442 s/iter. ETA=0:35:35\n",
            "\u001b[32m[04/30 19:40:46 d2.evaluation.evaluator]: \u001b[0mInference done 1085/5000. Dataloading: 0.0019 s/iter. Inference: 0.5421 s/iter. Eval: 0.0002 s/iter. Total: 0.5444 s/iter. ETA=0:35:31\n",
            "\u001b[32m[04/30 19:40:52 d2.evaluation.evaluator]: \u001b[0mInference done 1095/5000. Dataloading: 0.0019 s/iter. Inference: 0.5421 s/iter. Eval: 0.0002 s/iter. Total: 0.5444 s/iter. ETA=0:35:25\n",
            "\u001b[32m[04/30 19:40:57 d2.evaluation.evaluator]: \u001b[0mInference done 1104/5000. Dataloading: 0.0019 s/iter. Inference: 0.5423 s/iter. Eval: 0.0002 s/iter. Total: 0.5445 s/iter. ETA=0:35:21\n",
            "\u001b[32m[04/30 19:41:02 d2.evaluation.evaluator]: \u001b[0mInference done 1114/5000. Dataloading: 0.0019 s/iter. Inference: 0.5424 s/iter. Eval: 0.0002 s/iter. Total: 0.5446 s/iter. ETA=0:35:16\n",
            "\u001b[32m[04/30 19:41:08 d2.evaluation.evaluator]: \u001b[0mInference done 1124/5000. Dataloading: 0.0019 s/iter. Inference: 0.5424 s/iter. Eval: 0.0002 s/iter. Total: 0.5447 s/iter. ETA=0:35:11\n",
            "\u001b[32m[04/30 19:41:13 d2.evaluation.evaluator]: \u001b[0mInference done 1133/5000. Dataloading: 0.0019 s/iter. Inference: 0.5426 s/iter. Eval: 0.0002 s/iter. Total: 0.5449 s/iter. ETA=0:35:07\n",
            "\u001b[32m[04/30 19:41:19 d2.evaluation.evaluator]: \u001b[0mInference done 1143/5000. Dataloading: 0.0019 s/iter. Inference: 0.5427 s/iter. Eval: 0.0002 s/iter. Total: 0.5450 s/iter. ETA=0:35:01\n",
            "\u001b[32m[04/30 19:41:24 d2.evaluation.evaluator]: \u001b[0mInference done 1153/5000. Dataloading: 0.0019 s/iter. Inference: 0.5427 s/iter. Eval: 0.0002 s/iter. Total: 0.5450 s/iter. ETA=0:34:56\n",
            "\u001b[32m[04/30 19:41:29 d2.evaluation.evaluator]: \u001b[0mInference done 1162/5000. Dataloading: 0.0019 s/iter. Inference: 0.5428 s/iter. Eval: 0.0002 s/iter. Total: 0.5451 s/iter. ETA=0:34:52\n",
            "\u001b[32m[04/30 19:41:34 d2.evaluation.evaluator]: \u001b[0mInference done 1171/5000. Dataloading: 0.0019 s/iter. Inference: 0.5430 s/iter. Eval: 0.0002 s/iter. Total: 0.5452 s/iter. ETA=0:34:47\n",
            "\u001b[32m[04/30 19:41:40 d2.evaluation.evaluator]: \u001b[0mInference done 1181/5000. Dataloading: 0.0019 s/iter. Inference: 0.5430 s/iter. Eval: 0.0002 s/iter. Total: 0.5453 s/iter. ETA=0:34:42\n",
            "\u001b[32m[04/30 19:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 1190/5000. Dataloading: 0.0019 s/iter. Inference: 0.5431 s/iter. Eval: 0.0002 s/iter. Total: 0.5454 s/iter. ETA=0:34:37\n",
            "\u001b[32m[04/30 19:41:50 d2.evaluation.evaluator]: \u001b[0mInference done 1199/5000. Dataloading: 0.0019 s/iter. Inference: 0.5432 s/iter. Eval: 0.0002 s/iter. Total: 0.5454 s/iter. ETA=0:34:33\n",
            "\u001b[32m[04/30 19:41:55 d2.evaluation.evaluator]: \u001b[0mInference done 1208/5000. Dataloading: 0.0020 s/iter. Inference: 0.5433 s/iter. Eval: 0.0002 s/iter. Total: 0.5455 s/iter. ETA=0:34:28\n",
            "\u001b[32m[04/30 19:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 1218/5000. Dataloading: 0.0020 s/iter. Inference: 0.5433 s/iter. Eval: 0.0002 s/iter. Total: 0.5456 s/iter. ETA=0:34:23\n",
            "\u001b[32m[04/30 19:42:06 d2.evaluation.evaluator]: \u001b[0mInference done 1228/5000. Dataloading: 0.0020 s/iter. Inference: 0.5433 s/iter. Eval: 0.0002 s/iter. Total: 0.5456 s/iter. ETA=0:34:18\n",
            "\u001b[32m[04/30 19:42:11 d2.evaluation.evaluator]: \u001b[0mInference done 1237/5000. Dataloading: 0.0020 s/iter. Inference: 0.5434 s/iter. Eval: 0.0002 s/iter. Total: 0.5457 s/iter. ETA=0:34:13\n",
            "\u001b[32m[04/30 19:42:16 d2.evaluation.evaluator]: \u001b[0mInference done 1247/5000. Dataloading: 0.0020 s/iter. Inference: 0.5435 s/iter. Eval: 0.0002 s/iter. Total: 0.5458 s/iter. ETA=0:34:08\n",
            "\u001b[32m[04/30 19:42:22 d2.evaluation.evaluator]: \u001b[0mInference done 1257/5000. Dataloading: 0.0020 s/iter. Inference: 0.5435 s/iter. Eval: 0.0002 s/iter. Total: 0.5458 s/iter. ETA=0:34:02\n",
            "\u001b[32m[04/30 19:42:27 d2.evaluation.evaluator]: \u001b[0mInference done 1267/5000. Dataloading: 0.0020 s/iter. Inference: 0.5435 s/iter. Eval: 0.0002 s/iter. Total: 0.5457 s/iter. ETA=0:33:57\n",
            "\u001b[32m[04/30 19:42:32 d2.evaluation.evaluator]: \u001b[0mInference done 1276/5000. Dataloading: 0.0020 s/iter. Inference: 0.5436 s/iter. Eval: 0.0002 s/iter. Total: 0.5459 s/iter. ETA=0:33:52\n",
            "\u001b[32m[04/30 19:42:37 d2.evaluation.evaluator]: \u001b[0mInference done 1285/5000. Dataloading: 0.0020 s/iter. Inference: 0.5437 s/iter. Eval: 0.0002 s/iter. Total: 0.5460 s/iter. ETA=0:33:48\n",
            "\u001b[32m[04/30 19:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 1295/5000. Dataloading: 0.0020 s/iter. Inference: 0.5437 s/iter. Eval: 0.0002 s/iter. Total: 0.5460 s/iter. ETA=0:33:42\n",
            "\u001b[32m[04/30 19:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 1305/5000. Dataloading: 0.0020 s/iter. Inference: 0.5437 s/iter. Eval: 0.0002 s/iter. Total: 0.5460 s/iter. ETA=0:33:37\n",
            "\u001b[32m[04/30 19:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 1314/5000. Dataloading: 0.0020 s/iter. Inference: 0.5438 s/iter. Eval: 0.0002 s/iter. Total: 0.5460 s/iter. ETA=0:33:32\n",
            "\u001b[32m[04/30 19:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 1324/5000. Dataloading: 0.0020 s/iter. Inference: 0.5437 s/iter. Eval: 0.0002 s/iter. Total: 0.5460 s/iter. ETA=0:33:26\n",
            "\u001b[32m[04/30 19:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 1334/5000. Dataloading: 0.0019 s/iter. Inference: 0.5438 s/iter. Eval: 0.0002 s/iter. Total: 0.5460 s/iter. ETA=0:33:21\n",
            "\u001b[32m[04/30 19:43:09 d2.evaluation.evaluator]: \u001b[0mInference done 1343/5000. Dataloading: 0.0019 s/iter. Inference: 0.5439 s/iter. Eval: 0.0002 s/iter. Total: 0.5461 s/iter. ETA=0:33:17\n",
            "\u001b[32m[04/30 19:43:15 d2.evaluation.evaluator]: \u001b[0mInference done 1353/5000. Dataloading: 0.0019 s/iter. Inference: 0.5439 s/iter. Eval: 0.0002 s/iter. Total: 0.5461 s/iter. ETA=0:33:11\n",
            "\u001b[32m[04/30 19:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 1362/5000. Dataloading: 0.0019 s/iter. Inference: 0.5439 s/iter. Eval: 0.0002 s/iter. Total: 0.5462 s/iter. ETA=0:33:07\n",
            "\u001b[32m[04/30 19:43:25 d2.evaluation.evaluator]: \u001b[0mInference done 1371/5000. Dataloading: 0.0019 s/iter. Inference: 0.5440 s/iter. Eval: 0.0002 s/iter. Total: 0.5463 s/iter. ETA=0:33:02\n",
            "\u001b[32m[04/30 19:43:30 d2.evaluation.evaluator]: \u001b[0mInference done 1381/5000. Dataloading: 0.0019 s/iter. Inference: 0.5440 s/iter. Eval: 0.0002 s/iter. Total: 0.5463 s/iter. ETA=0:32:56\n",
            "\u001b[32m[04/30 19:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 1391/5000. Dataloading: 0.0020 s/iter. Inference: 0.5440 s/iter. Eval: 0.0002 s/iter. Total: 0.5462 s/iter. ETA=0:32:51\n",
            "\u001b[32m[04/30 19:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 1400/5000. Dataloading: 0.0020 s/iter. Inference: 0.5440 s/iter. Eval: 0.0002 s/iter. Total: 0.5463 s/iter. ETA=0:32:46\n",
            "\u001b[32m[04/30 19:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 1410/5000. Dataloading: 0.0020 s/iter. Inference: 0.5440 s/iter. Eval: 0.0002 s/iter. Total: 0.5463 s/iter. ETA=0:32:41\n",
            "\u001b[32m[04/30 19:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 1420/5000. Dataloading: 0.0020 s/iter. Inference: 0.5440 s/iter. Eval: 0.0002 s/iter. Total: 0.5463 s/iter. ETA=0:32:35\n",
            "\u001b[32m[04/30 19:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 1430/5000. Dataloading: 0.0020 s/iter. Inference: 0.5440 s/iter. Eval: 0.0002 s/iter. Total: 0.5463 s/iter. ETA=0:32:30\n",
            "\u001b[32m[04/30 19:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 1439/5000. Dataloading: 0.0020 s/iter. Inference: 0.5441 s/iter. Eval: 0.0002 s/iter. Total: 0.5464 s/iter. ETA=0:32:25\n",
            "\u001b[32m[04/30 19:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 1448/5000. Dataloading: 0.0020 s/iter. Inference: 0.5442 s/iter. Eval: 0.0002 s/iter. Total: 0.5464 s/iter. ETA=0:32:20\n",
            "\u001b[32m[04/30 19:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 1458/5000. Dataloading: 0.0020 s/iter. Inference: 0.5442 s/iter. Eval: 0.0002 s/iter. Total: 0.5464 s/iter. ETA=0:32:15\n",
            "\u001b[32m[04/30 19:44:18 d2.evaluation.evaluator]: \u001b[0mInference done 1468/5000. Dataloading: 0.0020 s/iter. Inference: 0.5441 s/iter. Eval: 0.0002 s/iter. Total: 0.5463 s/iter. ETA=0:32:09\n",
            "\u001b[32m[04/30 19:44:23 d2.evaluation.evaluator]: \u001b[0mInference done 1478/5000. Dataloading: 0.0020 s/iter. Inference: 0.5441 s/iter. Eval: 0.0002 s/iter. Total: 0.5464 s/iter. ETA=0:32:04\n",
            "\u001b[32m[04/30 19:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 1487/5000. Dataloading: 0.0020 s/iter. Inference: 0.5442 s/iter. Eval: 0.0002 s/iter. Total: 0.5465 s/iter. ETA=0:31:59\n",
            "\u001b[32m[04/30 19:44:34 d2.evaluation.evaluator]: \u001b[0mInference done 1497/5000. Dataloading: 0.0020 s/iter. Inference: 0.5442 s/iter. Eval: 0.0002 s/iter. Total: 0.5465 s/iter. ETA=0:31:54\n",
            "\u001b[32m[04/30 19:44:39 d2.evaluation.evaluator]: \u001b[0mInference done 1506/5000. Dataloading: 0.0020 s/iter. Inference: 0.5442 s/iter. Eval: 0.0002 s/iter. Total: 0.5467 s/iter. ETA=0:31:50\n",
            "\u001b[32m[04/30 19:44:44 d2.evaluation.evaluator]: \u001b[0mInference done 1516/5000. Dataloading: 0.0020 s/iter. Inference: 0.5441 s/iter. Eval: 0.0002 s/iter. Total: 0.5466 s/iter. ETA=0:31:44\n",
            "\u001b[32m[04/30 19:44:50 d2.evaluation.evaluator]: \u001b[0mInference done 1526/5000. Dataloading: 0.0020 s/iter. Inference: 0.5442 s/iter. Eval: 0.0002 s/iter. Total: 0.5467 s/iter. ETA=0:31:39\n",
            "\u001b[32m[04/30 19:44:55 d2.evaluation.evaluator]: \u001b[0mInference done 1535/5000. Dataloading: 0.0020 s/iter. Inference: 0.5443 s/iter. Eval: 0.0002 s/iter. Total: 0.5468 s/iter. ETA=0:31:34\n",
            "\u001b[32m[04/30 19:45:01 d2.evaluation.evaluator]: \u001b[0mInference done 1545/5000. Dataloading: 0.0020 s/iter. Inference: 0.5444 s/iter. Eval: 0.0002 s/iter. Total: 0.5469 s/iter. ETA=0:31:29\n",
            "\u001b[32m[04/30 19:45:06 d2.evaluation.evaluator]: \u001b[0mInference done 1554/5000. Dataloading: 0.0020 s/iter. Inference: 0.5445 s/iter. Eval: 0.0002 s/iter. Total: 0.5470 s/iter. ETA=0:31:24\n",
            "\u001b[32m[04/30 19:45:11 d2.evaluation.evaluator]: \u001b[0mInference done 1564/5000. Dataloading: 0.0020 s/iter. Inference: 0.5445 s/iter. Eval: 0.0002 s/iter. Total: 0.5470 s/iter. ETA=0:31:19\n",
            "\u001b[32m[04/30 19:45:16 d2.evaluation.evaluator]: \u001b[0mInference done 1573/5000. Dataloading: 0.0020 s/iter. Inference: 0.5446 s/iter. Eval: 0.0002 s/iter. Total: 0.5471 s/iter. ETA=0:31:14\n",
            "\u001b[32m[04/30 19:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 1583/5000. Dataloading: 0.0020 s/iter. Inference: 0.5446 s/iter. Eval: 0.0002 s/iter. Total: 0.5471 s/iter. ETA=0:31:09\n",
            "\u001b[32m[04/30 19:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 1592/5000. Dataloading: 0.0020 s/iter. Inference: 0.5447 s/iter. Eval: 0.0002 s/iter. Total: 0.5472 s/iter. ETA=0:31:04\n",
            "\u001b[32m[04/30 19:45:32 d2.evaluation.evaluator]: \u001b[0mInference done 1601/5000. Dataloading: 0.0020 s/iter. Inference: 0.5447 s/iter. Eval: 0.0002 s/iter. Total: 0.5475 s/iter. ETA=0:31:00\n",
            "\u001b[32m[04/30 19:45:38 d2.evaluation.evaluator]: \u001b[0mInference done 1611/5000. Dataloading: 0.0020 s/iter. Inference: 0.5447 s/iter. Eval: 0.0002 s/iter. Total: 0.5475 s/iter. ETA=0:30:55\n",
            "\u001b[32m[04/30 19:45:43 d2.evaluation.evaluator]: \u001b[0mInference done 1621/5000. Dataloading: 0.0020 s/iter. Inference: 0.5447 s/iter. Eval: 0.0002 s/iter. Total: 0.5475 s/iter. ETA=0:30:49\n",
            "\u001b[32m[04/30 19:45:48 d2.evaluation.evaluator]: \u001b[0mInference done 1630/5000. Dataloading: 0.0020 s/iter. Inference: 0.5448 s/iter. Eval: 0.0002 s/iter. Total: 0.5475 s/iter. ETA=0:30:45\n",
            "\u001b[32m[04/30 19:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 1640/5000. Dataloading: 0.0020 s/iter. Inference: 0.5448 s/iter. Eval: 0.0002 s/iter. Total: 0.5475 s/iter. ETA=0:30:39\n",
            "\u001b[32m[04/30 19:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 1650/5000. Dataloading: 0.0020 s/iter. Inference: 0.5448 s/iter. Eval: 0.0002 s/iter. Total: 0.5476 s/iter. ETA=0:30:34\n",
            "\u001b[32m[04/30 19:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 1659/5000. Dataloading: 0.0020 s/iter. Inference: 0.5449 s/iter. Eval: 0.0002 s/iter. Total: 0.5476 s/iter. ETA=0:30:29\n",
            "\u001b[32m[04/30 19:46:10 d2.evaluation.evaluator]: \u001b[0mInference done 1669/5000. Dataloading: 0.0020 s/iter. Inference: 0.5449 s/iter. Eval: 0.0002 s/iter. Total: 0.5476 s/iter. ETA=0:30:24\n",
            "\u001b[32m[04/30 19:46:15 d2.evaluation.evaluator]: \u001b[0mInference done 1679/5000. Dataloading: 0.0020 s/iter. Inference: 0.5449 s/iter. Eval: 0.0002 s/iter. Total: 0.5477 s/iter. ETA=0:30:18\n",
            "\u001b[32m[04/30 19:46:21 d2.evaluation.evaluator]: \u001b[0mInference done 1689/5000. Dataloading: 0.0020 s/iter. Inference: 0.5449 s/iter. Eval: 0.0002 s/iter. Total: 0.5477 s/iter. ETA=0:30:13\n",
            "\u001b[32m[04/30 19:46:26 d2.evaluation.evaluator]: \u001b[0mInference done 1698/5000. Dataloading: 0.0020 s/iter. Inference: 0.5450 s/iter. Eval: 0.0002 s/iter. Total: 0.5477 s/iter. ETA=0:30:08\n",
            "\u001b[32m[04/30 19:46:31 d2.evaluation.evaluator]: \u001b[0mInference done 1708/5000. Dataloading: 0.0020 s/iter. Inference: 0.5450 s/iter. Eval: 0.0002 s/iter. Total: 0.5477 s/iter. ETA=0:30:03\n",
            "\u001b[32m[04/30 19:46:37 d2.evaluation.evaluator]: \u001b[0mInference done 1718/5000. Dataloading: 0.0020 s/iter. Inference: 0.5450 s/iter. Eval: 0.0002 s/iter. Total: 0.5477 s/iter. ETA=0:29:57\n",
            "\u001b[32m[04/30 19:46:42 d2.evaluation.evaluator]: \u001b[0mInference done 1727/5000. Dataloading: 0.0020 s/iter. Inference: 0.5451 s/iter. Eval: 0.0002 s/iter. Total: 0.5478 s/iter. ETA=0:29:52\n",
            "\u001b[32m[04/30 19:46:47 d2.evaluation.evaluator]: \u001b[0mInference done 1737/5000. Dataloading: 0.0020 s/iter. Inference: 0.5451 s/iter. Eval: 0.0002 s/iter. Total: 0.5478 s/iter. ETA=0:29:47\n",
            "\u001b[32m[04/30 19:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 1746/5000. Dataloading: 0.0020 s/iter. Inference: 0.5451 s/iter. Eval: 0.0002 s/iter. Total: 0.5480 s/iter. ETA=0:29:43\n",
            "\u001b[32m[04/30 19:46:58 d2.evaluation.evaluator]: \u001b[0mInference done 1756/5000. Dataloading: 0.0020 s/iter. Inference: 0.5452 s/iter. Eval: 0.0002 s/iter. Total: 0.5480 s/iter. ETA=0:29:37\n",
            "\u001b[32m[04/30 19:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 1765/5000. Dataloading: 0.0020 s/iter. Inference: 0.5452 s/iter. Eval: 0.0002 s/iter. Total: 0.5481 s/iter. ETA=0:29:33\n",
            "\u001b[32m[04/30 19:47:08 d2.evaluation.evaluator]: \u001b[0mInference done 1775/5000. Dataloading: 0.0020 s/iter. Inference: 0.5451 s/iter. Eval: 0.0002 s/iter. Total: 0.5480 s/iter. ETA=0:29:27\n",
            "\u001b[32m[04/30 19:47:14 d2.evaluation.evaluator]: \u001b[0mInference done 1785/5000. Dataloading: 0.0020 s/iter. Inference: 0.5451 s/iter. Eval: 0.0002 s/iter. Total: 0.5480 s/iter. ETA=0:29:21\n",
            "\u001b[32m[04/30 19:47:19 d2.evaluation.evaluator]: \u001b[0mInference done 1794/5000. Dataloading: 0.0020 s/iter. Inference: 0.5451 s/iter. Eval: 0.0002 s/iter. Total: 0.5481 s/iter. ETA=0:29:17\n",
            "\u001b[32m[04/30 19:47:24 d2.evaluation.evaluator]: \u001b[0mInference done 1804/5000. Dataloading: 0.0020 s/iter. Inference: 0.5452 s/iter. Eval: 0.0002 s/iter. Total: 0.5481 s/iter. ETA=0:29:11\n",
            "\u001b[32m[04/30 19:47:30 d2.evaluation.evaluator]: \u001b[0mInference done 1814/5000. Dataloading: 0.0020 s/iter. Inference: 0.5452 s/iter. Eval: 0.0002 s/iter. Total: 0.5481 s/iter. ETA=0:29:06\n",
            "\u001b[32m[04/30 19:47:35 d2.evaluation.evaluator]: \u001b[0mInference done 1823/5000. Dataloading: 0.0020 s/iter. Inference: 0.5452 s/iter. Eval: 0.0002 s/iter. Total: 0.5482 s/iter. ETA=0:29:01\n",
            "\u001b[32m[04/30 19:47:40 d2.evaluation.evaluator]: \u001b[0mInference done 1833/5000. Dataloading: 0.0020 s/iter. Inference: 0.5452 s/iter. Eval: 0.0002 s/iter. Total: 0.5481 s/iter. ETA=0:28:55\n",
            "\u001b[32m[04/30 19:47:45 d2.evaluation.evaluator]: \u001b[0mInference done 1842/5000. Dataloading: 0.0020 s/iter. Inference: 0.5453 s/iter. Eval: 0.0002 s/iter. Total: 0.5482 s/iter. ETA=0:28:51\n",
            "\u001b[32m[04/30 19:47:51 d2.evaluation.evaluator]: \u001b[0mInference done 1852/5000. Dataloading: 0.0020 s/iter. Inference: 0.5452 s/iter. Eval: 0.0002 s/iter. Total: 0.5481 s/iter. ETA=0:28:45\n",
            "\u001b[32m[04/30 19:47:56 d2.evaluation.evaluator]: \u001b[0mInference done 1862/5000. Dataloading: 0.0020 s/iter. Inference: 0.5452 s/iter. Eval: 0.0002 s/iter. Total: 0.5482 s/iter. ETA=0:28:40\n",
            "\u001b[32m[04/30 19:48:01 d2.evaluation.evaluator]: \u001b[0mInference done 1871/5000. Dataloading: 0.0020 s/iter. Inference: 0.5453 s/iter. Eval: 0.0002 s/iter. Total: 0.5482 s/iter. ETA=0:28:35\n",
            "\u001b[32m[04/30 19:48:07 d2.evaluation.evaluator]: \u001b[0mInference done 1881/5000. Dataloading: 0.0020 s/iter. Inference: 0.5453 s/iter. Eval: 0.0002 s/iter. Total: 0.5482 s/iter. ETA=0:28:29\n",
            "\u001b[32m[04/30 19:48:12 d2.evaluation.evaluator]: \u001b[0mInference done 1890/5000. Dataloading: 0.0020 s/iter. Inference: 0.5454 s/iter. Eval: 0.0002 s/iter. Total: 0.5483 s/iter. ETA=0:28:25\n",
            "\u001b[32m[04/30 19:48:18 d2.evaluation.evaluator]: \u001b[0mInference done 1900/5000. Dataloading: 0.0020 s/iter. Inference: 0.5455 s/iter. Eval: 0.0002 s/iter. Total: 0.5483 s/iter. ETA=0:28:19\n",
            "\u001b[32m[04/30 19:48:23 d2.evaluation.evaluator]: \u001b[0mInference done 1910/5000. Dataloading: 0.0020 s/iter. Inference: 0.5454 s/iter. Eval: 0.0002 s/iter. Total: 0.5483 s/iter. ETA=0:28:14\n",
            "\u001b[32m[04/30 19:48:29 d2.evaluation.evaluator]: \u001b[0mInference done 1920/5000. Dataloading: 0.0020 s/iter. Inference: 0.5455 s/iter. Eval: 0.0002 s/iter. Total: 0.5484 s/iter. ETA=0:28:08\n",
            "\u001b[32m[04/30 19:48:34 d2.evaluation.evaluator]: \u001b[0mInference done 1930/5000. Dataloading: 0.0020 s/iter. Inference: 0.5454 s/iter. Eval: 0.0002 s/iter. Total: 0.5483 s/iter. ETA=0:28:03\n",
            "\u001b[32m[04/30 19:48:39 d2.evaluation.evaluator]: \u001b[0mInference done 1940/5000. Dataloading: 0.0020 s/iter. Inference: 0.5455 s/iter. Eval: 0.0002 s/iter. Total: 0.5483 s/iter. ETA=0:27:57\n",
            "\u001b[32m[04/30 19:48:45 d2.evaluation.evaluator]: \u001b[0mInference done 1950/5000. Dataloading: 0.0020 s/iter. Inference: 0.5455 s/iter. Eval: 0.0002 s/iter. Total: 0.5483 s/iter. ETA=0:27:52\n",
            "\u001b[32m[04/30 19:48:50 d2.evaluation.evaluator]: \u001b[0mInference done 1960/5000. Dataloading: 0.0020 s/iter. Inference: 0.5455 s/iter. Eval: 0.0002 s/iter. Total: 0.5484 s/iter. ETA=0:27:47\n",
            "\u001b[32m[04/30 19:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 1970/5000. Dataloading: 0.0020 s/iter. Inference: 0.5455 s/iter. Eval: 0.0002 s/iter. Total: 0.5484 s/iter. ETA=0:27:41\n",
            "\u001b[32m[04/30 19:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 1980/5000. Dataloading: 0.0020 s/iter. Inference: 0.5455 s/iter. Eval: 0.0002 s/iter. Total: 0.5484 s/iter. ETA=0:27:36\n",
            "\u001b[32m[04/30 19:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 1989/5000. Dataloading: 0.0020 s/iter. Inference: 0.5455 s/iter. Eval: 0.0002 s/iter. Total: 0.5484 s/iter. ETA=0:27:31\n",
            "\u001b[32m[04/30 19:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 1999/5000. Dataloading: 0.0020 s/iter. Inference: 0.5456 s/iter. Eval: 0.0002 s/iter. Total: 0.5484 s/iter. ETA=0:27:25\n",
            "\u001b[32m[04/30 19:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 2009/5000. Dataloading: 0.0020 s/iter. Inference: 0.5456 s/iter. Eval: 0.0002 s/iter. Total: 0.5484 s/iter. ETA=0:27:20\n",
            "\u001b[32m[04/30 19:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 2018/5000. Dataloading: 0.0020 s/iter. Inference: 0.5456 s/iter. Eval: 0.0002 s/iter. Total: 0.5485 s/iter. ETA=0:27:15\n",
            "\u001b[32m[04/30 19:49:28 d2.evaluation.evaluator]: \u001b[0mInference done 2027/5000. Dataloading: 0.0020 s/iter. Inference: 0.5457 s/iter. Eval: 0.0002 s/iter. Total: 0.5486 s/iter. ETA=0:27:10\n",
            "\u001b[32m[04/30 19:49:33 d2.evaluation.evaluator]: \u001b[0mInference done 2037/5000. Dataloading: 0.0020 s/iter. Inference: 0.5456 s/iter. Eval: 0.0002 s/iter. Total: 0.5485 s/iter. ETA=0:27:05\n",
            "\u001b[32m[04/30 19:49:38 d2.evaluation.evaluator]: \u001b[0mInference done 2047/5000. Dataloading: 0.0020 s/iter. Inference: 0.5456 s/iter. Eval: 0.0002 s/iter. Total: 0.5485 s/iter. ETA=0:26:59\n",
            "\u001b[32m[04/30 19:49:44 d2.evaluation.evaluator]: \u001b[0mInference done 2057/5000. Dataloading: 0.0020 s/iter. Inference: 0.5456 s/iter. Eval: 0.0002 s/iter. Total: 0.5485 s/iter. ETA=0:26:54\n",
            "\u001b[32m[04/30 19:49:49 d2.evaluation.evaluator]: \u001b[0mInference done 2066/5000. Dataloading: 0.0020 s/iter. Inference: 0.5457 s/iter. Eval: 0.0002 s/iter. Total: 0.5485 s/iter. ETA=0:26:49\n",
            "\u001b[32m[04/30 19:49:54 d2.evaluation.evaluator]: \u001b[0mInference done 2076/5000. Dataloading: 0.0020 s/iter. Inference: 0.5457 s/iter. Eval: 0.0002 s/iter. Total: 0.5485 s/iter. ETA=0:26:43\n",
            "\u001b[32m[04/30 19:49:59 d2.evaluation.evaluator]: \u001b[0mInference done 2085/5000. Dataloading: 0.0020 s/iter. Inference: 0.5457 s/iter. Eval: 0.0002 s/iter. Total: 0.5486 s/iter. ETA=0:26:39\n",
            "\u001b[32m[04/30 19:50:05 d2.evaluation.evaluator]: \u001b[0mInference done 2095/5000. Dataloading: 0.0020 s/iter. Inference: 0.5457 s/iter. Eval: 0.0002 s/iter. Total: 0.5486 s/iter. ETA=0:26:33\n",
            "\u001b[32m[04/30 19:50:10 d2.evaluation.evaluator]: \u001b[0mInference done 2105/5000. Dataloading: 0.0020 s/iter. Inference: 0.5457 s/iter. Eval: 0.0002 s/iter. Total: 0.5486 s/iter. ETA=0:26:28\n",
            "\u001b[32m[04/30 19:50:16 d2.evaluation.evaluator]: \u001b[0mInference done 2115/5000. Dataloading: 0.0020 s/iter. Inference: 0.5457 s/iter. Eval: 0.0002 s/iter. Total: 0.5486 s/iter. ETA=0:26:22\n",
            "\u001b[32m[04/30 19:50:21 d2.evaluation.evaluator]: \u001b[0mInference done 2125/5000. Dataloading: 0.0020 s/iter. Inference: 0.5458 s/iter. Eval: 0.0002 s/iter. Total: 0.5486 s/iter. ETA=0:26:17\n",
            "\u001b[32m[04/30 19:50:27 d2.evaluation.evaluator]: \u001b[0mInference done 2135/5000. Dataloading: 0.0020 s/iter. Inference: 0.5458 s/iter. Eval: 0.0002 s/iter. Total: 0.5486 s/iter. ETA=0:26:11\n",
            "\u001b[32m[04/30 19:50:32 d2.evaluation.evaluator]: \u001b[0mInference done 2145/5000. Dataloading: 0.0020 s/iter. Inference: 0.5457 s/iter. Eval: 0.0002 s/iter. Total: 0.5486 s/iter. ETA=0:26:06\n",
            "\u001b[32m[04/30 19:50:38 d2.evaluation.evaluator]: \u001b[0mInference done 2155/5000. Dataloading: 0.0020 s/iter. Inference: 0.5457 s/iter. Eval: 0.0002 s/iter. Total: 0.5486 s/iter. ETA=0:26:00\n",
            "\u001b[32m[04/30 19:50:43 d2.evaluation.evaluator]: \u001b[0mInference done 2165/5000. Dataloading: 0.0020 s/iter. Inference: 0.5457 s/iter. Eval: 0.0002 s/iter. Total: 0.5486 s/iter. ETA=0:25:55\n",
            "\u001b[32m[04/30 19:50:49 d2.evaluation.evaluator]: \u001b[0mInference done 2175/5000. Dataloading: 0.0020 s/iter. Inference: 0.5457 s/iter. Eval: 0.0002 s/iter. Total: 0.5486 s/iter. ETA=0:25:49\n",
            "\u001b[32m[04/30 19:50:54 d2.evaluation.evaluator]: \u001b[0mInference done 2185/5000. Dataloading: 0.0020 s/iter. Inference: 0.5457 s/iter. Eval: 0.0002 s/iter. Total: 0.5485 s/iter. ETA=0:25:44\n",
            "\u001b[32m[04/30 19:50:59 d2.evaluation.evaluator]: \u001b[0mInference done 2194/5000. Dataloading: 0.0020 s/iter. Inference: 0.5458 s/iter. Eval: 0.0002 s/iter. Total: 0.5486 s/iter. ETA=0:25:39\n",
            "\u001b[32m[04/30 19:51:04 d2.evaluation.evaluator]: \u001b[0mInference done 2203/5000. Dataloading: 0.0020 s/iter. Inference: 0.5458 s/iter. Eval: 0.0002 s/iter. Total: 0.5486 s/iter. ETA=0:25:34\n",
            "\u001b[32m[04/30 19:51:10 d2.evaluation.evaluator]: \u001b[0mInference done 2213/5000. Dataloading: 0.0020 s/iter. Inference: 0.5458 s/iter. Eval: 0.0002 s/iter. Total: 0.5486 s/iter. ETA=0:25:28\n",
            "\u001b[32m[04/30 19:51:15 d2.evaluation.evaluator]: \u001b[0mInference done 2222/5000. Dataloading: 0.0020 s/iter. Inference: 0.5458 s/iter. Eval: 0.0002 s/iter. Total: 0.5486 s/iter. ETA=0:25:24\n",
            "\u001b[32m[04/30 19:51:20 d2.evaluation.evaluator]: \u001b[0mInference done 2232/5000. Dataloading: 0.0020 s/iter. Inference: 0.5459 s/iter. Eval: 0.0002 s/iter. Total: 0.5487 s/iter. ETA=0:25:18\n",
            "\u001b[32m[04/30 19:51:25 d2.evaluation.evaluator]: \u001b[0mInference done 2241/5000. Dataloading: 0.0020 s/iter. Inference: 0.5459 s/iter. Eval: 0.0002 s/iter. Total: 0.5487 s/iter. ETA=0:25:13\n",
            "\u001b[32m[04/30 19:51:30 d2.evaluation.evaluator]: \u001b[0mInference done 2250/5000. Dataloading: 0.0020 s/iter. Inference: 0.5459 s/iter. Eval: 0.0002 s/iter. Total: 0.5488 s/iter. ETA=0:25:09\n",
            "\u001b[32m[04/30 19:51:35 d2.evaluation.evaluator]: \u001b[0mInference done 2259/5000. Dataloading: 0.0020 s/iter. Inference: 0.5460 s/iter. Eval: 0.0002 s/iter. Total: 0.5488 s/iter. ETA=0:25:04\n",
            "\u001b[32m[04/30 19:51:41 d2.evaluation.evaluator]: \u001b[0mInference done 2269/5000. Dataloading: 0.0020 s/iter. Inference: 0.5460 s/iter. Eval: 0.0002 s/iter. Total: 0.5488 s/iter. ETA=0:24:58\n",
            "\u001b[32m[04/30 19:51:46 d2.evaluation.evaluator]: \u001b[0mInference done 2278/5000. Dataloading: 0.0020 s/iter. Inference: 0.5460 s/iter. Eval: 0.0002 s/iter. Total: 0.5488 s/iter. ETA=0:24:53\n",
            "\u001b[32m[04/30 19:51:51 d2.evaluation.evaluator]: \u001b[0mInference done 2287/5000. Dataloading: 0.0020 s/iter. Inference: 0.5461 s/iter. Eval: 0.0002 s/iter. Total: 0.5489 s/iter. ETA=0:24:49\n",
            "\u001b[32m[04/30 19:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 2297/5000. Dataloading: 0.0020 s/iter. Inference: 0.5460 s/iter. Eval: 0.0002 s/iter. Total: 0.5488 s/iter. ETA=0:24:43\n",
            "\u001b[32m[04/30 19:52:01 d2.evaluation.evaluator]: \u001b[0mInference done 2306/5000. Dataloading: 0.0020 s/iter. Inference: 0.5460 s/iter. Eval: 0.0002 s/iter. Total: 0.5488 s/iter. ETA=0:24:38\n",
            "\u001b[32m[04/30 19:52:07 d2.evaluation.evaluator]: \u001b[0mInference done 2316/5000. Dataloading: 0.0020 s/iter. Inference: 0.5461 s/iter. Eval: 0.0002 s/iter. Total: 0.5489 s/iter. ETA=0:24:33\n",
            "\u001b[32m[04/30 19:52:12 d2.evaluation.evaluator]: \u001b[0mInference done 2326/5000. Dataloading: 0.0020 s/iter. Inference: 0.5461 s/iter. Eval: 0.0002 s/iter. Total: 0.5489 s/iter. ETA=0:24:27\n",
            "\u001b[32m[04/30 19:52:18 d2.evaluation.evaluator]: \u001b[0mInference done 2336/5000. Dataloading: 0.0020 s/iter. Inference: 0.5461 s/iter. Eval: 0.0002 s/iter. Total: 0.5489 s/iter. ETA=0:24:22\n",
            "\u001b[32m[04/30 19:52:23 d2.evaluation.evaluator]: \u001b[0mInference done 2345/5000. Dataloading: 0.0020 s/iter. Inference: 0.5462 s/iter. Eval: 0.0002 s/iter. Total: 0.5490 s/iter. ETA=0:24:17\n",
            "\u001b[32m[04/30 19:52:28 d2.evaluation.evaluator]: \u001b[0mInference done 2354/5000. Dataloading: 0.0020 s/iter. Inference: 0.5462 s/iter. Eval: 0.0002 s/iter. Total: 0.5490 s/iter. ETA=0:24:12\n",
            "\u001b[32m[04/30 19:52:34 d2.evaluation.evaluator]: \u001b[0mInference done 2364/5000. Dataloading: 0.0020 s/iter. Inference: 0.5462 s/iter. Eval: 0.0002 s/iter. Total: 0.5490 s/iter. ETA=0:24:07\n",
            "\u001b[32m[04/30 19:52:39 d2.evaluation.evaluator]: \u001b[0mInference done 2374/5000. Dataloading: 0.0020 s/iter. Inference: 0.5462 s/iter. Eval: 0.0002 s/iter. Total: 0.5490 s/iter. ETA=0:24:01\n",
            "\u001b[32m[04/30 19:52:45 d2.evaluation.evaluator]: \u001b[0mInference done 2384/5000. Dataloading: 0.0020 s/iter. Inference: 0.5462 s/iter. Eval: 0.0002 s/iter. Total: 0.5490 s/iter. ETA=0:23:56\n",
            "\u001b[32m[04/30 19:52:50 d2.evaluation.evaluator]: \u001b[0mInference done 2394/5000. Dataloading: 0.0020 s/iter. Inference: 0.5463 s/iter. Eval: 0.0002 s/iter. Total: 0.5490 s/iter. ETA=0:23:50\n",
            "\u001b[32m[04/30 19:52:56 d2.evaluation.evaluator]: \u001b[0mInference done 2404/5000. Dataloading: 0.0020 s/iter. Inference: 0.5463 s/iter. Eval: 0.0002 s/iter. Total: 0.5490 s/iter. ETA=0:23:45\n",
            "\u001b[32m[04/30 19:53:01 d2.evaluation.evaluator]: \u001b[0mInference done 2413/5000. Dataloading: 0.0020 s/iter. Inference: 0.5463 s/iter. Eval: 0.0002 s/iter. Total: 0.5491 s/iter. ETA=0:23:40\n",
            "\u001b[32m[04/30 19:53:06 d2.evaluation.evaluator]: \u001b[0mInference done 2423/5000. Dataloading: 0.0020 s/iter. Inference: 0.5463 s/iter. Eval: 0.0002 s/iter. Total: 0.5491 s/iter. ETA=0:23:34\n",
            "\u001b[32m[04/30 19:53:11 d2.evaluation.evaluator]: \u001b[0mInference done 2432/5000. Dataloading: 0.0020 s/iter. Inference: 0.5463 s/iter. Eval: 0.0002 s/iter. Total: 0.5491 s/iter. ETA=0:23:30\n",
            "\u001b[32m[04/30 19:53:16 d2.evaluation.evaluator]: \u001b[0mInference done 2441/5000. Dataloading: 0.0020 s/iter. Inference: 0.5464 s/iter. Eval: 0.0002 s/iter. Total: 0.5492 s/iter. ETA=0:23:25\n",
            "\u001b[32m[04/30 19:53:22 d2.evaluation.evaluator]: \u001b[0mInference done 2451/5000. Dataloading: 0.0020 s/iter. Inference: 0.5464 s/iter. Eval: 0.0002 s/iter. Total: 0.5492 s/iter. ETA=0:23:19\n",
            "\u001b[32m[04/30 19:53:27 d2.evaluation.evaluator]: \u001b[0mInference done 2460/5000. Dataloading: 0.0020 s/iter. Inference: 0.5464 s/iter. Eval: 0.0002 s/iter. Total: 0.5492 s/iter. ETA=0:23:14\n",
            "\u001b[32m[04/30 19:53:32 d2.evaluation.evaluator]: \u001b[0mInference done 2470/5000. Dataloading: 0.0020 s/iter. Inference: 0.5465 s/iter. Eval: 0.0002 s/iter. Total: 0.5492 s/iter. ETA=0:23:09\n",
            "\u001b[32m[04/30 19:53:38 d2.evaluation.evaluator]: \u001b[0mInference done 2480/5000. Dataloading: 0.0020 s/iter. Inference: 0.5464 s/iter. Eval: 0.0002 s/iter. Total: 0.5491 s/iter. ETA=0:23:03\n",
            "\u001b[32m[04/30 19:53:43 d2.evaluation.evaluator]: \u001b[0mInference done 2490/5000. Dataloading: 0.0020 s/iter. Inference: 0.5464 s/iter. Eval: 0.0002 s/iter. Total: 0.5492 s/iter. ETA=0:22:58\n",
            "\u001b[32m[04/30 19:53:49 d2.evaluation.evaluator]: \u001b[0mInference done 2500/5000. Dataloading: 0.0020 s/iter. Inference: 0.5464 s/iter. Eval: 0.0002 s/iter. Total: 0.5492 s/iter. ETA=0:22:52\n",
            "\u001b[32m[04/30 19:53:54 d2.evaluation.evaluator]: \u001b[0mInference done 2510/5000. Dataloading: 0.0020 s/iter. Inference: 0.5464 s/iter. Eval: 0.0002 s/iter. Total: 0.5492 s/iter. ETA=0:22:47\n",
            "\u001b[32m[04/30 19:54:00 d2.evaluation.evaluator]: \u001b[0mInference done 2520/5000. Dataloading: 0.0020 s/iter. Inference: 0.5464 s/iter. Eval: 0.0002 s/iter. Total: 0.5492 s/iter. ETA=0:22:42\n",
            "\u001b[32m[04/30 19:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 2530/5000. Dataloading: 0.0020 s/iter. Inference: 0.5464 s/iter. Eval: 0.0002 s/iter. Total: 0.5491 s/iter. ETA=0:22:36\n",
            "\u001b[32m[04/30 19:54:11 d2.evaluation.evaluator]: \u001b[0mInference done 2540/5000. Dataloading: 0.0020 s/iter. Inference: 0.5464 s/iter. Eval: 0.0002 s/iter. Total: 0.5492 s/iter. ETA=0:22:30\n",
            "\u001b[32m[04/30 19:54:16 d2.evaluation.evaluator]: \u001b[0mInference done 2549/5000. Dataloading: 0.0020 s/iter. Inference: 0.5465 s/iter. Eval: 0.0002 s/iter. Total: 0.5492 s/iter. ETA=0:22:26\n",
            "\u001b[32m[04/30 19:54:21 d2.evaluation.evaluator]: \u001b[0mInference done 2558/5000. Dataloading: 0.0020 s/iter. Inference: 0.5465 s/iter. Eval: 0.0002 s/iter. Total: 0.5492 s/iter. ETA=0:22:21\n",
            "\u001b[32m[04/30 19:54:26 d2.evaluation.evaluator]: \u001b[0mInference done 2568/5000. Dataloading: 0.0020 s/iter. Inference: 0.5465 s/iter. Eval: 0.0002 s/iter. Total: 0.5493 s/iter. ETA=0:22:15\n",
            "\u001b[32m[04/30 19:54:32 d2.evaluation.evaluator]: \u001b[0mInference done 2578/5000. Dataloading: 0.0020 s/iter. Inference: 0.5465 s/iter. Eval: 0.0002 s/iter. Total: 0.5492 s/iter. ETA=0:22:10\n",
            "\u001b[32m[04/30 19:54:37 d2.evaluation.evaluator]: \u001b[0mInference done 2588/5000. Dataloading: 0.0020 s/iter. Inference: 0.5465 s/iter. Eval: 0.0002 s/iter. Total: 0.5492 s/iter. ETA=0:22:04\n",
            "\u001b[32m[04/30 19:54:42 d2.evaluation.evaluator]: \u001b[0mInference done 2598/5000. Dataloading: 0.0020 s/iter. Inference: 0.5464 s/iter. Eval: 0.0002 s/iter. Total: 0.5492 s/iter. ETA=0:21:59\n",
            "\u001b[32m[04/30 19:54:48 d2.evaluation.evaluator]: \u001b[0mInference done 2607/5000. Dataloading: 0.0020 s/iter. Inference: 0.5465 s/iter. Eval: 0.0002 s/iter. Total: 0.5492 s/iter. ETA=0:21:54\n",
            "\u001b[32m[04/30 19:54:53 d2.evaluation.evaluator]: \u001b[0mInference done 2616/5000. Dataloading: 0.0020 s/iter. Inference: 0.5465 s/iter. Eval: 0.0002 s/iter. Total: 0.5493 s/iter. ETA=0:21:49\n",
            "\u001b[32m[04/30 19:54:58 d2.evaluation.evaluator]: \u001b[0mInference done 2626/5000. Dataloading: 0.0020 s/iter. Inference: 0.5465 s/iter. Eval: 0.0002 s/iter. Total: 0.5493 s/iter. ETA=0:21:43\n",
            "\u001b[32m[04/30 19:55:03 d2.evaluation.evaluator]: \u001b[0mInference done 2635/5000. Dataloading: 0.0020 s/iter. Inference: 0.5466 s/iter. Eval: 0.0002 s/iter. Total: 0.5493 s/iter. ETA=0:21:39\n",
            "\u001b[32m[04/30 19:55:08 d2.evaluation.evaluator]: \u001b[0mInference done 2644/5000. Dataloading: 0.0020 s/iter. Inference: 0.5466 s/iter. Eval: 0.0002 s/iter. Total: 0.5493 s/iter. ETA=0:21:34\n",
            "\u001b[32m[04/30 19:55:14 d2.evaluation.evaluator]: \u001b[0mInference done 2654/5000. Dataloading: 0.0020 s/iter. Inference: 0.5466 s/iter. Eval: 0.0002 s/iter. Total: 0.5494 s/iter. ETA=0:21:28\n",
            "\u001b[32m[04/30 19:55:19 d2.evaluation.evaluator]: \u001b[0mInference done 2664/5000. Dataloading: 0.0020 s/iter. Inference: 0.5466 s/iter. Eval: 0.0002 s/iter. Total: 0.5494 s/iter. ETA=0:21:23\n",
            "\u001b[32m[04/30 19:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 2673/5000. Dataloading: 0.0020 s/iter. Inference: 0.5467 s/iter. Eval: 0.0002 s/iter. Total: 0.5494 s/iter. ETA=0:21:18\n",
            "\u001b[32m[04/30 19:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 2682/5000. Dataloading: 0.0020 s/iter. Inference: 0.5467 s/iter. Eval: 0.0002 s/iter. Total: 0.5494 s/iter. ETA=0:21:13\n",
            "\u001b[32m[04/30 19:55:34 d2.evaluation.evaluator]: \u001b[0mInference done 2691/5000. Dataloading: 0.0020 s/iter. Inference: 0.5467 s/iter. Eval: 0.0002 s/iter. Total: 0.5495 s/iter. ETA=0:21:08\n",
            "\u001b[32m[04/30 19:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 2700/5000. Dataloading: 0.0020 s/iter. Inference: 0.5468 s/iter. Eval: 0.0002 s/iter. Total: 0.5495 s/iter. ETA=0:21:03\n",
            "\u001b[32m[04/30 19:55:45 d2.evaluation.evaluator]: \u001b[0mInference done 2710/5000. Dataloading: 0.0020 s/iter. Inference: 0.5468 s/iter. Eval: 0.0002 s/iter. Total: 0.5495 s/iter. ETA=0:20:58\n",
            "\u001b[32m[04/30 19:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 2720/5000. Dataloading: 0.0020 s/iter. Inference: 0.5468 s/iter. Eval: 0.0002 s/iter. Total: 0.5495 s/iter. ETA=0:20:52\n",
            "\u001b[32m[04/30 19:55:56 d2.evaluation.evaluator]: \u001b[0mInference done 2730/5000. Dataloading: 0.0020 s/iter. Inference: 0.5468 s/iter. Eval: 0.0002 s/iter. Total: 0.5495 s/iter. ETA=0:20:47\n",
            "\u001b[32m[04/30 19:56:01 d2.evaluation.evaluator]: \u001b[0mInference done 2740/5000. Dataloading: 0.0020 s/iter. Inference: 0.5468 s/iter. Eval: 0.0002 s/iter. Total: 0.5495 s/iter. ETA=0:20:41\n",
            "\u001b[32m[04/30 19:56:07 d2.evaluation.evaluator]: \u001b[0mInference done 2750/5000. Dataloading: 0.0020 s/iter. Inference: 0.5468 s/iter. Eval: 0.0002 s/iter. Total: 0.5495 s/iter. ETA=0:20:36\n",
            "\u001b[32m[04/30 19:56:12 d2.evaluation.evaluator]: \u001b[0mInference done 2760/5000. Dataloading: 0.0020 s/iter. Inference: 0.5468 s/iter. Eval: 0.0002 s/iter. Total: 0.5495 s/iter. ETA=0:20:30\n",
            "\u001b[32m[04/30 19:56:17 d2.evaluation.evaluator]: \u001b[0mInference done 2769/5000. Dataloading: 0.0020 s/iter. Inference: 0.5468 s/iter. Eval: 0.0002 s/iter. Total: 0.5495 s/iter. ETA=0:20:25\n",
            "\u001b[32m[04/30 19:56:22 d2.evaluation.evaluator]: \u001b[0mInference done 2778/5000. Dataloading: 0.0020 s/iter. Inference: 0.5468 s/iter. Eval: 0.0002 s/iter. Total: 0.5496 s/iter. ETA=0:20:21\n",
            "\u001b[32m[04/30 19:56:28 d2.evaluation.evaluator]: \u001b[0mInference done 2788/5000. Dataloading: 0.0020 s/iter. Inference: 0.5468 s/iter. Eval: 0.0002 s/iter. Total: 0.5496 s/iter. ETA=0:20:15\n",
            "\u001b[32m[04/30 19:56:33 d2.evaluation.evaluator]: \u001b[0mInference done 2798/5000. Dataloading: 0.0020 s/iter. Inference: 0.5468 s/iter. Eval: 0.0002 s/iter. Total: 0.5495 s/iter. ETA=0:20:10\n",
            "\u001b[32m[04/30 19:56:38 d2.evaluation.evaluator]: \u001b[0mInference done 2807/5000. Dataloading: 0.0020 s/iter. Inference: 0.5468 s/iter. Eval: 0.0002 s/iter. Total: 0.5496 s/iter. ETA=0:20:05\n",
            "\u001b[32m[04/30 19:56:44 d2.evaluation.evaluator]: \u001b[0mInference done 2817/5000. Dataloading: 0.0020 s/iter. Inference: 0.5468 s/iter. Eval: 0.0002 s/iter. Total: 0.5495 s/iter. ETA=0:19:59\n",
            "\u001b[32m[04/30 19:56:49 d2.evaluation.evaluator]: \u001b[0mInference done 2827/5000. Dataloading: 0.0020 s/iter. Inference: 0.5468 s/iter. Eval: 0.0002 s/iter. Total: 0.5495 s/iter. ETA=0:19:54\n",
            "\u001b[32m[04/30 19:56:54 d2.evaluation.evaluator]: \u001b[0mInference done 2836/5000. Dataloading: 0.0020 s/iter. Inference: 0.5469 s/iter. Eval: 0.0002 s/iter. Total: 0.5496 s/iter. ETA=0:19:49\n",
            "\u001b[32m[04/30 19:56:59 d2.evaluation.evaluator]: \u001b[0mInference done 2845/5000. Dataloading: 0.0020 s/iter. Inference: 0.5469 s/iter. Eval: 0.0002 s/iter. Total: 0.5497 s/iter. ETA=0:19:44\n",
            "\u001b[32m[04/30 19:57:05 d2.evaluation.evaluator]: \u001b[0mInference done 2855/5000. Dataloading: 0.0020 s/iter. Inference: 0.5469 s/iter. Eval: 0.0002 s/iter. Total: 0.5496 s/iter. ETA=0:19:38\n",
            "\u001b[32m[04/30 19:57:10 d2.evaluation.evaluator]: \u001b[0mInference done 2865/5000. Dataloading: 0.0020 s/iter. Inference: 0.5469 s/iter. Eval: 0.0002 s/iter. Total: 0.5496 s/iter. ETA=0:19:33\n",
            "\u001b[32m[04/30 19:57:15 d2.evaluation.evaluator]: \u001b[0mInference done 2874/5000. Dataloading: 0.0020 s/iter. Inference: 0.5470 s/iter. Eval: 0.0002 s/iter. Total: 0.5497 s/iter. ETA=0:19:28\n",
            "\u001b[32m[04/30 19:57:21 d2.evaluation.evaluator]: \u001b[0mInference done 2883/5000. Dataloading: 0.0020 s/iter. Inference: 0.5470 s/iter. Eval: 0.0002 s/iter. Total: 0.5497 s/iter. ETA=0:19:23\n",
            "\u001b[32m[04/30 19:57:26 d2.evaluation.evaluator]: \u001b[0mInference done 2893/5000. Dataloading: 0.0020 s/iter. Inference: 0.5470 s/iter. Eval: 0.0002 s/iter. Total: 0.5497 s/iter. ETA=0:19:18\n",
            "\u001b[32m[04/30 19:57:32 d2.evaluation.evaluator]: \u001b[0mInference done 2903/5000. Dataloading: 0.0020 s/iter. Inference: 0.5470 s/iter. Eval: 0.0002 s/iter. Total: 0.5497 s/iter. ETA=0:19:12\n",
            "\u001b[32m[04/30 19:57:37 d2.evaluation.evaluator]: \u001b[0mInference done 2912/5000. Dataloading: 0.0020 s/iter. Inference: 0.5471 s/iter. Eval: 0.0002 s/iter. Total: 0.5498 s/iter. ETA=0:19:07\n",
            "\u001b[32m[04/30 19:57:42 d2.evaluation.evaluator]: \u001b[0mInference done 2922/5000. Dataloading: 0.0020 s/iter. Inference: 0.5471 s/iter. Eval: 0.0002 s/iter. Total: 0.5497 s/iter. ETA=0:19:02\n",
            "\u001b[32m[04/30 19:57:48 d2.evaluation.evaluator]: \u001b[0mInference done 2932/5000. Dataloading: 0.0020 s/iter. Inference: 0.5471 s/iter. Eval: 0.0002 s/iter. Total: 0.5498 s/iter. ETA=0:18:56\n",
            "\u001b[32m[04/30 19:57:53 d2.evaluation.evaluator]: \u001b[0mInference done 2941/5000. Dataloading: 0.0020 s/iter. Inference: 0.5471 s/iter. Eval: 0.0002 s/iter. Total: 0.5498 s/iter. ETA=0:18:52\n",
            "\u001b[32m[04/30 19:57:58 d2.evaluation.evaluator]: \u001b[0mInference done 2951/5000. Dataloading: 0.0020 s/iter. Inference: 0.5471 s/iter. Eval: 0.0002 s/iter. Total: 0.5498 s/iter. ETA=0:18:46\n",
            "\u001b[32m[04/30 19:58:04 d2.evaluation.evaluator]: \u001b[0mInference done 2961/5000. Dataloading: 0.0020 s/iter. Inference: 0.5471 s/iter. Eval: 0.0002 s/iter. Total: 0.5498 s/iter. ETA=0:18:41\n",
            "\u001b[32m[04/30 19:58:09 d2.evaluation.evaluator]: \u001b[0mInference done 2971/5000. Dataloading: 0.0020 s/iter. Inference: 0.5471 s/iter. Eval: 0.0002 s/iter. Total: 0.5498 s/iter. ETA=0:18:35\n",
            "\u001b[32m[04/30 19:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 2980/5000. Dataloading: 0.0020 s/iter. Inference: 0.5471 s/iter. Eval: 0.0002 s/iter. Total: 0.5498 s/iter. ETA=0:18:30\n",
            "\u001b[32m[04/30 19:58:20 d2.evaluation.evaluator]: \u001b[0mInference done 2990/5000. Dataloading: 0.0020 s/iter. Inference: 0.5471 s/iter. Eval: 0.0002 s/iter. Total: 0.5498 s/iter. ETA=0:18:25\n",
            "\u001b[32m[04/30 19:58:25 d2.evaluation.evaluator]: \u001b[0mInference done 2999/5000. Dataloading: 0.0020 s/iter. Inference: 0.5471 s/iter. Eval: 0.0002 s/iter. Total: 0.5498 s/iter. ETA=0:18:20\n",
            "\u001b[32m[04/30 19:58:30 d2.evaluation.evaluator]: \u001b[0mInference done 3009/5000. Dataloading: 0.0020 s/iter. Inference: 0.5471 s/iter. Eval: 0.0002 s/iter. Total: 0.5498 s/iter. ETA=0:18:14\n",
            "\u001b[32m[04/30 19:58:35 d2.evaluation.evaluator]: \u001b[0mInference done 3018/5000. Dataloading: 0.0020 s/iter. Inference: 0.5472 s/iter. Eval: 0.0002 s/iter. Total: 0.5498 s/iter. ETA=0:18:09\n",
            "\u001b[32m[04/30 19:58:41 d2.evaluation.evaluator]: \u001b[0mInference done 3028/5000. Dataloading: 0.0020 s/iter. Inference: 0.5472 s/iter. Eval: 0.0002 s/iter. Total: 0.5499 s/iter. ETA=0:18:04\n",
            "\u001b[32m[04/30 19:58:46 d2.evaluation.evaluator]: \u001b[0mInference done 3037/5000. Dataloading: 0.0020 s/iter. Inference: 0.5472 s/iter. Eval: 0.0002 s/iter. Total: 0.5499 s/iter. ETA=0:17:59\n",
            "\u001b[32m[04/30 19:58:51 d2.evaluation.evaluator]: \u001b[0mInference done 3046/5000. Dataloading: 0.0020 s/iter. Inference: 0.5472 s/iter. Eval: 0.0002 s/iter. Total: 0.5499 s/iter. ETA=0:17:54\n",
            "\u001b[32m[04/30 19:58:56 d2.evaluation.evaluator]: \u001b[0mInference done 3055/5000. Dataloading: 0.0020 s/iter. Inference: 0.5473 s/iter. Eval: 0.0002 s/iter. Total: 0.5500 s/iter. ETA=0:17:49\n",
            "\u001b[32m[04/30 19:59:01 d2.evaluation.evaluator]: \u001b[0mInference done 3064/5000. Dataloading: 0.0020 s/iter. Inference: 0.5473 s/iter. Eval: 0.0002 s/iter. Total: 0.5500 s/iter. ETA=0:17:44\n",
            "\u001b[32m[04/30 19:59:06 d2.evaluation.evaluator]: \u001b[0mInference done 3074/5000. Dataloading: 0.0020 s/iter. Inference: 0.5473 s/iter. Eval: 0.0002 s/iter. Total: 0.5500 s/iter. ETA=0:17:39\n",
            "\u001b[32m[04/30 19:59:11 d2.evaluation.evaluator]: \u001b[0mInference done 3083/5000. Dataloading: 0.0020 s/iter. Inference: 0.5474 s/iter. Eval: 0.0002 s/iter. Total: 0.5500 s/iter. ETA=0:17:34\n",
            "\u001b[32m[04/30 19:59:17 d2.evaluation.evaluator]: \u001b[0mInference done 3093/5000. Dataloading: 0.0020 s/iter. Inference: 0.5474 s/iter. Eval: 0.0002 s/iter. Total: 0.5501 s/iter. ETA=0:17:28\n",
            "\u001b[32m[04/30 19:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 3103/5000. Dataloading: 0.0020 s/iter. Inference: 0.5474 s/iter. Eval: 0.0002 s/iter. Total: 0.5500 s/iter. ETA=0:17:23\n",
            "\u001b[32m[04/30 19:59:28 d2.evaluation.evaluator]: \u001b[0mInference done 3113/5000. Dataloading: 0.0020 s/iter. Inference: 0.5474 s/iter. Eval: 0.0002 s/iter. Total: 0.5500 s/iter. ETA=0:17:17\n",
            "\u001b[32m[04/30 19:59:33 d2.evaluation.evaluator]: \u001b[0mInference done 3122/5000. Dataloading: 0.0020 s/iter. Inference: 0.5474 s/iter. Eval: 0.0002 s/iter. Total: 0.5501 s/iter. ETA=0:17:13\n",
            "\u001b[32m[04/30 19:59:38 d2.evaluation.evaluator]: \u001b[0mInference done 3131/5000. Dataloading: 0.0020 s/iter. Inference: 0.5474 s/iter. Eval: 0.0002 s/iter. Total: 0.5501 s/iter. ETA=0:17:08\n",
            "\u001b[32m[04/30 19:59:44 d2.evaluation.evaluator]: \u001b[0mInference done 3141/5000. Dataloading: 0.0020 s/iter. Inference: 0.5474 s/iter. Eval: 0.0002 s/iter. Total: 0.5501 s/iter. ETA=0:17:02\n",
            "\u001b[32m[04/30 19:59:49 d2.evaluation.evaluator]: \u001b[0mInference done 3151/5000. Dataloading: 0.0020 s/iter. Inference: 0.5474 s/iter. Eval: 0.0002 s/iter. Total: 0.5501 s/iter. ETA=0:16:57\n",
            "\u001b[32m[04/30 19:59:55 d2.evaluation.evaluator]: \u001b[0mInference done 3161/5000. Dataloading: 0.0020 s/iter. Inference: 0.5474 s/iter. Eval: 0.0002 s/iter. Total: 0.5501 s/iter. ETA=0:16:51\n",
            "\u001b[32m[04/30 20:00:00 d2.evaluation.evaluator]: \u001b[0mInference done 3171/5000. Dataloading: 0.0020 s/iter. Inference: 0.5474 s/iter. Eval: 0.0002 s/iter. Total: 0.5501 s/iter. ETA=0:16:46\n",
            "\u001b[32m[04/30 20:00:06 d2.evaluation.evaluator]: \u001b[0mInference done 3181/5000. Dataloading: 0.0020 s/iter. Inference: 0.5474 s/iter. Eval: 0.0002 s/iter. Total: 0.5501 s/iter. ETA=0:16:40\n",
            "\u001b[32m[04/30 20:00:11 d2.evaluation.evaluator]: \u001b[0mInference done 3191/5000. Dataloading: 0.0020 s/iter. Inference: 0.5475 s/iter. Eval: 0.0002 s/iter. Total: 0.5501 s/iter. ETA=0:16:35\n",
            "\u001b[32m[04/30 20:00:16 d2.evaluation.evaluator]: \u001b[0mInference done 3200/5000. Dataloading: 0.0020 s/iter. Inference: 0.5475 s/iter. Eval: 0.0002 s/iter. Total: 0.5501 s/iter. ETA=0:16:30\n",
            "\u001b[32m[04/30 20:00:22 d2.evaluation.evaluator]: \u001b[0mInference done 3210/5000. Dataloading: 0.0020 s/iter. Inference: 0.5475 s/iter. Eval: 0.0002 s/iter. Total: 0.5501 s/iter. ETA=0:16:24\n",
            "\u001b[32m[04/30 20:00:27 d2.evaluation.evaluator]: \u001b[0mInference done 3220/5000. Dataloading: 0.0020 s/iter. Inference: 0.5475 s/iter. Eval: 0.0002 s/iter. Total: 0.5501 s/iter. ETA=0:16:19\n",
            "\u001b[32m[04/30 20:00:32 d2.evaluation.evaluator]: \u001b[0mInference done 3229/5000. Dataloading: 0.0020 s/iter. Inference: 0.5475 s/iter. Eval: 0.0002 s/iter. Total: 0.5502 s/iter. ETA=0:16:14\n",
            "\u001b[32m[04/30 20:00:38 d2.evaluation.evaluator]: \u001b[0mInference done 3239/5000. Dataloading: 0.0020 s/iter. Inference: 0.5475 s/iter. Eval: 0.0002 s/iter. Total: 0.5502 s/iter. ETA=0:16:08\n",
            "\u001b[32m[04/30 20:00:43 d2.evaluation.evaluator]: \u001b[0mInference done 3248/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5502 s/iter. ETA=0:16:03\n",
            "\u001b[32m[04/30 20:00:48 d2.evaluation.evaluator]: \u001b[0mInference done 3258/5000. Dataloading: 0.0020 s/iter. Inference: 0.5475 s/iter. Eval: 0.0002 s/iter. Total: 0.5502 s/iter. ETA=0:15:58\n",
            "\u001b[32m[04/30 20:00:54 d2.evaluation.evaluator]: \u001b[0mInference done 3268/5000. Dataloading: 0.0020 s/iter. Inference: 0.5475 s/iter. Eval: 0.0002 s/iter. Total: 0.5502 s/iter. ETA=0:15:52\n",
            "\u001b[32m[04/30 20:00:59 d2.evaluation.evaluator]: \u001b[0mInference done 3277/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5502 s/iter. ETA=0:15:48\n",
            "\u001b[32m[04/30 20:01:04 d2.evaluation.evaluator]: \u001b[0mInference done 3286/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5502 s/iter. ETA=0:15:43\n",
            "\u001b[32m[04/30 20:01:09 d2.evaluation.evaluator]: \u001b[0mInference done 3295/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:15:38\n",
            "\u001b[32m[04/30 20:01:14 d2.evaluation.evaluator]: \u001b[0mInference done 3305/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:15:32\n",
            "\u001b[32m[04/30 20:01:20 d2.evaluation.evaluator]: \u001b[0mInference done 3315/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:15:27\n",
            "\u001b[32m[04/30 20:01:25 d2.evaluation.evaluator]: \u001b[0mInference done 3325/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:15:21\n",
            "\u001b[32m[04/30 20:01:31 d2.evaluation.evaluator]: \u001b[0mInference done 3335/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:15:16\n",
            "\u001b[32m[04/30 20:01:36 d2.evaluation.evaluator]: \u001b[0mInference done 3345/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:15:10\n",
            "\u001b[32m[04/30 20:01:42 d2.evaluation.evaluator]: \u001b[0mInference done 3355/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:15:05\n",
            "\u001b[32m[04/30 20:01:47 d2.evaluation.evaluator]: \u001b[0mInference done 3365/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:14:59\n",
            "\u001b[32m[04/30 20:01:53 d2.evaluation.evaluator]: \u001b[0mInference done 3375/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:14:54\n",
            "\u001b[32m[04/30 20:01:58 d2.evaluation.evaluator]: \u001b[0mInference done 3384/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:14:49\n",
            "\u001b[32m[04/30 20:02:03 d2.evaluation.evaluator]: \u001b[0mInference done 3394/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:14:43\n",
            "\u001b[32m[04/30 20:02:09 d2.evaluation.evaluator]: \u001b[0mInference done 3404/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5502 s/iter. ETA=0:14:38\n",
            "\u001b[32m[04/30 20:02:14 d2.evaluation.evaluator]: \u001b[0mInference done 3414/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5502 s/iter. ETA=0:14:32\n",
            "\u001b[32m[04/30 20:02:20 d2.evaluation.evaluator]: \u001b[0mInference done 3424/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5502 s/iter. ETA=0:14:27\n",
            "\u001b[32m[04/30 20:02:25 d2.evaluation.evaluator]: \u001b[0mInference done 3433/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:14:22\n",
            "\u001b[32m[04/30 20:02:30 d2.evaluation.evaluator]: \u001b[0mInference done 3443/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:14:16\n",
            "\u001b[32m[04/30 20:02:36 d2.evaluation.evaluator]: \u001b[0mInference done 3453/5000. Dataloading: 0.0020 s/iter. Inference: 0.5476 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:14:11\n",
            "\u001b[32m[04/30 20:02:41 d2.evaluation.evaluator]: \u001b[0mInference done 3462/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:14:06\n",
            "\u001b[32m[04/30 20:02:46 d2.evaluation.evaluator]: \u001b[0mInference done 3471/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:14:01\n",
            "\u001b[32m[04/30 20:02:51 d2.evaluation.evaluator]: \u001b[0mInference done 3481/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:13:55\n",
            "\u001b[32m[04/30 20:02:57 d2.evaluation.evaluator]: \u001b[0mInference done 3491/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:13:50\n",
            "\u001b[32m[04/30 20:03:02 d2.evaluation.evaluator]: \u001b[0mInference done 3501/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:13:44\n",
            "\u001b[32m[04/30 20:03:07 d2.evaluation.evaluator]: \u001b[0mInference done 3510/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:13:39\n",
            "\u001b[32m[04/30 20:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 3520/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:13:34\n",
            "\u001b[32m[04/30 20:03:18 d2.evaluation.evaluator]: \u001b[0mInference done 3530/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:13:28\n",
            "\u001b[32m[04/30 20:03:24 d2.evaluation.evaluator]: \u001b[0mInference done 3540/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:13:23\n",
            "\u001b[32m[04/30 20:03:29 d2.evaluation.evaluator]: \u001b[0mInference done 3550/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:13:17\n",
            "\u001b[32m[04/30 20:03:35 d2.evaluation.evaluator]: \u001b[0mInference done 3560/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:13:12\n",
            "\u001b[32m[04/30 20:03:40 d2.evaluation.evaluator]: \u001b[0mInference done 3569/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:13:07\n",
            "\u001b[32m[04/30 20:03:45 d2.evaluation.evaluator]: \u001b[0mInference done 3578/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:13:02\n",
            "\u001b[32m[04/30 20:03:50 d2.evaluation.evaluator]: \u001b[0mInference done 3588/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:12:57\n",
            "\u001b[32m[04/30 20:03:56 d2.evaluation.evaluator]: \u001b[0mInference done 3598/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:12:51\n",
            "\u001b[32m[04/30 20:04:01 d2.evaluation.evaluator]: \u001b[0mInference done 3608/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:12:46\n",
            "\u001b[32m[04/30 20:04:06 d2.evaluation.evaluator]: \u001b[0mInference done 3617/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:12:41\n",
            "\u001b[32m[04/30 20:04:12 d2.evaluation.evaluator]: \u001b[0mInference done 3627/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:12:35\n",
            "\u001b[32m[04/30 20:04:17 d2.evaluation.evaluator]: \u001b[0mInference done 3636/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:12:30\n",
            "\u001b[32m[04/30 20:04:22 d2.evaluation.evaluator]: \u001b[0mInference done 3646/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:12:25\n",
            "\u001b[32m[04/30 20:04:27 d2.evaluation.evaluator]: \u001b[0mInference done 3655/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5504 s/iter. ETA=0:12:20\n",
            "\u001b[32m[04/30 20:04:33 d2.evaluation.evaluator]: \u001b[0mInference done 3665/5000. Dataloading: 0.0020 s/iter. Inference: 0.5477 s/iter. Eval: 0.0002 s/iter. Total: 0.5503 s/iter. ETA=0:12:14\n",
            "\u001b[32m[04/30 20:04:38 d2.evaluation.evaluator]: \u001b[0mInference done 3674/5000. Dataloading: 0.0020 s/iter. Inference: 0.5478 s/iter. Eval: 0.0002 s/iter. Total: 0.5504 s/iter. ETA=0:12:09\n",
            "\u001b[32m[04/30 20:04:43 d2.evaluation.evaluator]: \u001b[0mInference done 3683/5000. Dataloading: 0.0020 s/iter. Inference: 0.5478 s/iter. Eval: 0.0002 s/iter. Total: 0.5504 s/iter. ETA=0:12:04\n",
            "\u001b[32m[04/30 20:04:48 d2.evaluation.evaluator]: \u001b[0mInference done 3693/5000. Dataloading: 0.0020 s/iter. Inference: 0.5478 s/iter. Eval: 0.0002 s/iter. Total: 0.5504 s/iter. ETA=0:11:59\n",
            "\u001b[32m[04/30 20:04:53 d2.evaluation.evaluator]: \u001b[0mInference done 3702/5000. Dataloading: 0.0020 s/iter. Inference: 0.5478 s/iter. Eval: 0.0002 s/iter. Total: 0.5504 s/iter. ETA=0:11:54\n",
            "\u001b[32m[04/30 20:04:59 d2.evaluation.evaluator]: \u001b[0mInference done 3712/5000. Dataloading: 0.0020 s/iter. Inference: 0.5478 s/iter. Eval: 0.0002 s/iter. Total: 0.5504 s/iter. ETA=0:11:48\n",
            "\u001b[32m[04/30 20:05:04 d2.evaluation.evaluator]: \u001b[0mInference done 3721/5000. Dataloading: 0.0020 s/iter. Inference: 0.5478 s/iter. Eval: 0.0002 s/iter. Total: 0.5504 s/iter. ETA=0:11:44\n",
            "\u001b[32m[04/30 20:05:09 d2.evaluation.evaluator]: \u001b[0mInference done 3730/5000. Dataloading: 0.0020 s/iter. Inference: 0.5479 s/iter. Eval: 0.0002 s/iter. Total: 0.5505 s/iter. ETA=0:11:39\n",
            "\u001b[32m[04/30 20:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 3740/5000. Dataloading: 0.0020 s/iter. Inference: 0.5479 s/iter. Eval: 0.0002 s/iter. Total: 0.5505 s/iter. ETA=0:11:33\n",
            "\u001b[32m[04/30 20:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 3750/5000. Dataloading: 0.0020 s/iter. Inference: 0.5479 s/iter. Eval: 0.0002 s/iter. Total: 0.5505 s/iter. ETA=0:11:28\n",
            "\u001b[32m[04/30 20:05:25 d2.evaluation.evaluator]: \u001b[0mInference done 3760/5000. Dataloading: 0.0020 s/iter. Inference: 0.5479 s/iter. Eval: 0.0002 s/iter. Total: 0.5505 s/iter. ETA=0:11:22\n",
            "\u001b[32m[04/30 20:05:31 d2.evaluation.evaluator]: \u001b[0mInference done 3770/5000. Dataloading: 0.0020 s/iter. Inference: 0.5479 s/iter. Eval: 0.0002 s/iter. Total: 0.5505 s/iter. ETA=0:11:17\n",
            "\u001b[32m[04/30 20:05:36 d2.evaluation.evaluator]: \u001b[0mInference done 3779/5000. Dataloading: 0.0020 s/iter. Inference: 0.5479 s/iter. Eval: 0.0002 s/iter. Total: 0.5505 s/iter. ETA=0:11:12\n",
            "\u001b[32m[04/30 20:05:41 d2.evaluation.evaluator]: \u001b[0mInference done 3788/5000. Dataloading: 0.0020 s/iter. Inference: 0.5479 s/iter. Eval: 0.0002 s/iter. Total: 0.5505 s/iter. ETA=0:11:07\n",
            "\u001b[32m[04/30 20:05:46 d2.evaluation.evaluator]: \u001b[0mInference done 3797/5000. Dataloading: 0.0020 s/iter. Inference: 0.5479 s/iter. Eval: 0.0002 s/iter. Total: 0.5505 s/iter. ETA=0:11:02\n",
            "\u001b[32m[04/30 20:05:52 d2.evaluation.evaluator]: \u001b[0mInference done 3807/5000. Dataloading: 0.0020 s/iter. Inference: 0.5479 s/iter. Eval: 0.0002 s/iter. Total: 0.5505 s/iter. ETA=0:10:56\n",
            "\u001b[32m[04/30 20:05:57 d2.evaluation.evaluator]: \u001b[0mInference done 3817/5000. Dataloading: 0.0020 s/iter. Inference: 0.5479 s/iter. Eval: 0.0002 s/iter. Total: 0.5505 s/iter. ETA=0:10:51\n",
            "\u001b[32m[04/30 20:06:03 d2.evaluation.evaluator]: \u001b[0mInference done 3827/5000. Dataloading: 0.0020 s/iter. Inference: 0.5479 s/iter. Eval: 0.0002 s/iter. Total: 0.5505 s/iter. ETA=0:10:45\n",
            "\u001b[32m[04/30 20:06:08 d2.evaluation.evaluator]: \u001b[0mInference done 3836/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:10:40\n",
            "\u001b[32m[04/30 20:06:13 d2.evaluation.evaluator]: \u001b[0mInference done 3845/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:10:35\n",
            "\u001b[32m[04/30 20:06:18 d2.evaluation.evaluator]: \u001b[0mInference done 3854/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:10:31\n",
            "\u001b[32m[04/30 20:06:23 d2.evaluation.evaluator]: \u001b[0mInference done 3864/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:10:25\n",
            "\u001b[32m[04/30 20:06:29 d2.evaluation.evaluator]: \u001b[0mInference done 3874/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:10:19\n",
            "\u001b[32m[04/30 20:06:34 d2.evaluation.evaluator]: \u001b[0mInference done 3884/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:10:14\n",
            "\u001b[32m[04/30 20:06:40 d2.evaluation.evaluator]: \u001b[0mInference done 3894/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:10:08\n",
            "\u001b[32m[04/30 20:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 3904/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:10:03\n",
            "\u001b[32m[04/30 20:06:51 d2.evaluation.evaluator]: \u001b[0mInference done 3914/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:09:57\n",
            "\u001b[32m[04/30 20:06:56 d2.evaluation.evaluator]: \u001b[0mInference done 3924/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:09:52\n",
            "\u001b[32m[04/30 20:07:02 d2.evaluation.evaluator]: \u001b[0mInference done 3934/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:09:46\n",
            "\u001b[32m[04/30 20:07:07 d2.evaluation.evaluator]: \u001b[0mInference done 3944/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:09:41\n",
            "\u001b[32m[04/30 20:07:12 d2.evaluation.evaluator]: \u001b[0mInference done 3953/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:09:36\n",
            "\u001b[32m[04/30 20:07:18 d2.evaluation.evaluator]: \u001b[0mInference done 3963/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:09:30\n",
            "\u001b[32m[04/30 20:07:23 d2.evaluation.evaluator]: \u001b[0mInference done 3973/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:09:25\n",
            "\u001b[32m[04/30 20:07:29 d2.evaluation.evaluator]: \u001b[0mInference done 3983/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:09:19\n",
            "\u001b[32m[04/30 20:07:34 d2.evaluation.evaluator]: \u001b[0mInference done 3993/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:09:14\n",
            "\u001b[32m[04/30 20:07:39 d2.evaluation.evaluator]: \u001b[0mInference done 4002/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:09:09\n",
            "\u001b[32m[04/30 20:07:45 d2.evaluation.evaluator]: \u001b[0mInference done 4012/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:09:03\n",
            "\u001b[32m[04/30 20:07:50 d2.evaluation.evaluator]: \u001b[0mInference done 4022/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:08:58\n",
            "\u001b[32m[04/30 20:07:56 d2.evaluation.evaluator]: \u001b[0mInference done 4032/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:08:52\n",
            "\u001b[32m[04/30 20:08:01 d2.evaluation.evaluator]: \u001b[0mInference done 4041/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:08:48\n",
            "\u001b[32m[04/30 20:08:06 d2.evaluation.evaluator]: \u001b[0mInference done 4050/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:08:43\n",
            "\u001b[32m[04/30 20:08:11 d2.evaluation.evaluator]: \u001b[0mInference done 4060/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:08:37\n",
            "\u001b[32m[04/30 20:08:17 d2.evaluation.evaluator]: \u001b[0mInference done 4070/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:08:32\n",
            "\u001b[32m[04/30 20:08:22 d2.evaluation.evaluator]: \u001b[0mInference done 4080/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:08:26\n",
            "\u001b[32m[04/30 20:08:28 d2.evaluation.evaluator]: \u001b[0mInference done 4090/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:08:21\n",
            "\u001b[32m[04/30 20:08:33 d2.evaluation.evaluator]: \u001b[0mInference done 4099/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:08:16\n",
            "\u001b[32m[04/30 20:08:38 d2.evaluation.evaluator]: \u001b[0mInference done 4109/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:08:10\n",
            "\u001b[32m[04/30 20:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 4118/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:08:05\n",
            "\u001b[32m[04/30 20:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 4127/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:08:00\n",
            "\u001b[32m[04/30 20:08:53 d2.evaluation.evaluator]: \u001b[0mInference done 4136/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:07:55\n",
            "\u001b[32m[04/30 20:08:59 d2.evaluation.evaluator]: \u001b[0mInference done 4146/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:07:50\n",
            "\u001b[32m[04/30 20:09:04 d2.evaluation.evaluator]: \u001b[0mInference done 4156/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:07:44\n",
            "\u001b[32m[04/30 20:09:10 d2.evaluation.evaluator]: \u001b[0mInference done 4166/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:07:39\n",
            "\u001b[32m[04/30 20:09:15 d2.evaluation.evaluator]: \u001b[0mInference done 4176/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:07:33\n",
            "\u001b[32m[04/30 20:09:21 d2.evaluation.evaluator]: \u001b[0mInference done 4186/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:07:28\n",
            "\u001b[32m[04/30 20:09:26 d2.evaluation.evaluator]: \u001b[0mInference done 4195/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:07:23\n",
            "\u001b[32m[04/30 20:09:31 d2.evaluation.evaluator]: \u001b[0mInference done 4205/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:07:17\n",
            "\u001b[32m[04/30 20:09:37 d2.evaluation.evaluator]: \u001b[0mInference done 4215/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:07:12\n",
            "\u001b[32m[04/30 20:09:42 d2.evaluation.evaluator]: \u001b[0mInference done 4224/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:07:07\n",
            "\u001b[32m[04/30 20:09:47 d2.evaluation.evaluator]: \u001b[0mInference done 4234/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:07:01\n",
            "\u001b[32m[04/30 20:09:52 d2.evaluation.evaluator]: \u001b[0mInference done 4244/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:06:56\n",
            "\u001b[32m[04/30 20:09:58 d2.evaluation.evaluator]: \u001b[0mInference done 4254/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:06:50\n",
            "\u001b[32m[04/30 20:10:03 d2.evaluation.evaluator]: \u001b[0mInference done 4264/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:06:45\n",
            "\u001b[32m[04/30 20:10:09 d2.evaluation.evaluator]: \u001b[0mInference done 4274/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:06:39\n",
            "\u001b[32m[04/30 20:10:14 d2.evaluation.evaluator]: \u001b[0mInference done 4284/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:06:34\n",
            "\u001b[32m[04/30 20:10:19 d2.evaluation.evaluator]: \u001b[0mInference done 4293/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:06:29\n",
            "\u001b[32m[04/30 20:10:24 d2.evaluation.evaluator]: \u001b[0mInference done 4302/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:06:24\n",
            "\u001b[32m[04/30 20:10:30 d2.evaluation.evaluator]: \u001b[0mInference done 4312/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:06:18\n",
            "\u001b[32m[04/30 20:10:35 d2.evaluation.evaluator]: \u001b[0mInference done 4322/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:06:13\n",
            "\u001b[32m[04/30 20:10:41 d2.evaluation.evaluator]: \u001b[0mInference done 4332/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:06:07\n",
            "\u001b[32m[04/30 20:10:46 d2.evaluation.evaluator]: \u001b[0mInference done 4342/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:06:02\n",
            "\u001b[32m[04/30 20:10:52 d2.evaluation.evaluator]: \u001b[0mInference done 4352/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:05:56\n",
            "\u001b[32m[04/30 20:10:57 d2.evaluation.evaluator]: \u001b[0mInference done 4361/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:05:51\n",
            "\u001b[32m[04/30 20:11:02 d2.evaluation.evaluator]: \u001b[0mInference done 4371/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:05:46\n",
            "\u001b[32m[04/30 20:11:08 d2.evaluation.evaluator]: \u001b[0mInference done 4381/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:05:40\n",
            "\u001b[32m[04/30 20:11:13 d2.evaluation.evaluator]: \u001b[0mInference done 4390/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:05:35\n",
            "\u001b[32m[04/30 20:11:18 d2.evaluation.evaluator]: \u001b[0mInference done 4400/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:05:30\n",
            "\u001b[32m[04/30 20:11:24 d2.evaluation.evaluator]: \u001b[0mInference done 4410/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:05:24\n",
            "\u001b[32m[04/30 20:11:29 d2.evaluation.evaluator]: \u001b[0mInference done 4420/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:05:19\n",
            "\u001b[32m[04/30 20:11:35 d2.evaluation.evaluator]: \u001b[0mInference done 4430/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:05:13\n",
            "\u001b[32m[04/30 20:11:40 d2.evaluation.evaluator]: \u001b[0mInference done 4440/5000. Dataloading: 0.0020 s/iter. Inference: 0.5480 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:05:08\n",
            "\u001b[32m[04/30 20:11:45 d2.evaluation.evaluator]: \u001b[0mInference done 4449/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:05:03\n",
            "\u001b[32m[04/30 20:11:50 d2.evaluation.evaluator]: \u001b[0mInference done 4458/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:04:58\n",
            "\u001b[32m[04/30 20:11:56 d2.evaluation.evaluator]: \u001b[0mInference done 4468/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:04:52\n",
            "\u001b[32m[04/30 20:12:01 d2.evaluation.evaluator]: \u001b[0mInference done 4478/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:04:47\n",
            "\u001b[32m[04/30 20:12:07 d2.evaluation.evaluator]: \u001b[0mInference done 4488/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:04:41\n",
            "\u001b[32m[04/30 20:12:12 d2.evaluation.evaluator]: \u001b[0mInference done 4497/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:04:36\n",
            "\u001b[32m[04/30 20:12:17 d2.evaluation.evaluator]: \u001b[0mInference done 4506/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:04:32\n",
            "\u001b[32m[04/30 20:12:22 d2.evaluation.evaluator]: \u001b[0mInference done 4516/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:04:26\n",
            "\u001b[32m[04/30 20:12:28 d2.evaluation.evaluator]: \u001b[0mInference done 4526/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:04:20\n",
            "\u001b[32m[04/30 20:12:33 d2.evaluation.evaluator]: \u001b[0mInference done 4536/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:04:15\n",
            "\u001b[32m[04/30 20:12:39 d2.evaluation.evaluator]: \u001b[0mInference done 4546/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:04:09\n",
            "\u001b[32m[04/30 20:12:44 d2.evaluation.evaluator]: \u001b[0mInference done 4556/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:04:04\n",
            "\u001b[32m[04/30 20:12:50 d2.evaluation.evaluator]: \u001b[0mInference done 4566/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:03:58\n",
            "\u001b[32m[04/30 20:12:55 d2.evaluation.evaluator]: \u001b[0mInference done 4576/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:03:53\n",
            "\u001b[32m[04/30 20:13:01 d2.evaluation.evaluator]: \u001b[0mInference done 4586/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:03:47\n",
            "\u001b[32m[04/30 20:13:06 d2.evaluation.evaluator]: \u001b[0mInference done 4595/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:03:43\n",
            "\u001b[32m[04/30 20:13:11 d2.evaluation.evaluator]: \u001b[0mInference done 4605/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:03:37\n",
            "\u001b[32m[04/30 20:13:17 d2.evaluation.evaluator]: \u001b[0mInference done 4615/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:03:31\n",
            "\u001b[32m[04/30 20:13:22 d2.evaluation.evaluator]: \u001b[0mInference done 4625/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:03:26\n",
            "\u001b[32m[04/30 20:13:27 d2.evaluation.evaluator]: \u001b[0mInference done 4634/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:03:21\n",
            "\u001b[32m[04/30 20:13:33 d2.evaluation.evaluator]: \u001b[0mInference done 4644/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:03:16\n",
            "\u001b[32m[04/30 20:13:38 d2.evaluation.evaluator]: \u001b[0mInference done 4653/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:03:11\n",
            "\u001b[32m[04/30 20:13:43 d2.evaluation.evaluator]: \u001b[0mInference done 4663/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:03:05\n",
            "\u001b[32m[04/30 20:13:49 d2.evaluation.evaluator]: \u001b[0mInference done 4673/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:03:00\n",
            "\u001b[32m[04/30 20:13:54 d2.evaluation.evaluator]: \u001b[0mInference done 4683/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:02:54\n",
            "\u001b[32m[04/30 20:13:59 d2.evaluation.evaluator]: \u001b[0mInference done 4692/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:02:49\n",
            "\u001b[32m[04/30 20:14:05 d2.evaluation.evaluator]: \u001b[0mInference done 4702/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:02:44\n",
            "\u001b[32m[04/30 20:14:10 d2.evaluation.evaluator]: \u001b[0mInference done 4712/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:02:38\n",
            "\u001b[32m[04/30 20:14:15 d2.evaluation.evaluator]: \u001b[0mInference done 4721/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5506 s/iter. ETA=0:02:33\n",
            "\u001b[32m[04/30 20:14:21 d2.evaluation.evaluator]: \u001b[0mInference done 4731/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:02:28\n",
            "\u001b[32m[04/30 20:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 4740/5000. Dataloading: 0.0020 s/iter. Inference: 0.5482 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:02:23\n",
            "\u001b[32m[04/30 20:14:31 d2.evaluation.evaluator]: \u001b[0mInference done 4750/5000. Dataloading: 0.0020 s/iter. Inference: 0.5482 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:02:17\n",
            "\u001b[32m[04/30 20:14:36 d2.evaluation.evaluator]: \u001b[0mInference done 4759/5000. Dataloading: 0.0020 s/iter. Inference: 0.5482 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:02:12\n",
            "\u001b[32m[04/30 20:14:42 d2.evaluation.evaluator]: \u001b[0mInference done 4769/5000. Dataloading: 0.0020 s/iter. Inference: 0.5482 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:02:07\n",
            "\u001b[32m[04/30 20:14:47 d2.evaluation.evaluator]: \u001b[0mInference done 4778/5000. Dataloading: 0.0020 s/iter. Inference: 0.5482 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:02:02\n",
            "\u001b[32m[04/30 20:14:52 d2.evaluation.evaluator]: \u001b[0mInference done 4787/5000. Dataloading: 0.0020 s/iter. Inference: 0.5482 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:01:57\n",
            "\u001b[32m[04/30 20:14:57 d2.evaluation.evaluator]: \u001b[0mInference done 4796/5000. Dataloading: 0.0020 s/iter. Inference: 0.5482 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:01:52\n",
            "\u001b[32m[04/30 20:15:02 d2.evaluation.evaluator]: \u001b[0mInference done 4805/5000. Dataloading: 0.0020 s/iter. Inference: 0.5482 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:01:47\n",
            "\u001b[32m[04/30 20:15:07 d2.evaluation.evaluator]: \u001b[0mInference done 4815/5000. Dataloading: 0.0020 s/iter. Inference: 0.5482 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:01:41\n",
            "\u001b[32m[04/30 20:15:13 d2.evaluation.evaluator]: \u001b[0mInference done 4825/5000. Dataloading: 0.0020 s/iter. Inference: 0.5482 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:01:36\n",
            "\u001b[32m[04/30 20:15:18 d2.evaluation.evaluator]: \u001b[0mInference done 4835/5000. Dataloading: 0.0020 s/iter. Inference: 0.5481 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:01:30\n",
            "\u001b[32m[04/30 20:15:23 d2.evaluation.evaluator]: \u001b[0mInference done 4844/5000. Dataloading: 0.0020 s/iter. Inference: 0.5482 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:01:25\n",
            "\u001b[32m[04/30 20:15:28 d2.evaluation.evaluator]: \u001b[0mInference done 4853/5000. Dataloading: 0.0020 s/iter. Inference: 0.5482 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:01:20\n",
            "\u001b[32m[04/30 20:15:33 d2.evaluation.evaluator]: \u001b[0mInference done 4862/5000. Dataloading: 0.0020 s/iter. Inference: 0.5482 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:01:15\n",
            "\u001b[32m[04/30 20:15:39 d2.evaluation.evaluator]: \u001b[0mInference done 4872/5000. Dataloading: 0.0020 s/iter. Inference: 0.5482 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:01:10\n",
            "\u001b[32m[04/30 20:15:44 d2.evaluation.evaluator]: \u001b[0mInference done 4882/5000. Dataloading: 0.0020 s/iter. Inference: 0.5482 s/iter. Eval: 0.0002 s/iter. Total: 0.5507 s/iter. ETA=0:01:04\n",
            "\u001b[32m[04/30 20:15:50 d2.evaluation.evaluator]: \u001b[0mInference done 4891/5000. Dataloading: 0.0020 s/iter. Inference: 0.5483 s/iter. Eval: 0.0002 s/iter. Total: 0.5508 s/iter. ETA=0:01:00\n",
            "\u001b[32m[04/30 20:15:55 d2.evaluation.evaluator]: \u001b[0mInference done 4901/5000. Dataloading: 0.0020 s/iter. Inference: 0.5483 s/iter. Eval: 0.0002 s/iter. Total: 0.5508 s/iter. ETA=0:00:54\n",
            "\u001b[32m[04/30 20:16:00 d2.evaluation.evaluator]: \u001b[0mInference done 4910/5000. Dataloading: 0.0020 s/iter. Inference: 0.5483 s/iter. Eval: 0.0002 s/iter. Total: 0.5508 s/iter. ETA=0:00:49\n",
            "\u001b[32m[04/30 20:16:05 d2.evaluation.evaluator]: \u001b[0mInference done 4919/5000. Dataloading: 0.0020 s/iter. Inference: 0.5483 s/iter. Eval: 0.0002 s/iter. Total: 0.5508 s/iter. ETA=0:00:44\n",
            "\u001b[32m[04/30 20:16:11 d2.evaluation.evaluator]: \u001b[0mInference done 4929/5000. Dataloading: 0.0020 s/iter. Inference: 0.5483 s/iter. Eval: 0.0002 s/iter. Total: 0.5508 s/iter. ETA=0:00:39\n",
            "\u001b[32m[04/30 20:16:16 d2.evaluation.evaluator]: \u001b[0mInference done 4939/5000. Dataloading: 0.0020 s/iter. Inference: 0.5483 s/iter. Eval: 0.0002 s/iter. Total: 0.5508 s/iter. ETA=0:00:33\n",
            "\u001b[32m[04/30 20:16:21 d2.evaluation.evaluator]: \u001b[0mInference done 4948/5000. Dataloading: 0.0020 s/iter. Inference: 0.5483 s/iter. Eval: 0.0002 s/iter. Total: 0.5508 s/iter. ETA=0:00:28\n",
            "\u001b[32m[04/30 20:16:26 d2.evaluation.evaluator]: \u001b[0mInference done 4957/5000. Dataloading: 0.0020 s/iter. Inference: 0.5483 s/iter. Eval: 0.0002 s/iter. Total: 0.5508 s/iter. ETA=0:00:23\n",
            "\u001b[32m[04/30 20:16:31 d2.evaluation.evaluator]: \u001b[0mInference done 4966/5000. Dataloading: 0.0020 s/iter. Inference: 0.5483 s/iter. Eval: 0.0002 s/iter. Total: 0.5509 s/iter. ETA=0:00:18\n",
            "\u001b[32m[04/30 20:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 4976/5000. Dataloading: 0.0020 s/iter. Inference: 0.5483 s/iter. Eval: 0.0002 s/iter. Total: 0.5508 s/iter. ETA=0:00:13\n",
            "\u001b[32m[04/30 20:16:42 d2.evaluation.evaluator]: \u001b[0mInference done 4985/5000. Dataloading: 0.0020 s/iter. Inference: 0.5483 s/iter. Eval: 0.0002 s/iter. Total: 0.5509 s/iter. ETA=0:00:08\n",
            "\u001b[32m[04/30 20:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 4995/5000. Dataloading: 0.0020 s/iter. Inference: 0.5484 s/iter. Eval: 0.0002 s/iter. Total: 0.5509 s/iter. ETA=0:00:02\n",
            "\u001b[32m[04/30 20:16:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:45:51.734372 (0.550898 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 20:16:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:45:38 (0.548342 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 20:16:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/30 20:16:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/30 20:16:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.35s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 20:16:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/30 20:17:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 7.47 seconds.\n",
            "\u001b[32m[04/30 20:17:00 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 20:17:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.84 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.491\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.678\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.532\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.526\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.628\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.370\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.591\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.619\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.427\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.655\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759\n",
            "\u001b[32m[04/30 20:17:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 49.100 | 67.841 | 53.237 | 31.559 | 52.632 | 62.791 |\n",
            "\u001b[32m[04/30 20:17:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 61.325 | bicycle      | 37.857 | car            | 51.206 |\n",
            "| motorcycle    | 49.764 | airplane     | 72.973 | bus            | 71.993 |\n",
            "| train         | 69.132 | truck        | 43.334 | boat           | 33.009 |\n",
            "| traffic light | 31.858 | fire hydrant | 72.615 | stop sign      | 68.455 |\n",
            "| parking meter | 48.372 | bench        | 30.180 | bird           | 44.496 |\n",
            "| cat           | 76.402 | dog          | 72.127 | horse          | 65.282 |\n",
            "| sheep         | 59.432 | cow          | 64.278 | elephant       | 72.043 |\n",
            "| bear          | 78.150 | zebra        | 71.900 | giraffe        | 74.699 |\n",
            "| backpack      | 19.540 | umbrella     | 46.275 | handbag        | 21.602 |\n",
            "| tie           | 42.347 | suitcase     | 48.024 | frisbee        | 72.254 |\n",
            "| skis          | 30.847 | snowboard    | 48.402 | sports ball    | 53.535 |\n",
            "| kite          | 50.927 | baseball bat | 45.300 | baseball glove | 45.672 |\n",
            "| skateboard    | 63.022 | surfboard    | 46.913 | tennis racket  | 59.845 |\n",
            "| bottle        | 46.823 | wine glass   | 42.767 | cup            | 50.333 |\n",
            "| fork          | 46.528 | knife        | 30.136 | spoon          | 29.304 |\n",
            "| bowl          | 48.629 | banana       | 30.450 | apple          | 26.279 |\n",
            "| sandwich      | 40.454 | orange       | 34.738 | broccoli       | 25.598 |\n",
            "| carrot        | 27.642 | hot dog      | 43.526 | pizza          | 58.402 |\n",
            "| donut         | 55.741 | cake         | 44.402 | chair          | 34.076 |\n",
            "| couch         | 47.636 | potted plant | 34.283 | bed            | 49.012 |\n",
            "| dining table  | 33.137 | toilet       | 66.193 | tv             | 62.202 |\n",
            "| laptop        | 67.402 | mouse        | 65.922 | remote         | 47.984 |\n",
            "| keyboard      | 57.533 | cell phone   | 46.542 | microwave      | 64.843 |\n",
            "| oven          | 40.213 | toaster      | 44.876 | sink           | 43.941 |\n",
            "| refrigerator  | 64.069 | book         | 21.736 | clock          | 56.639 |\n",
            "| vase          | 44.325 | scissors     | 41.910 | teddy bear     | 55.026 |\n",
            "| hair drier    | 6.521  | toothbrush   | 34.860 |                |        |\n",
            "\u001b[32m[04/30 20:17:01 d2.engine.defaults]: \u001b[0mEvaluation results for coco_2017_val in csv format:\n",
            "\u001b[32m[04/30 20:17:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/30 20:17:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 20:17:01 d2.evaluation.testing]: \u001b[0mcopypaste: 49.1003,67.8413,53.2367,31.5592,52.6322,62.7913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "faster_cascade_rcnn_ResNeSt_200 - evaluation results for coco_2017_val in csv format:\n",
        "\n",
        "Task\\metrics  | AP | AP50 | AP75 | APs | APm | APl |\n",
        "--------------|----|------|------|-----|-----|-----|\n",
        "**bbox**    | 49.1003 | 67.8413 | 53.2367 | 31.5592 | 52.6322 | 62.7913"
      ],
      "metadata": {
        "id": "MtQ-sGFOH3Qs"
      },
      "id": "MtQ-sGFOH3Qs"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-Detection/faster_rcnn_ResNeSt_50_FPN_syncbn_range-scale_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-ObjectDetection/faster_rcnn_ResNeSt_50_FPN_syncbn_range-scale_1x-ad123c0b.pth"
      ],
      "metadata": {
        "id": "IFLGp30O9Pb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9d67d2-2836-4e3d-aa7b-8561db508fd8"
      },
      "id": "IFLGp30O9Pb1",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command Line Args: Namespace(config_file='./configs/COCO-Detection/faster_rcnn_ResNeSt_50_FPN_syncbn_range-scale_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-ObjectDetection1/faster_rcnn_ResNeSt_50_FPN_syncbn_range-scale_1x-ad123c0b.pth'], resume=False)\n",
            "\u001b[32m[04/30 20:17:37 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[04/30 20:17:38 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ----------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "numpy                   1.21.6\n",
            "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.5\n",
            "CUDA compiler           CUDA 11.1\n",
            "detectron2 arch flags   7.5\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.11.0+cu113 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           Yes\n",
            "GPU 0                   Tesla T4 (arch=7.5)\n",
            "Driver version          460.32.03\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.12.0+cu113 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
            "fvcore                  0.1.5.post20220414\n",
            "iopath                  0.1.9\n",
            "cv2                     4.1.2\n",
            "----------------------  ----------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.3\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.2\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "\u001b[32m[04/30 20:17:38 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='./configs/COCO-Detection/faster_rcnn_ResNeSt_50_FPN_syncbn_range-scale_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-ObjectDetection1/faster_rcnn_ResNeSt_50_FPN_syncbn_range-scale_1x-ad123c0b.pth'], resume=False)\n",
            "\u001b[32m[04/30 20:17:38 detectron2]: \u001b[0mContents of args.config_file=./configs/COCO-Detection/faster_rcnn_ResNeSt_50_FPN_syncbn_range-scale_1x.yaml:\n",
            "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186m../ResNest-Base-RCNN-FPN.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mhttps://s3.us-west-1.wasabisys.com/resnest/detectron/resnest50_detectron-255b5649.pth\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mFastRCNNConvFCHead\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m123.68\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m116.779\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m103.939\u001b[39m]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m58.393\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.12\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.375\u001b[39m]\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\u001b[38;5;15m  \u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\u001b[38;5;15m    \u001b[39m\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m(640, 800)\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mrange\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mRGB\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\n",
            "\u001b[32m[04/30 20:17:38 detectron2]: \u001b[0mRunning with full config:\n",
            "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRGB\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mpolygon\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrange\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnest_fpn_backbone\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGeneralizedRCNN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.68\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.779\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.939\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m58.393\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.12\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.375\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRPN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVG_DOWN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOTTLENECK_WIDTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEEP_STEM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_NUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFastRCNNConvFCHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_FED_LOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_SIGMOID_CE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardROIHeads\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./checkpoints/COCO-ObjectDetection1/faster_rcnn_ResNeSt_50_FPN_syncbn_range-scale_1x-ad123c0b.pth\n",
            "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./output\n",
            "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR_END\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m90000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m60000\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m80000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\n",
            "\u001b[32m[04/30 20:17:38 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[04/30 20:17:39 d2.utils.env]: \u001b[0mUsing a generated random seed 39090234\n",
            "\u001b[32m[04/30 20:17:43 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(\n",
            "      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output2): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral3): Conv2d(\n",
            "      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output3): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral4): Conv2d(\n",
            "      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output4): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral5): Conv2d(\n",
            "      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output5): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNeSt(\n",
            "      (stem): BasicStem(\n",
            "        (conv1_1): Conv2d(\n",
            "          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "        )\n",
            "        (conv1_2): Conv2d(\n",
            "          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "        )\n",
            "        (conv1_3): Conv2d(\n",
            "          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (conv1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (conv4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/30 20:17:43 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from ./checkpoints/COCO-ObjectDetection1/faster_rcnn_ResNeSt_50_FPN_syncbn_range-scale_1x-ad123c0b.pth ...\n",
            "\u001b[32m[04/30 20:17:47 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
            "| Names in Model                                  | Names in Checkpoint                                                                                                           | Shapes                                             |\n",
            "|:------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------|\n",
            "| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,1,1)                |\n",
            "| backbone.bottom_up.res2.0.conv2.bn0.*           | backbone.bottom_up.res2.0.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.0.conv2.bn1.*           | backbone.bottom_up.res2.0.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.0.conv2.conv.weight     | backbone.bottom_up.res2.0.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.0.conv2.fc1.*           | backbone.bottom_up.res2.0.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.0.conv2.fc2.*           | backbone.bottom_up.res2.0.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.1.conv2.bn0.*           | backbone.bottom_up.res2.1.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.1.conv2.bn1.*           | backbone.bottom_up.res2.1.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.1.conv2.conv.weight     | backbone.bottom_up.res2.1.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.1.conv2.fc1.*           | backbone.bottom_up.res2.1.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.1.conv2.fc2.*           | backbone.bottom_up.res2.1.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.2.conv2.bn0.*           | backbone.bottom_up.res2.2.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.2.conv2.bn1.*           | backbone.bottom_up.res2.2.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.2.conv2.conv.weight     | backbone.bottom_up.res2.2.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.2.conv2.fc1.*           | backbone.bottom_up.res2.2.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.2.conv2.fc2.*           | backbone.bottom_up.res2.2.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv2.bn0.*           | backbone.bottom_up.res3.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.0.conv2.bn1.*           | backbone.bottom_up.res3.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.0.conv2.conv.weight     | backbone.bottom_up.res3.0.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.0.conv2.fc1.*           | backbone.bottom_up.res3.0.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.0.conv2.fc2.*           | backbone.bottom_up.res3.0.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv2.bn0.*           | backbone.bottom_up.res3.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.1.conv2.bn1.*           | backbone.bottom_up.res3.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.1.conv2.conv.weight     | backbone.bottom_up.res3.1.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.1.conv2.fc1.*           | backbone.bottom_up.res3.1.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.1.conv2.fc2.*           | backbone.bottom_up.res3.1.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv2.bn0.*           | backbone.bottom_up.res3.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.2.conv2.bn1.*           | backbone.bottom_up.res3.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.2.conv2.conv.weight     | backbone.bottom_up.res3.2.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.2.conv2.fc1.*           | backbone.bottom_up.res3.2.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.2.conv2.fc2.*           | backbone.bottom_up.res3.2.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv2.bn0.*           | backbone.bottom_up.res3.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.3.conv2.bn1.*           | backbone.bottom_up.res3.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.3.conv2.conv.weight     | backbone.bottom_up.res3.3.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.3.conv2.fc1.*           | backbone.bottom_up.res3.3.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.3.conv2.fc2.*           | backbone.bottom_up.res3.3.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv2.bn0.*           | backbone.bottom_up.res4.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.bn1.*           | backbone.bottom_up.res4.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.conv.weight     | backbone.bottom_up.res4.0.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.0.conv2.fc1.*           | backbone.bottom_up.res4.0.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv2.fc2.*           | backbone.bottom_up.res4.0.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.1.conv2.bn0.*           | backbone.bottom_up.res4.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.bn1.*           | backbone.bottom_up.res4.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.conv.weight     | backbone.bottom_up.res4.1.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.1.conv2.fc1.*           | backbone.bottom_up.res4.1.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv2.fc2.*           | backbone.bottom_up.res4.1.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.2.conv2.bn0.*           | backbone.bottom_up.res4.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.bn1.*           | backbone.bottom_up.res4.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.conv.weight     | backbone.bottom_up.res4.2.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.2.conv2.fc1.*           | backbone.bottom_up.res4.2.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv2.fc2.*           | backbone.bottom_up.res4.2.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.3.conv2.bn0.*           | backbone.bottom_up.res4.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.bn1.*           | backbone.bottom_up.res4.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.conv.weight     | backbone.bottom_up.res4.3.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.3.conv2.fc1.*           | backbone.bottom_up.res4.3.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv2.fc2.*           | backbone.bottom_up.res4.3.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.4.conv2.bn0.*           | backbone.bottom_up.res4.4.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.bn1.*           | backbone.bottom_up.res4.4.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.conv.weight     | backbone.bottom_up.res4.4.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.4.conv2.fc1.*           | backbone.bottom_up.res4.4.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv2.fc2.*           | backbone.bottom_up.res4.4.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.5.conv2.bn0.*           | backbone.bottom_up.res4.5.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.bn1.*           | backbone.bottom_up.res4.5.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.conv.weight     | backbone.bottom_up.res4.5.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.5.conv2.fc1.*           | backbone.bottom_up.res4.5.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv2.fc2.*           | backbone.bottom_up.res4.5.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| backbone.bottom_up.res5.0.conv2.bn0.*           | backbone.bottom_up.res5.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.0.conv2.bn1.*           | backbone.bottom_up.res5.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.0.conv2.conv.weight     | backbone.bottom_up.res5.0.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.0.conv2.fc1.*           | backbone.bottom_up.res5.0.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.0.conv2.fc2.*           | backbone.bottom_up.res5.0.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.1.conv2.bn0.*           | backbone.bottom_up.res5.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.1.conv2.bn1.*           | backbone.bottom_up.res5.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.1.conv2.conv.weight     | backbone.bottom_up.res5.1.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.1.conv2.fc1.*           | backbone.bottom_up.res5.1.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.1.conv2.fc2.*           | backbone.bottom_up.res5.1.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.2.conv2.bn0.*           | backbone.bottom_up.res5.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.2.conv2.bn1.*           | backbone.bottom_up.res5.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.2.conv2.conv.weight     | backbone.bottom_up.res5.2.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.2.conv2.fc1.*           | backbone.bottom_up.res5.2.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.2.conv2.fc2.*           | backbone.bottom_up.res5.2.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.stem.conv1_1.*               | backbone.bottom_up.stem.conv1_1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (32,) (32,) (32,) (32,) (32,3,3,3)                 |\n",
            "| backbone.bottom_up.stem.conv1_2.*               | backbone.bottom_up.stem.conv1_2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (32,) (32,) (32,) (32,) (32,32,3,3)                |\n",
            "| backbone.bottom_up.stem.conv1_3.*               | backbone.bottom_up.stem.conv1_3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,32,3,3)                |\n",
            "| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,2048,1,1)      |\n",
            "| backbone.fpn_output2.*                          | backbone.fpn_output2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output3.*                          | backbone.fpn_output3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output4.*                          | backbone.fpn_output4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output5.*                          | backbone.fpn_output5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                                                       | (12,) (12,256,1,1)                                 |\n",
            "| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                                                | (256,) (256,256,3,3)                               |\n",
            "| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                                                   | (3,) (3,256,1,1)                                   |\n",
            "| roi_heads.box_head.conv1.*                      | roi_heads.box_head.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.conv2.*                      | roi_heads.box_head.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.conv3.*                      | roi_heads.box_head.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.conv4.*                      | roi_heads.box_head.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                                          | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                                               | (320,) (320,1024)                                  |\n",
            "| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                                               | (81,) (81,1024)                                    |\n",
            "\u001b[32m[04/30 20:17:48 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json\n",
            "\u001b[32m[04/30 20:17:48 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n",
            "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
            "|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\n",
            "|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\n",
            "|     train     | 190          |    truck     | 414          |     boat      | 424          |\n",
            "| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\n",
            "| parking meter | 60           |    bench     | 411          |     bird      | 427          |\n",
            "|      cat      | 202          |     dog      | 218          |     horse     | 272          |\n",
            "|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\n",
            "|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\n",
            "|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\n",
            "|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\n",
            "|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\n",
            "|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\n",
            "|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\n",
            "|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\n",
            "|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\n",
            "|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\n",
            "|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\n",
            "|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\n",
            "|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\n",
            "|     couch     | 261          | potted plant | 342          |      bed      | 163          |\n",
            "| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\n",
            "|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\n",
            "|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\n",
            "|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\n",
            "| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\n",
            "|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\n",
            "|  hair drier   | 11           |  toothbrush  | 57           |               |              |\n",
            "|     total     | 36335        |              |              |               |              |\u001b[0m\n",
            "\u001b[32m[04/30 20:17:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/30 20:17:48 d2.data.common]: \u001b[0mSerializing 5000 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/30 20:17:48 d2.data.common]: \u001b[0mSerialized dataset takes 19.10 MiB\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[32m[04/30 20:17:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 5000 batches\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m[04/30 20:17:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/5000. Dataloading: 0.0012 s/iter. Inference: 0.1943 s/iter. Eval: 0.0002 s/iter. Total: 0.1957 s/iter. ETA=0:16:16\n",
            "\u001b[32m[04/30 20:17:57 d2.evaluation.evaluator]: \u001b[0mInference done 37/5000. Dataloading: 0.0016 s/iter. Inference: 0.1952 s/iter. Eval: 0.0002 s/iter. Total: 0.1971 s/iter. ETA=0:16:18\n",
            "\u001b[32m[04/30 20:18:02 d2.evaluation.evaluator]: \u001b[0mInference done 63/5000. Dataloading: 0.0017 s/iter. Inference: 0.1959 s/iter. Eval: 0.0003 s/iter. Total: 0.1979 s/iter. ETA=0:16:17\n",
            "\u001b[32m[04/30 20:18:07 d2.evaluation.evaluator]: \u001b[0mInference done 89/5000. Dataloading: 0.0017 s/iter. Inference: 0.1957 s/iter. Eval: 0.0003 s/iter. Total: 0.1977 s/iter. ETA=0:16:11\n",
            "\u001b[32m[04/30 20:18:12 d2.evaluation.evaluator]: \u001b[0mInference done 115/5000. Dataloading: 0.0017 s/iter. Inference: 0.1953 s/iter. Eval: 0.0003 s/iter. Total: 0.1973 s/iter. ETA=0:16:03\n",
            "\u001b[32m[04/30 20:18:17 d2.evaluation.evaluator]: \u001b[0mInference done 140/5000. Dataloading: 0.0017 s/iter. Inference: 0.1963 s/iter. Eval: 0.0003 s/iter. Total: 0.1983 s/iter. ETA=0:16:03\n",
            "\u001b[32m[04/30 20:18:22 d2.evaluation.evaluator]: \u001b[0mInference done 165/5000. Dataloading: 0.0018 s/iter. Inference: 0.1967 s/iter. Eval: 0.0002 s/iter. Total: 0.1988 s/iter. ETA=0:16:01\n",
            "\u001b[32m[04/30 20:18:27 d2.evaluation.evaluator]: \u001b[0mInference done 190/5000. Dataloading: 0.0018 s/iter. Inference: 0.1972 s/iter. Eval: 0.0002 s/iter. Total: 0.1993 s/iter. ETA=0:15:58\n",
            "\u001b[32m[04/30 20:18:32 d2.evaluation.evaluator]: \u001b[0mInference done 215/5000. Dataloading: 0.0018 s/iter. Inference: 0.1973 s/iter. Eval: 0.0002 s/iter. Total: 0.1994 s/iter. ETA=0:15:54\n",
            "\u001b[32m[04/30 20:18:37 d2.evaluation.evaluator]: \u001b[0mInference done 240/5000. Dataloading: 0.0018 s/iter. Inference: 0.1975 s/iter. Eval: 0.0002 s/iter. Total: 0.1996 s/iter. ETA=0:15:50\n",
            "\u001b[32m[04/30 20:18:42 d2.evaluation.evaluator]: \u001b[0mInference done 265/5000. Dataloading: 0.0018 s/iter. Inference: 0.1978 s/iter. Eval: 0.0002 s/iter. Total: 0.1999 s/iter. ETA=0:15:46\n",
            "\u001b[32m[04/30 20:18:48 d2.evaluation.evaluator]: \u001b[0mInference done 290/5000. Dataloading: 0.0018 s/iter. Inference: 0.1981 s/iter. Eval: 0.0002 s/iter. Total: 0.2002 s/iter. ETA=0:15:42\n",
            "\u001b[32m[04/30 20:18:53 d2.evaluation.evaluator]: \u001b[0mInference done 315/5000. Dataloading: 0.0018 s/iter. Inference: 0.1983 s/iter. Eval: 0.0002 s/iter. Total: 0.2004 s/iter. ETA=0:15:38\n",
            "\u001b[32m[04/30 20:18:58 d2.evaluation.evaluator]: \u001b[0mInference done 340/5000. Dataloading: 0.0018 s/iter. Inference: 0.1986 s/iter. Eval: 0.0002 s/iter. Total: 0.2007 s/iter. ETA=0:15:35\n",
            "\u001b[32m[04/30 20:19:03 d2.evaluation.evaluator]: \u001b[0mInference done 365/5000. Dataloading: 0.0018 s/iter. Inference: 0.1989 s/iter. Eval: 0.0002 s/iter. Total: 0.2010 s/iter. ETA=0:15:31\n",
            "\u001b[32m[04/30 20:19:08 d2.evaluation.evaluator]: \u001b[0mInference done 390/5000. Dataloading: 0.0018 s/iter. Inference: 0.1990 s/iter. Eval: 0.0002 s/iter. Total: 0.2011 s/iter. ETA=0:15:27\n",
            "\u001b[32m[04/30 20:19:13 d2.evaluation.evaluator]: \u001b[0mInference done 415/5000. Dataloading: 0.0018 s/iter. Inference: 0.1993 s/iter. Eval: 0.0002 s/iter. Total: 0.2014 s/iter. ETA=0:15:23\n",
            "\u001b[32m[04/30 20:19:18 d2.evaluation.evaluator]: \u001b[0mInference done 440/5000. Dataloading: 0.0018 s/iter. Inference: 0.1995 s/iter. Eval: 0.0002 s/iter. Total: 0.2016 s/iter. ETA=0:15:19\n",
            "\u001b[32m[04/30 20:19:23 d2.evaluation.evaluator]: \u001b[0mInference done 465/5000. Dataloading: 0.0018 s/iter. Inference: 0.1997 s/iter. Eval: 0.0002 s/iter. Total: 0.2018 s/iter. ETA=0:15:15\n",
            "\u001b[32m[04/30 20:19:29 d2.evaluation.evaluator]: \u001b[0mInference done 490/5000. Dataloading: 0.0018 s/iter. Inference: 0.2000 s/iter. Eval: 0.0002 s/iter. Total: 0.2021 s/iter. ETA=0:15:11\n",
            "\u001b[32m[04/30 20:19:34 d2.evaluation.evaluator]: \u001b[0mInference done 515/5000. Dataloading: 0.0018 s/iter. Inference: 0.2000 s/iter. Eval: 0.0002 s/iter. Total: 0.2021 s/iter. ETA=0:15:06\n",
            "\u001b[32m[04/30 20:19:39 d2.evaluation.evaluator]: \u001b[0mInference done 540/5000. Dataloading: 0.0018 s/iter. Inference: 0.2002 s/iter. Eval: 0.0002 s/iter. Total: 0.2023 s/iter. ETA=0:15:02\n",
            "\u001b[32m[04/30 20:19:44 d2.evaluation.evaluator]: \u001b[0mInference done 565/5000. Dataloading: 0.0018 s/iter. Inference: 0.2004 s/iter. Eval: 0.0002 s/iter. Total: 0.2025 s/iter. ETA=0:14:57\n",
            "\u001b[32m[04/30 20:19:49 d2.evaluation.evaluator]: \u001b[0mInference done 590/5000. Dataloading: 0.0018 s/iter. Inference: 0.2005 s/iter. Eval: 0.0002 s/iter. Total: 0.2026 s/iter. ETA=0:14:53\n",
            "\u001b[32m[04/30 20:19:54 d2.evaluation.evaluator]: \u001b[0mInference done 615/5000. Dataloading: 0.0018 s/iter. Inference: 0.2006 s/iter. Eval: 0.0002 s/iter. Total: 0.2027 s/iter. ETA=0:14:48\n",
            "\u001b[32m[04/30 20:19:59 d2.evaluation.evaluator]: \u001b[0mInference done 639/5000. Dataloading: 0.0018 s/iter. Inference: 0.2010 s/iter. Eval: 0.0002 s/iter. Total: 0.2032 s/iter. ETA=0:14:45\n",
            "\u001b[32m[04/30 20:20:04 d2.evaluation.evaluator]: \u001b[0mInference done 664/5000. Dataloading: 0.0018 s/iter. Inference: 0.2011 s/iter. Eval: 0.0002 s/iter. Total: 0.2033 s/iter. ETA=0:14:41\n",
            "\u001b[32m[04/30 20:20:09 d2.evaluation.evaluator]: \u001b[0mInference done 688/5000. Dataloading: 0.0018 s/iter. Inference: 0.2014 s/iter. Eval: 0.0002 s/iter. Total: 0.2035 s/iter. ETA=0:14:37\n",
            "\u001b[32m[04/30 20:20:14 d2.evaluation.evaluator]: \u001b[0mInference done 712/5000. Dataloading: 0.0018 s/iter. Inference: 0.2015 s/iter. Eval: 0.0002 s/iter. Total: 0.2036 s/iter. ETA=0:14:33\n",
            "\u001b[32m[04/30 20:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 737/5000. Dataloading: 0.0018 s/iter. Inference: 0.2017 s/iter. Eval: 0.0002 s/iter. Total: 0.2038 s/iter. ETA=0:14:28\n",
            "\u001b[32m[04/30 20:20:25 d2.evaluation.evaluator]: \u001b[0mInference done 762/5000. Dataloading: 0.0018 s/iter. Inference: 0.2018 s/iter. Eval: 0.0002 s/iter. Total: 0.2040 s/iter. ETA=0:14:24\n",
            "\u001b[32m[04/30 20:20:30 d2.evaluation.evaluator]: \u001b[0mInference done 786/5000. Dataloading: 0.0018 s/iter. Inference: 0.2020 s/iter. Eval: 0.0002 s/iter. Total: 0.2041 s/iter. ETA=0:14:20\n",
            "\u001b[32m[04/30 20:20:35 d2.evaluation.evaluator]: \u001b[0mInference done 811/5000. Dataloading: 0.0018 s/iter. Inference: 0.2021 s/iter. Eval: 0.0002 s/iter. Total: 0.2043 s/iter. ETA=0:14:15\n",
            "\u001b[32m[04/30 20:20:40 d2.evaluation.evaluator]: \u001b[0mInference done 836/5000. Dataloading: 0.0019 s/iter. Inference: 0.2022 s/iter. Eval: 0.0002 s/iter. Total: 0.2044 s/iter. ETA=0:14:10\n",
            "\u001b[32m[04/30 20:20:45 d2.evaluation.evaluator]: \u001b[0mInference done 860/5000. Dataloading: 0.0019 s/iter. Inference: 0.2024 s/iter. Eval: 0.0002 s/iter. Total: 0.2045 s/iter. ETA=0:14:06\n",
            "\u001b[32m[04/30 20:20:50 d2.evaluation.evaluator]: \u001b[0mInference done 884/5000. Dataloading: 0.0019 s/iter. Inference: 0.2025 s/iter. Eval: 0.0002 s/iter. Total: 0.2046 s/iter. ETA=0:14:02\n",
            "\u001b[32m[04/30 20:20:56 d2.evaluation.evaluator]: \u001b[0mInference done 909/5000. Dataloading: 0.0019 s/iter. Inference: 0.2025 s/iter. Eval: 0.0002 s/iter. Total: 0.2047 s/iter. ETA=0:13:57\n",
            "\u001b[32m[04/30 20:21:01 d2.evaluation.evaluator]: \u001b[0mInference done 933/5000. Dataloading: 0.0019 s/iter. Inference: 0.2026 s/iter. Eval: 0.0002 s/iter. Total: 0.2048 s/iter. ETA=0:13:52\n",
            "\u001b[32m[04/30 20:21:06 d2.evaluation.evaluator]: \u001b[0mInference done 957/5000. Dataloading: 0.0019 s/iter. Inference: 0.2028 s/iter. Eval: 0.0002 s/iter. Total: 0.2049 s/iter. ETA=0:13:48\n",
            "\u001b[32m[04/30 20:21:11 d2.evaluation.evaluator]: \u001b[0mInference done 982/5000. Dataloading: 0.0019 s/iter. Inference: 0.2028 s/iter. Eval: 0.0002 s/iter. Total: 0.2050 s/iter. ETA=0:13:43\n",
            "\u001b[32m[04/30 20:21:16 d2.evaluation.evaluator]: \u001b[0mInference done 1006/5000. Dataloading: 0.0019 s/iter. Inference: 0.2029 s/iter. Eval: 0.0002 s/iter. Total: 0.2051 s/iter. ETA=0:13:39\n",
            "\u001b[32m[04/30 20:21:21 d2.evaluation.evaluator]: \u001b[0mInference done 1031/5000. Dataloading: 0.0019 s/iter. Inference: 0.2029 s/iter. Eval: 0.0002 s/iter. Total: 0.2051 s/iter. ETA=0:13:34\n",
            "\u001b[32m[04/30 20:21:26 d2.evaluation.evaluator]: \u001b[0mInference done 1055/5000. Dataloading: 0.0019 s/iter. Inference: 0.2031 s/iter. Eval: 0.0002 s/iter. Total: 0.2052 s/iter. ETA=0:13:29\n",
            "\u001b[32m[04/30 20:21:31 d2.evaluation.evaluator]: \u001b[0mInference done 1079/5000. Dataloading: 0.0019 s/iter. Inference: 0.2032 s/iter. Eval: 0.0002 s/iter. Total: 0.2054 s/iter. ETA=0:13:25\n",
            "\u001b[32m[04/30 20:21:36 d2.evaluation.evaluator]: \u001b[0mInference done 1103/5000. Dataloading: 0.0019 s/iter. Inference: 0.2033 s/iter. Eval: 0.0002 s/iter. Total: 0.2055 s/iter. ETA=0:13:20\n",
            "\u001b[32m[04/30 20:21:41 d2.evaluation.evaluator]: \u001b[0mInference done 1127/5000. Dataloading: 0.0019 s/iter. Inference: 0.2034 s/iter. Eval: 0.0002 s/iter. Total: 0.2056 s/iter. ETA=0:13:16\n",
            "\u001b[32m[04/30 20:21:46 d2.evaluation.evaluator]: \u001b[0mInference done 1151/5000. Dataloading: 0.0019 s/iter. Inference: 0.2035 s/iter. Eval: 0.0002 s/iter. Total: 0.2057 s/iter. ETA=0:13:11\n",
            "\u001b[32m[04/30 20:21:51 d2.evaluation.evaluator]: \u001b[0mInference done 1175/5000. Dataloading: 0.0019 s/iter. Inference: 0.2037 s/iter. Eval: 0.0002 s/iter. Total: 0.2059 s/iter. ETA=0:13:07\n",
            "\u001b[32m[04/30 20:21:56 d2.evaluation.evaluator]: \u001b[0mInference done 1199/5000. Dataloading: 0.0019 s/iter. Inference: 0.2037 s/iter. Eval: 0.0002 s/iter. Total: 0.2059 s/iter. ETA=0:13:02\n",
            "\u001b[32m[04/30 20:22:01 d2.evaluation.evaluator]: \u001b[0mInference done 1223/5000. Dataloading: 0.0019 s/iter. Inference: 0.2038 s/iter. Eval: 0.0002 s/iter. Total: 0.2060 s/iter. ETA=0:12:57\n",
            "\u001b[32m[04/30 20:22:06 d2.evaluation.evaluator]: \u001b[0mInference done 1247/5000. Dataloading: 0.0019 s/iter. Inference: 0.2039 s/iter. Eval: 0.0002 s/iter. Total: 0.2061 s/iter. ETA=0:12:53\n",
            "\u001b[32m[04/30 20:22:12 d2.evaluation.evaluator]: \u001b[0mInference done 1272/5000. Dataloading: 0.0019 s/iter. Inference: 0.2039 s/iter. Eval: 0.0002 s/iter. Total: 0.2061 s/iter. ETA=0:12:48\n",
            "\u001b[32m[04/30 20:22:17 d2.evaluation.evaluator]: \u001b[0mInference done 1296/5000. Dataloading: 0.0019 s/iter. Inference: 0.2040 s/iter. Eval: 0.0002 s/iter. Total: 0.2062 s/iter. ETA=0:12:43\n",
            "\u001b[32m[04/30 20:22:22 d2.evaluation.evaluator]: \u001b[0mInference done 1321/5000. Dataloading: 0.0019 s/iter. Inference: 0.2039 s/iter. Eval: 0.0002 s/iter. Total: 0.2062 s/iter. ETA=0:12:38\n",
            "\u001b[32m[04/30 20:22:27 d2.evaluation.evaluator]: \u001b[0mInference done 1345/5000. Dataloading: 0.0019 s/iter. Inference: 0.2040 s/iter. Eval: 0.0002 s/iter. Total: 0.2062 s/iter. ETA=0:12:33\n",
            "\u001b[32m[04/30 20:22:32 d2.evaluation.evaluator]: \u001b[0mInference done 1369/5000. Dataloading: 0.0019 s/iter. Inference: 0.2041 s/iter. Eval: 0.0002 s/iter. Total: 0.2063 s/iter. ETA=0:12:29\n",
            "\u001b[32m[04/30 20:22:37 d2.evaluation.evaluator]: \u001b[0mInference done 1394/5000. Dataloading: 0.0019 s/iter. Inference: 0.2041 s/iter. Eval: 0.0002 s/iter. Total: 0.2063 s/iter. ETA=0:12:24\n",
            "\u001b[32m[04/30 20:22:42 d2.evaluation.evaluator]: \u001b[0mInference done 1419/5000. Dataloading: 0.0019 s/iter. Inference: 0.2041 s/iter. Eval: 0.0002 s/iter. Total: 0.2064 s/iter. ETA=0:12:19\n",
            "\u001b[32m[04/30 20:22:47 d2.evaluation.evaluator]: \u001b[0mInference done 1443/5000. Dataloading: 0.0019 s/iter. Inference: 0.2042 s/iter. Eval: 0.0002 s/iter. Total: 0.2064 s/iter. ETA=0:12:14\n",
            "\u001b[32m[04/30 20:22:52 d2.evaluation.evaluator]: \u001b[0mInference done 1468/5000. Dataloading: 0.0019 s/iter. Inference: 0.2042 s/iter. Eval: 0.0002 s/iter. Total: 0.2064 s/iter. ETA=0:12:08\n",
            "\u001b[32m[04/30 20:22:58 d2.evaluation.evaluator]: \u001b[0mInference done 1492/5000. Dataloading: 0.0019 s/iter. Inference: 0.2042 s/iter. Eval: 0.0002 s/iter. Total: 0.2065 s/iter. ETA=0:12:04\n",
            "\u001b[32m[04/30 20:23:03 d2.evaluation.evaluator]: \u001b[0mInference done 1517/5000. Dataloading: 0.0019 s/iter. Inference: 0.2042 s/iter. Eval: 0.0002 s/iter. Total: 0.2064 s/iter. ETA=0:11:58\n",
            "\u001b[32m[04/30 20:23:08 d2.evaluation.evaluator]: \u001b[0mInference done 1541/5000. Dataloading: 0.0019 s/iter. Inference: 0.2043 s/iter. Eval: 0.0002 s/iter. Total: 0.2065 s/iter. ETA=0:11:54\n",
            "\u001b[32m[04/30 20:23:13 d2.evaluation.evaluator]: \u001b[0mInference done 1565/5000. Dataloading: 0.0019 s/iter. Inference: 0.2043 s/iter. Eval: 0.0002 s/iter. Total: 0.2065 s/iter. ETA=0:11:49\n",
            "\u001b[32m[04/30 20:23:18 d2.evaluation.evaluator]: \u001b[0mInference done 1589/5000. Dataloading: 0.0019 s/iter. Inference: 0.2044 s/iter. Eval: 0.0002 s/iter. Total: 0.2066 s/iter. ETA=0:11:44\n",
            "\u001b[32m[04/30 20:23:23 d2.evaluation.evaluator]: \u001b[0mInference done 1613/5000. Dataloading: 0.0019 s/iter. Inference: 0.2045 s/iter. Eval: 0.0002 s/iter. Total: 0.2067 s/iter. ETA=0:11:40\n",
            "\u001b[32m[04/30 20:23:28 d2.evaluation.evaluator]: \u001b[0mInference done 1638/5000. Dataloading: 0.0019 s/iter. Inference: 0.2045 s/iter. Eval: 0.0002 s/iter. Total: 0.2067 s/iter. ETA=0:11:34\n",
            "\u001b[32m[04/30 20:23:33 d2.evaluation.evaluator]: \u001b[0mInference done 1662/5000. Dataloading: 0.0019 s/iter. Inference: 0.2045 s/iter. Eval: 0.0002 s/iter. Total: 0.2067 s/iter. ETA=0:11:30\n",
            "\u001b[32m[04/30 20:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 1686/5000. Dataloading: 0.0019 s/iter. Inference: 0.2046 s/iter. Eval: 0.0002 s/iter. Total: 0.2068 s/iter. ETA=0:11:25\n",
            "\u001b[32m[04/30 20:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 1710/5000. Dataloading: 0.0019 s/iter. Inference: 0.2046 s/iter. Eval: 0.0002 s/iter. Total: 0.2069 s/iter. ETA=0:11:20\n",
            "\u001b[32m[04/30 20:23:48 d2.evaluation.evaluator]: \u001b[0mInference done 1734/5000. Dataloading: 0.0019 s/iter. Inference: 0.2047 s/iter. Eval: 0.0002 s/iter. Total: 0.2069 s/iter. ETA=0:11:15\n",
            "\u001b[32m[04/30 20:23:53 d2.evaluation.evaluator]: \u001b[0mInference done 1758/5000. Dataloading: 0.0019 s/iter. Inference: 0.2047 s/iter. Eval: 0.0002 s/iter. Total: 0.2070 s/iter. ETA=0:11:11\n",
            "\u001b[32m[04/30 20:23:58 d2.evaluation.evaluator]: \u001b[0mInference done 1783/5000. Dataloading: 0.0019 s/iter. Inference: 0.2047 s/iter. Eval: 0.0002 s/iter. Total: 0.2069 s/iter. ETA=0:11:05\n",
            "\u001b[32m[04/30 20:24:03 d2.evaluation.evaluator]: \u001b[0mInference done 1807/5000. Dataloading: 0.0019 s/iter. Inference: 0.2047 s/iter. Eval: 0.0002 s/iter. Total: 0.2070 s/iter. ETA=0:11:00\n",
            "\u001b[32m[04/30 20:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 1831/5000. Dataloading: 0.0019 s/iter. Inference: 0.2048 s/iter. Eval: 0.0002 s/iter. Total: 0.2070 s/iter. ETA=0:10:56\n",
            "\u001b[32m[04/30 20:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 1856/5000. Dataloading: 0.0019 s/iter. Inference: 0.2048 s/iter. Eval: 0.0002 s/iter. Total: 0.2070 s/iter. ETA=0:10:50\n",
            "\u001b[32m[04/30 20:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 1880/5000. Dataloading: 0.0019 s/iter. Inference: 0.2049 s/iter. Eval: 0.0002 s/iter. Total: 0.2071 s/iter. ETA=0:10:46\n",
            "\u001b[32m[04/30 20:24:24 d2.evaluation.evaluator]: \u001b[0mInference done 1904/5000. Dataloading: 0.0019 s/iter. Inference: 0.2049 s/iter. Eval: 0.0002 s/iter. Total: 0.2071 s/iter. ETA=0:10:41\n",
            "\u001b[32m[04/30 20:24:29 d2.evaluation.evaluator]: \u001b[0mInference done 1928/5000. Dataloading: 0.0019 s/iter. Inference: 0.2049 s/iter. Eval: 0.0002 s/iter. Total: 0.2072 s/iter. ETA=0:10:36\n",
            "\u001b[32m[04/30 20:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 1953/5000. Dataloading: 0.0019 s/iter. Inference: 0.2049 s/iter. Eval: 0.0002 s/iter. Total: 0.2072 s/iter. ETA=0:10:31\n",
            "\u001b[32m[04/30 20:24:39 d2.evaluation.evaluator]: \u001b[0mInference done 1978/5000. Dataloading: 0.0019 s/iter. Inference: 0.2050 s/iter. Eval: 0.0002 s/iter. Total: 0.2072 s/iter. ETA=0:10:26\n",
            "\u001b[32m[04/30 20:24:44 d2.evaluation.evaluator]: \u001b[0mInference done 2002/5000. Dataloading: 0.0019 s/iter. Inference: 0.2050 s/iter. Eval: 0.0002 s/iter. Total: 0.2072 s/iter. ETA=0:10:21\n",
            "\u001b[32m[04/30 20:24:49 d2.evaluation.evaluator]: \u001b[0mInference done 2026/5000. Dataloading: 0.0019 s/iter. Inference: 0.2051 s/iter. Eval: 0.0002 s/iter. Total: 0.2073 s/iter. ETA=0:10:16\n",
            "\u001b[32m[04/30 20:24:55 d2.evaluation.evaluator]: \u001b[0mInference done 2051/5000. Dataloading: 0.0019 s/iter. Inference: 0.2050 s/iter. Eval: 0.0002 s/iter. Total: 0.2072 s/iter. ETA=0:10:11\n",
            "\u001b[32m[04/30 20:25:00 d2.evaluation.evaluator]: \u001b[0mInference done 2075/5000. Dataloading: 0.0019 s/iter. Inference: 0.2051 s/iter. Eval: 0.0002 s/iter. Total: 0.2073 s/iter. ETA=0:10:06\n",
            "\u001b[32m[04/30 20:25:05 d2.evaluation.evaluator]: \u001b[0mInference done 2099/5000. Dataloading: 0.0019 s/iter. Inference: 0.2051 s/iter. Eval: 0.0002 s/iter. Total: 0.2073 s/iter. ETA=0:10:01\n",
            "\u001b[32m[04/30 20:25:10 d2.evaluation.evaluator]: \u001b[0mInference done 2123/5000. Dataloading: 0.0019 s/iter. Inference: 0.2051 s/iter. Eval: 0.0002 s/iter. Total: 0.2073 s/iter. ETA=0:09:56\n",
            "\u001b[32m[04/30 20:25:15 d2.evaluation.evaluator]: \u001b[0mInference done 2148/5000. Dataloading: 0.0019 s/iter. Inference: 0.2051 s/iter. Eval: 0.0002 s/iter. Total: 0.2073 s/iter. ETA=0:09:51\n",
            "\u001b[32m[04/30 20:25:20 d2.evaluation.evaluator]: \u001b[0mInference done 2172/5000. Dataloading: 0.0019 s/iter. Inference: 0.2051 s/iter. Eval: 0.0002 s/iter. Total: 0.2073 s/iter. ETA=0:09:46\n",
            "\u001b[32m[04/30 20:25:25 d2.evaluation.evaluator]: \u001b[0mInference done 2196/5000. Dataloading: 0.0019 s/iter. Inference: 0.2051 s/iter. Eval: 0.0002 s/iter. Total: 0.2074 s/iter. ETA=0:09:41\n",
            "\u001b[32m[04/30 20:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 2220/5000. Dataloading: 0.0019 s/iter. Inference: 0.2052 s/iter. Eval: 0.0003 s/iter. Total: 0.2074 s/iter. ETA=0:09:36\n",
            "\u001b[32m[04/30 20:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 2244/5000. Dataloading: 0.0019 s/iter. Inference: 0.2052 s/iter. Eval: 0.0003 s/iter. Total: 0.2075 s/iter. ETA=0:09:31\n",
            "\u001b[32m[04/30 20:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 2268/5000. Dataloading: 0.0019 s/iter. Inference: 0.2053 s/iter. Eval: 0.0003 s/iter. Total: 0.2076 s/iter. ETA=0:09:27\n",
            "\u001b[32m[04/30 20:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 2292/5000. Dataloading: 0.0019 s/iter. Inference: 0.2053 s/iter. Eval: 0.0003 s/iter. Total: 0.2076 s/iter. ETA=0:09:22\n",
            "\u001b[32m[04/30 20:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 2317/5000. Dataloading: 0.0019 s/iter. Inference: 0.2053 s/iter. Eval: 0.0003 s/iter. Total: 0.2076 s/iter. ETA=0:09:16\n",
            "\u001b[32m[04/30 20:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 2341/5000. Dataloading: 0.0019 s/iter. Inference: 0.2053 s/iter. Eval: 0.0003 s/iter. Total: 0.2076 s/iter. ETA=0:09:12\n",
            "\u001b[32m[04/30 20:26:01 d2.evaluation.evaluator]: \u001b[0mInference done 2365/5000. Dataloading: 0.0019 s/iter. Inference: 0.2054 s/iter. Eval: 0.0003 s/iter. Total: 0.2077 s/iter. ETA=0:09:07\n",
            "\u001b[32m[04/30 20:26:06 d2.evaluation.evaluator]: \u001b[0mInference done 2389/5000. Dataloading: 0.0019 s/iter. Inference: 0.2054 s/iter. Eval: 0.0003 s/iter. Total: 0.2077 s/iter. ETA=0:09:02\n",
            "\u001b[32m[04/30 20:26:11 d2.evaluation.evaluator]: \u001b[0mInference done 2413/5000. Dataloading: 0.0019 s/iter. Inference: 0.2054 s/iter. Eval: 0.0003 s/iter. Total: 0.2077 s/iter. ETA=0:08:57\n",
            "\u001b[32m[04/30 20:26:16 d2.evaluation.evaluator]: \u001b[0mInference done 2437/5000. Dataloading: 0.0019 s/iter. Inference: 0.2055 s/iter. Eval: 0.0003 s/iter. Total: 0.2078 s/iter. ETA=0:08:52\n",
            "\u001b[32m[04/30 20:26:21 d2.evaluation.evaluator]: \u001b[0mInference done 2461/5000. Dataloading: 0.0019 s/iter. Inference: 0.2055 s/iter. Eval: 0.0003 s/iter. Total: 0.2078 s/iter. ETA=0:08:47\n",
            "\u001b[32m[04/30 20:26:26 d2.evaluation.evaluator]: \u001b[0mInference done 2486/5000. Dataloading: 0.0019 s/iter. Inference: 0.2055 s/iter. Eval: 0.0003 s/iter. Total: 0.2078 s/iter. ETA=0:08:42\n",
            "\u001b[32m[04/30 20:26:31 d2.evaluation.evaluator]: \u001b[0mInference done 2510/5000. Dataloading: 0.0019 s/iter. Inference: 0.2055 s/iter. Eval: 0.0003 s/iter. Total: 0.2078 s/iter. ETA=0:08:37\n",
            "\u001b[32m[04/30 20:26:36 d2.evaluation.evaluator]: \u001b[0mInference done 2535/5000. Dataloading: 0.0019 s/iter. Inference: 0.2055 s/iter. Eval: 0.0003 s/iter. Total: 0.2078 s/iter. ETA=0:08:32\n",
            "\u001b[32m[04/30 20:26:41 d2.evaluation.evaluator]: \u001b[0mInference done 2559/5000. Dataloading: 0.0019 s/iter. Inference: 0.2056 s/iter. Eval: 0.0003 s/iter. Total: 0.2078 s/iter. ETA=0:08:27\n",
            "\u001b[32m[04/30 20:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 2584/5000. Dataloading: 0.0019 s/iter. Inference: 0.2055 s/iter. Eval: 0.0003 s/iter. Total: 0.2078 s/iter. ETA=0:08:22\n",
            "\u001b[32m[04/30 20:26:52 d2.evaluation.evaluator]: \u001b[0mInference done 2608/5000. Dataloading: 0.0019 s/iter. Inference: 0.2055 s/iter. Eval: 0.0003 s/iter. Total: 0.2078 s/iter. ETA=0:08:17\n",
            "\u001b[32m[04/30 20:26:57 d2.evaluation.evaluator]: \u001b[0mInference done 2632/5000. Dataloading: 0.0019 s/iter. Inference: 0.2056 s/iter. Eval: 0.0003 s/iter. Total: 0.2079 s/iter. ETA=0:08:12\n",
            "\u001b[32m[04/30 20:27:02 d2.evaluation.evaluator]: \u001b[0mInference done 2656/5000. Dataloading: 0.0019 s/iter. Inference: 0.2056 s/iter. Eval: 0.0003 s/iter. Total: 0.2079 s/iter. ETA=0:08:07\n",
            "\u001b[32m[04/30 20:27:07 d2.evaluation.evaluator]: \u001b[0mInference done 2680/5000. Dataloading: 0.0019 s/iter. Inference: 0.2056 s/iter. Eval: 0.0003 s/iter. Total: 0.2079 s/iter. ETA=0:08:02\n",
            "\u001b[32m[04/30 20:27:12 d2.evaluation.evaluator]: \u001b[0mInference done 2704/5000. Dataloading: 0.0019 s/iter. Inference: 0.2057 s/iter. Eval: 0.0003 s/iter. Total: 0.2080 s/iter. ETA=0:07:57\n",
            "\u001b[32m[04/30 20:27:17 d2.evaluation.evaluator]: \u001b[0mInference done 2728/5000. Dataloading: 0.0019 s/iter. Inference: 0.2057 s/iter. Eval: 0.0003 s/iter. Total: 0.2080 s/iter. ETA=0:07:52\n",
            "\u001b[32m[04/30 20:27:22 d2.evaluation.evaluator]: \u001b[0mInference done 2753/5000. Dataloading: 0.0019 s/iter. Inference: 0.2057 s/iter. Eval: 0.0003 s/iter. Total: 0.2080 s/iter. ETA=0:07:47\n",
            "\u001b[32m[04/30 20:27:27 d2.evaluation.evaluator]: \u001b[0mInference done 2777/5000. Dataloading: 0.0019 s/iter. Inference: 0.2057 s/iter. Eval: 0.0003 s/iter. Total: 0.2080 s/iter. ETA=0:07:42\n",
            "\u001b[32m[04/30 20:27:32 d2.evaluation.evaluator]: \u001b[0mInference done 2802/5000. Dataloading: 0.0019 s/iter. Inference: 0.2057 s/iter. Eval: 0.0003 s/iter. Total: 0.2080 s/iter. ETA=0:07:37\n",
            "\u001b[32m[04/30 20:27:37 d2.evaluation.evaluator]: \u001b[0mInference done 2826/5000. Dataloading: 0.0019 s/iter. Inference: 0.2057 s/iter. Eval: 0.0003 s/iter. Total: 0.2080 s/iter. ETA=0:07:32\n",
            "\u001b[32m[04/30 20:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 2850/5000. Dataloading: 0.0020 s/iter. Inference: 0.2058 s/iter. Eval: 0.0003 s/iter. Total: 0.2081 s/iter. ETA=0:07:27\n",
            "\u001b[32m[04/30 20:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 2874/5000. Dataloading: 0.0019 s/iter. Inference: 0.2058 s/iter. Eval: 0.0003 s/iter. Total: 0.2081 s/iter. ETA=0:07:22\n",
            "\u001b[32m[04/30 20:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 2898/5000. Dataloading: 0.0019 s/iter. Inference: 0.2058 s/iter. Eval: 0.0003 s/iter. Total: 0.2081 s/iter. ETA=0:07:17\n",
            "\u001b[32m[04/30 20:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 2922/5000. Dataloading: 0.0019 s/iter. Inference: 0.2058 s/iter. Eval: 0.0003 s/iter. Total: 0.2081 s/iter. ETA=0:07:12\n",
            "\u001b[32m[04/30 20:28:03 d2.evaluation.evaluator]: \u001b[0mInference done 2946/5000. Dataloading: 0.0019 s/iter. Inference: 0.2059 s/iter. Eval: 0.0003 s/iter. Total: 0.2081 s/iter. ETA=0:07:07\n",
            "\u001b[32m[04/30 20:28:08 d2.evaluation.evaluator]: \u001b[0mInference done 2970/5000. Dataloading: 0.0020 s/iter. Inference: 0.2059 s/iter. Eval: 0.0003 s/iter. Total: 0.2082 s/iter. ETA=0:07:02\n",
            "\u001b[32m[04/30 20:28:13 d2.evaluation.evaluator]: \u001b[0mInference done 2994/5000. Dataloading: 0.0020 s/iter. Inference: 0.2059 s/iter. Eval: 0.0003 s/iter. Total: 0.2082 s/iter. ETA=0:06:57\n",
            "\u001b[32m[04/30 20:28:18 d2.evaluation.evaluator]: \u001b[0mInference done 3018/5000. Dataloading: 0.0020 s/iter. Inference: 0.2059 s/iter. Eval: 0.0003 s/iter. Total: 0.2082 s/iter. ETA=0:06:52\n",
            "\u001b[32m[04/30 20:28:23 d2.evaluation.evaluator]: \u001b[0mInference done 3042/5000. Dataloading: 0.0020 s/iter. Inference: 0.2059 s/iter. Eval: 0.0003 s/iter. Total: 0.2082 s/iter. ETA=0:06:47\n",
            "\u001b[32m[04/30 20:28:28 d2.evaluation.evaluator]: \u001b[0mInference done 3066/5000. Dataloading: 0.0020 s/iter. Inference: 0.2060 s/iter. Eval: 0.0003 s/iter. Total: 0.2083 s/iter. ETA=0:06:42\n",
            "\u001b[32m[04/30 20:28:33 d2.evaluation.evaluator]: \u001b[0mInference done 3090/5000. Dataloading: 0.0020 s/iter. Inference: 0.2060 s/iter. Eval: 0.0003 s/iter. Total: 0.2083 s/iter. ETA=0:06:37\n",
            "\u001b[32m[04/30 20:28:38 d2.evaluation.evaluator]: \u001b[0mInference done 3115/5000. Dataloading: 0.0020 s/iter. Inference: 0.2060 s/iter. Eval: 0.0003 s/iter. Total: 0.2083 s/iter. ETA=0:06:32\n",
            "\u001b[32m[04/30 20:28:43 d2.evaluation.evaluator]: \u001b[0mInference done 3139/5000. Dataloading: 0.0020 s/iter. Inference: 0.2060 s/iter. Eval: 0.0003 s/iter. Total: 0.2083 s/iter. ETA=0:06:27\n",
            "\u001b[32m[04/30 20:28:49 d2.evaluation.evaluator]: \u001b[0mInference done 3163/5000. Dataloading: 0.0020 s/iter. Inference: 0.2061 s/iter. Eval: 0.0003 s/iter. Total: 0.2084 s/iter. ETA=0:06:22\n",
            "\u001b[32m[04/30 20:28:54 d2.evaluation.evaluator]: \u001b[0mInference done 3187/5000. Dataloading: 0.0020 s/iter. Inference: 0.2061 s/iter. Eval: 0.0003 s/iter. Total: 0.2084 s/iter. ETA=0:06:17\n",
            "\u001b[32m[04/30 20:28:59 d2.evaluation.evaluator]: \u001b[0mInference done 3211/5000. Dataloading: 0.0020 s/iter. Inference: 0.2061 s/iter. Eval: 0.0003 s/iter. Total: 0.2084 s/iter. ETA=0:06:12\n",
            "\u001b[32m[04/30 20:29:04 d2.evaluation.evaluator]: \u001b[0mInference done 3235/5000. Dataloading: 0.0020 s/iter. Inference: 0.2061 s/iter. Eval: 0.0003 s/iter. Total: 0.2084 s/iter. ETA=0:06:07\n",
            "\u001b[32m[04/30 20:29:09 d2.evaluation.evaluator]: \u001b[0mInference done 3259/5000. Dataloading: 0.0020 s/iter. Inference: 0.2061 s/iter. Eval: 0.0003 s/iter. Total: 0.2084 s/iter. ETA=0:06:02\n",
            "\u001b[32m[04/30 20:29:14 d2.evaluation.evaluator]: \u001b[0mInference done 3283/5000. Dataloading: 0.0020 s/iter. Inference: 0.2061 s/iter. Eval: 0.0003 s/iter. Total: 0.2084 s/iter. ETA=0:05:57\n",
            "\u001b[32m[04/30 20:29:19 d2.evaluation.evaluator]: \u001b[0mInference done 3307/5000. Dataloading: 0.0020 s/iter. Inference: 0.2062 s/iter. Eval: 0.0003 s/iter. Total: 0.2085 s/iter. ETA=0:05:52\n",
            "\u001b[32m[04/30 20:29:24 d2.evaluation.evaluator]: \u001b[0mInference done 3331/5000. Dataloading: 0.0020 s/iter. Inference: 0.2062 s/iter. Eval: 0.0003 s/iter. Total: 0.2085 s/iter. ETA=0:05:47\n",
            "\u001b[32m[04/30 20:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 3355/5000. Dataloading: 0.0020 s/iter. Inference: 0.2062 s/iter. Eval: 0.0003 s/iter. Total: 0.2085 s/iter. ETA=0:05:42\n",
            "\u001b[32m[04/30 20:29:34 d2.evaluation.evaluator]: \u001b[0mInference done 3379/5000. Dataloading: 0.0020 s/iter. Inference: 0.2062 s/iter. Eval: 0.0003 s/iter. Total: 0.2085 s/iter. ETA=0:05:37\n",
            "\u001b[32m[04/30 20:29:39 d2.evaluation.evaluator]: \u001b[0mInference done 3404/5000. Dataloading: 0.0020 s/iter. Inference: 0.2062 s/iter. Eval: 0.0003 s/iter. Total: 0.2085 s/iter. ETA=0:05:32\n",
            "\u001b[32m[04/30 20:29:44 d2.evaluation.evaluator]: \u001b[0mInference done 3428/5000. Dataloading: 0.0020 s/iter. Inference: 0.2062 s/iter. Eval: 0.0003 s/iter. Total: 0.2085 s/iter. ETA=0:05:27\n",
            "\u001b[32m[04/30 20:29:49 d2.evaluation.evaluator]: \u001b[0mInference done 3452/5000. Dataloading: 0.0020 s/iter. Inference: 0.2062 s/iter. Eval: 0.0003 s/iter. Total: 0.2085 s/iter. ETA=0:05:22\n",
            "\u001b[32m[04/30 20:29:54 d2.evaluation.evaluator]: \u001b[0mInference done 3476/5000. Dataloading: 0.0020 s/iter. Inference: 0.2062 s/iter. Eval: 0.0003 s/iter. Total: 0.2085 s/iter. ETA=0:05:17\n",
            "\u001b[32m[04/30 20:29:59 d2.evaluation.evaluator]: \u001b[0mInference done 3500/5000. Dataloading: 0.0020 s/iter. Inference: 0.2062 s/iter. Eval: 0.0003 s/iter. Total: 0.2085 s/iter. ETA=0:05:12\n",
            "\u001b[32m[04/30 20:30:04 d2.evaluation.evaluator]: \u001b[0mInference done 3524/5000. Dataloading: 0.0020 s/iter. Inference: 0.2062 s/iter. Eval: 0.0003 s/iter. Total: 0.2085 s/iter. ETA=0:05:07\n",
            "\u001b[32m[04/30 20:30:09 d2.evaluation.evaluator]: \u001b[0mInference done 3548/5000. Dataloading: 0.0020 s/iter. Inference: 0.2063 s/iter. Eval: 0.0003 s/iter. Total: 0.2085 s/iter. ETA=0:05:02\n",
            "\u001b[32m[04/30 20:30:14 d2.evaluation.evaluator]: \u001b[0mInference done 3572/5000. Dataloading: 0.0020 s/iter. Inference: 0.2063 s/iter. Eval: 0.0003 s/iter. Total: 0.2086 s/iter. ETA=0:04:57\n",
            "\u001b[32m[04/30 20:30:19 d2.evaluation.evaluator]: \u001b[0mInference done 3596/5000. Dataloading: 0.0020 s/iter. Inference: 0.2063 s/iter. Eval: 0.0003 s/iter. Total: 0.2086 s/iter. ETA=0:04:52\n",
            "\u001b[32m[04/30 20:30:25 d2.evaluation.evaluator]: \u001b[0mInference done 3620/5000. Dataloading: 0.0020 s/iter. Inference: 0.2063 s/iter. Eval: 0.0003 s/iter. Total: 0.2086 s/iter. ETA=0:04:47\n",
            "\u001b[32m[04/30 20:30:30 d2.evaluation.evaluator]: \u001b[0mInference done 3644/5000. Dataloading: 0.0020 s/iter. Inference: 0.2063 s/iter. Eval: 0.0003 s/iter. Total: 0.2086 s/iter. ETA=0:04:42\n",
            "\u001b[32m[04/30 20:30:35 d2.evaluation.evaluator]: \u001b[0mInference done 3668/5000. Dataloading: 0.0020 s/iter. Inference: 0.2063 s/iter. Eval: 0.0003 s/iter. Total: 0.2086 s/iter. ETA=0:04:37\n",
            "\u001b[32m[04/30 20:30:40 d2.evaluation.evaluator]: \u001b[0mInference done 3692/5000. Dataloading: 0.0020 s/iter. Inference: 0.2063 s/iter. Eval: 0.0003 s/iter. Total: 0.2086 s/iter. ETA=0:04:32\n",
            "\u001b[32m[04/30 20:30:45 d2.evaluation.evaluator]: \u001b[0mInference done 3716/5000. Dataloading: 0.0020 s/iter. Inference: 0.2063 s/iter. Eval: 0.0003 s/iter. Total: 0.2086 s/iter. ETA=0:04:27\n",
            "\u001b[32m[04/30 20:30:50 d2.evaluation.evaluator]: \u001b[0mInference done 3740/5000. Dataloading: 0.0020 s/iter. Inference: 0.2064 s/iter. Eval: 0.0003 s/iter. Total: 0.2087 s/iter. ETA=0:04:22\n",
            "\u001b[32m[04/30 20:30:55 d2.evaluation.evaluator]: \u001b[0mInference done 3764/5000. Dataloading: 0.0020 s/iter. Inference: 0.2064 s/iter. Eval: 0.0003 s/iter. Total: 0.2087 s/iter. ETA=0:04:17\n",
            "\u001b[32m[04/30 20:31:00 d2.evaluation.evaluator]: \u001b[0mInference done 3788/5000. Dataloading: 0.0020 s/iter. Inference: 0.2064 s/iter. Eval: 0.0003 s/iter. Total: 0.2087 s/iter. ETA=0:04:12\n",
            "\u001b[32m[04/30 20:31:05 d2.evaluation.evaluator]: \u001b[0mInference done 3812/5000. Dataloading: 0.0020 s/iter. Inference: 0.2064 s/iter. Eval: 0.0003 s/iter. Total: 0.2087 s/iter. ETA=0:04:07\n",
            "\u001b[32m[04/30 20:31:10 d2.evaluation.evaluator]: \u001b[0mInference done 3836/5000. Dataloading: 0.0020 s/iter. Inference: 0.2064 s/iter. Eval: 0.0003 s/iter. Total: 0.2087 s/iter. ETA=0:04:02\n",
            "\u001b[32m[04/30 20:31:15 d2.evaluation.evaluator]: \u001b[0mInference done 3860/5000. Dataloading: 0.0020 s/iter. Inference: 0.2064 s/iter. Eval: 0.0003 s/iter. Total: 0.2087 s/iter. ETA=0:03:57\n",
            "\u001b[32m[04/30 20:31:20 d2.evaluation.evaluator]: \u001b[0mInference done 3884/5000. Dataloading: 0.0020 s/iter. Inference: 0.2064 s/iter. Eval: 0.0003 s/iter. Total: 0.2087 s/iter. ETA=0:03:52\n",
            "\u001b[32m[04/30 20:31:25 d2.evaluation.evaluator]: \u001b[0mInference done 3908/5000. Dataloading: 0.0020 s/iter. Inference: 0.2064 s/iter. Eval: 0.0003 s/iter. Total: 0.2087 s/iter. ETA=0:03:47\n",
            "\u001b[32m[04/30 20:31:30 d2.evaluation.evaluator]: \u001b[0mInference done 3932/5000. Dataloading: 0.0020 s/iter. Inference: 0.2064 s/iter. Eval: 0.0003 s/iter. Total: 0.2087 s/iter. ETA=0:03:42\n",
            "\u001b[32m[04/30 20:31:35 d2.evaluation.evaluator]: \u001b[0mInference done 3956/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2087 s/iter. ETA=0:03:37\n",
            "\u001b[32m[04/30 20:31:40 d2.evaluation.evaluator]: \u001b[0mInference done 3981/5000. Dataloading: 0.0020 s/iter. Inference: 0.2064 s/iter. Eval: 0.0003 s/iter. Total: 0.2087 s/iter. ETA=0:03:32\n",
            "\u001b[32m[04/30 20:31:46 d2.evaluation.evaluator]: \u001b[0mInference done 4006/5000. Dataloading: 0.0020 s/iter. Inference: 0.2064 s/iter. Eval: 0.0003 s/iter. Total: 0.2087 s/iter. ETA=0:03:27\n",
            "\u001b[32m[04/30 20:31:51 d2.evaluation.evaluator]: \u001b[0mInference done 4030/5000. Dataloading: 0.0020 s/iter. Inference: 0.2064 s/iter. Eval: 0.0003 s/iter. Total: 0.2087 s/iter. ETA=0:03:22\n",
            "\u001b[32m[04/30 20:31:56 d2.evaluation.evaluator]: \u001b[0mInference done 4054/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2088 s/iter. ETA=0:03:17\n",
            "\u001b[32m[04/30 20:32:01 d2.evaluation.evaluator]: \u001b[0mInference done 4079/5000. Dataloading: 0.0020 s/iter. Inference: 0.2064 s/iter. Eval: 0.0003 s/iter. Total: 0.2087 s/iter. ETA=0:03:12\n",
            "\u001b[32m[04/30 20:32:06 d2.evaluation.evaluator]: \u001b[0mInference done 4103/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2088 s/iter. ETA=0:03:07\n",
            "\u001b[32m[04/30 20:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 4127/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2088 s/iter. ETA=0:03:02\n",
            "\u001b[32m[04/30 20:32:16 d2.evaluation.evaluator]: \u001b[0mInference done 4151/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2088 s/iter. ETA=0:02:57\n",
            "\u001b[32m[04/30 20:32:21 d2.evaluation.evaluator]: \u001b[0mInference done 4176/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2088 s/iter. ETA=0:02:52\n",
            "\u001b[32m[04/30 20:32:26 d2.evaluation.evaluator]: \u001b[0mInference done 4200/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2088 s/iter. ETA=0:02:47\n",
            "\u001b[32m[04/30 20:32:31 d2.evaluation.evaluator]: \u001b[0mInference done 4223/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2089 s/iter. ETA=0:02:42\n",
            "\u001b[32m[04/30 20:32:37 d2.evaluation.evaluator]: \u001b[0mInference done 4248/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2088 s/iter. ETA=0:02:37\n",
            "\u001b[32m[04/30 20:32:42 d2.evaluation.evaluator]: \u001b[0mInference done 4273/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2088 s/iter. ETA=0:02:31\n",
            "\u001b[32m[04/30 20:32:47 d2.evaluation.evaluator]: \u001b[0mInference done 4298/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2088 s/iter. ETA=0:02:26\n",
            "\u001b[32m[04/30 20:32:52 d2.evaluation.evaluator]: \u001b[0mInference done 4322/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2088 s/iter. ETA=0:02:21\n",
            "\u001b[32m[04/30 20:32:57 d2.evaluation.evaluator]: \u001b[0mInference done 4346/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2088 s/iter. ETA=0:02:16\n",
            "\u001b[32m[04/30 20:33:02 d2.evaluation.evaluator]: \u001b[0mInference done 4370/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2088 s/iter. ETA=0:02:11\n",
            "\u001b[32m[04/30 20:33:07 d2.evaluation.evaluator]: \u001b[0mInference done 4394/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2088 s/iter. ETA=0:02:06\n",
            "\u001b[32m[04/30 20:33:12 d2.evaluation.evaluator]: \u001b[0mInference done 4418/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2088 s/iter. ETA=0:02:01\n",
            "\u001b[32m[04/30 20:33:17 d2.evaluation.evaluator]: \u001b[0mInference done 4442/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2088 s/iter. ETA=0:01:56\n",
            "\u001b[32m[04/30 20:33:22 d2.evaluation.evaluator]: \u001b[0mInference done 4466/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2089 s/iter. ETA=0:01:51\n",
            "\u001b[32m[04/30 20:33:27 d2.evaluation.evaluator]: \u001b[0mInference done 4490/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2089 s/iter. ETA=0:01:46\n",
            "\u001b[32m[04/30 20:33:32 d2.evaluation.evaluator]: \u001b[0mInference done 4514/5000. Dataloading: 0.0020 s/iter. Inference: 0.2065 s/iter. Eval: 0.0003 s/iter. Total: 0.2089 s/iter. ETA=0:01:41\n",
            "\u001b[32m[04/30 20:33:37 d2.evaluation.evaluator]: \u001b[0mInference done 4538/5000. Dataloading: 0.0020 s/iter. Inference: 0.2066 s/iter. Eval: 0.0003 s/iter. Total: 0.2089 s/iter. ETA=0:01:36\n",
            "\u001b[32m[04/30 20:33:42 d2.evaluation.evaluator]: \u001b[0mInference done 4562/5000. Dataloading: 0.0020 s/iter. Inference: 0.2066 s/iter. Eval: 0.0003 s/iter. Total: 0.2089 s/iter. ETA=0:01:31\n",
            "\u001b[32m[04/30 20:33:47 d2.evaluation.evaluator]: \u001b[0mInference done 4586/5000. Dataloading: 0.0020 s/iter. Inference: 0.2066 s/iter. Eval: 0.0003 s/iter. Total: 0.2089 s/iter. ETA=0:01:26\n",
            "\u001b[32m[04/30 20:33:53 d2.evaluation.evaluator]: \u001b[0mInference done 4610/5000. Dataloading: 0.0020 s/iter. Inference: 0.2066 s/iter. Eval: 0.0003 s/iter. Total: 0.2089 s/iter. ETA=0:01:21\n",
            "\u001b[32m[04/30 20:33:58 d2.evaluation.evaluator]: \u001b[0mInference done 4634/5000. Dataloading: 0.0020 s/iter. Inference: 0.2066 s/iter. Eval: 0.0003 s/iter. Total: 0.2089 s/iter. ETA=0:01:16\n",
            "\u001b[32m[04/30 20:34:03 d2.evaluation.evaluator]: \u001b[0mInference done 4658/5000. Dataloading: 0.0020 s/iter. Inference: 0.2066 s/iter. Eval: 0.0003 s/iter. Total: 0.2089 s/iter. ETA=0:01:11\n",
            "\u001b[32m[04/30 20:34:08 d2.evaluation.evaluator]: \u001b[0mInference done 4683/5000. Dataloading: 0.0020 s/iter. Inference: 0.2066 s/iter. Eval: 0.0003 s/iter. Total: 0.2089 s/iter. ETA=0:01:06\n",
            "\u001b[32m[04/30 20:34:13 d2.evaluation.evaluator]: \u001b[0mInference done 4707/5000. Dataloading: 0.0020 s/iter. Inference: 0.2066 s/iter. Eval: 0.0003 s/iter. Total: 0.2089 s/iter. ETA=0:01:01\n",
            "\u001b[32m[04/30 20:34:18 d2.evaluation.evaluator]: \u001b[0mInference done 4731/5000. Dataloading: 0.0020 s/iter. Inference: 0.2066 s/iter. Eval: 0.0003 s/iter. Total: 0.2089 s/iter. ETA=0:00:56\n",
            "\u001b[32m[04/30 20:34:23 d2.evaluation.evaluator]: \u001b[0mInference done 4755/5000. Dataloading: 0.0020 s/iter. Inference: 0.2066 s/iter. Eval: 0.0003 s/iter. Total: 0.2090 s/iter. ETA=0:00:51\n",
            "\u001b[32m[04/30 20:34:28 d2.evaluation.evaluator]: \u001b[0mInference done 4779/5000. Dataloading: 0.0020 s/iter. Inference: 0.2066 s/iter. Eval: 0.0003 s/iter. Total: 0.2090 s/iter. ETA=0:00:46\n",
            "\u001b[32m[04/30 20:34:33 d2.evaluation.evaluator]: \u001b[0mInference done 4803/5000. Dataloading: 0.0020 s/iter. Inference: 0.2066 s/iter. Eval: 0.0003 s/iter. Total: 0.2090 s/iter. ETA=0:00:41\n",
            "\u001b[32m[04/30 20:34:38 d2.evaluation.evaluator]: \u001b[0mInference done 4828/5000. Dataloading: 0.0020 s/iter. Inference: 0.2066 s/iter. Eval: 0.0003 s/iter. Total: 0.2090 s/iter. ETA=0:00:35\n",
            "\u001b[32m[04/30 20:34:43 d2.evaluation.evaluator]: \u001b[0mInference done 4852/5000. Dataloading: 0.0020 s/iter. Inference: 0.2066 s/iter. Eval: 0.0003 s/iter. Total: 0.2090 s/iter. ETA=0:00:30\n",
            "\u001b[32m[04/30 20:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 4876/5000. Dataloading: 0.0020 s/iter. Inference: 0.2067 s/iter. Eval: 0.0003 s/iter. Total: 0.2090 s/iter. ETA=0:00:25\n",
            "\u001b[32m[04/30 20:34:54 d2.evaluation.evaluator]: \u001b[0mInference done 4900/5000. Dataloading: 0.0020 s/iter. Inference: 0.2067 s/iter. Eval: 0.0003 s/iter. Total: 0.2090 s/iter. ETA=0:00:20\n",
            "\u001b[32m[04/30 20:34:59 d2.evaluation.evaluator]: \u001b[0mInference done 4924/5000. Dataloading: 0.0020 s/iter. Inference: 0.2067 s/iter. Eval: 0.0003 s/iter. Total: 0.2090 s/iter. ETA=0:00:15\n",
            "\u001b[32m[04/30 20:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 4948/5000. Dataloading: 0.0020 s/iter. Inference: 0.2067 s/iter. Eval: 0.0003 s/iter. Total: 0.2090 s/iter. ETA=0:00:10\n",
            "\u001b[32m[04/30 20:35:09 d2.evaluation.evaluator]: \u001b[0mInference done 4972/5000. Dataloading: 0.0020 s/iter. Inference: 0.2067 s/iter. Eval: 0.0003 s/iter. Total: 0.2090 s/iter. ETA=0:00:05\n",
            "\u001b[32m[04/30 20:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 4996/5000. Dataloading: 0.0020 s/iter. Inference: 0.2067 s/iter. Eval: 0.0003 s/iter. Total: 0.2091 s/iter. ETA=0:00:00\n",
            "\u001b[32m[04/30 20:35:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:17:24.366304 (0.209082 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 20:35:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:17:12 (0.206719 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 20:35:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/30 20:35:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/30 20:35:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.39s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 20:35:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/30 20:35:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 7.92 seconds.\n",
            "\u001b[32m[04/30 20:35:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 20:35:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.94 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.424\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.637\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.460\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.262\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.459\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.542\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.534\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.381\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685\n",
            "\u001b[32m[04/30 20:35:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 42.389 | 63.727 | 46.024 | 26.248 | 45.879 | 54.241 |\n",
            "\u001b[32m[04/30 20:35:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 55.169 | bicycle      | 31.101 | car            | 44.571 |\n",
            "| motorcycle    | 44.501 | airplane     | 64.258 | bus            | 65.554 |\n",
            "| train         | 60.996 | truck        | 36.444 | boat           | 27.836 |\n",
            "| traffic light | 28.269 | fire hydrant | 69.832 | stop sign      | 66.446 |\n",
            "| parking meter | 46.743 | bench        | 24.965 | bird           | 37.939 |\n",
            "| cat           | 65.335 | dog          | 64.075 | horse          | 60.602 |\n",
            "| sheep         | 51.345 | cow          | 55.214 | elephant       | 64.671 |\n",
            "| bear          | 67.695 | zebra        | 65.241 | giraffe        | 66.971 |\n",
            "| backpack      | 14.297 | umbrella     | 39.895 | handbag        | 16.508 |\n",
            "| tie           | 34.980 | suitcase     | 39.931 | frisbee        | 67.448 |\n",
            "| skis          | 25.466 | snowboard    | 42.347 | sports ball    | 49.106 |\n",
            "| kite          | 43.558 | baseball bat | 37.755 | baseball glove | 38.683 |\n",
            "| skateboard    | 54.345 | surfboard    | 42.121 | tennis racket  | 49.905 |\n",
            "| bottle        | 39.710 | wine glass   | 37.518 | cup            | 44.088 |\n",
            "| fork          | 38.701 | knife        | 20.356 | spoon          | 19.930 |\n",
            "| bowl          | 43.038 | banana       | 21.928 | apple          | 20.905 |\n",
            "| sandwich      | 34.244 | orange       | 30.695 | broccoli       | 25.024 |\n",
            "| carrot        | 23.077 | hot dog      | 32.853 | pizza          | 52.206 |\n",
            "| donut         | 44.882 | cake         | 37.592 | chair          | 27.783 |\n",
            "| couch         | 40.350 | potted plant | 28.599 | bed            | 42.044 |\n",
            "| dining table  | 27.545 | toilet       | 59.630 | tv             | 56.141 |\n",
            "| laptop        | 61.076 | mouse        | 61.590 | remote         | 37.545 |\n",
            "| keyboard      | 51.438 | cell phone   | 36.038 | microwave      | 56.228 |\n",
            "| oven          | 33.275 | toaster      | 25.968 | sink           | 37.513 |\n",
            "| refrigerator  | 56.007 | book         | 16.507 | clock          | 53.552 |\n",
            "| vase          | 38.328 | scissors     | 30.742 | teddy bear     | 46.903 |\n",
            "| hair drier    | 6.386  | toothbrush   | 31.066 |                |        |\n",
            "\u001b[32m[04/30 20:35:28 d2.engine.defaults]: \u001b[0mEvaluation results for coco_2017_val in csv format:\n",
            "\u001b[32m[04/30 20:35:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/30 20:35:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 20:35:28 d2.evaluation.testing]: \u001b[0mcopypaste: 42.3890,63.7270,46.0242,26.2481,45.8789,54.2413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "faster_rcnn_ResNeSt_50 - evaluation results for coco_2017_val in csv format:\n",
        "\n",
        "Task\\metrics  | AP | AP50 | AP75 | APs | APm | APl |\n",
        "--------------|----|------|------|-----|-----|-----|\n",
        "**bbox**    | 42.3890 | 63.7270 | 46.0242 | 26.2481 | 45.8789 | 54.2413"
      ],
      "metadata": {
        "id": "rDxApz0-IiRa"
      },
      "id": "rDxApz0-IiRa"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-Detection/faster_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-ObjectDetection/faster_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x-d8f284b6.pth"
      ],
      "metadata": {
        "id": "7ZqaE4aq9Xis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f45d9655-deb9-45e6-a433-12f3d37cf82e"
      },
      "id": "7ZqaE4aq9Xis",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command Line Args: Namespace(config_file='./configs/COCO-Detection/faster_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-ObjectDetection1/faster_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x-d8f284b6.pth'], resume=False)\n",
            "\u001b[32m[04/30 20:35:52 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[04/30 20:35:53 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ----------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "numpy                   1.21.6\n",
            "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.5\n",
            "CUDA compiler           CUDA 11.1\n",
            "detectron2 arch flags   7.5\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.11.0+cu113 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           Yes\n",
            "GPU 0                   Tesla T4 (arch=7.5)\n",
            "Driver version          460.32.03\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.12.0+cu113 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
            "fvcore                  0.1.5.post20220414\n",
            "iopath                  0.1.9\n",
            "cv2                     4.1.2\n",
            "----------------------  ----------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.3\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.2\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "\u001b[32m[04/30 20:35:53 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='./configs/COCO-Detection/faster_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-ObjectDetection1/faster_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x-d8f284b6.pth'], resume=False)\n",
            "\u001b[32m[04/30 20:35:53 detectron2]: \u001b[0mContents of args.config_file=./configs/COCO-Detection/faster_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x.yaml:\n",
            "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186m../ResNest-Base-RCNN-FPN.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mhttps://s3.us-west-1.wasabisys.com/resnest/detectron/resnest101_detectron-486f69a8.pth\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m101\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mFastRCNNConvFCHead\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m123.68\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m116.779\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m103.939\u001b[39m]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m58.393\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.12\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.375\u001b[39m]\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\u001b[38;5;15m  \u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\u001b[38;5;15m    \u001b[39m\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m(640, 800)\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mrange\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mRGB\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\n",
            "\u001b[32m[04/30 20:35:53 detectron2]: \u001b[0mRunning with full config:\n",
            "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRGB\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mpolygon\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrange\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnest_fpn_backbone\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGeneralizedRCNN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.68\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.779\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.939\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m58.393\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.12\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.375\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRPN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVG_DOWN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOTTLENECK_WIDTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEEP_STEM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m101\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_NUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFastRCNNConvFCHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_FED_LOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_SIGMOID_CE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardROIHeads\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./checkpoints/COCO-ObjectDetection1/faster_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x-d8f284b6.pth\n",
            "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./output\n",
            "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR_END\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m90000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m60000\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m80000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\n",
            "\u001b[32m[04/30 20:35:53 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[04/30 20:35:53 d2.utils.env]: \u001b[0mUsing a generated random seed 53836437\n",
            "\u001b[32m[04/30 20:35:58 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(\n",
            "      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output2): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral3): Conv2d(\n",
            "      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output3): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral4): Conv2d(\n",
            "      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output4): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral5): Conv2d(\n",
            "      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output5): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNeSt(\n",
            "      (stem): BasicStem(\n",
            "        (conv1_1): Conv2d(\n",
            "          3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv1_2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv1_3): Conv2d(\n",
            "          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (conv1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (conv4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/30 20:35:58 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from ./checkpoints/COCO-ObjectDetection1/faster_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x-d8f284b6.pth ...\n",
            "\u001b[32m[04/30 20:36:06 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
            "| Names in Model                                  | Names in Checkpoint                                                                                                           | Shapes                                             |\n",
            "|:------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------|\n",
            "| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,128,1,1)               |\n",
            "| backbone.bottom_up.res2.0.conv2.bn0.*           | backbone.bottom_up.res2.0.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.0.conv2.bn1.*           | backbone.bottom_up.res2.0.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.0.conv2.conv.weight     | backbone.bottom_up.res2.0.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.0.conv2.fc1.*           | backbone.bottom_up.res2.0.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.0.conv2.fc2.*           | backbone.bottom_up.res2.0.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,128,1,1)          |\n",
            "| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.1.conv2.bn0.*           | backbone.bottom_up.res2.1.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.1.conv2.bn1.*           | backbone.bottom_up.res2.1.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.1.conv2.conv.weight     | backbone.bottom_up.res2.1.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.1.conv2.fc1.*           | backbone.bottom_up.res2.1.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.1.conv2.fc2.*           | backbone.bottom_up.res2.1.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.2.conv2.bn0.*           | backbone.bottom_up.res2.2.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.2.conv2.bn1.*           | backbone.bottom_up.res2.2.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.2.conv2.conv.weight     | backbone.bottom_up.res2.2.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.2.conv2.fc1.*           | backbone.bottom_up.res2.2.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.2.conv2.fc2.*           | backbone.bottom_up.res2.2.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv2.bn0.*           | backbone.bottom_up.res3.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.0.conv2.bn1.*           | backbone.bottom_up.res3.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.0.conv2.conv.weight     | backbone.bottom_up.res3.0.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.0.conv2.fc1.*           | backbone.bottom_up.res3.0.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.0.conv2.fc2.*           | backbone.bottom_up.res3.0.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv2.bn0.*           | backbone.bottom_up.res3.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.1.conv2.bn1.*           | backbone.bottom_up.res3.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.1.conv2.conv.weight     | backbone.bottom_up.res3.1.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.1.conv2.fc1.*           | backbone.bottom_up.res3.1.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.1.conv2.fc2.*           | backbone.bottom_up.res3.1.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv2.bn0.*           | backbone.bottom_up.res3.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.2.conv2.bn1.*           | backbone.bottom_up.res3.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.2.conv2.conv.weight     | backbone.bottom_up.res3.2.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.2.conv2.fc1.*           | backbone.bottom_up.res3.2.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.2.conv2.fc2.*           | backbone.bottom_up.res3.2.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv2.bn0.*           | backbone.bottom_up.res3.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.3.conv2.bn1.*           | backbone.bottom_up.res3.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.3.conv2.conv.weight     | backbone.bottom_up.res3.3.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.3.conv2.fc1.*           | backbone.bottom_up.res3.3.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.3.conv2.fc2.*           | backbone.bottom_up.res3.3.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv2.bn0.*           | backbone.bottom_up.res4.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.bn1.*           | backbone.bottom_up.res4.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.conv.weight     | backbone.bottom_up.res4.0.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.0.conv2.fc1.*           | backbone.bottom_up.res4.0.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv2.fc2.*           | backbone.bottom_up.res4.0.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.1.conv2.bn0.*           | backbone.bottom_up.res4.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.bn1.*           | backbone.bottom_up.res4.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.conv.weight     | backbone.bottom_up.res4.1.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.1.conv2.fc1.*           | backbone.bottom_up.res4.1.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv2.fc2.*           | backbone.bottom_up.res4.1.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.10.conv1.*              | backbone.bottom_up.res4.10.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.10.conv2.bn0.*          | backbone.bottom_up.res4.10.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.10.conv2.bn1.*          | backbone.bottom_up.res4.10.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.10.conv2.conv.weight    | backbone.bottom_up.res4.10.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.10.conv2.fc1.*          | backbone.bottom_up.res4.10.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.10.conv2.fc2.*          | backbone.bottom_up.res4.10.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.10.conv3.*              | backbone.bottom_up.res4.10.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.11.conv1.*              | backbone.bottom_up.res4.11.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.11.conv2.bn0.*          | backbone.bottom_up.res4.11.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.11.conv2.bn1.*          | backbone.bottom_up.res4.11.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.11.conv2.conv.weight    | backbone.bottom_up.res4.11.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.11.conv2.fc1.*          | backbone.bottom_up.res4.11.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.11.conv2.fc2.*          | backbone.bottom_up.res4.11.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.11.conv3.*              | backbone.bottom_up.res4.11.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.12.conv1.*              | backbone.bottom_up.res4.12.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.12.conv2.bn0.*          | backbone.bottom_up.res4.12.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.12.conv2.bn1.*          | backbone.bottom_up.res4.12.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.12.conv2.conv.weight    | backbone.bottom_up.res4.12.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.12.conv2.fc1.*          | backbone.bottom_up.res4.12.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.12.conv2.fc2.*          | backbone.bottom_up.res4.12.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.12.conv3.*              | backbone.bottom_up.res4.12.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.13.conv1.*              | backbone.bottom_up.res4.13.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.13.conv2.bn0.*          | backbone.bottom_up.res4.13.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.13.conv2.bn1.*          | backbone.bottom_up.res4.13.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.13.conv2.conv.weight    | backbone.bottom_up.res4.13.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.13.conv2.fc1.*          | backbone.bottom_up.res4.13.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.13.conv2.fc2.*          | backbone.bottom_up.res4.13.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.13.conv3.*              | backbone.bottom_up.res4.13.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.14.conv1.*              | backbone.bottom_up.res4.14.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.14.conv2.bn0.*          | backbone.bottom_up.res4.14.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.14.conv2.bn1.*          | backbone.bottom_up.res4.14.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.14.conv2.conv.weight    | backbone.bottom_up.res4.14.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.14.conv2.fc1.*          | backbone.bottom_up.res4.14.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.14.conv2.fc2.*          | backbone.bottom_up.res4.14.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.14.conv3.*              | backbone.bottom_up.res4.14.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.15.conv1.*              | backbone.bottom_up.res4.15.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.15.conv2.bn0.*          | backbone.bottom_up.res4.15.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.15.conv2.bn1.*          | backbone.bottom_up.res4.15.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.15.conv2.conv.weight    | backbone.bottom_up.res4.15.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.15.conv2.fc1.*          | backbone.bottom_up.res4.15.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.15.conv2.fc2.*          | backbone.bottom_up.res4.15.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.15.conv3.*              | backbone.bottom_up.res4.15.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.16.conv1.*              | backbone.bottom_up.res4.16.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.16.conv2.bn0.*          | backbone.bottom_up.res4.16.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.16.conv2.bn1.*          | backbone.bottom_up.res4.16.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.16.conv2.conv.weight    | backbone.bottom_up.res4.16.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.16.conv2.fc1.*          | backbone.bottom_up.res4.16.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.16.conv2.fc2.*          | backbone.bottom_up.res4.16.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.16.conv3.*              | backbone.bottom_up.res4.16.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.17.conv1.*              | backbone.bottom_up.res4.17.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.17.conv2.bn0.*          | backbone.bottom_up.res4.17.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.17.conv2.bn1.*          | backbone.bottom_up.res4.17.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.17.conv2.conv.weight    | backbone.bottom_up.res4.17.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.17.conv2.fc1.*          | backbone.bottom_up.res4.17.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.17.conv2.fc2.*          | backbone.bottom_up.res4.17.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.17.conv3.*              | backbone.bottom_up.res4.17.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.18.conv1.*              | backbone.bottom_up.res4.18.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.18.conv2.bn0.*          | backbone.bottom_up.res4.18.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.18.conv2.bn1.*          | backbone.bottom_up.res4.18.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.18.conv2.conv.weight    | backbone.bottom_up.res4.18.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.18.conv2.fc1.*          | backbone.bottom_up.res4.18.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.18.conv2.fc2.*          | backbone.bottom_up.res4.18.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.18.conv3.*              | backbone.bottom_up.res4.18.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.19.conv1.*              | backbone.bottom_up.res4.19.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.19.conv2.bn0.*          | backbone.bottom_up.res4.19.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.19.conv2.bn1.*          | backbone.bottom_up.res4.19.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.19.conv2.conv.weight    | backbone.bottom_up.res4.19.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.19.conv2.fc1.*          | backbone.bottom_up.res4.19.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.19.conv2.fc2.*          | backbone.bottom_up.res4.19.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.19.conv3.*              | backbone.bottom_up.res4.19.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.2.conv2.bn0.*           | backbone.bottom_up.res4.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.bn1.*           | backbone.bottom_up.res4.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.conv.weight     | backbone.bottom_up.res4.2.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.2.conv2.fc1.*           | backbone.bottom_up.res4.2.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv2.fc2.*           | backbone.bottom_up.res4.2.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.20.conv1.*              | backbone.bottom_up.res4.20.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.20.conv2.bn0.*          | backbone.bottom_up.res4.20.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.20.conv2.bn1.*          | backbone.bottom_up.res4.20.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.20.conv2.conv.weight    | backbone.bottom_up.res4.20.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.20.conv2.fc1.*          | backbone.bottom_up.res4.20.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.20.conv2.fc2.*          | backbone.bottom_up.res4.20.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.20.conv3.*              | backbone.bottom_up.res4.20.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.21.conv1.*              | backbone.bottom_up.res4.21.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.21.conv2.bn0.*          | backbone.bottom_up.res4.21.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.21.conv2.bn1.*          | backbone.bottom_up.res4.21.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.21.conv2.conv.weight    | backbone.bottom_up.res4.21.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.21.conv2.fc1.*          | backbone.bottom_up.res4.21.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.21.conv2.fc2.*          | backbone.bottom_up.res4.21.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.21.conv3.*              | backbone.bottom_up.res4.21.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.22.conv1.*              | backbone.bottom_up.res4.22.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.22.conv2.bn0.*          | backbone.bottom_up.res4.22.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.22.conv2.bn1.*          | backbone.bottom_up.res4.22.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                               | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.22.conv2.conv.weight    | backbone.bottom_up.res4.22.conv2.conv.weight                                                                                  | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.22.conv2.fc1.*          | backbone.bottom_up.res4.22.conv2.fc1.{bias,weight}                                                                            | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.22.conv2.fc2.*          | backbone.bottom_up.res4.22.conv2.fc2.{bias,weight}                                                                            | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.22.conv3.*              | backbone.bottom_up.res4.22.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.3.conv2.bn0.*           | backbone.bottom_up.res4.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.bn1.*           | backbone.bottom_up.res4.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.conv.weight     | backbone.bottom_up.res4.3.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.3.conv2.fc1.*           | backbone.bottom_up.res4.3.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv2.fc2.*           | backbone.bottom_up.res4.3.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.4.conv2.bn0.*           | backbone.bottom_up.res4.4.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.bn1.*           | backbone.bottom_up.res4.4.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.conv.weight     | backbone.bottom_up.res4.4.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.4.conv2.fc1.*           | backbone.bottom_up.res4.4.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv2.fc2.*           | backbone.bottom_up.res4.4.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.5.conv2.bn0.*           | backbone.bottom_up.res4.5.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.bn1.*           | backbone.bottom_up.res4.5.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.conv.weight     | backbone.bottom_up.res4.5.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.5.conv2.fc1.*           | backbone.bottom_up.res4.5.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv2.fc2.*           | backbone.bottom_up.res4.5.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.6.conv1.*               | backbone.bottom_up.res4.6.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.6.conv2.bn0.*           | backbone.bottom_up.res4.6.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.6.conv2.bn1.*           | backbone.bottom_up.res4.6.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.6.conv2.conv.weight     | backbone.bottom_up.res4.6.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.6.conv2.fc1.*           | backbone.bottom_up.res4.6.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.6.conv2.fc2.*           | backbone.bottom_up.res4.6.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.6.conv3.*               | backbone.bottom_up.res4.6.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.7.conv1.*               | backbone.bottom_up.res4.7.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.7.conv2.bn0.*           | backbone.bottom_up.res4.7.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.7.conv2.bn1.*           | backbone.bottom_up.res4.7.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.7.conv2.conv.weight     | backbone.bottom_up.res4.7.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.7.conv2.fc1.*           | backbone.bottom_up.res4.7.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.7.conv2.fc2.*           | backbone.bottom_up.res4.7.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.7.conv3.*               | backbone.bottom_up.res4.7.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.8.conv1.*               | backbone.bottom_up.res4.8.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.8.conv2.bn0.*           | backbone.bottom_up.res4.8.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.8.conv2.bn1.*           | backbone.bottom_up.res4.8.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.8.conv2.conv.weight     | backbone.bottom_up.res4.8.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.8.conv2.fc1.*           | backbone.bottom_up.res4.8.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.8.conv2.fc2.*           | backbone.bottom_up.res4.8.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.8.conv3.*               | backbone.bottom_up.res4.8.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.9.conv1.*               | backbone.bottom_up.res4.9.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.9.conv2.bn0.*           | backbone.bottom_up.res4.9.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.9.conv2.bn1.*           | backbone.bottom_up.res4.9.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.9.conv2.conv.weight     | backbone.bottom_up.res4.9.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.9.conv2.fc1.*           | backbone.bottom_up.res4.9.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.9.conv2.fc2.*           | backbone.bottom_up.res4.9.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.9.conv3.*               | backbone.bottom_up.res4.9.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| backbone.bottom_up.res5.0.conv2.bn0.*           | backbone.bottom_up.res5.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.0.conv2.bn1.*           | backbone.bottom_up.res5.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.0.conv2.conv.weight     | backbone.bottom_up.res5.0.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.0.conv2.fc1.*           | backbone.bottom_up.res5.0.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.0.conv2.fc2.*           | backbone.bottom_up.res5.0.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.1.conv2.bn0.*           | backbone.bottom_up.res5.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.1.conv2.bn1.*           | backbone.bottom_up.res5.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.1.conv2.conv.weight     | backbone.bottom_up.res5.1.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.1.conv2.fc1.*           | backbone.bottom_up.res5.1.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.1.conv2.fc2.*           | backbone.bottom_up.res5.1.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.2.conv2.bn0.*           | backbone.bottom_up.res5.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.2.conv2.bn1.*           | backbone.bottom_up.res5.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.2.conv2.conv.weight     | backbone.bottom_up.res5.2.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.2.conv2.fc1.*           | backbone.bottom_up.res5.2.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.2.conv2.fc2.*           | backbone.bottom_up.res5.2.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.stem.conv1_1.*               | backbone.bottom_up.stem.conv1_1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,3,3,3)                 |\n",
            "| backbone.bottom_up.stem.conv1_2.*               | backbone.bottom_up.stem.conv1_2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |\n",
            "| backbone.bottom_up.stem.conv1_3.*               | backbone.bottom_up.stem.conv1_3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,64,3,3)           |\n",
            "| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,2048,1,1)      |\n",
            "| backbone.fpn_output2.*                          | backbone.fpn_output2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output3.*                          | backbone.fpn_output3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output4.*                          | backbone.fpn_output4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output5.*                          | backbone.fpn_output5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                                                       | (12,) (12,256,1,1)                                 |\n",
            "| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                                                | (256,) (256,256,3,3)                               |\n",
            "| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                                                   | (3,) (3,256,1,1)                                   |\n",
            "| roi_heads.box_head.conv1.*                      | roi_heads.box_head.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.conv2.*                      | roi_heads.box_head.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.conv3.*                      | roi_heads.box_head.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.conv4.*                      | roi_heads.box_head.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}           | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                                          | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                                               | (320,) (320,1024)                                  |\n",
            "| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                                               | (81,) (81,1024)                                    |\n",
            "\u001b[32m[04/30 20:36:07 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json\n",
            "\u001b[32m[04/30 20:36:07 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n",
            "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
            "|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\n",
            "|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\n",
            "|     train     | 190          |    truck     | 414          |     boat      | 424          |\n",
            "| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\n",
            "| parking meter | 60           |    bench     | 411          |     bird      | 427          |\n",
            "|      cat      | 202          |     dog      | 218          |     horse     | 272          |\n",
            "|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\n",
            "|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\n",
            "|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\n",
            "|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\n",
            "|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\n",
            "|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\n",
            "|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\n",
            "|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\n",
            "|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\n",
            "|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\n",
            "|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\n",
            "|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\n",
            "|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\n",
            "|     couch     | 261          | potted plant | 342          |      bed      | 163          |\n",
            "| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\n",
            "|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\n",
            "|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\n",
            "|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\n",
            "| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\n",
            "|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\n",
            "|  hair drier   | 11           |  toothbrush  | 57           |               |              |\n",
            "|     total     | 36335        |              |              |               |              |\u001b[0m\n",
            "\u001b[32m[04/30 20:36:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/30 20:36:07 d2.data.common]: \u001b[0mSerializing 5000 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/30 20:36:07 d2.data.common]: \u001b[0mSerialized dataset takes 19.10 MiB\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[32m[04/30 20:36:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 5000 batches\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m[04/30 20:36:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/5000. Dataloading: 0.0010 s/iter. Inference: 0.2455 s/iter. Eval: 0.0002 s/iter. Total: 0.2467 s/iter. ETA=0:20:30\n",
            "\u001b[32m[04/30 20:36:16 d2.evaluation.evaluator]: \u001b[0mInference done 32/5000. Dataloading: 0.0015 s/iter. Inference: 0.2473 s/iter. Eval: 0.0002 s/iter. Total: 0.2490 s/iter. ETA=0:20:37\n",
            "\u001b[32m[04/30 20:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 53/5000. Dataloading: 0.0015 s/iter. Inference: 0.2476 s/iter. Eval: 0.0002 s/iter. Total: 0.2494 s/iter. ETA=0:20:33\n",
            "\u001b[32m[04/30 20:36:27 d2.evaluation.evaluator]: \u001b[0mInference done 73/5000. Dataloading: 0.0015 s/iter. Inference: 0.2488 s/iter. Eval: 0.0002 s/iter. Total: 0.2507 s/iter. ETA=0:20:35\n",
            "\u001b[32m[04/30 20:36:32 d2.evaluation.evaluator]: \u001b[0mInference done 94/5000. Dataloading: 0.0016 s/iter. Inference: 0.2479 s/iter. Eval: 0.0002 s/iter. Total: 0.2498 s/iter. ETA=0:20:25\n",
            "\u001b[32m[04/30 20:36:37 d2.evaluation.evaluator]: \u001b[0mInference done 115/5000. Dataloading: 0.0016 s/iter. Inference: 0.2474 s/iter. Eval: 0.0002 s/iter. Total: 0.2493 s/iter. ETA=0:20:17\n",
            "\u001b[32m[04/30 20:36:42 d2.evaluation.evaluator]: \u001b[0mInference done 135/5000. Dataloading: 0.0016 s/iter. Inference: 0.2485 s/iter. Eval: 0.0002 s/iter. Total: 0.2504 s/iter. ETA=0:20:18\n",
            "\u001b[32m[04/30 20:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 155/5000. Dataloading: 0.0016 s/iter. Inference: 0.2496 s/iter. Eval: 0.0002 s/iter. Total: 0.2515 s/iter. ETA=0:20:18\n",
            "\u001b[32m[04/30 20:36:52 d2.evaluation.evaluator]: \u001b[0mInference done 175/5000. Dataloading: 0.0017 s/iter. Inference: 0.2496 s/iter. Eval: 0.0002 s/iter. Total: 0.2516 s/iter. ETA=0:20:13\n",
            "\u001b[32m[04/30 20:36:58 d2.evaluation.evaluator]: \u001b[0mInference done 195/5000. Dataloading: 0.0017 s/iter. Inference: 0.2500 s/iter. Eval: 0.0002 s/iter. Total: 0.2520 s/iter. ETA=0:20:10\n",
            "\u001b[32m[04/30 20:37:03 d2.evaluation.evaluator]: \u001b[0mInference done 215/5000. Dataloading: 0.0017 s/iter. Inference: 0.2502 s/iter. Eval: 0.0002 s/iter. Total: 0.2523 s/iter. ETA=0:20:07\n",
            "\u001b[32m[04/30 20:37:08 d2.evaluation.evaluator]: \u001b[0mInference done 235/5000. Dataloading: 0.0018 s/iter. Inference: 0.2506 s/iter. Eval: 0.0002 s/iter. Total: 0.2527 s/iter. ETA=0:20:03\n",
            "\u001b[32m[04/30 20:37:13 d2.evaluation.evaluator]: \u001b[0mInference done 255/5000. Dataloading: 0.0018 s/iter. Inference: 0.2510 s/iter. Eval: 0.0002 s/iter. Total: 0.2530 s/iter. ETA=0:20:00\n",
            "\u001b[32m[04/30 20:37:18 d2.evaluation.evaluator]: \u001b[0mInference done 275/5000. Dataloading: 0.0018 s/iter. Inference: 0.2510 s/iter. Eval: 0.0002 s/iter. Total: 0.2531 s/iter. ETA=0:19:55\n",
            "\u001b[32m[04/30 20:37:23 d2.evaluation.evaluator]: \u001b[0mInference done 295/5000. Dataloading: 0.0018 s/iter. Inference: 0.2513 s/iter. Eval: 0.0002 s/iter. Total: 0.2533 s/iter. ETA=0:19:51\n",
            "\u001b[32m[04/30 20:37:28 d2.evaluation.evaluator]: \u001b[0mInference done 315/5000. Dataloading: 0.0018 s/iter. Inference: 0.2516 s/iter. Eval: 0.0002 s/iter. Total: 0.2537 s/iter. ETA=0:19:48\n",
            "\u001b[32m[04/30 20:37:33 d2.evaluation.evaluator]: \u001b[0mInference done 335/5000. Dataloading: 0.0018 s/iter. Inference: 0.2519 s/iter. Eval: 0.0002 s/iter. Total: 0.2540 s/iter. ETA=0:19:44\n",
            "\u001b[32m[04/30 20:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 354/5000. Dataloading: 0.0018 s/iter. Inference: 0.2525 s/iter. Eval: 0.0002 s/iter. Total: 0.2546 s/iter. ETA=0:19:42\n",
            "\u001b[32m[04/30 20:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 374/5000. Dataloading: 0.0018 s/iter. Inference: 0.2529 s/iter. Eval: 0.0002 s/iter. Total: 0.2550 s/iter. ETA=0:19:39\n",
            "\u001b[32m[04/30 20:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 394/5000. Dataloading: 0.0018 s/iter. Inference: 0.2527 s/iter. Eval: 0.0002 s/iter. Total: 0.2548 s/iter. ETA=0:19:33\n",
            "\u001b[32m[04/30 20:37:54 d2.evaluation.evaluator]: \u001b[0mInference done 414/5000. Dataloading: 0.0018 s/iter. Inference: 0.2529 s/iter. Eval: 0.0002 s/iter. Total: 0.2550 s/iter. ETA=0:19:29\n",
            "\u001b[32m[04/30 20:37:59 d2.evaluation.evaluator]: \u001b[0mInference done 434/5000. Dataloading: 0.0018 s/iter. Inference: 0.2531 s/iter. Eval: 0.0002 s/iter. Total: 0.2552 s/iter. ETA=0:19:25\n",
            "\u001b[32m[04/30 20:38:04 d2.evaluation.evaluator]: \u001b[0mInference done 454/5000. Dataloading: 0.0018 s/iter. Inference: 0.2532 s/iter. Eval: 0.0002 s/iter. Total: 0.2553 s/iter. ETA=0:19:20\n",
            "\u001b[32m[04/30 20:38:09 d2.evaluation.evaluator]: \u001b[0mInference done 473/5000. Dataloading: 0.0018 s/iter. Inference: 0.2537 s/iter. Eval: 0.0002 s/iter. Total: 0.2558 s/iter. ETA=0:19:17\n",
            "\u001b[32m[04/30 20:38:14 d2.evaluation.evaluator]: \u001b[0mInference done 492/5000. Dataloading: 0.0018 s/iter. Inference: 0.2540 s/iter. Eval: 0.0002 s/iter. Total: 0.2561 s/iter. ETA=0:19:14\n",
            "\u001b[32m[04/30 20:38:19 d2.evaluation.evaluator]: \u001b[0mInference done 512/5000. Dataloading: 0.0018 s/iter. Inference: 0.2539 s/iter. Eval: 0.0002 s/iter. Total: 0.2560 s/iter. ETA=0:19:08\n",
            "\u001b[32m[04/30 20:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 532/5000. Dataloading: 0.0018 s/iter. Inference: 0.2541 s/iter. Eval: 0.0002 s/iter. Total: 0.2562 s/iter. ETA=0:19:04\n",
            "\u001b[32m[04/30 20:38:30 d2.evaluation.evaluator]: \u001b[0mInference done 552/5000. Dataloading: 0.0019 s/iter. Inference: 0.2542 s/iter. Eval: 0.0002 s/iter. Total: 0.2563 s/iter. ETA=0:19:00\n",
            "\u001b[32m[04/30 20:38:35 d2.evaluation.evaluator]: \u001b[0mInference done 572/5000. Dataloading: 0.0019 s/iter. Inference: 0.2544 s/iter. Eval: 0.0002 s/iter. Total: 0.2565 s/iter. ETA=0:18:55\n",
            "\u001b[32m[04/30 20:38:40 d2.evaluation.evaluator]: \u001b[0mInference done 592/5000. Dataloading: 0.0019 s/iter. Inference: 0.2544 s/iter. Eval: 0.0002 s/iter. Total: 0.2565 s/iter. ETA=0:18:50\n",
            "\u001b[32m[04/30 20:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 611/5000. Dataloading: 0.0019 s/iter. Inference: 0.2548 s/iter. Eval: 0.0002 s/iter. Total: 0.2569 s/iter. ETA=0:18:47\n",
            "\u001b[32m[04/30 20:38:50 d2.evaluation.evaluator]: \u001b[0mInference done 630/5000. Dataloading: 0.0019 s/iter. Inference: 0.2550 s/iter. Eval: 0.0002 s/iter. Total: 0.2572 s/iter. ETA=0:18:43\n",
            "\u001b[32m[04/30 20:38:56 d2.evaluation.evaluator]: \u001b[0mInference done 650/5000. Dataloading: 0.0019 s/iter. Inference: 0.2551 s/iter. Eval: 0.0002 s/iter. Total: 0.2572 s/iter. ETA=0:18:38\n",
            "\u001b[32m[04/30 20:39:01 d2.evaluation.evaluator]: \u001b[0mInference done 670/5000. Dataloading: 0.0019 s/iter. Inference: 0.2553 s/iter. Eval: 0.0002 s/iter. Total: 0.2574 s/iter. ETA=0:18:34\n",
            "\u001b[32m[04/30 20:39:06 d2.evaluation.evaluator]: \u001b[0mInference done 689/5000. Dataloading: 0.0019 s/iter. Inference: 0.2555 s/iter. Eval: 0.0002 s/iter. Total: 0.2577 s/iter. ETA=0:18:30\n",
            "\u001b[32m[04/30 20:39:11 d2.evaluation.evaluator]: \u001b[0mInference done 708/5000. Dataloading: 0.0019 s/iter. Inference: 0.2557 s/iter. Eval: 0.0002 s/iter. Total: 0.2578 s/iter. ETA=0:18:26\n",
            "\u001b[32m[04/30 20:39:16 d2.evaluation.evaluator]: \u001b[0mInference done 727/5000. Dataloading: 0.0019 s/iter. Inference: 0.2558 s/iter. Eval: 0.0002 s/iter. Total: 0.2580 s/iter. ETA=0:18:22\n",
            "\u001b[32m[04/30 20:39:21 d2.evaluation.evaluator]: \u001b[0mInference done 747/5000. Dataloading: 0.0019 s/iter. Inference: 0.2559 s/iter. Eval: 0.0002 s/iter. Total: 0.2581 s/iter. ETA=0:18:17\n",
            "\u001b[32m[04/30 20:39:26 d2.evaluation.evaluator]: \u001b[0mInference done 767/5000. Dataloading: 0.0019 s/iter. Inference: 0.2560 s/iter. Eval: 0.0002 s/iter. Total: 0.2582 s/iter. ETA=0:18:13\n",
            "\u001b[32m[04/30 20:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 786/5000. Dataloading: 0.0019 s/iter. Inference: 0.2563 s/iter. Eval: 0.0002 s/iter. Total: 0.2584 s/iter. ETA=0:18:09\n",
            "\u001b[32m[04/30 20:39:37 d2.evaluation.evaluator]: \u001b[0mInference done 805/5000. Dataloading: 0.0019 s/iter. Inference: 0.2564 s/iter. Eval: 0.0002 s/iter. Total: 0.2586 s/iter. ETA=0:18:04\n",
            "\u001b[32m[04/30 20:39:42 d2.evaluation.evaluator]: \u001b[0mInference done 825/5000. Dataloading: 0.0019 s/iter. Inference: 0.2564 s/iter. Eval: 0.0002 s/iter. Total: 0.2586 s/iter. ETA=0:17:59\n",
            "\u001b[32m[04/30 20:39:47 d2.evaluation.evaluator]: \u001b[0mInference done 844/5000. Dataloading: 0.0019 s/iter. Inference: 0.2566 s/iter. Eval: 0.0002 s/iter. Total: 0.2587 s/iter. ETA=0:17:55\n",
            "\u001b[32m[04/30 20:39:52 d2.evaluation.evaluator]: \u001b[0mInference done 863/5000. Dataloading: 0.0019 s/iter. Inference: 0.2567 s/iter. Eval: 0.0002 s/iter. Total: 0.2588 s/iter. ETA=0:17:50\n",
            "\u001b[32m[04/30 20:39:57 d2.evaluation.evaluator]: \u001b[0mInference done 883/5000. Dataloading: 0.0019 s/iter. Inference: 0.2568 s/iter. Eval: 0.0002 s/iter. Total: 0.2589 s/iter. ETA=0:17:46\n",
            "\u001b[32m[04/30 20:40:02 d2.evaluation.evaluator]: \u001b[0mInference done 903/5000. Dataloading: 0.0019 s/iter. Inference: 0.2568 s/iter. Eval: 0.0002 s/iter. Total: 0.2590 s/iter. ETA=0:17:41\n",
            "\u001b[32m[04/30 20:40:07 d2.evaluation.evaluator]: \u001b[0mInference done 923/5000. Dataloading: 0.0019 s/iter. Inference: 0.2568 s/iter. Eval: 0.0002 s/iter. Total: 0.2590 s/iter. ETA=0:17:35\n",
            "\u001b[32m[04/30 20:40:12 d2.evaluation.evaluator]: \u001b[0mInference done 942/5000. Dataloading: 0.0019 s/iter. Inference: 0.2569 s/iter. Eval: 0.0002 s/iter. Total: 0.2591 s/iter. ETA=0:17:31\n",
            "\u001b[32m[04/30 20:40:18 d2.evaluation.evaluator]: \u001b[0mInference done 961/5000. Dataloading: 0.0019 s/iter. Inference: 0.2571 s/iter. Eval: 0.0002 s/iter. Total: 0.2592 s/iter. ETA=0:17:27\n",
            "\u001b[32m[04/30 20:40:23 d2.evaluation.evaluator]: \u001b[0mInference done 981/5000. Dataloading: 0.0019 s/iter. Inference: 0.2571 s/iter. Eval: 0.0002 s/iter. Total: 0.2593 s/iter. ETA=0:17:21\n",
            "\u001b[32m[04/30 20:40:28 d2.evaluation.evaluator]: \u001b[0mInference done 1001/5000. Dataloading: 0.0019 s/iter. Inference: 0.2572 s/iter. Eval: 0.0002 s/iter. Total: 0.2593 s/iter. ETA=0:17:17\n",
            "\u001b[32m[04/30 20:40:33 d2.evaluation.evaluator]: \u001b[0mInference done 1021/5000. Dataloading: 0.0019 s/iter. Inference: 0.2571 s/iter. Eval: 0.0002 s/iter. Total: 0.2593 s/iter. ETA=0:17:11\n",
            "\u001b[32m[04/30 20:40:38 d2.evaluation.evaluator]: \u001b[0mInference done 1041/5000. Dataloading: 0.0019 s/iter. Inference: 0.2572 s/iter. Eval: 0.0002 s/iter. Total: 0.2593 s/iter. ETA=0:17:06\n",
            "\u001b[32m[04/30 20:40:43 d2.evaluation.evaluator]: \u001b[0mInference done 1060/5000. Dataloading: 0.0019 s/iter. Inference: 0.2573 s/iter. Eval: 0.0002 s/iter. Total: 0.2595 s/iter. ETA=0:17:02\n",
            "\u001b[32m[04/30 20:40:48 d2.evaluation.evaluator]: \u001b[0mInference done 1079/5000. Dataloading: 0.0019 s/iter. Inference: 0.2574 s/iter. Eval: 0.0002 s/iter. Total: 0.2596 s/iter. ETA=0:16:57\n",
            "\u001b[32m[04/30 20:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 1099/5000. Dataloading: 0.0019 s/iter. Inference: 0.2575 s/iter. Eval: 0.0002 s/iter. Total: 0.2596 s/iter. ETA=0:16:52\n",
            "\u001b[32m[04/30 20:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 1118/5000. Dataloading: 0.0019 s/iter. Inference: 0.2576 s/iter. Eval: 0.0002 s/iter. Total: 0.2598 s/iter. ETA=0:16:48\n",
            "\u001b[32m[04/30 20:41:04 d2.evaluation.evaluator]: \u001b[0mInference done 1137/5000. Dataloading: 0.0019 s/iter. Inference: 0.2578 s/iter. Eval: 0.0002 s/iter. Total: 0.2599 s/iter. ETA=0:16:44\n",
            "\u001b[32m[04/30 20:41:09 d2.evaluation.evaluator]: \u001b[0mInference done 1157/5000. Dataloading: 0.0019 s/iter. Inference: 0.2578 s/iter. Eval: 0.0002 s/iter. Total: 0.2599 s/iter. ETA=0:16:38\n",
            "\u001b[32m[04/30 20:41:14 d2.evaluation.evaluator]: \u001b[0mInference done 1176/5000. Dataloading: 0.0019 s/iter. Inference: 0.2580 s/iter. Eval: 0.0002 s/iter. Total: 0.2601 s/iter. ETA=0:16:34\n",
            "\u001b[32m[04/30 20:41:20 d2.evaluation.evaluator]: \u001b[0mInference done 1196/5000. Dataloading: 0.0019 s/iter. Inference: 0.2580 s/iter. Eval: 0.0002 s/iter. Total: 0.2602 s/iter. ETA=0:16:29\n",
            "\u001b[32m[04/30 20:41:25 d2.evaluation.evaluator]: \u001b[0mInference done 1216/5000. Dataloading: 0.0019 s/iter. Inference: 0.2581 s/iter. Eval: 0.0002 s/iter. Total: 0.2602 s/iter. ETA=0:16:24\n",
            "\u001b[32m[04/30 20:41:30 d2.evaluation.evaluator]: \u001b[0mInference done 1235/5000. Dataloading: 0.0019 s/iter. Inference: 0.2581 s/iter. Eval: 0.0002 s/iter. Total: 0.2603 s/iter. ETA=0:16:20\n",
            "\u001b[32m[04/30 20:41:35 d2.evaluation.evaluator]: \u001b[0mInference done 1254/5000. Dataloading: 0.0019 s/iter. Inference: 0.2582 s/iter. Eval: 0.0002 s/iter. Total: 0.2603 s/iter. ETA=0:16:15\n",
            "\u001b[32m[04/30 20:41:40 d2.evaluation.evaluator]: \u001b[0mInference done 1274/5000. Dataloading: 0.0019 s/iter. Inference: 0.2582 s/iter. Eval: 0.0002 s/iter. Total: 0.2603 s/iter. ETA=0:16:10\n",
            "\u001b[32m[04/30 20:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 1293/5000. Dataloading: 0.0019 s/iter. Inference: 0.2583 s/iter. Eval: 0.0002 s/iter. Total: 0.2604 s/iter. ETA=0:16:05\n",
            "\u001b[32m[04/30 20:41:50 d2.evaluation.evaluator]: \u001b[0mInference done 1313/5000. Dataloading: 0.0019 s/iter. Inference: 0.2583 s/iter. Eval: 0.0002 s/iter. Total: 0.2604 s/iter. ETA=0:16:00\n",
            "\u001b[32m[04/30 20:41:56 d2.evaluation.evaluator]: \u001b[0mInference done 1333/5000. Dataloading: 0.0019 s/iter. Inference: 0.2583 s/iter. Eval: 0.0002 s/iter. Total: 0.2604 s/iter. ETA=0:15:55\n",
            "\u001b[32m[04/30 20:42:01 d2.evaluation.evaluator]: \u001b[0mInference done 1353/5000. Dataloading: 0.0019 s/iter. Inference: 0.2583 s/iter. Eval: 0.0002 s/iter. Total: 0.2605 s/iter. ETA=0:15:49\n",
            "\u001b[32m[04/30 20:42:06 d2.evaluation.evaluator]: \u001b[0mInference done 1372/5000. Dataloading: 0.0019 s/iter. Inference: 0.2584 s/iter. Eval: 0.0002 s/iter. Total: 0.2605 s/iter. ETA=0:15:45\n",
            "\u001b[32m[04/30 20:42:11 d2.evaluation.evaluator]: \u001b[0mInference done 1392/5000. Dataloading: 0.0019 s/iter. Inference: 0.2583 s/iter. Eval: 0.0002 s/iter. Total: 0.2605 s/iter. ETA=0:15:39\n",
            "\u001b[32m[04/30 20:42:16 d2.evaluation.evaluator]: \u001b[0mInference done 1412/5000. Dataloading: 0.0019 s/iter. Inference: 0.2584 s/iter. Eval: 0.0002 s/iter. Total: 0.2605 s/iter. ETA=0:15:34\n",
            "\u001b[32m[04/30 20:42:21 d2.evaluation.evaluator]: \u001b[0mInference done 1432/5000. Dataloading: 0.0019 s/iter. Inference: 0.2584 s/iter. Eval: 0.0002 s/iter. Total: 0.2605 s/iter. ETA=0:15:29\n",
            "\u001b[32m[04/30 20:42:27 d2.evaluation.evaluator]: \u001b[0mInference done 1451/5000. Dataloading: 0.0019 s/iter. Inference: 0.2585 s/iter. Eval: 0.0002 s/iter. Total: 0.2606 s/iter. ETA=0:15:24\n",
            "\u001b[32m[04/30 20:42:32 d2.evaluation.evaluator]: \u001b[0mInference done 1471/5000. Dataloading: 0.0019 s/iter. Inference: 0.2584 s/iter. Eval: 0.0002 s/iter. Total: 0.2605 s/iter. ETA=0:15:19\n",
            "\u001b[32m[04/30 20:42:37 d2.evaluation.evaluator]: \u001b[0mInference done 1490/5000. Dataloading: 0.0019 s/iter. Inference: 0.2584 s/iter. Eval: 0.0002 s/iter. Total: 0.2606 s/iter. ETA=0:15:14\n",
            "\u001b[32m[04/30 20:42:42 d2.evaluation.evaluator]: \u001b[0mInference done 1510/5000. Dataloading: 0.0019 s/iter. Inference: 0.2584 s/iter. Eval: 0.0002 s/iter. Total: 0.2605 s/iter. ETA=0:15:09\n",
            "\u001b[32m[04/30 20:42:47 d2.evaluation.evaluator]: \u001b[0mInference done 1530/5000. Dataloading: 0.0019 s/iter. Inference: 0.2584 s/iter. Eval: 0.0002 s/iter. Total: 0.2605 s/iter. ETA=0:15:04\n",
            "\u001b[32m[04/30 20:42:52 d2.evaluation.evaluator]: \u001b[0mInference done 1549/5000. Dataloading: 0.0019 s/iter. Inference: 0.2584 s/iter. Eval: 0.0002 s/iter. Total: 0.2606 s/iter. ETA=0:14:59\n",
            "\u001b[32m[04/30 20:42:57 d2.evaluation.evaluator]: \u001b[0mInference done 1568/5000. Dataloading: 0.0019 s/iter. Inference: 0.2585 s/iter. Eval: 0.0002 s/iter. Total: 0.2607 s/iter. ETA=0:14:54\n",
            "\u001b[32m[04/30 20:43:02 d2.evaluation.evaluator]: \u001b[0mInference done 1587/5000. Dataloading: 0.0019 s/iter. Inference: 0.2586 s/iter. Eval: 0.0002 s/iter. Total: 0.2607 s/iter. ETA=0:14:49\n",
            "\u001b[32m[04/30 20:43:07 d2.evaluation.evaluator]: \u001b[0mInference done 1606/5000. Dataloading: 0.0019 s/iter. Inference: 0.2586 s/iter. Eval: 0.0002 s/iter. Total: 0.2608 s/iter. ETA=0:14:45\n",
            "\u001b[32m[04/30 20:43:12 d2.evaluation.evaluator]: \u001b[0mInference done 1626/5000. Dataloading: 0.0019 s/iter. Inference: 0.2586 s/iter. Eval: 0.0002 s/iter. Total: 0.2608 s/iter. ETA=0:14:39\n",
            "\u001b[32m[04/30 20:43:18 d2.evaluation.evaluator]: \u001b[0mInference done 1646/5000. Dataloading: 0.0019 s/iter. Inference: 0.2586 s/iter. Eval: 0.0002 s/iter. Total: 0.2608 s/iter. ETA=0:14:34\n",
            "\u001b[32m[04/30 20:43:23 d2.evaluation.evaluator]: \u001b[0mInference done 1666/5000. Dataloading: 0.0019 s/iter. Inference: 0.2586 s/iter. Eval: 0.0002 s/iter. Total: 0.2608 s/iter. ETA=0:14:29\n",
            "\u001b[32m[04/30 20:43:28 d2.evaluation.evaluator]: \u001b[0mInference done 1685/5000. Dataloading: 0.0019 s/iter. Inference: 0.2587 s/iter. Eval: 0.0002 s/iter. Total: 0.2609 s/iter. ETA=0:14:24\n",
            "\u001b[32m[04/30 20:43:33 d2.evaluation.evaluator]: \u001b[0mInference done 1704/5000. Dataloading: 0.0019 s/iter. Inference: 0.2587 s/iter. Eval: 0.0002 s/iter. Total: 0.2609 s/iter. ETA=0:14:20\n",
            "\u001b[32m[04/30 20:43:38 d2.evaluation.evaluator]: \u001b[0mInference done 1724/5000. Dataloading: 0.0019 s/iter. Inference: 0.2588 s/iter. Eval: 0.0002 s/iter. Total: 0.2609 s/iter. ETA=0:14:14\n",
            "\u001b[32m[04/30 20:43:43 d2.evaluation.evaluator]: \u001b[0mInference done 1743/5000. Dataloading: 0.0019 s/iter. Inference: 0.2588 s/iter. Eval: 0.0002 s/iter. Total: 0.2610 s/iter. ETA=0:14:10\n",
            "\u001b[32m[04/30 20:43:48 d2.evaluation.evaluator]: \u001b[0mInference done 1762/5000. Dataloading: 0.0019 s/iter. Inference: 0.2589 s/iter. Eval: 0.0002 s/iter. Total: 0.2611 s/iter. ETA=0:14:05\n",
            "\u001b[32m[04/30 20:43:53 d2.evaluation.evaluator]: \u001b[0mInference done 1782/5000. Dataloading: 0.0019 s/iter. Inference: 0.2588 s/iter. Eval: 0.0002 s/iter. Total: 0.2610 s/iter. ETA=0:13:59\n",
            "\u001b[32m[04/30 20:43:59 d2.evaluation.evaluator]: \u001b[0mInference done 1802/5000. Dataloading: 0.0019 s/iter. Inference: 0.2588 s/iter. Eval: 0.0002 s/iter. Total: 0.2610 s/iter. ETA=0:13:54\n",
            "\u001b[32m[04/30 20:44:04 d2.evaluation.evaluator]: \u001b[0mInference done 1821/5000. Dataloading: 0.0019 s/iter. Inference: 0.2589 s/iter. Eval: 0.0002 s/iter. Total: 0.2611 s/iter. ETA=0:13:49\n",
            "\u001b[32m[04/30 20:44:09 d2.evaluation.evaluator]: \u001b[0mInference done 1841/5000. Dataloading: 0.0019 s/iter. Inference: 0.2589 s/iter. Eval: 0.0002 s/iter. Total: 0.2611 s/iter. ETA=0:13:44\n",
            "\u001b[32m[04/30 20:44:14 d2.evaluation.evaluator]: \u001b[0mInference done 1861/5000. Dataloading: 0.0019 s/iter. Inference: 0.2588 s/iter. Eval: 0.0002 s/iter. Total: 0.2610 s/iter. ETA=0:13:39\n",
            "\u001b[32m[04/30 20:44:19 d2.evaluation.evaluator]: \u001b[0mInference done 1880/5000. Dataloading: 0.0019 s/iter. Inference: 0.2589 s/iter. Eval: 0.0002 s/iter. Total: 0.2611 s/iter. ETA=0:13:34\n",
            "\u001b[32m[04/30 20:44:24 d2.evaluation.evaluator]: \u001b[0mInference done 1899/5000. Dataloading: 0.0019 s/iter. Inference: 0.2590 s/iter. Eval: 0.0002 s/iter. Total: 0.2612 s/iter. ETA=0:13:29\n",
            "\u001b[32m[04/30 20:44:30 d2.evaluation.evaluator]: \u001b[0mInference done 1919/5000. Dataloading: 0.0019 s/iter. Inference: 0.2590 s/iter. Eval: 0.0002 s/iter. Total: 0.2612 s/iter. ETA=0:13:24\n",
            "\u001b[32m[04/30 20:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 1939/5000. Dataloading: 0.0019 s/iter. Inference: 0.2590 s/iter. Eval: 0.0002 s/iter. Total: 0.2612 s/iter. ETA=0:13:19\n",
            "\u001b[32m[04/30 20:44:40 d2.evaluation.evaluator]: \u001b[0mInference done 1958/5000. Dataloading: 0.0019 s/iter. Inference: 0.2590 s/iter. Eval: 0.0002 s/iter. Total: 0.2613 s/iter. ETA=0:13:14\n",
            "\u001b[32m[04/30 20:44:45 d2.evaluation.evaluator]: \u001b[0mInference done 1978/5000. Dataloading: 0.0019 s/iter. Inference: 0.2590 s/iter. Eval: 0.0002 s/iter. Total: 0.2613 s/iter. ETA=0:13:09\n",
            "\u001b[32m[04/30 20:44:50 d2.evaluation.evaluator]: \u001b[0mInference done 1997/5000. Dataloading: 0.0019 s/iter. Inference: 0.2590 s/iter. Eval: 0.0002 s/iter. Total: 0.2614 s/iter. ETA=0:13:04\n",
            "\u001b[32m[04/30 20:44:55 d2.evaluation.evaluator]: \u001b[0mInference done 2016/5000. Dataloading: 0.0019 s/iter. Inference: 0.2591 s/iter. Eval: 0.0002 s/iter. Total: 0.2614 s/iter. ETA=0:13:00\n",
            "\u001b[32m[04/30 20:45:01 d2.evaluation.evaluator]: \u001b[0mInference done 2036/5000. Dataloading: 0.0019 s/iter. Inference: 0.2591 s/iter. Eval: 0.0002 s/iter. Total: 0.2614 s/iter. ETA=0:12:54\n",
            "\u001b[32m[04/30 20:45:06 d2.evaluation.evaluator]: \u001b[0mInference done 2056/5000. Dataloading: 0.0019 s/iter. Inference: 0.2590 s/iter. Eval: 0.0002 s/iter. Total: 0.2614 s/iter. ETA=0:12:49\n",
            "\u001b[32m[04/30 20:45:11 d2.evaluation.evaluator]: \u001b[0mInference done 2075/5000. Dataloading: 0.0019 s/iter. Inference: 0.2591 s/iter. Eval: 0.0002 s/iter. Total: 0.2614 s/iter. ETA=0:12:44\n",
            "\u001b[32m[04/30 20:45:16 d2.evaluation.evaluator]: \u001b[0mInference done 2095/5000. Dataloading: 0.0019 s/iter. Inference: 0.2591 s/iter. Eval: 0.0002 s/iter. Total: 0.2614 s/iter. ETA=0:12:39\n",
            "\u001b[32m[04/30 20:45:21 d2.evaluation.evaluator]: \u001b[0mInference done 2115/5000. Dataloading: 0.0019 s/iter. Inference: 0.2591 s/iter. Eval: 0.0002 s/iter. Total: 0.2614 s/iter. ETA=0:12:34\n",
            "\u001b[32m[04/30 20:45:26 d2.evaluation.evaluator]: \u001b[0mInference done 2134/5000. Dataloading: 0.0019 s/iter. Inference: 0.2591 s/iter. Eval: 0.0002 s/iter. Total: 0.2615 s/iter. ETA=0:12:29\n",
            "\u001b[32m[04/30 20:45:31 d2.evaluation.evaluator]: \u001b[0mInference done 2154/5000. Dataloading: 0.0019 s/iter. Inference: 0.2591 s/iter. Eval: 0.0002 s/iter. Total: 0.2614 s/iter. ETA=0:12:24\n",
            "\u001b[32m[04/30 20:45:37 d2.evaluation.evaluator]: \u001b[0mInference done 2174/5000. Dataloading: 0.0019 s/iter. Inference: 0.2591 s/iter. Eval: 0.0002 s/iter. Total: 0.2614 s/iter. ETA=0:12:18\n",
            "\u001b[32m[04/30 20:45:42 d2.evaluation.evaluator]: \u001b[0mInference done 2194/5000. Dataloading: 0.0019 s/iter. Inference: 0.2591 s/iter. Eval: 0.0002 s/iter. Total: 0.2614 s/iter. ETA=0:12:13\n",
            "\u001b[32m[04/30 20:45:47 d2.evaluation.evaluator]: \u001b[0mInference done 2214/5000. Dataloading: 0.0019 s/iter. Inference: 0.2591 s/iter. Eval: 0.0002 s/iter. Total: 0.2614 s/iter. ETA=0:12:08\n",
            "\u001b[32m[04/30 20:45:52 d2.evaluation.evaluator]: \u001b[0mInference done 2233/5000. Dataloading: 0.0019 s/iter. Inference: 0.2592 s/iter. Eval: 0.0002 s/iter. Total: 0.2615 s/iter. ETA=0:12:03\n",
            "\u001b[32m[04/30 20:45:57 d2.evaluation.evaluator]: \u001b[0mInference done 2252/5000. Dataloading: 0.0019 s/iter. Inference: 0.2592 s/iter. Eval: 0.0002 s/iter. Total: 0.2616 s/iter. ETA=0:11:58\n",
            "\u001b[32m[04/30 20:46:02 d2.evaluation.evaluator]: \u001b[0mInference done 2271/5000. Dataloading: 0.0019 s/iter. Inference: 0.2593 s/iter. Eval: 0.0002 s/iter. Total: 0.2616 s/iter. ETA=0:11:53\n",
            "\u001b[32m[04/30 20:46:08 d2.evaluation.evaluator]: \u001b[0mInference done 2290/5000. Dataloading: 0.0019 s/iter. Inference: 0.2593 s/iter. Eval: 0.0002 s/iter. Total: 0.2616 s/iter. ETA=0:11:49\n",
            "\u001b[32m[04/30 20:46:13 d2.evaluation.evaluator]: \u001b[0mInference done 2310/5000. Dataloading: 0.0019 s/iter. Inference: 0.2593 s/iter. Eval: 0.0002 s/iter. Total: 0.2616 s/iter. ETA=0:11:43\n",
            "\u001b[32m[04/30 20:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 2329/5000. Dataloading: 0.0019 s/iter. Inference: 0.2593 s/iter. Eval: 0.0002 s/iter. Total: 0.2617 s/iter. ETA=0:11:38\n",
            "\u001b[32m[04/30 20:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 2348/5000. Dataloading: 0.0019 s/iter. Inference: 0.2594 s/iter. Eval: 0.0002 s/iter. Total: 0.2617 s/iter. ETA=0:11:34\n",
            "\u001b[32m[04/30 20:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 2368/5000. Dataloading: 0.0019 s/iter. Inference: 0.2594 s/iter. Eval: 0.0002 s/iter. Total: 0.2617 s/iter. ETA=0:11:28\n",
            "\u001b[32m[04/30 20:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 2388/5000. Dataloading: 0.0019 s/iter. Inference: 0.2594 s/iter. Eval: 0.0002 s/iter. Total: 0.2617 s/iter. ETA=0:11:23\n",
            "\u001b[32m[04/30 20:46:39 d2.evaluation.evaluator]: \u001b[0mInference done 2407/5000. Dataloading: 0.0019 s/iter. Inference: 0.2595 s/iter. Eval: 0.0002 s/iter. Total: 0.2618 s/iter. ETA=0:11:18\n",
            "\u001b[32m[04/30 20:46:44 d2.evaluation.evaluator]: \u001b[0mInference done 2426/5000. Dataloading: 0.0019 s/iter. Inference: 0.2595 s/iter. Eval: 0.0002 s/iter. Total: 0.2619 s/iter. ETA=0:11:14\n",
            "\u001b[32m[04/30 20:46:49 d2.evaluation.evaluator]: \u001b[0mInference done 2445/5000. Dataloading: 0.0019 s/iter. Inference: 0.2596 s/iter. Eval: 0.0002 s/iter. Total: 0.2619 s/iter. ETA=0:11:09\n",
            "\u001b[32m[04/30 20:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 2464/5000. Dataloading: 0.0019 s/iter. Inference: 0.2596 s/iter. Eval: 0.0002 s/iter. Total: 0.2619 s/iter. ETA=0:11:04\n",
            "\u001b[32m[04/30 20:46:59 d2.evaluation.evaluator]: \u001b[0mInference done 2484/5000. Dataloading: 0.0019 s/iter. Inference: 0.2596 s/iter. Eval: 0.0002 s/iter. Total: 0.2619 s/iter. ETA=0:10:58\n",
            "\u001b[32m[04/30 20:47:04 d2.evaluation.evaluator]: \u001b[0mInference done 2503/5000. Dataloading: 0.0019 s/iter. Inference: 0.2596 s/iter. Eval: 0.0002 s/iter. Total: 0.2619 s/iter. ETA=0:10:53\n",
            "\u001b[32m[04/30 20:47:09 d2.evaluation.evaluator]: \u001b[0mInference done 2523/5000. Dataloading: 0.0019 s/iter. Inference: 0.2596 s/iter. Eval: 0.0002 s/iter. Total: 0.2619 s/iter. ETA=0:10:48\n",
            "\u001b[32m[04/30 20:47:14 d2.evaluation.evaluator]: \u001b[0mInference done 2539/5000. Dataloading: 0.0019 s/iter. Inference: 0.2596 s/iter. Eval: 0.0002 s/iter. Total: 0.2622 s/iter. ETA=0:10:45\n",
            "\u001b[32m[04/30 20:47:19 d2.evaluation.evaluator]: \u001b[0mInference done 2558/5000. Dataloading: 0.0019 s/iter. Inference: 0.2596 s/iter. Eval: 0.0002 s/iter. Total: 0.2623 s/iter. ETA=0:10:40\n",
            "\u001b[32m[04/30 20:47:24 d2.evaluation.evaluator]: \u001b[0mInference done 2578/5000. Dataloading: 0.0019 s/iter. Inference: 0.2596 s/iter. Eval: 0.0002 s/iter. Total: 0.2623 s/iter. ETA=0:10:35\n",
            "\u001b[32m[04/30 20:47:30 d2.evaluation.evaluator]: \u001b[0mInference done 2598/5000. Dataloading: 0.0019 s/iter. Inference: 0.2595 s/iter. Eval: 0.0002 s/iter. Total: 0.2622 s/iter. ETA=0:10:29\n",
            "\u001b[32m[04/30 20:47:35 d2.evaluation.evaluator]: \u001b[0mInference done 2617/5000. Dataloading: 0.0019 s/iter. Inference: 0.2596 s/iter. Eval: 0.0002 s/iter. Total: 0.2623 s/iter. ETA=0:10:24\n",
            "\u001b[32m[04/30 20:47:40 d2.evaluation.evaluator]: \u001b[0mInference done 2636/5000. Dataloading: 0.0019 s/iter. Inference: 0.2596 s/iter. Eval: 0.0002 s/iter. Total: 0.2623 s/iter. ETA=0:10:20\n",
            "\u001b[32m[04/30 20:47:45 d2.evaluation.evaluator]: \u001b[0mInference done 2655/5000. Dataloading: 0.0019 s/iter. Inference: 0.2597 s/iter. Eval: 0.0002 s/iter. Total: 0.2623 s/iter. ETA=0:10:15\n",
            "\u001b[32m[04/30 20:47:50 d2.evaluation.evaluator]: \u001b[0mInference done 2674/5000. Dataloading: 0.0019 s/iter. Inference: 0.2597 s/iter. Eval: 0.0002 s/iter. Total: 0.2623 s/iter. ETA=0:10:10\n",
            "\u001b[32m[04/30 20:47:55 d2.evaluation.evaluator]: \u001b[0mInference done 2693/5000. Dataloading: 0.0019 s/iter. Inference: 0.2597 s/iter. Eval: 0.0002 s/iter. Total: 0.2624 s/iter. ETA=0:10:05\n",
            "\u001b[32m[04/30 20:48:00 d2.evaluation.evaluator]: \u001b[0mInference done 2712/5000. Dataloading: 0.0019 s/iter. Inference: 0.2597 s/iter. Eval: 0.0002 s/iter. Total: 0.2624 s/iter. ETA=0:10:00\n",
            "\u001b[32m[04/30 20:48:05 d2.evaluation.evaluator]: \u001b[0mInference done 2731/5000. Dataloading: 0.0019 s/iter. Inference: 0.2598 s/iter. Eval: 0.0002 s/iter. Total: 0.2624 s/iter. ETA=0:09:55\n",
            "\u001b[32m[04/30 20:48:10 d2.evaluation.evaluator]: \u001b[0mInference done 2751/5000. Dataloading: 0.0019 s/iter. Inference: 0.2597 s/iter. Eval: 0.0002 s/iter. Total: 0.2624 s/iter. ETA=0:09:50\n",
            "\u001b[32m[04/30 20:48:15 d2.evaluation.evaluator]: \u001b[0mInference done 2770/5000. Dataloading: 0.0019 s/iter. Inference: 0.2597 s/iter. Eval: 0.0002 s/iter. Total: 0.2624 s/iter. ETA=0:09:45\n",
            "\u001b[32m[04/30 20:48:20 d2.evaluation.evaluator]: \u001b[0mInference done 2789/5000. Dataloading: 0.0019 s/iter. Inference: 0.2597 s/iter. Eval: 0.0002 s/iter. Total: 0.2624 s/iter. ETA=0:09:40\n",
            "\u001b[32m[04/30 20:48:25 d2.evaluation.evaluator]: \u001b[0mInference done 2809/5000. Dataloading: 0.0019 s/iter. Inference: 0.2597 s/iter. Eval: 0.0002 s/iter. Total: 0.2624 s/iter. ETA=0:09:34\n",
            "\u001b[32m[04/30 20:48:30 d2.evaluation.evaluator]: \u001b[0mInference done 2828/5000. Dataloading: 0.0019 s/iter. Inference: 0.2597 s/iter. Eval: 0.0002 s/iter. Total: 0.2624 s/iter. ETA=0:09:29\n",
            "\u001b[32m[04/30 20:48:36 d2.evaluation.evaluator]: \u001b[0mInference done 2847/5000. Dataloading: 0.0019 s/iter. Inference: 0.2598 s/iter. Eval: 0.0002 s/iter. Total: 0.2624 s/iter. ETA=0:09:25\n",
            "\u001b[32m[04/30 20:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 2867/5000. Dataloading: 0.0019 s/iter. Inference: 0.2598 s/iter. Eval: 0.0002 s/iter. Total: 0.2624 s/iter. ETA=0:09:19\n",
            "\u001b[32m[04/30 20:48:46 d2.evaluation.evaluator]: \u001b[0mInference done 2886/5000. Dataloading: 0.0019 s/iter. Inference: 0.2598 s/iter. Eval: 0.0002 s/iter. Total: 0.2625 s/iter. ETA=0:09:14\n",
            "\u001b[32m[04/30 20:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 2906/5000. Dataloading: 0.0019 s/iter. Inference: 0.2598 s/iter. Eval: 0.0002 s/iter. Total: 0.2625 s/iter. ETA=0:09:09\n",
            "\u001b[32m[04/30 20:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 2926/5000. Dataloading: 0.0019 s/iter. Inference: 0.2598 s/iter. Eval: 0.0002 s/iter. Total: 0.2625 s/iter. ETA=0:09:04\n",
            "\u001b[32m[04/30 20:49:02 d2.evaluation.evaluator]: \u001b[0mInference done 2946/5000. Dataloading: 0.0019 s/iter. Inference: 0.2598 s/iter. Eval: 0.0002 s/iter. Total: 0.2625 s/iter. ETA=0:08:59\n",
            "\u001b[32m[04/30 20:49:07 d2.evaluation.evaluator]: \u001b[0mInference done 2965/5000. Dataloading: 0.0019 s/iter. Inference: 0.2599 s/iter. Eval: 0.0002 s/iter. Total: 0.2625 s/iter. ETA=0:08:54\n",
            "\u001b[32m[04/30 20:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 2984/5000. Dataloading: 0.0019 s/iter. Inference: 0.2599 s/iter. Eval: 0.0002 s/iter. Total: 0.2625 s/iter. ETA=0:08:49\n",
            "\u001b[32m[04/30 20:49:17 d2.evaluation.evaluator]: \u001b[0mInference done 3003/5000. Dataloading: 0.0019 s/iter. Inference: 0.2599 s/iter. Eval: 0.0002 s/iter. Total: 0.2625 s/iter. ETA=0:08:44\n",
            "\u001b[32m[04/30 20:49:22 d2.evaluation.evaluator]: \u001b[0mInference done 3022/5000. Dataloading: 0.0019 s/iter. Inference: 0.2599 s/iter. Eval: 0.0002 s/iter. Total: 0.2625 s/iter. ETA=0:08:39\n",
            "\u001b[32m[04/30 20:49:27 d2.evaluation.evaluator]: \u001b[0mInference done 3041/5000. Dataloading: 0.0019 s/iter. Inference: 0.2599 s/iter. Eval: 0.0002 s/iter. Total: 0.2625 s/iter. ETA=0:08:34\n",
            "\u001b[32m[04/30 20:49:32 d2.evaluation.evaluator]: \u001b[0mInference done 3060/5000. Dataloading: 0.0019 s/iter. Inference: 0.2600 s/iter. Eval: 0.0002 s/iter. Total: 0.2626 s/iter. ETA=0:08:29\n",
            "\u001b[32m[04/30 20:49:37 d2.evaluation.evaluator]: \u001b[0mInference done 3079/5000. Dataloading: 0.0019 s/iter. Inference: 0.2600 s/iter. Eval: 0.0002 s/iter. Total: 0.2626 s/iter. ETA=0:08:24\n",
            "\u001b[32m[04/30 20:49:42 d2.evaluation.evaluator]: \u001b[0mInference done 3098/5000. Dataloading: 0.0019 s/iter. Inference: 0.2600 s/iter. Eval: 0.0002 s/iter. Total: 0.2626 s/iter. ETA=0:08:19\n",
            "\u001b[32m[04/30 20:49:47 d2.evaluation.evaluator]: \u001b[0mInference done 3118/5000. Dataloading: 0.0019 s/iter. Inference: 0.2600 s/iter. Eval: 0.0002 s/iter. Total: 0.2626 s/iter. ETA=0:08:14\n",
            "\u001b[32m[04/30 20:49:52 d2.evaluation.evaluator]: \u001b[0mInference done 3137/5000. Dataloading: 0.0019 s/iter. Inference: 0.2600 s/iter. Eval: 0.0002 s/iter. Total: 0.2626 s/iter. ETA=0:08:09\n",
            "\u001b[32m[04/30 20:49:58 d2.evaluation.evaluator]: \u001b[0mInference done 3157/5000. Dataloading: 0.0019 s/iter. Inference: 0.2600 s/iter. Eval: 0.0002 s/iter. Total: 0.2626 s/iter. ETA=0:08:04\n",
            "\u001b[32m[04/30 20:50:03 d2.evaluation.evaluator]: \u001b[0mInference done 3177/5000. Dataloading: 0.0019 s/iter. Inference: 0.2600 s/iter. Eval: 0.0002 s/iter. Total: 0.2626 s/iter. ETA=0:07:58\n",
            "\u001b[32m[04/30 20:50:08 d2.evaluation.evaluator]: \u001b[0mInference done 3196/5000. Dataloading: 0.0019 s/iter. Inference: 0.2600 s/iter. Eval: 0.0002 s/iter. Total: 0.2626 s/iter. ETA=0:07:53\n",
            "\u001b[32m[04/30 20:50:13 d2.evaluation.evaluator]: \u001b[0mInference done 3216/5000. Dataloading: 0.0019 s/iter. Inference: 0.2600 s/iter. Eval: 0.0002 s/iter. Total: 0.2626 s/iter. ETA=0:07:48\n",
            "\u001b[32m[04/30 20:50:18 d2.evaluation.evaluator]: \u001b[0mInference done 3235/5000. Dataloading: 0.0019 s/iter. Inference: 0.2601 s/iter. Eval: 0.0002 s/iter. Total: 0.2626 s/iter. ETA=0:07:43\n",
            "\u001b[32m[04/30 20:50:23 d2.evaluation.evaluator]: \u001b[0mInference done 3255/5000. Dataloading: 0.0019 s/iter. Inference: 0.2601 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:07:38\n",
            "\u001b[32m[04/30 20:50:28 d2.evaluation.evaluator]: \u001b[0mInference done 3274/5000. Dataloading: 0.0019 s/iter. Inference: 0.2601 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:07:33\n",
            "\u001b[32m[04/30 20:50:33 d2.evaluation.evaluator]: \u001b[0mInference done 3293/5000. Dataloading: 0.0019 s/iter. Inference: 0.2601 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:07:28\n",
            "\u001b[32m[04/30 20:50:39 d2.evaluation.evaluator]: \u001b[0mInference done 3313/5000. Dataloading: 0.0019 s/iter. Inference: 0.2601 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:07:23\n",
            "\u001b[32m[04/30 20:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 3333/5000. Dataloading: 0.0019 s/iter. Inference: 0.2601 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:07:17\n",
            "\u001b[32m[04/30 20:50:49 d2.evaluation.evaluator]: \u001b[0mInference done 3353/5000. Dataloading: 0.0019 s/iter. Inference: 0.2601 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:07:12\n",
            "\u001b[32m[04/30 20:50:54 d2.evaluation.evaluator]: \u001b[0mInference done 3372/5000. Dataloading: 0.0019 s/iter. Inference: 0.2601 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:07:07\n",
            "\u001b[32m[04/30 20:50:59 d2.evaluation.evaluator]: \u001b[0mInference done 3392/5000. Dataloading: 0.0019 s/iter. Inference: 0.2601 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:07:02\n",
            "\u001b[32m[04/30 20:51:05 d2.evaluation.evaluator]: \u001b[0mInference done 3412/5000. Dataloading: 0.0019 s/iter. Inference: 0.2601 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:06:57\n",
            "\u001b[32m[04/30 20:51:10 d2.evaluation.evaluator]: \u001b[0mInference done 3431/5000. Dataloading: 0.0019 s/iter. Inference: 0.2601 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:06:52\n",
            "\u001b[32m[04/30 20:51:15 d2.evaluation.evaluator]: \u001b[0mInference done 3451/5000. Dataloading: 0.0019 s/iter. Inference: 0.2601 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:06:46\n",
            "\u001b[32m[04/30 20:51:20 d2.evaluation.evaluator]: \u001b[0mInference done 3470/5000. Dataloading: 0.0019 s/iter. Inference: 0.2602 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:06:41\n",
            "\u001b[32m[04/30 20:51:25 d2.evaluation.evaluator]: \u001b[0mInference done 3490/5000. Dataloading: 0.0019 s/iter. Inference: 0.2602 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:06:36\n",
            "\u001b[32m[04/30 20:51:30 d2.evaluation.evaluator]: \u001b[0mInference done 3509/5000. Dataloading: 0.0019 s/iter. Inference: 0.2602 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:06:31\n",
            "\u001b[32m[04/30 20:51:36 d2.evaluation.evaluator]: \u001b[0mInference done 3529/5000. Dataloading: 0.0019 s/iter. Inference: 0.2602 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:06:26\n",
            "\u001b[32m[04/30 20:51:41 d2.evaluation.evaluator]: \u001b[0mInference done 3549/5000. Dataloading: 0.0019 s/iter. Inference: 0.2602 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:06:21\n",
            "\u001b[32m[04/30 20:51:46 d2.evaluation.evaluator]: \u001b[0mInference done 3569/5000. Dataloading: 0.0019 s/iter. Inference: 0.2602 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:06:15\n",
            "\u001b[32m[04/30 20:51:51 d2.evaluation.evaluator]: \u001b[0mInference done 3588/5000. Dataloading: 0.0019 s/iter. Inference: 0.2602 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:06:10\n",
            "\u001b[32m[04/30 20:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 3608/5000. Dataloading: 0.0019 s/iter. Inference: 0.2602 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:06:05\n",
            "\u001b[32m[04/30 20:52:01 d2.evaluation.evaluator]: \u001b[0mInference done 3627/5000. Dataloading: 0.0019 s/iter. Inference: 0.2602 s/iter. Eval: 0.0002 s/iter. Total: 0.2627 s/iter. ETA=0:06:00\n",
            "\u001b[32m[04/30 20:52:06 d2.evaluation.evaluator]: \u001b[0mInference done 3646/5000. Dataloading: 0.0019 s/iter. Inference: 0.2602 s/iter. Eval: 0.0002 s/iter. Total: 0.2628 s/iter. ETA=0:05:55\n",
            "\u001b[32m[04/30 20:52:11 d2.evaluation.evaluator]: \u001b[0mInference done 3665/5000. Dataloading: 0.0019 s/iter. Inference: 0.2602 s/iter. Eval: 0.0002 s/iter. Total: 0.2628 s/iter. ETA=0:05:50\n",
            "\u001b[32m[04/30 20:52:16 d2.evaluation.evaluator]: \u001b[0mInference done 3684/5000. Dataloading: 0.0019 s/iter. Inference: 0.2602 s/iter. Eval: 0.0002 s/iter. Total: 0.2628 s/iter. ETA=0:05:45\n",
            "\u001b[32m[04/30 20:52:21 d2.evaluation.evaluator]: \u001b[0mInference done 3703/5000. Dataloading: 0.0019 s/iter. Inference: 0.2602 s/iter. Eval: 0.0002 s/iter. Total: 0.2628 s/iter. ETA=0:05:40\n",
            "\u001b[32m[04/30 20:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 3723/5000. Dataloading: 0.0019 s/iter. Inference: 0.2603 s/iter. Eval: 0.0002 s/iter. Total: 0.2628 s/iter. ETA=0:05:35\n",
            "\u001b[32m[04/30 20:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 3742/5000. Dataloading: 0.0019 s/iter. Inference: 0.2603 s/iter. Eval: 0.0002 s/iter. Total: 0.2628 s/iter. ETA=0:05:30\n",
            "\u001b[32m[04/30 20:52:37 d2.evaluation.evaluator]: \u001b[0mInference done 3762/5000. Dataloading: 0.0019 s/iter. Inference: 0.2603 s/iter. Eval: 0.0002 s/iter. Total: 0.2628 s/iter. ETA=0:05:25\n",
            "\u001b[32m[04/30 20:52:42 d2.evaluation.evaluator]: \u001b[0mInference done 3781/5000. Dataloading: 0.0019 s/iter. Inference: 0.2603 s/iter. Eval: 0.0002 s/iter. Total: 0.2628 s/iter. ETA=0:05:20\n",
            "\u001b[32m[04/30 20:52:47 d2.evaluation.evaluator]: \u001b[0mInference done 3800/5000. Dataloading: 0.0019 s/iter. Inference: 0.2603 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:05:15\n",
            "\u001b[32m[04/30 20:52:52 d2.evaluation.evaluator]: \u001b[0mInference done 3820/5000. Dataloading: 0.0019 s/iter. Inference: 0.2603 s/iter. Eval: 0.0002 s/iter. Total: 0.2628 s/iter. ETA=0:05:10\n",
            "\u001b[32m[04/30 20:52:58 d2.evaluation.evaluator]: \u001b[0mInference done 3839/5000. Dataloading: 0.0019 s/iter. Inference: 0.2603 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:05:05\n",
            "\u001b[32m[04/30 20:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 3858/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:05:00\n",
            "\u001b[32m[04/30 20:53:08 d2.evaluation.evaluator]: \u001b[0mInference done 3878/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:04:54\n",
            "\u001b[32m[04/30 20:53:13 d2.evaluation.evaluator]: \u001b[0mInference done 3898/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:04:49\n",
            "\u001b[32m[04/30 20:53:18 d2.evaluation.evaluator]: \u001b[0mInference done 3917/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:04:44\n",
            "\u001b[32m[04/30 20:53:23 d2.evaluation.evaluator]: \u001b[0mInference done 3937/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:04:39\n",
            "\u001b[32m[04/30 20:53:29 d2.evaluation.evaluator]: \u001b[0mInference done 3957/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:04:34\n",
            "\u001b[32m[04/30 20:53:34 d2.evaluation.evaluator]: \u001b[0mInference done 3977/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:04:28\n",
            "\u001b[32m[04/30 20:53:39 d2.evaluation.evaluator]: \u001b[0mInference done 3997/5000. Dataloading: 0.0019 s/iter. Inference: 0.2603 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:04:23\n",
            "\u001b[32m[04/30 20:53:44 d2.evaluation.evaluator]: \u001b[0mInference done 4017/5000. Dataloading: 0.0019 s/iter. Inference: 0.2603 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:04:18\n",
            "\u001b[32m[04/30 20:53:49 d2.evaluation.evaluator]: \u001b[0mInference done 4036/5000. Dataloading: 0.0019 s/iter. Inference: 0.2603 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:04:13\n",
            "\u001b[32m[04/30 20:53:54 d2.evaluation.evaluator]: \u001b[0mInference done 4055/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:04:08\n",
            "\u001b[32m[04/30 20:54:00 d2.evaluation.evaluator]: \u001b[0mInference done 4075/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:04:03\n",
            "\u001b[32m[04/30 20:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 4094/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:03:58\n",
            "\u001b[32m[04/30 20:54:10 d2.evaluation.evaluator]: \u001b[0mInference done 4113/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:03:53\n",
            "\u001b[32m[04/30 20:54:15 d2.evaluation.evaluator]: \u001b[0mInference done 4132/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:03:48\n",
            "\u001b[32m[04/30 20:54:20 d2.evaluation.evaluator]: \u001b[0mInference done 4152/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:03:42\n",
            "\u001b[32m[04/30 20:54:25 d2.evaluation.evaluator]: \u001b[0mInference done 4172/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:03:37\n",
            "\u001b[32m[04/30 20:54:30 d2.evaluation.evaluator]: \u001b[0mInference done 4191/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:03:32\n",
            "\u001b[32m[04/30 20:54:36 d2.evaluation.evaluator]: \u001b[0mInference done 4211/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:03:27\n",
            "\u001b[32m[04/30 20:54:41 d2.evaluation.evaluator]: \u001b[0mInference done 4230/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:03:22\n",
            "\u001b[32m[04/30 20:54:46 d2.evaluation.evaluator]: \u001b[0mInference done 4250/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:03:17\n",
            "\u001b[32m[04/30 20:54:51 d2.evaluation.evaluator]: \u001b[0mInference done 4270/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:03:11\n",
            "\u001b[32m[04/30 20:54:56 d2.evaluation.evaluator]: \u001b[0mInference done 4290/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:03:06\n",
            "\u001b[32m[04/30 20:55:01 d2.evaluation.evaluator]: \u001b[0mInference done 4309/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:03:01\n",
            "\u001b[32m[04/30 20:55:06 d2.evaluation.evaluator]: \u001b[0mInference done 4328/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:02:56\n",
            "\u001b[32m[04/30 20:55:11 d2.evaluation.evaluator]: \u001b[0mInference done 4348/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:02:51\n",
            "\u001b[32m[04/30 20:55:17 d2.evaluation.evaluator]: \u001b[0mInference done 4367/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:02:46\n",
            "\u001b[32m[04/30 20:55:22 d2.evaluation.evaluator]: \u001b[0mInference done 4387/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:02:41\n",
            "\u001b[32m[04/30 20:55:27 d2.evaluation.evaluator]: \u001b[0mInference done 4406/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:02:36\n",
            "\u001b[32m[04/30 20:55:32 d2.evaluation.evaluator]: \u001b[0mInference done 4426/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:02:30\n",
            "\u001b[32m[04/30 20:55:37 d2.evaluation.evaluator]: \u001b[0mInference done 4446/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:02:25\n",
            "\u001b[32m[04/30 20:55:42 d2.evaluation.evaluator]: \u001b[0mInference done 4465/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:02:20\n",
            "\u001b[32m[04/30 20:55:48 d2.evaluation.evaluator]: \u001b[0mInference done 4485/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:02:15\n",
            "\u001b[32m[04/30 20:55:53 d2.evaluation.evaluator]: \u001b[0mInference done 4504/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:02:10\n",
            "\u001b[32m[04/30 20:55:58 d2.evaluation.evaluator]: \u001b[0mInference done 4524/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:02:05\n",
            "\u001b[32m[04/30 20:56:03 d2.evaluation.evaluator]: \u001b[0mInference done 4544/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:01:59\n",
            "\u001b[32m[04/30 20:56:08 d2.evaluation.evaluator]: \u001b[0mInference done 4563/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:01:54\n",
            "\u001b[32m[04/30 20:56:13 d2.evaluation.evaluator]: \u001b[0mInference done 4583/5000. Dataloading: 0.0019 s/iter. Inference: 0.2604 s/iter. Eval: 0.0002 s/iter. Total: 0.2629 s/iter. ETA=0:01:49\n",
            "\u001b[32m[04/30 20:56:18 d2.evaluation.evaluator]: \u001b[0mInference done 4601/5000. Dataloading: 0.0019 s/iter. Inference: 0.2605 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:01:44\n",
            "\u001b[32m[04/30 20:56:24 d2.evaluation.evaluator]: \u001b[0mInference done 4621/5000. Dataloading: 0.0019 s/iter. Inference: 0.2605 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:01:39\n",
            "\u001b[32m[04/30 20:56:29 d2.evaluation.evaluator]: \u001b[0mInference done 4640/5000. Dataloading: 0.0019 s/iter. Inference: 0.2605 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:01:34\n",
            "\u001b[32m[04/30 20:56:34 d2.evaluation.evaluator]: \u001b[0mInference done 4660/5000. Dataloading: 0.0019 s/iter. Inference: 0.2605 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:01:29\n",
            "\u001b[32m[04/30 20:56:39 d2.evaluation.evaluator]: \u001b[0mInference done 4680/5000. Dataloading: 0.0019 s/iter. Inference: 0.2605 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:01:24\n",
            "\u001b[32m[04/30 20:56:44 d2.evaluation.evaluator]: \u001b[0mInference done 4699/5000. Dataloading: 0.0019 s/iter. Inference: 0.2605 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:01:19\n",
            "\u001b[32m[04/30 20:56:49 d2.evaluation.evaluator]: \u001b[0mInference done 4719/5000. Dataloading: 0.0019 s/iter. Inference: 0.2605 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:01:13\n",
            "\u001b[32m[04/30 20:56:54 d2.evaluation.evaluator]: \u001b[0mInference done 4738/5000. Dataloading: 0.0019 s/iter. Inference: 0.2605 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:01:08\n",
            "\u001b[32m[04/30 20:56:59 d2.evaluation.evaluator]: \u001b[0mInference done 4757/5000. Dataloading: 0.0019 s/iter. Inference: 0.2605 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:01:03\n",
            "\u001b[32m[04/30 20:57:05 d2.evaluation.evaluator]: \u001b[0mInference done 4776/5000. Dataloading: 0.0019 s/iter. Inference: 0.2605 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:00:58\n",
            "\u001b[32m[04/30 20:57:10 d2.evaluation.evaluator]: \u001b[0mInference done 4795/5000. Dataloading: 0.0019 s/iter. Inference: 0.2605 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:00:53\n",
            "\u001b[32m[04/30 20:57:15 d2.evaluation.evaluator]: \u001b[0mInference done 4815/5000. Dataloading: 0.0019 s/iter. Inference: 0.2605 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:00:48\n",
            "\u001b[32m[04/30 20:57:20 d2.evaluation.evaluator]: \u001b[0mInference done 4835/5000. Dataloading: 0.0019 s/iter. Inference: 0.2605 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:00:43\n",
            "\u001b[32m[04/30 20:57:25 d2.evaluation.evaluator]: \u001b[0mInference done 4854/5000. Dataloading: 0.0019 s/iter. Inference: 0.2605 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:00:38\n",
            "\u001b[32m[04/30 20:57:30 d2.evaluation.evaluator]: \u001b[0mInference done 4873/5000. Dataloading: 0.0019 s/iter. Inference: 0.2605 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:00:33\n",
            "\u001b[32m[04/30 20:57:35 d2.evaluation.evaluator]: \u001b[0mInference done 4892/5000. Dataloading: 0.0019 s/iter. Inference: 0.2606 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:00:28\n",
            "\u001b[32m[04/30 20:57:40 d2.evaluation.evaluator]: \u001b[0mInference done 4911/5000. Dataloading: 0.0019 s/iter. Inference: 0.2606 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:00:23\n",
            "\u001b[32m[04/30 20:57:45 d2.evaluation.evaluator]: \u001b[0mInference done 4930/5000. Dataloading: 0.0019 s/iter. Inference: 0.2606 s/iter. Eval: 0.0002 s/iter. Total: 0.2630 s/iter. ETA=0:00:18\n",
            "\u001b[32m[04/30 20:57:50 d2.evaluation.evaluator]: \u001b[0mInference done 4949/5000. Dataloading: 0.0019 s/iter. Inference: 0.2606 s/iter. Eval: 0.0002 s/iter. Total: 0.2631 s/iter. ETA=0:00:13\n",
            "\u001b[32m[04/30 20:57:55 d2.evaluation.evaluator]: \u001b[0mInference done 4968/5000. Dataloading: 0.0019 s/iter. Inference: 0.2606 s/iter. Eval: 0.0002 s/iter. Total: 0.2631 s/iter. ETA=0:00:08\n",
            "\u001b[32m[04/30 20:58:01 d2.evaluation.evaluator]: \u001b[0mInference done 4988/5000. Dataloading: 0.0019 s/iter. Inference: 0.2606 s/iter. Eval: 0.0002 s/iter. Total: 0.2631 s/iter. ETA=0:00:03\n",
            "\u001b[32m[04/30 20:58:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:21:54.244041 (0.263112 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 20:58:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:21:41 (0.260598 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 20:58:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/30 20:58:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/30 20:58:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.36s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 20:58:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/30 20:58:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 7.64 seconds.\n",
            "\u001b[32m[04/30 20:58:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 20:58:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.87 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.661\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.485\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.286\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.487\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.571\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.547\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.573\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.395\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.612\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.702\n",
            "\u001b[32m[04/30 20:58:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 44.716 | 66.110 | 48.496 | 28.557 | 48.657 | 57.072 |\n",
            "\u001b[32m[04/30 20:58:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 56.554 | bicycle      | 34.601 | car            | 46.499 |\n",
            "| motorcycle    | 47.494 | airplane     | 65.930 | bus            | 69.363 |\n",
            "| train         | 64.844 | truck        | 39.742 | boat           | 30.483 |\n",
            "| traffic light | 30.449 | fire hydrant | 70.315 | stop sign      | 67.873 |\n",
            "| parking meter | 47.470 | bench        | 27.090 | bird           | 38.928 |\n",
            "| cat           | 70.504 | dog          | 66.169 | horse          | 60.230 |\n",
            "| sheep         | 56.823 | cow          | 58.583 | elephant       | 64.669 |\n",
            "| bear          | 68.113 | zebra        | 65.313 | giraffe        | 66.885 |\n",
            "| backpack      | 18.166 | umbrella     | 43.112 | handbag        | 18.733 |\n",
            "| tie           | 38.862 | suitcase     | 44.717 | frisbee        | 69.848 |\n",
            "| skis          | 28.737 | snowboard    | 45.267 | sports ball    | 49.197 |\n",
            "| kite          | 46.225 | baseball bat | 36.598 | baseball glove | 41.829 |\n",
            "| skateboard    | 57.467 | surfboard    | 42.700 | tennis racket  | 52.318 |\n",
            "| bottle        | 43.363 | wine glass   | 40.660 | cup            | 45.897 |\n",
            "| fork          | 40.951 | knife        | 25.737 | spoon          | 22.259 |\n",
            "| bowl          | 43.800 | banana       | 26.980 | apple          | 22.779 |\n",
            "| sandwich      | 38.436 | orange       | 31.392 | broccoli       | 26.537 |\n",
            "| carrot        | 24.441 | hot dog      | 36.116 | pizza          | 53.827 |\n",
            "| donut         | 49.825 | cake         | 38.328 | chair          | 30.324 |\n",
            "| couch         | 43.805 | potted plant | 30.322 | bed            | 43.183 |\n",
            "| dining table  | 30.185 | toilet       | 64.022 | tv             | 57.624 |\n",
            "| laptop        | 62.752 | mouse        | 61.924 | remote         | 41.506 |\n",
            "| keyboard      | 54.775 | cell phone   | 39.843 | microwave      | 59.500 |\n",
            "| oven          | 36.946 | toaster      | 30.475 | sink           | 39.490 |\n",
            "| refrigerator  | 60.189 | book         | 17.438 | clock          | 53.186 |\n",
            "| vase          | 41.712 | scissors     | 32.351 | teddy bear     | 49.108 |\n",
            "| hair drier    | 6.743  | toothbrush   | 29.810 |                |        |\n",
            "\u001b[32m[04/30 20:58:15 d2.engine.defaults]: \u001b[0mEvaluation results for coco_2017_val in csv format:\n",
            "\u001b[32m[04/30 20:58:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/30 20:58:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 20:58:15 d2.evaluation.testing]: \u001b[0mcopypaste: 44.7156,66.1098,48.4963,28.5572,48.6570,57.0720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "faster_rcnn_ResNeSt_101 - evaluation results for coco_2017_val in csv format:\n",
        "\n",
        "Task\\metrics  | AP | AP50 | AP75 | APs | APm | APl |\n",
        "--------------|----|------|------|-----|-----|-----|\n",
        "**bbox**    | 44.7156 | 66.1098 | 48.4963 | 28.5572 | 48.6570 | 57.0720\n",
        "\n",
        "Once again the overall results match those found in the original paper, the pretrained models perform as expected _(in the table mAP% = AP)_. \n",
        "\n",
        "Method           | Backbone   | mAP%  |\n",
        "-----------------|------------|-------|\n",
        "**Faster-RCNN**  | ResNeSt50  | 42.39 |\n",
        "**Faster-RCNN**  | ResNeSt101 | 44.72 |\n",
        "**Cascade-RCNN** | ResNeSt50  | 45.41 |\n",
        "**Cascade-RCNN** | ResNeSt101 | 47.51 |\n",
        "**Cascade-RCNN** | ResNeSt200 | 49.10 |\n",
        "\n",
        "Please consult the final report for additional comments."
      ],
      "metadata": {
        "id": "DHuw4RKnIoaQ"
      },
      "id": "DHuw4RKnIoaQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "We were ultimately able to reproduce all the experiments conducted on the pretrained models for the transfer learning tasks. ResNeSts indeed constitute an improvement to ResNets as backbone models for downstream tasks, at the same computational cost.\n",
        "\n",
        "The replications were conducted on semantic segmentation, instance segmentation and objet detection, with different level of ease. Semantic segmentation was easy to reproduce on ADE20k but the pretrained models are missing for CityScapes on both the GluonCV platform and the original article first author's website. Furthermore, we encountered several difficulties on instance segmentation and object detection because the documentation was not as clear, in particular concerning the match between the configurations files and the weight files. The task would have been made easier if it was possible to download the pretrained models from the net with pip, like in the other cases. Yet, we were still able to reproduce the experiments successfully.\n",
        "\n",
        "We chose to conduct the experiments on Colab. All things considered, opting immediatly for an AWS instance could have simplified the ordeal, for we have experienced many memory errors using Colab Pro.\n",
        "\n",
        "**For further comments and analyses please consult our final report.**"
      ],
      "metadata": {
        "id": "wD6N-UR4i5k7"
      },
      "id": "wD6N-UR4i5k7"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qQtiLem0gzFq"
      },
      "id": "qQtiLem0gzFq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "ResNeSt-TransferLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}