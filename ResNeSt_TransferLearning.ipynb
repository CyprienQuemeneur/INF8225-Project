{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "abstract-tomato",
      "metadata": {
        "id": "abstract-tomato"
      },
      "source": [
        "# ResNet meets Split-Attention: replication, ablation and analysis of ResNeSt\n",
        "# Transfer learning subsection\n",
        "\n",
        "*Authors: Emilie OURAOU, Cyprien QUEMENEUR, Hugo RODET*\n",
        "\n",
        "\n",
        "<img src=\"https://pytorch.org/assets/images/resnest.jpg\" alt=\"alt\" width=\"50%\"/>\n",
        "\n",
        "### Abstract\n",
        "ResNeSt is an architecture of neural networks, applied to computer vision, proposing a mix between a modern convolutive neural network (CNN), the ResNest, as well as the attention mechanism. For our final project we propose a study of the article which introduced the ResNeSts and conduct some additional analyses and ablations. This work indirectly follows our article presentation which focused on vision transformers (ViTs).\n",
        "\n",
        "ResNeSts can be trained as a general model on image classification then fine-tuned on more downstream tasks (aka transfer learning). This notebook reproduces the experiments of the pretrained models made available by the authors of the article on semantic segmentation, instance segmentation and object detection.\n",
        "\n",
        "### References\n",
        "\n",
        " - [ResNeSt: Split-Attention Networks](https://arxiv.org/abs/2004.08955)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semantic segmentation on ADE20k"
      ],
      "metadata": {
        "id": "ApeHVSAySAeM"
      },
      "id": "ApeHVSAySAeM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A simple example"
      ],
      "metadata": {
        "id": "sBOpM9q89-8M"
      },
      "id": "sBOpM9q89-8M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The links to download the pretrained ResNeSt models for semantic segmentation are available on:\n",
        "\n",
        "- Gluon (https://cv.gluon.ai/model_zoo/segmentation.html)\n",
        "- The first author's personal website (https://hangzhang.org/PyTorch-Encoding/model_zoo/segmentation.html)\n",
        "\n",
        "We first test the pretrained model on a single image."
      ],
      "metadata": {
        "id": "99uzcBkoTOag"
      },
      "id": "99uzcBkoTOag"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import encoding"
      ],
      "metadata": {
        "id": "HkAYdfFrgUlu"
      },
      "id": "HkAYdfFrgUlu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/zhanghang1989/PyTorch-Encoding/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8PsGCGA6FK7",
        "outputId": "10efac5a-e9e8-4bad-bc7e-0c20e97fa37b"
      },
      "id": "C8PsGCGA6FK7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/zhanghang1989/PyTorch-Encoding/\n",
            "  Cloning https://github.com/zhanghang1989/PyTorch-Encoding/ to /tmp/pip-req-build-l4kp7bi2\n",
            "  Running command git clone -q https://github.com/zhanghang1989/PyTorch-Encoding/ /tmp/pip-req-build-l4kp7bi2\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20220417) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20220417) (4.64.0)\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20220417) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20220417) (0.11.1+cu111)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20220417) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20220417) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20220417) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->torch-encoding==1.2.2b20220417) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20220417) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20220417) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20220417) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20220417) (1.24.3)\n",
            "Building wheels for collected packages: torch-encoding\n",
            "  Building wheel for torch-encoding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-encoding: filename=torch_encoding-1.2.2b20220417-cp37-cp37m-linux_x86_64.whl size=9153068 sha256=1f64cddd24e8c0ca370aff102c57a3512c148517b86ff0399c2c05ef6243d508\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dqwic_uh/wheels/d4/83/00/5a9524a23f206528125bf76110b7304681afa76adbba084b5c\n",
            "Successfully built torch-encoding\n",
            "Installing collected packages: portalocker, nose, torch-encoding\n",
            "Successfully installed nose-1.3.7 portalocker-2.4.0 torch-encoding-1.2.2b20220417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the pretrained model ResNeSt50 from the net and load the image."
      ],
      "metadata": {
        "id": "gn9V0DMTTaWe"
      },
      "id": "gn9V0DMTTaWe"
    },
    {
      "cell_type": "code",
      "source": [
        "model = encoding.models.get_model('DeepLab_ResNeSt50_PContext', pretrained=True).cuda()\n",
        "model.eval()\n",
        "\n",
        "url = 'https://github.com/zhanghang1989/image-data/blob/master/' + \\\n",
        "      'encoding/segmentation/pcontext/2010_001829_org.jpg?raw=true'\n",
        "filename = 'example.jpg'\n",
        "img = encoding.utils.load_image(\n",
        "    encoding.utils.download(url, filename)).cuda().unsqueeze(0)"
      ],
      "metadata": {
        "id": "3fp4JqIUgYyf"
      },
      "id": "3fp4JqIUgYyf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting the result and visualising it. The image is stored on the drive."
      ],
      "metadata": {
        "id": "qnPCnFy7Tlne"
      },
      "id": "qnPCnFy7Tlne"
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.evaluate(img)\n",
        "predict = torch.max(output, 1)[1].cpu().numpy() + 1\n",
        "\n",
        "mask = encoding.utils.get_mask_pallete(predict, 'pascal_voc')\n",
        "mask.save('output.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tfXgafm51HR",
        "outputId": "bf6e61a0-f760-48a0-ab3a-ba09e83c7577"
      },
      "id": "5tfXgafm51HR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model file /root/.encoding/models/resnest50-fb9de5b3.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/resnest50-fb9de5b3.zip from https://s3.us-west-1.wasabisys.com/encoding/models/resnest50-fb9de5b3.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 107689/107689 [00:07<00:00, 13739.36KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model file /root/.encoding/models/deeplab_resnest50_pcontext-08dccbc4.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/deeplab_resnest50_pcontext-08dccbc4.zip from https://s3.us-west-1.wasabisys.com/encoding/models/deeplab_resnest50_pcontext-08dccbc4.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "172046KB [00:07, 21675.93KB/s]                            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conducting the experiments"
      ],
      "metadata": {
        "id": "38rHRo9D-Cvs"
      },
      "id": "38rHRo9D-Cvs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now replicate the results of the paper for the pretrained models fine-tuned for semantic segmentation. The dataset used is ADE20K. \n",
        "\n",
        "The original paper also includes experiments on CityScapes, but contrary to what is announced we could not find the pretrained model for this dataset.\n",
        "\n",
        "For more information on these two datasets see:\n",
        "* https://groups.csail.mit.edu/vision/datasets/ADE20K/\n",
        "* https://www.cityscapes-dataset.com/\n",
        "\n",
        "We will access the necessary file from the drive and run the experiments with Colab. For this to work you will need to download the PyTorch-Encoding repository and add it to your drive (all rights reserved). The link to the repository is the following: \n",
        "* https://github.com/zhanghang1989/PyTorch-Encoding"
      ],
      "metadata": {
        "id": "yQeBmPJqTtfx"
      },
      "id": "yQeBmPJqTtfx"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kos0q-2pkHe6",
        "outputId": "1227bdb7-6802-4d85-d4a0-9ae08d0cd0e2"
      },
      "id": "kos0q-2pkHe6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZb2hN0ikmPT",
        "outputId": "8493dbb2-ee8a-4162-8c1c-c258a8b3231c"
      },
      "id": "RZb2hN0ikmPT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may need to update the path according to your drive's files organisation."
      ],
      "metadata": {
        "id": "Z2Hs5R6Xcwy8"
      },
      "id": "Z2Hs5R6Xcwy8"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/PyTorch-Encoding && python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGBTpUKVkOaX",
        "outputId": "34fb2b18-0d37-4197-a62d-714aa39acbe5"
      },
      "id": "iGBTpUKVkOaX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Building version 1.2.2b20220417\n",
            "c++:  ['/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.cpp', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/syncbn_cpu.cpp', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/encoding_cpu.cpp', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/rectify_cpu.cpp', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/operator.cpp', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp']\n",
            "cuda:  ['/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/operator.cpp', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/encoding_kernel.cu', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/lib_ssd.cu', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/roi_align_kernel.cu', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.cu', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/rectify_cuda.cu', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/syncbn_kernel.cu', '/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/activation_kernel.cu']\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing torch_encoding.egg-info/PKG-INFO\n",
            "writing dependency_links to torch_encoding.egg-info/dependency_links.txt\n",
            "writing requirements to torch_encoding.egg-info/requires.txt\n",
            "writing top-level names to torch_encoding.egg-info/top_level.txt\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:381: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'torch_encoding.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/encoding\n",
            "copying encoding/__init__.py -> build/lib.linux-x86_64-3.7/encoding\n",
            "copying encoding/parallel.py -> build/lib.linux-x86_64-3.7/encoding\n",
            "copying encoding/version.py -> build/lib.linux-x86_64-3.7/encoding\n",
            "creating build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/pcontext.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/cityscapescoarse.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/ade20k.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/pascal_aug.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/imagenet.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/pascal_voc.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/__init__.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/minc.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/cityscapes.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/base.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/hpw18.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/coco.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "copying encoding/datasets/folder.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n",
            "creating build/lib.linux-x86_64-3.7/encoding/functions\n",
            "copying encoding/functions/rectify.py -> build/lib.linux-x86_64-3.7/encoding/functions\n",
            "copying encoding/functions/customize.py -> build/lib.linux-x86_64-3.7/encoding/functions\n",
            "copying encoding/functions/dist_syncbn.py -> build/lib.linux-x86_64-3.7/encoding/functions\n",
            "copying encoding/functions/__init__.py -> build/lib.linux-x86_64-3.7/encoding/functions\n",
            "copying encoding/functions/encoding.py -> build/lib.linux-x86_64-3.7/encoding/functions\n",
            "copying encoding/functions/syncbn.py -> build/lib.linux-x86_64-3.7/encoding/functions\n",
            "creating build/lib.linux-x86_64-3.7/encoding/models\n",
            "copying encoding/models/model_zoo.py -> build/lib.linux-x86_64-3.7/encoding/models\n",
            "copying encoding/models/__init__.py -> build/lib.linux-x86_64-3.7/encoding/models\n",
            "copying encoding/models/model_store.py -> build/lib.linux-x86_64-3.7/encoding/models\n",
            "copying encoding/models/deepten.py -> build/lib.linux-x86_64-3.7/encoding/models\n",
            "creating build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/lr_scheduler.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/__init__.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/files.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/dist_helper.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/metrics.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/presets.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/pallete.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/precise_bn.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/misc.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "copying encoding/utils/train_helper.py -> build/lib.linux-x86_64-3.7/encoding/utils\n",
            "creating build/lib.linux-x86_64-3.7/encoding/transforms\n",
            "copying encoding/transforms/autoaug.py -> build/lib.linux-x86_64-3.7/encoding/transforms\n",
            "copying encoding/transforms/__init__.py -> build/lib.linux-x86_64-3.7/encoding/transforms\n",
            "copying encoding/transforms/get_transform.py -> build/lib.linux-x86_64-3.7/encoding/transforms\n",
            "copying encoding/transforms/transforms.py -> build/lib.linux-x86_64-3.7/encoding/transforms\n",
            "creating build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/attention.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/customize.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/syncbn.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/encoding.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/__init__.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/splat.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/rectify.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/dropblock.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "copying encoding/nn/loss.py -> build/lib.linux-x86_64-3.7/encoding/nn\n",
            "creating build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "copying encoding/models/backbone/resnest.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "copying encoding/models/backbone/wideresnet.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "copying encoding/models/backbone/resnet_variants.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "copying encoding/models/backbone/xception.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "copying encoding/models/backbone/resnext.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "copying encoding/models/backbone/resnet.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "copying encoding/models/backbone/__init__.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n",
            "creating build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/psp.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/atten.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/deeplab.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/upernet.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/fcfpn.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/__init__.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/encnet.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/base.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "copying encoding/models/sseg/fcn.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n",
            "creating build/lib.linux-x86_64-3.7/encoding/lib\n",
            "creating build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "copying encoding/lib/cpu/operator.h -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "copying encoding/lib/cpu/roi_align_cpu.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "copying encoding/lib/cpu/syncbn_cpu.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "copying encoding/lib/cpu/encoding_cpu.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "copying encoding/lib/cpu/rectify_cpu.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "copying encoding/lib/cpu/operator.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "copying encoding/lib/cpu/nms_cpu.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n",
            "creating build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/common.h -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/device_tensor.h -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/operator.h -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/operator.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/encoding_kernel.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/lib_ssd.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/roi_align_kernel.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/nms_kernel.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/rectify_cuda.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/syncbn_kernel.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "copying encoding/lib/gpu/activation_kernel.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n",
            "running build_ext\n",
            "building 'encoding.cpu' extension\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/content\n",
            "creating build/temp.linux-x86_64-3.7/content/drive\n",
            "creating build/temp.linux-x86_64-3.7/content/drive/MyDrive\n",
            "creating build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks\n",
            "creating build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding\n",
            "creating build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding\n",
            "creating build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib\n",
            "creating build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.cpp -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.cpp:183:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n",
            " #pragma omp parallel for private(c) \\\n",
            " \n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/syncbn_cpu.cpp -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/syncbn_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/encoding_cpu.cpp -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/encoding_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/rectify_cpu.cpp -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/rectify_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/operator.cpp -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/operator.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/operator.cpp:1:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/operator.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kpybind11::array_t<float> apply_transform(int, int, int, pybind11::array_t<float>, pybind11::array_t<float>)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/operator.h:96:29:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Knarrowing conversion of ‘\u001b[01m\u001b[K(long unsigned int)img_buf.pybind11::buffer_info::size\u001b[m\u001b[K’ from ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’ to ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ inside { } [\u001b[01;35m\u001b[K-Wnarrowing\u001b[m\u001b[K]\n",
            "   py::array_t<float> result{\u001b[01;35m\u001b[K(unsigned long)img_buf.size\u001b[m\u001b[K};\n",
            "                             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:61:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n",
            " #pragma omp parallel for\n",
            " \n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:83:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n",
            " #pragma omp parallel for\n",
            " \n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<at::Tensor> Non_Max_Suppression_CPU(const at::Tensor&, const at::Tensor&, double)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:35:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_ASSERT(input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == at::kFloat || input.type().scalarType() == at::kDouble);\n",
            "                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:241:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            " #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:261:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            " #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:313:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                         \\\n",
            "       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:585:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(__VA_ARGS__)); \\\n",
            "                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:35:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_ASSERT(input.type().scalarType() == at::kFloat || input.type().scalarType() == at::kDouble);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:35:67:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_ASSERT(input.type().scalarType() == at::kFloat || input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == at::kDouble);\n",
            "                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:241:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            " #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:261:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            " #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:313:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                         \\\n",
            "       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:585:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(__VA_ARGS__)); \\\n",
            "                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:35:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_ASSERT(input.type().scalarType() == at::kFloat || input.type().scalarType() == at::kDouble);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:36:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_ASSERT(scores.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == at::kFloat || scores.type().scalarType() == at::kDouble);\n",
            "                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:241:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            " #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:261:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            " #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:313:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                         \\\n",
            "       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:585:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(__VA_ARGS__)); \\\n",
            "                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:36:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_ASSERT(scores.type().scalarType() == at::kFloat || scores.type().scalarType() == at::kDouble);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:36:69:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_ASSERT(scores.type().scalarType() == at::kFloat || scores.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == at::kDouble);\n",
            "                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:241:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            " #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:261:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            " #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:313:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                         \\\n",
            "       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:585:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(__VA_ARGS__)); \\\n",
            "                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:36:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_ASSERT(scores.type().scalarType() == at::kFloat || scores.type().scalarType() == at::kDouble);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:46:64:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto mask = torch::zeros({batch_size, num_boxes}, input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.toScalarType(at::kByte));\n",
            "                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:49:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = unsigned char]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto *rawMask = mask.data<unsigned char>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:216:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:50:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto *rawIdx = sorted_inds.data<int64_t>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:216:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:52:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   if (input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == at::kFloat)\n",
            "                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:54:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     auto *rawInput = input.data<float>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:216:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:77:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     auto *rawInput = input.data<double>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:216:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/syncbn_cpu.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/encoding_cpu.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/rectify_cpu.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/operator.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/encoding/cpu.cpython-37m-x86_64-linux-gnu.so\n",
            "building 'encoding.gpu' extension\n",
            "creating build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/operator.cpp -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/operator.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/encoding_kernel.cu -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/encoding_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/lib_ssd.cu -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/lib_ssd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/roi_align_kernel.cu -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/roi_align_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.cu -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<at::Tensor> Non_Max_Suppression_CUDA(const at::Tensor&, const at::Tensor&, double)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.cu:80:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto mask = torch::zeros({batch_size, num_boxes}, input.typ\u001b[01;35m\u001b[Ke\u001b[m\u001b[K().toScalarType(at::kByte));\n",
            "                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:194:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/rectify_cuda.cu -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/rectify_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/syncbn_kernel.cu -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/syncbn_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/activation_kernel.cu -o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/activation_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/operator.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/encoding_kernel.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/lib_ssd.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/roi_align_kernel.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/rectify_cuda.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/syncbn_kernel.o build/temp.linux-x86_64-3.7/content/drive/MyDrive/Colab Notebooks/PyTorch-Encoding/encoding/lib/gpu/activation_kernel.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/encoding/gpu.cpython-37m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/encoding\n",
            "copying build/lib.linux-x86_64-3.7/encoding/__init__.py -> build/bdist.linux-x86_64/egg/encoding\n",
            "copying build/lib.linux-x86_64-3.7/encoding/parallel.py -> build/bdist.linux-x86_64/egg/encoding\n",
            "copying build/lib.linux-x86_64-3.7/encoding/version.py -> build/bdist.linux-x86_64/egg/encoding\n",
            "creating build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/pcontext.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/cityscapescoarse.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/ade20k.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/pascal_aug.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/imagenet.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/pascal_voc.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/__init__.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/minc.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/cityscapes.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/base.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/hpw18.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/coco.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "copying build/lib.linux-x86_64-3.7/encoding/datasets/folder.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n",
            "creating build/bdist.linux-x86_64/egg/encoding/functions\n",
            "copying build/lib.linux-x86_64-3.7/encoding/functions/rectify.py -> build/bdist.linux-x86_64/egg/encoding/functions\n",
            "copying build/lib.linux-x86_64-3.7/encoding/functions/customize.py -> build/bdist.linux-x86_64/egg/encoding/functions\n",
            "copying build/lib.linux-x86_64-3.7/encoding/functions/dist_syncbn.py -> build/bdist.linux-x86_64/egg/encoding/functions\n",
            "copying build/lib.linux-x86_64-3.7/encoding/functions/__init__.py -> build/bdist.linux-x86_64/egg/encoding/functions\n",
            "copying build/lib.linux-x86_64-3.7/encoding/functions/encoding.py -> build/bdist.linux-x86_64/egg/encoding/functions\n",
            "copying build/lib.linux-x86_64-3.7/encoding/functions/syncbn.py -> build/bdist.linux-x86_64/egg/encoding/functions\n",
            "creating build/bdist.linux-x86_64/egg/encoding/models\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/model_zoo.py -> build/bdist.linux-x86_64/egg/encoding/models\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/__init__.py -> build/bdist.linux-x86_64/egg/encoding/models\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/model_store.py -> build/bdist.linux-x86_64/egg/encoding/models\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/deepten.py -> build/bdist.linux-x86_64/egg/encoding/models\n",
            "creating build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/backbone/resnest.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/backbone/wideresnet.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/backbone/resnet_variants.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/backbone/xception.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/backbone/resnext.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/backbone/resnet.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/backbone/__init__.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n",
            "creating build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/psp.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/atten.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/deeplab.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/upernet.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/fcfpn.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/__init__.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/encnet.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/base.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "copying build/lib.linux-x86_64-3.7/encoding/models/sseg/fcn.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n",
            "creating build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/lr_scheduler.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/__init__.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/files.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/dist_helper.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/metrics.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/presets.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/pallete.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/precise_bn.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/misc.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "copying build/lib.linux-x86_64-3.7/encoding/utils/train_helper.py -> build/bdist.linux-x86_64/egg/encoding/utils\n",
            "creating build/bdist.linux-x86_64/egg/encoding/transforms\n",
            "copying build/lib.linux-x86_64-3.7/encoding/transforms/autoaug.py -> build/bdist.linux-x86_64/egg/encoding/transforms\n",
            "copying build/lib.linux-x86_64-3.7/encoding/transforms/__init__.py -> build/bdist.linux-x86_64/egg/encoding/transforms\n",
            "copying build/lib.linux-x86_64-3.7/encoding/transforms/get_transform.py -> build/bdist.linux-x86_64/egg/encoding/transforms\n",
            "copying build/lib.linux-x86_64-3.7/encoding/transforms/transforms.py -> build/bdist.linux-x86_64/egg/encoding/transforms\n",
            "creating build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/attention.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/customize.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/syncbn.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/encoding.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/__init__.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/splat.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/rectify.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/dropblock.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "copying build/lib.linux-x86_64-3.7/encoding/nn/loss.py -> build/bdist.linux-x86_64/egg/encoding/nn\n",
            "creating build/bdist.linux-x86_64/egg/encoding/lib\n",
            "creating build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/operator.h -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/roi_align_cpu.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/syncbn_cpu.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/encoding_cpu.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/rectify_cpu.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/operator.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/nms_cpu.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n",
            "creating build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/common.h -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/device_tensor.h -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/operator.h -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/operator.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/encoding_kernel.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/lib_ssd.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/roi_align_kernel.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/nms_kernel.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/rectify_cuda.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/syncbn_kernel.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/activation_kernel.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n",
            "copying build/lib.linux-x86_64-3.7/encoding/cpu.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/encoding\n",
            "copying build/lib.linux-x86_64-3.7/encoding/gpu.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/encoding\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/parallel.py to parallel.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/version.py to version.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/pcontext.py to pcontext.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/cityscapescoarse.py to cityscapescoarse.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/ade20k.py to ade20k.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/pascal_aug.py to pascal_aug.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/imagenet.py to imagenet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/pascal_voc.py to pascal_voc.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/minc.py to minc.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/cityscapes.py to cityscapes.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/base.py to base.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/hpw18.py to hpw18.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/coco.py to coco.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/folder.py to folder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/rectify.py to rectify.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/customize.py to customize.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/dist_syncbn.py to dist_syncbn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/encoding.py to encoding.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/syncbn.py to syncbn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/model_zoo.py to model_zoo.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/model_store.py to model_store.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/deepten.py to deepten.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/resnest.py to resnest.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/wideresnet.py to wideresnet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/resnet_variants.py to resnet_variants.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/xception.py to xception.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/resnext.py to resnext.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/resnet.py to resnet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/psp.py to psp.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/atten.py to atten.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/deeplab.py to deeplab.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/upernet.py to upernet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/fcfpn.py to fcfpn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/encnet.py to encnet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/base.py to base.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/fcn.py to fcn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/lr_scheduler.py to lr_scheduler.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/files.py to files.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/dist_helper.py to dist_helper.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/metrics.py to metrics.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/presets.py to presets.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/pallete.py to pallete.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/precise_bn.py to precise_bn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/misc.py to misc.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/train_helper.py to train_helper.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/transforms/autoaug.py to autoaug.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/transforms/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/transforms/get_transform.py to get_transform.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/transforms/transforms.py to transforms.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/attention.py to attention.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/customize.py to customize.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/syncbn.py to syncbn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/encoding.py to encoding.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/splat.py to splat.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/rectify.py to rectify.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/dropblock.py to dropblock.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/loss.py to loss.cpython-37.pyc\n",
            "creating stub loader for encoding/cpu.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for encoding/gpu.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/cpu.py to cpu.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/encoding/gpu.py to gpu.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torch_encoding.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torch_encoding.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torch_encoding.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torch_encoding.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torch_encoding.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "encoding.__pycache__.cpu.cpython-37: module references __file__\n",
            "encoding.__pycache__.gpu.cpython-37: module references __file__\n",
            "creating dist\n",
            "creating 'dist/torch_encoding-1.2.2b20220417-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing torch_encoding-1.2.2b20220417-py3.7-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/torch_encoding-1.2.2b20220417-py3.7-linux-x86_64.egg\n",
            "Extracting torch_encoding-1.2.2b20220417-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding torch-encoding 1.2.2b20220417 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/torch_encoding-1.2.2b20220417-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for torch-encoding==1.2.2b20220417\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Pillow==7.1.2\n",
            "Best match: Pillow 7.1.2\n",
            "Adding Pillow 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torchvision==0.11.1+cu111\n",
            "Best match: torchvision 0.11.1+cu111\n",
            "Adding torchvision 0.11.1+cu111 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torch==1.10.0+cu111\n",
            "Best match: torch 1.10.0+cu111\n",
            "Adding torch 1.10.0+cu111 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for portalocker==2.4.0\n",
            "Best match: portalocker 2.4.0\n",
            "Adding portalocker 2.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for nose==1.3.7\n",
            "Best match: nose 1.3.7\n",
            "Adding nose 1.3.7 to easy-install.pth file\n",
            "Installing nosetests script to /usr/local/bin\n",
            "Installing nosetests-3.4 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.64.0\n",
            "Best match: tqdm 4.64.0\n",
            "Adding tqdm 4.64.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.5\n",
            "Best match: numpy 1.21.5\n",
            "Adding numpy 1.21.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2021.10.8\n",
            "Best match: certifi 2021.10.8\n",
            "Adding certifi 2021.10.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.1.1\n",
            "Best match: typing-extensions 4.1.1\n",
            "Adding typing-extensions 4.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for torch-encoding==1.2.2b20220417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading and preparing the dataset ADE20k"
      ],
      "metadata": {
        "id": "JBDBUCF7SH8d"
      },
      "id": "JBDBUCF7SH8d"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/PyTorch-Encoding && python scripts/prepare_ade20k.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hqg3sOhm4Hm",
        "outputId": "2695de0c-8077-460e-b76e-946a3dfcaef3"
      },
      "id": "5Hqg3sOhm4Hm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.encoding/data/downloads/ADEChallengeData2016.zip from http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip...\n",
            "944710KB [00:12, 72823.05KB/s]                \n",
            "Downloading /root/.encoding/data/downloads/release_test.zip from http://data.csail.mit.edu/places/ADEchallenge/release_test.zip...\n",
            "100% 206856/206856 [00:03<00:00, 67270.39KB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and evaluating ResNeST50 on the validation set."
      ],
      "metadata": {
        "id": "IlJAjz1aSOSD"
      },
      "id": "IlJAjz1aSOSD"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/PyTorch-Encoding/experiments/segmentation/ && python test.py --dataset ADE20K --model-zoo DeepLab_ResNeSt50_ADE --eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wdgxdkokROF",
        "outputId": "768e65f1-c7d1-4b97-f57a-235dd1b85799"
      },
      "id": "5wdgxdkokROF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(acc_bn=False, aux=False, backbone='resnet50', base_size=520, batch_size=16, crop_size=480, cuda=True, dataset='ADE20K', eval=True, export=None, model='encnet', model_zoo='DeepLab_ResNeSt50_ADE', no_cuda=False, no_val=False, resume=None, se_loss=False, se_weight=0.2, seed=1, test_batch_size=16, test_folder=None, test_val=False, train_split='train', verify=None, workers=16)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Model file /root/.encoding/models/resnest50-fb9de5b3.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/resnest50-fb9de5b3.zip from https://s3.us-west-1.wasabisys.com/encoding/models/resnest50-fb9de5b3.zip...\n",
            "100% 107689/107689 [00:08<00:00, 12596.27KB/s]\n",
            "Model file /root/.encoding/models/deeplab_resnest50_ade-2225f09d.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/deeplab_resnest50_ade-2225f09d.zip from https://s3.us-west-1.wasabisys.com/encoding/models/deeplab_resnest50_ade-2225f09d.zip...\n",
            "172229KB [00:09, 18697.87KB/s]                \n",
            "DeepLabV3(\n",
            "  (pretrained): ResNet(\n",
            "    (conv1): Sequential(\n",
            "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): GlobalAvgPool2d()\n",
            "    (fc): None\n",
            "  )\n",
            "  (head): DeepLabV3Head(\n",
            "    (aspp): ASPP_Module(\n",
            "      (b0): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b1): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b2): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b3): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b4): AsppPooling(\n",
            "        (gap): Sequential(\n",
            "          (0): AdaptiveAvgPool2d(output_size=1)\n",
            "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (3): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (project): Sequential(\n",
            "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Dropout2d(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (auxlayer): FCNHead(\n",
            "    (conv5): Sequential(\n",
            "      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "MultiEvalModule: base_size 520, crop_size 480\n",
            "pixAcc: 0.8117, mIoU: 0.4512: 100% 2000/2000 [1:26:53<00:00,  2.61s/it]\n",
            "pixAcc: 0.8117, mIoU: 0.4512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation results for ResNeSt50 on ADE20k validation set:\n",
        "* pixAcc: 0.8117\n",
        "* mIoU: 0.4512"
      ],
      "metadata": {
        "id": "980tAdNk8BXF"
      },
      "id": "980tAdNk8BXF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and evaluating ResNeST101 on the validation set."
      ],
      "metadata": {
        "id": "3r_WKhdeSWiG"
      },
      "id": "3r_WKhdeSWiG"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/PyTorch-Encoding/experiments/segmentation/ && python test.py --dataset ADE20K --model-zoo DeepLab_ResNeSt101_ADE --eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQsOdDnT8JIR",
        "outputId": "6d68d2c0-c45d-4992-b06b-5022e9aa5b49"
      },
      "id": "jQsOdDnT8JIR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(acc_bn=False, aux=False, backbone='resnet50', base_size=520, batch_size=16, crop_size=480, cuda=True, dataset='ADE20K', eval=True, export=None, model='encnet', model_zoo='DeepLab_ResNeSt101_ADE', no_cuda=False, no_val=False, resume=None, se_loss=False, se_weight=0.2, seed=1, test_batch_size=16, test_folder=None, test_val=False, train_split='train', verify=None, workers=16)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Model file /root/.encoding/models/resnest101-966fb78c.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/resnest101-966fb78c.zip from https://s3.us-west-1.wasabisys.com/encoding/models/resnest101-966fb78c.zip...\n",
            "189242KB [00:09, 19363.69KB/s]                \n",
            "Model file /root/.encoding/models/deeplab_resnest101_ade-06ca799c.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/deeplab_resnest101_ade-06ca799c.zip from https://s3.us-west-1.wasabisys.com/encoding/models/deeplab_resnest101_ade-06ca799c.zip...\n",
            "100% 253789/253789 [00:12<00:00, 21111.08KB/s]\n",
            "DeepLabV3(\n",
            "  (pretrained): ResNet(\n",
            "    (conv1): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (6): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (7): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (8): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (9): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (10): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (11): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (12): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (13): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (14): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (15): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (16): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (17): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (18): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (19): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (20): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (21): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (22): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): GlobalAvgPool2d()\n",
            "    (fc): None\n",
            "  )\n",
            "  (head): DeepLabV3Head(\n",
            "    (aspp): ASPP_Module(\n",
            "      (b0): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b1): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b2): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b3): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b4): AsppPooling(\n",
            "        (gap): Sequential(\n",
            "          (0): AdaptiveAvgPool2d(output_size=1)\n",
            "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (3): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (project): Sequential(\n",
            "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Dropout2d(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (auxlayer): FCNHead(\n",
            "    (conv5): Sequential(\n",
            "      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "MultiEvalModule: base_size 520, crop_size 480\n",
            "pixAcc: 0.8207, mIoU: 0.4691: 100% 2000/2000 [2:09:42<00:00,  3.89s/it]\n",
            "pixAcc: 0.8207, mIoU: 0.4691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation results for ResNeSt101 on ADE20k validation set:\n",
        "* pixAcc: 0.8207\n",
        "* mIoU: 0.4691"
      ],
      "metadata": {
        "id": "hO8f9IygaM4H"
      },
      "id": "hO8f9IygaM4H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and evaluating ResNeST200 on the validation set."
      ],
      "metadata": {
        "id": "tfLX5LlqSdK-"
      },
      "id": "tfLX5LlqSdK-"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/PyTorch-Encoding/experiments/segmentation/ && python test.py --dataset ADE20K --model-zoo DeepLab_ResNeSt200_ADE --eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U77b134jaRFw",
        "outputId": "73e70b1e-6d3a-46e6-8218-4b372141864c"
      },
      "id": "U77b134jaRFw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(acc_bn=False, aux=False, backbone='resnet50', base_size=520, batch_size=16, crop_size=480, cuda=True, dataset='ADE20K', eval=True, export=None, model='encnet', model_zoo='DeepLab_ResNeSt200_ADE', no_cuda=False, no_val=False, resume=None, se_loss=False, se_weight=0.2, seed=1, test_batch_size=16, test_folder=None, test_val=False, train_split='train', verify=None, workers=16)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Model file /root/.encoding/models/resnest200-d7fd712f.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/resnest200-d7fd712f.zip from https://s3.us-west-1.wasabisys.com/encoding/models/resnest200-d7fd712f.zip...\n",
            "100% 275389/275389 [00:12<00:00, 21324.48KB/s]\n",
            "Model file /root/.encoding/models/deeplab_resnest200_ade-7b9e7d3e.pth is not found. Downloading.\n",
            "Downloading /root/.encoding/models/deeplab_resnest200_ade-7b9e7d3e.zip from https://s3.us-west-1.wasabisys.com/encoding/models/deeplab_resnest200_ade-7b9e7d3e.zip...\n",
            "100% 339949/339949 [00:13<00:00, 24641.55KB/s]\n",
            "DeepLabV3(\n",
            "  (pretrained): ResNet(\n",
            "    (conv1): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (6): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (7): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (8): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (9): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (10): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (11): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (12): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (13): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (14): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (15): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (16): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (17): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (18): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (19): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (20): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (21): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (22): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (23): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (6): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (7): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (8): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (9): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (10): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (11): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (12): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (13): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (14): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (15): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (16): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (17): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (18): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (19): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (20): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (21): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (22): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (23): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (24): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (25): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (26): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (27): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (28): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (29): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (30): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (31): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (32): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (33): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (34): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (35): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): SplAtConv2d(\n",
            "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n",
            "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (rsoftmax): rSoftMax()\n",
            "        )\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): GlobalAvgPool2d()\n",
            "    (fc): None\n",
            "  )\n",
            "  (head): DeepLabV3Head(\n",
            "    (aspp): ASPP_Module(\n",
            "      (b0): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b1): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b2): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b3): Sequential(\n",
            "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (b4): AsppPooling(\n",
            "        (gap): Sequential(\n",
            "          (0): AdaptiveAvgPool2d(output_size=1)\n",
            "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (3): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (project): Sequential(\n",
            "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Dropout2d(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (auxlayer): FCNHead(\n",
            "    (conv5): Sequential(\n",
            "      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "MultiEvalModule: base_size 520, crop_size 480\n",
            "pixAcc: 0.8245, mIoU: 0.4836: 100% 2000/2000 [2:59:07<00:00,  5.37s/it]\n",
            "pixAcc: 0.8245, mIoU: 0.4836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation results for ResNeSt200 on ADE20k validation set:\n",
        "* pixAcc: 0.8245\n",
        "* mIoU: 0.4836\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UOZ8t5dEFbiP"
      },
      "id": "UOZ8t5dEFbiP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final results match those found in the original paper, the pretrained models thus perform as expected.\n",
        "\n",
        "model\\metrics  | pixAcc | mIoU |\n",
        "------------------|------------------|------------------|\n",
        "**ResNeSt50**    | 0.8117 | 0.4512 | \n",
        "**ResNeSt101**   | 0.8207 | 0.4691 | \n",
        "**ResNeSt200**   | 0.8245 | 0.4836 | \n",
        "\n",
        "Please consult the final report for additional comments."
      ],
      "metadata": {
        "id": "GSloc6OaVGy0"
      },
      "id": "GSloc6OaVGy0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instance segmentation"
      ],
      "metadata": {
        "id": "9Gw7TkmtU_4r"
      },
      "id": "9Gw7TkmtU_4r"
    },
    {
      "cell_type": "markdown",
      "source": [
        "For conducting the experiments for instance segmentation and object detection we will need to load and prepare the dataset COCO. The pretrained models use a Detectron2 wrapper to function so we will also need to install this library.\n",
        "\n",
        "We will access the necessary file from the drive and run the experiments with Colab. For this to work you will need to download the ResNeSt repository and add it to your drive (all rights reserved).\n",
        "\n",
        "Link to the ReSNeSt repository:\n",
        "* https://github.com/zhanghang1989/ResNeSt\n",
        "\n",
        "Most of the documentation needed here is available in the detectron2 wrapper subsection as well as in the detectron2 repository.  \n",
        "* https://github.com/zhanghang1989/ResNeSt/tree/master/d2  \n",
        "* https://github.com/facebookresearch/detectron2/blob/main/GETTING_STARTED.md\n",
        "\n",
        "In the wrapper subsection you will find both the configuration files as well as the weights, saved under the .pth format. The weights need to be downloaded manually and added to the repository, the path should be the following:\n",
        "* ResNeSt-master/d2/checkpoints/COCO-InstanceSegmentation/someweights.pth\n",
        "\n",
        "The configuration files are available by default when cloning the repository, it is not needed to download them."
      ],
      "metadata": {
        "id": "5mIkh6MDVtml"
      },
      "id": "5mIkh6MDVtml"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "8RUg-2g86DjS"
      },
      "id": "8RUg-2g86DjS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_tEl7ai6BCK",
        "outputId": "4b4cdc1c-5933-4fac-c395-f32eefb95eec"
      },
      "id": "z_tEl7ai6BCK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You main need to update the path according to your drive's files organisation."
      ],
      "metadata": {
        "id": "z1ilxob_XPmm"
      },
      "id": "z1ilxob_XPmm"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master && python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IhfuLPD6Jrn",
        "outputId": "a1a9918f-8a52-4b13-e658-ab558398ad26"
      },
      "id": "8IhfuLPD6Jrn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Building version 0.0.6b20220430\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing resnest.egg-info/PKG-INFO\n",
            "writing dependency_links to resnest.egg-info/dependency_links.txt\n",
            "writing requirements to resnest.egg-info/requires.txt\n",
            "writing top-level names to resnest.egg-info/top_level.txt\n",
            "reading manifest file 'resnest.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'resnest.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "copying resnest/version.py -> build/lib/resnest\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/resnest\n",
            "copying build/lib/resnest/__init__.py -> build/bdist.linux-x86_64/egg/resnest\n",
            "copying build/lib/resnest/utils.py -> build/bdist.linux-x86_64/egg/resnest\n",
            "creating build/bdist.linux-x86_64/egg/resnest/d2\n",
            "copying build/lib/resnest/d2/config.py -> build/bdist.linux-x86_64/egg/resnest/d2\n",
            "copying build/lib/resnest/d2/__init__.py -> build/bdist.linux-x86_64/egg/resnest/d2\n",
            "copying build/lib/resnest/d2/splat.py -> build/bdist.linux-x86_64/egg/resnest/d2\n",
            "copying build/lib/resnest/d2/resnest.py -> build/bdist.linux-x86_64/egg/resnest/d2\n",
            "creating build/bdist.linux-x86_64/egg/resnest/torch\n",
            "copying build/lib/resnest/torch/config.py -> build/bdist.linux-x86_64/egg/resnest/torch\n",
            "copying build/lib/resnest/torch/utils.py -> build/bdist.linux-x86_64/egg/resnest/torch\n",
            "copying build/lib/resnest/torch/loss.py -> build/bdist.linux-x86_64/egg/resnest/torch\n",
            "copying build/lib/resnest/torch/__init__.py -> build/bdist.linux-x86_64/egg/resnest/torch\n",
            "creating build/bdist.linux-x86_64/egg/resnest/torch/datasets\n",
            "copying build/lib/resnest/torch/datasets/__init__.py -> build/bdist.linux-x86_64/egg/resnest/torch/datasets\n",
            "copying build/lib/resnest/torch/datasets/imagenet.py -> build/bdist.linux-x86_64/egg/resnest/torch/datasets\n",
            "copying build/lib/resnest/torch/datasets/build.py -> build/bdist.linux-x86_64/egg/resnest/torch/datasets\n",
            "creating build/bdist.linux-x86_64/egg/resnest/torch/models\n",
            "copying build/lib/resnest/torch/models/splat.py -> build/bdist.linux-x86_64/egg/resnest/torch/models\n",
            "copying build/lib/resnest/torch/models/resnest.py -> build/bdist.linux-x86_64/egg/resnest/torch/models\n",
            "copying build/lib/resnest/torch/models/__init__.py -> build/bdist.linux-x86_64/egg/resnest/torch/models\n",
            "copying build/lib/resnest/torch/models/ablation.py -> build/bdist.linux-x86_64/egg/resnest/torch/models\n",
            "copying build/lib/resnest/torch/models/build.py -> build/bdist.linux-x86_64/egg/resnest/torch/models\n",
            "copying build/lib/resnest/torch/models/resnet.py -> build/bdist.linux-x86_64/egg/resnest/torch/models\n",
            "creating build/bdist.linux-x86_64/egg/resnest/torch/transforms\n",
            "copying build/lib/resnest/torch/transforms/__init__.py -> build/bdist.linux-x86_64/egg/resnest/torch/transforms\n",
            "copying build/lib/resnest/torch/transforms/build.py -> build/bdist.linux-x86_64/egg/resnest/torch/transforms\n",
            "copying build/lib/resnest/torch/transforms/transforms.py -> build/bdist.linux-x86_64/egg/resnest/torch/transforms\n",
            "copying build/lib/resnest/torch/transforms/autoaug.py -> build/bdist.linux-x86_64/egg/resnest/torch/transforms\n",
            "creating build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/dropblock.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/splat.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/resnet.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/transforms.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/data_utils.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/__init__.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/model_zoo.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/ablation.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/resnest.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/gluon/model_store.py -> build/bdist.linux-x86_64/egg/resnest/gluon\n",
            "copying build/lib/resnest/version.py -> build/bdist.linux-x86_64/egg/resnest\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/d2/config.py to config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/d2/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/d2/splat.py to splat.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/d2/resnest.py to resnest.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/config.py to config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/loss.py to loss.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/datasets/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/datasets/imagenet.py to imagenet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/datasets/build.py to build.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/models/splat.py to splat.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/models/resnest.py to resnest.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/models/ablation.py to ablation.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/models/build.py to build.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/models/resnet.py to resnet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/transforms/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/transforms/build.py to build.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/transforms/transforms.py to transforms.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/torch/transforms/autoaug.py to autoaug.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/dropblock.py to dropblock.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/splat.py to splat.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/resnet.py to resnet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/transforms.py to transforms.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/data_utils.py to data_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/model_zoo.py to model_zoo.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/ablation.py to ablation.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/resnest.py to resnest.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/gluon/model_store.py to model_store.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resnest/version.py to version.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resnest.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resnest.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resnest.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resnest.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resnest.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/resnest-0.0.6b20220430-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing resnest-0.0.6b20220430-py3.7.egg\n",
            "Copying resnest-0.0.6b20220430-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding resnest 0.0.6b20220430 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/resnest-0.0.6b20220430-py3.7.egg\n",
            "Processing dependencies for resnest==0.0.6b20220430\n",
            "Searching for fvcore\n",
            "Reading https://pypi.org/simple/fvcore/\n",
            "Downloading https://files.pythonhosted.org/packages/f7/07/daa016cd34f7ba8a439983236f67345d4c32ae56a607eec1cf2440c3e4a6/fvcore-0.1.5.post20220414.tar.gz#sha256=3b95983a799047661422c01671da2fa4749f60fa947e2b0ad0520f1ebc11be43\n",
            "Best match: fvcore 0.1.5.post20220414\n",
            "Processing fvcore-0.1.5.post20220414.tar.gz\n",
            "Writing /tmp/easy_install-p60avdnh/fvcore-0.1.5.post20220414/setup.cfg\n",
            "Running fvcore-0.1.5.post20220414/setup.py -q bdist_egg --dist-dir /tmp/easy_install-p60avdnh/fvcore-0.1.5.post20220414/egg-dist-tmp-olz12_z0\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Moving fvcore-0.1.5.post20220414-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding fvcore 0.1.5.post20220414 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/fvcore-0.1.5.post20220414-py3.7.egg\n",
            "Searching for iopath\n",
            "Reading https://pypi.org/simple/iopath/\n",
            "Downloading https://files.pythonhosted.org/packages/af/20/65dd9bd25a1eb7fa35b5ae38d289126af065f8a0c1f6a90564f4bff0f89d/iopath-0.1.9-py3-none-any.whl#sha256=9058ac24f0328decdf8dbe209b33074b8702a3c4d9ba2f7801d46cb61a880b6e\n",
            "Best match: iopath 0.1.9\n",
            "Processing iopath-0.1.9-py3-none-any.whl\n",
            "Installing iopath-0.1.9-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding iopath 0.1.9 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/iopath-0.1.9-py3.7.egg\n",
            "Searching for nose\n",
            "Reading https://pypi.org/simple/nose/\n",
            "Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl#sha256=9ff7c6cc443f8c51994b34a667bbcf45afd6d945be7477b52e97516fd17c53ac\n",
            "Best match: nose 1.3.7\n",
            "Processing nose-1.3.7-py3-none-any.whl\n",
            "Installing nose-1.3.7-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding nose 1.3.7 to easy-install.pth file\n",
            "Installing nosetests script to /usr/local/bin\n",
            "Installing nosetests-3.4 script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/nose-1.3.7-py3.7.egg\n",
            "Searching for pyyaml>=5.1\n",
            "Reading https://pypi.org/simple/pyyaml/\n",
            "Downloading https://files.pythonhosted.org/packages/eb/5f/6e6fe6904e1a9c67bc2ca5629a69e7a5a0b17f079da838bab98a1e548b25/PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl#sha256=231710d57adfd809ef5d34183b8ed1eeae3f76459c18fb4a0b373ad56bedcdd9\n",
            "Best match: PyYAML 6.0\n",
            "Processing PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
            "Installing PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding PyYAML 6.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/PyYAML-6.0-py3.7-linux-x86_64.egg\n",
            "Searching for yacs>=0.1.6\n",
            "Reading https://pypi.org/simple/yacs/\n",
            "Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl#sha256=99f893e30497a4b66842821bac316386f7bd5c4f47ad35c9073ef089aa33af32\n",
            "Best match: yacs 0.1.8\n",
            "Processing yacs-0.1.8-py3-none-any.whl\n",
            "Installing yacs-0.1.8-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding yacs 0.1.8 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/yacs-0.1.8-py3.7.egg\n",
            "Searching for portalocker\n",
            "Reading https://pypi.org/simple/portalocker/\n",
            "Downloading https://files.pythonhosted.org/packages/f1/4e/1030afbf2e64e676e968bbbc82014ce4ddf1cc1ed0b492585958768cf79a/portalocker-2.4.0-py2.py3-none-any.whl#sha256=b092f48e1e30a234ab3dd1cfd44f2f235e8a41f4e310e463fc8d6798d1c3c235\n",
            "Best match: portalocker 2.4.0\n",
            "Processing portalocker-2.4.0-py2.py3-none-any.whl\n",
            "Installing portalocker-2.4.0-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding portalocker 2.4.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/portalocker-2.4.0-py3.7.egg\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Pillow==7.1.2\n",
            "Best match: Pillow 7.1.2\n",
            "Adding Pillow 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torch==1.11.0+cu113\n",
            "Best match: torch 1.11.0+cu113\n",
            "Adding torch 1.11.0+cu113 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.64.0\n",
            "Best match: tqdm 4.64.0\n",
            "Adding tqdm 4.64.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tabulate==0.8.9\n",
            "Best match: tabulate 0.8.9\n",
            "Adding tabulate 0.8.9 to easy-install.pth file\n",
            "Installing tabulate script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2021.10.8\n",
            "Best match: certifi 2021.10.8\n",
            "Adding certifi 2021.10.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.2.0\n",
            "Best match: typing-extensions 4.2.0\n",
            "Adding typing-extensions 4.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for resnest==0.0.6b20220430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation of detectron2. For an example on how to use detectron2 in colab see:\n",
        "* https://colab.research.google.com/drive/1uK6zkmNEbdRcSv1gL2GFG8rk24T9IMtZ"
      ],
      "metadata": {
        "id": "vDxPZvVuVfDw"
      },
      "id": "vDxPZvVuVfDw"
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvdYLy-66Uiu",
        "outputId": "c2135c61-e74b-45d5-e20a-a2836f191fef"
      },
      "id": "IvdYLy-66Uiu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-_q0x50c6\n",
            "  Running command git clone -q https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-_q0x50c6\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (3.2.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.0.4)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.1.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.7/dist-packages/yacs-0.1.8-py3.7.egg (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.8.9)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (4.64.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.8.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.7/dist-packages/fvcore-0.1.5.post20220414-py3.7.egg (from detectron2==0.6) (0.1.5.post20220414)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.7/dist-packages/iopath-0.1.9-py3.7.egg (from detectron2==0.6) (0.1.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.16.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n",
            "Collecting omegaconf>=2.1\n",
            "  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.1.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 17.2 MB/s \n",
            "\u001b[?25hCollecting black==21.4b2\n",
            "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 67.1 MB/s \n",
            "\u001b[?25hCollecting scipy>1.5.1\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting regex>=2020.1.8\n",
            "  Downloading regex-2022.4.24-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 62.0 MB/s \n",
            "\u001b[?25hCollecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (4.2.0)\n",
            "Collecting pathspec<1,>=0.8.1\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (7.1.2)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 61.5 MB/s \n",
            "\u001b[?25hCollecting toml>=0.10.1\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.21.6)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 57.0 MB/s \n",
            "\u001b[?25hCollecting importlib-resources<5.3\n",
            "  Downloading importlib_resources-5.2.3-py3-none-any.whl (27 kB)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 73.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources<5.3->hydra-core>=1.1->detectron2==0.6) (3.8.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages/portalocker-2.4.0-py3.7.egg (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (3.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (1.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2==0.6) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.44.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.3.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.6) (4.11.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.2.0)\n",
            "Building wheels for collected packages: detectron2, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp37-cp37m-linux_x86_64.whl size=5286162 sha256=26defbfbcd1682b97fc83f3ab10cbfdf09636db8a5704b211be65dfdeb1dbe4f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0z3dmo1q/wheels/07/dc/32/0322cb484dbefab8b9366bfedbaff5060ac7d149d69c27ca5d\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=ed2c27780663546344789b0d7d39b002a883ff7e9d3622dc0a8db207ede400f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built detectron2 antlr4-python3-runtime\n",
            "Installing collected packages: pyyaml, antlr4-python3-runtime, typed-ast, toml, regex, pathspec, omegaconf, mypy-extensions, importlib-resources, scipy, hydra-core, black, detectron2\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 5.7.1\n",
            "    Uninstalling importlib-resources-5.7.1:\n",
            "      Successfully uninstalled importlib-resources-5.7.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed antlr4-python3-runtime-4.8 black-21.4b2 detectron2-0.6 hydra-core-1.1.2 importlib-resources-5.2.3 mypy-extensions-0.4.3 omegaconf-2.1.2 pathspec-0.9.0 pyyaml-6.0 regex-2022.4.24 scipy-1.7.3 toml-0.10.2 typed-ast-1.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading and preparing the dataset COCO. For more information on this dataset see: https://cocodataset.org/#home."
      ],
      "metadata": {
        "id": "Bx6KiQmXViyS"
      },
      "id": "Bx6KiQmXViyS"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2/datasets && python prepare_coco.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dvGLpMLeOGR",
        "outputId": "87323be6-30a0-4c96-c9d4-282750ad12f7"
      },
      "id": "6dvGLpMLeOGR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18883655KB [07:23, 42600.08KB/s]                  \n",
            "796471KB [00:21, 37923.51KB/s]                \n",
            "246981KB [00:06, 39193.58KB/s]                \n",
            "100% 432/432 [00:00<00:00, 4898.18KB/s]\n",
            "19KB [00:00, 992.67KB/s]  \n",
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 12.85 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating pycocotools.egg-info\n",
            "writing pycocotools.egg-info/PKG-INFO\n",
            "writing dependency_links to pycocotools.egg-info/dependency_links.txt\n",
            "writing requirements to pycocotools.egg-info/requires.txt\n",
            "writing top-level names to pycocotools.egg-info/top_level.txt\n",
            "writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
            "writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/pycocotools\n",
            "copying pycocotools/__init__.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
            "copying pycocotools/coco.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
            "copying pycocotools/cocoeval.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
            "copying pycocotools/mask.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
            "running build_ext\n",
            "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/MyDrive/Colab Notebooks/ResNeSt-master/d2/datasets/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/__init__.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/coco.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/cocoeval.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/mask.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/coco.py to coco.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/cocoeval.py to cocoeval.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/mask.py to mask.cpython-37.pyc\n",
            "creating stub loader for pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/_mask.py to _mask.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "pycocotools.__pycache__._mask.cpython-37: module references __file__\n",
            "creating dist\n",
            "creating 'dist/pycocotools-2.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing pycocotools-2.0-py3.7-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/pycocotools-2.0-py3.7-linux-x86_64.egg\n",
            "Extracting pycocotools-2.0-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding pycocotools 2.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/pycocotools-2.0-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for pycocotools==2.0\n",
            "Searching for matplotlib==3.2.2\n",
            "Best match: matplotlib 3.2.2\n",
            "Adding matplotlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Cython==0.29.28\n",
            "Best match: Cython 0.29.28\n",
            "Adding Cython 0.29.28 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for setuptools==57.4.0\n",
            "Best match: setuptools 57.4.0\n",
            "Adding setuptools 57.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cycler==0.11.0\n",
            "Best match: cycler 0.11.0\n",
            "Adding cycler 0.11.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyparsing==3.0.8\n",
            "Best match: pyparsing 3.0.8\n",
            "Adding pyparsing 3.0.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for kiwisolver==1.4.2\n",
            "Best match: kiwisolver 1.4.2\n",
            "Adding kiwisolver 1.4.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.2.0\n",
            "Best match: typing-extensions 4.2.0\n",
            "Adding typing-extensions 4.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for pycocotools==2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cd into the dataset. We need a training set, a validation set and the annotations set to perform the experiments."
      ],
      "metadata": {
        "id": "Cd6vLRrIXkaY"
      },
      "id": "Cd6vLRrIXkaY"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2/datasets/coco && ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xhc0t3AWVv7o",
        "outputId": "c9f03d9c-97a6-4ae0-f362-b609469feda7"
      },
      "id": "Xhc0t3AWVv7o",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "annotations\t\t      train2017      val2017\n",
            "annotations_trainval2017.zip  train2017.zip  val2017.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x-c58bd325.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pmYW7my6iEb",
        "outputId": "fdd8f061-332c-4507-a4dc-daa52aaa8017"
      },
      "id": "9pmYW7my6iEb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command Line Args: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x-c58bd325.pth'], resume=False)\n",
            "\u001b[32m[04/30 13:31:58 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[04/30 13:31:59 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ----------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "numpy                   1.21.6\n",
            "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.5\n",
            "CUDA compiler           CUDA 11.1\n",
            "detectron2 arch flags   7.5\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.11.0+cu113 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           Yes\n",
            "GPU 0                   Tesla T4 (arch=7.5)\n",
            "Driver version          460.32.03\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.12.0+cu113 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
            "fvcore                  0.1.5.post20220414\n",
            "iopath                  0.1.9\n",
            "cv2                     4.1.2\n",
            "----------------------  ----------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.3\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.2\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "\u001b[32m[04/30 13:31:59 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x-c58bd325.pth'], resume=False)\n",
            "\u001b[32m[04/30 13:31:59 detectron2]: \u001b[0mContents of args.config_file=./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml:\n",
            "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186m../ResNest-Base-RCNN-FPN.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mhttps://s3.us-west-1.wasabisys.com/resnest/detectron/resnest50_detectron-255b5649.pth\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mFastRCNNConvFCHead\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m123.68\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m116.779\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m103.939\u001b[39m]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m58.393\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.12\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.375\u001b[39m]\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\u001b[38;5;15m    \u001b[39m\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mRGB\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\n",
            "\u001b[32m[04/30 13:31:59 detectron2]: \u001b[0mRunning with full config:\n",
            "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRGB\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mpolygon\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m672\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m704\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m736\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m768\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mchoice\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnest_fpn_backbone\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGeneralizedRCNN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.68\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.779\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.939\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m58.393\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.12\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.375\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRPN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVG_DOWN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOTTLENECK_WIDTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEEP_STEM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_NUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFastRCNNConvFCHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_FED_LOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_SIGMOID_CE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x-c58bd325.pth\n",
            "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./output\n",
            "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR_END\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m90000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m60000\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m80000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\n",
            "\u001b[32m[04/30 13:32:00 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[04/30 13:32:00 d2.utils.env]: \u001b[0mUsing a generated random seed 363649\n",
            "\u001b[32m[04/30 13:32:10 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(\n",
            "      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output2): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral3): Conv2d(\n",
            "      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output3): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral4): Conv2d(\n",
            "      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output4): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral5): Conv2d(\n",
            "      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output5): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNeSt(\n",
            "      (stem): BasicStem(\n",
            "        (conv1_1): Conv2d(\n",
            "          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "        )\n",
            "        (conv1_2): Conv2d(\n",
            "          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "        )\n",
            "        (conv1_3): Conv2d(\n",
            "          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): CascadeROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): ModuleList(\n",
            "      (0): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (1): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (2): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): ModuleList(\n",
            "      (0): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (1): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (2): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/30 13:32:11 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from ./checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_50_FPN_syncBN_1x-c58bd325.pth ...\n",
            "\u001b[32m[04/30 13:32:19 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
            "| Names in Model                                  | Names in Checkpoint                                                                                                           | Shapes                                             |\n",
            "|:------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------|\n",
            "| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,1,1)                |\n",
            "| backbone.bottom_up.res2.0.conv2.bn0.*           | backbone.bottom_up.res2.0.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.0.conv2.bn1.*           | backbone.bottom_up.res2.0.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.0.conv2.conv.weight     | backbone.bottom_up.res2.0.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.0.conv2.fc1.*           | backbone.bottom_up.res2.0.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.0.conv2.fc2.*           | backbone.bottom_up.res2.0.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.1.conv2.bn0.*           | backbone.bottom_up.res2.1.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.1.conv2.bn1.*           | backbone.bottom_up.res2.1.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.1.conv2.conv.weight     | backbone.bottom_up.res2.1.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.1.conv2.fc1.*           | backbone.bottom_up.res2.1.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.1.conv2.fc2.*           | backbone.bottom_up.res2.1.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.2.conv2.bn0.*           | backbone.bottom_up.res2.2.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.2.conv2.bn1.*           | backbone.bottom_up.res2.2.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.2.conv2.conv.weight     | backbone.bottom_up.res2.2.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.2.conv2.fc1.*           | backbone.bottom_up.res2.2.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.2.conv2.fc2.*           | backbone.bottom_up.res2.2.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv2.bn0.*           | backbone.bottom_up.res3.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.0.conv2.bn1.*           | backbone.bottom_up.res3.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.0.conv2.conv.weight     | backbone.bottom_up.res3.0.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.0.conv2.fc1.*           | backbone.bottom_up.res3.0.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.0.conv2.fc2.*           | backbone.bottom_up.res3.0.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv2.bn0.*           | backbone.bottom_up.res3.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.1.conv2.bn1.*           | backbone.bottom_up.res3.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.1.conv2.conv.weight     | backbone.bottom_up.res3.1.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.1.conv2.fc1.*           | backbone.bottom_up.res3.1.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.1.conv2.fc2.*           | backbone.bottom_up.res3.1.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv2.bn0.*           | backbone.bottom_up.res3.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.2.conv2.bn1.*           | backbone.bottom_up.res3.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.2.conv2.conv.weight     | backbone.bottom_up.res3.2.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.2.conv2.fc1.*           | backbone.bottom_up.res3.2.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.2.conv2.fc2.*           | backbone.bottom_up.res3.2.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv2.bn0.*           | backbone.bottom_up.res3.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.3.conv2.bn1.*           | backbone.bottom_up.res3.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.3.conv2.conv.weight     | backbone.bottom_up.res3.3.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.3.conv2.fc1.*           | backbone.bottom_up.res3.3.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.3.conv2.fc2.*           | backbone.bottom_up.res3.3.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv2.bn0.*           | backbone.bottom_up.res4.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.bn1.*           | backbone.bottom_up.res4.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.conv.weight     | backbone.bottom_up.res4.0.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.0.conv2.fc1.*           | backbone.bottom_up.res4.0.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv2.fc2.*           | backbone.bottom_up.res4.0.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.1.conv2.bn0.*           | backbone.bottom_up.res4.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.bn1.*           | backbone.bottom_up.res4.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.conv.weight     | backbone.bottom_up.res4.1.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.1.conv2.fc1.*           | backbone.bottom_up.res4.1.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv2.fc2.*           | backbone.bottom_up.res4.1.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.2.conv2.bn0.*           | backbone.bottom_up.res4.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.bn1.*           | backbone.bottom_up.res4.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.conv.weight     | backbone.bottom_up.res4.2.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.2.conv2.fc1.*           | backbone.bottom_up.res4.2.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv2.fc2.*           | backbone.bottom_up.res4.2.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.3.conv2.bn0.*           | backbone.bottom_up.res4.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.bn1.*           | backbone.bottom_up.res4.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.conv.weight     | backbone.bottom_up.res4.3.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.3.conv2.fc1.*           | backbone.bottom_up.res4.3.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv2.fc2.*           | backbone.bottom_up.res4.3.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.4.conv2.bn0.*           | backbone.bottom_up.res4.4.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.bn1.*           | backbone.bottom_up.res4.4.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.conv.weight     | backbone.bottom_up.res4.4.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.4.conv2.fc1.*           | backbone.bottom_up.res4.4.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv2.fc2.*           | backbone.bottom_up.res4.4.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.5.conv2.bn0.*           | backbone.bottom_up.res4.5.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.bn1.*           | backbone.bottom_up.res4.5.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.conv.weight     | backbone.bottom_up.res4.5.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.5.conv2.fc1.*           | backbone.bottom_up.res4.5.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv2.fc2.*           | backbone.bottom_up.res4.5.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| backbone.bottom_up.res5.0.conv2.bn0.*           | backbone.bottom_up.res5.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.0.conv2.bn1.*           | backbone.bottom_up.res5.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.0.conv2.conv.weight     | backbone.bottom_up.res5.0.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.0.conv2.fc1.*           | backbone.bottom_up.res5.0.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.0.conv2.fc2.*           | backbone.bottom_up.res5.0.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.1.conv2.bn0.*           | backbone.bottom_up.res5.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.1.conv2.bn1.*           | backbone.bottom_up.res5.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.1.conv2.conv.weight     | backbone.bottom_up.res5.1.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.1.conv2.fc1.*           | backbone.bottom_up.res5.1.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.1.conv2.fc2.*           | backbone.bottom_up.res5.1.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.2.conv2.bn0.*           | backbone.bottom_up.res5.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.2.conv2.bn1.*           | backbone.bottom_up.res5.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.2.conv2.conv.weight     | backbone.bottom_up.res5.2.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.2.conv2.fc1.*           | backbone.bottom_up.res5.2.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.2.conv2.fc2.*           | backbone.bottom_up.res5.2.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.stem.conv1_1.*               | backbone.bottom_up.stem.conv1_1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (32,) (32,) (32,) (32,) (32,3,3,3)                 |\n",
            "| backbone.bottom_up.stem.conv1_2.*               | backbone.bottom_up.stem.conv1_2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (32,) (32,) (32,) (32,) (32,32,3,3)                |\n",
            "| backbone.bottom_up.stem.conv1_3.*               | backbone.bottom_up.stem.conv1_3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,32,3,3)                |\n",
            "| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,2048,1,1)      |\n",
            "| backbone.fpn_output2.*                          | backbone.fpn_output2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output3.*                          | backbone.fpn_output3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output4.*                          | backbone.fpn_output4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output5.*                          | backbone.fpn_output5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                                                       | (12,) (12,256,1,1)                                 |\n",
            "| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                                                | (256,) (256,256,3,3)                               |\n",
            "| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                                                   | (3,) (3,256,1,1)                                   |\n",
            "| roi_heads.box_head.0.conv1.*                    | roi_heads.box_head.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv2.*                    | roi_heads.box_head.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv3.*                    | roi_heads.box_head.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv4.*                    | roi_heads.box_head.0.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.fc1.*                      | roi_heads.box_head.0.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_head.1.conv1.*                    | roi_heads.box_head.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv2.*                    | roi_heads.box_head.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv3.*                    | roi_heads.box_head.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv4.*                    | roi_heads.box_head.1.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.fc1.*                      | roi_heads.box_head.1.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_head.2.conv1.*                    | roi_heads.box_head.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv2.*                    | roi_heads.box_head.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv3.*                    | roi_heads.box_head.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv4.*                    | roi_heads.box_head.2.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.fc1.*                      | roi_heads.box_head.2.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_predictor.0.bbox_pred.*           | roi_heads.box_predictor.0.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.0.cls_score.*           | roi_heads.box_predictor.0.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.box_predictor.1.bbox_pred.*           | roi_heads.box_predictor.1.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.1.cls_score.*           | roi_heads.box_predictor.1.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.box_predictor.2.bbox_pred.*           | roi_heads.box_predictor.2.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.2.cls_score.*           | roi_heads.box_predictor.2.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.mask_head.deconv.*                    | roi_heads.mask_head.deconv.{bias,weight}                                                                                      | (256,) (256,256,2,2)                               |\n",
            "| roi_heads.mask_head.mask_fcn1.*                 | roi_heads.mask_head.mask_fcn1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.mask_fcn2.*                 | roi_heads.mask_head.mask_fcn2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.mask_fcn3.*                 | roi_heads.mask_head.mask_fcn3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.mask_fcn4.*                 | roi_heads.mask_head.mask_fcn4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.mask_head.predictor.*                 | roi_heads.mask_head.predictor.{bias,weight}                                                                                   | (80,) (80,256,1,1)                                 |\n",
            "\u001b[32m[04/30 13:32:20 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json\n",
            "\u001b[32m[04/30 13:32:21 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n",
            "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
            "|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\n",
            "|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\n",
            "|     train     | 190          |    truck     | 414          |     boat      | 424          |\n",
            "| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\n",
            "| parking meter | 60           |    bench     | 411          |     bird      | 427          |\n",
            "|      cat      | 202          |     dog      | 218          |     horse     | 272          |\n",
            "|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\n",
            "|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\n",
            "|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\n",
            "|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\n",
            "|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\n",
            "|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\n",
            "|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\n",
            "|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\n",
            "|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\n",
            "|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\n",
            "|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\n",
            "|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\n",
            "|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\n",
            "|     couch     | 261          | potted plant | 342          |      bed      | 163          |\n",
            "| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\n",
            "|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\n",
            "|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\n",
            "|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\n",
            "| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\n",
            "|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\n",
            "|  hair drier   | 11           |  toothbrush  | 57           |               |              |\n",
            "|     total     | 36335        |              |              |               |              |\u001b[0m\n",
            "\u001b[32m[04/30 13:32:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/30 13:32:21 d2.data.common]: \u001b[0mSerializing 5000 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/30 13:32:21 d2.data.common]: \u001b[0mSerialized dataset takes 19.10 MiB\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[32m[04/30 13:32:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 5000 batches\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m[04/30 13:32:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/5000. Dataloading: 0.0012 s/iter. Inference: 0.3588 s/iter. Eval: 0.0187 s/iter. Total: 0.3787 s/iter. ETA=0:31:29\n",
            "\u001b[32m[04/30 13:32:32 d2.evaluation.evaluator]: \u001b[0mInference done 25/5000. Dataloading: 0.0018 s/iter. Inference: 0.3572 s/iter. Eval: 0.0175 s/iter. Total: 0.3767 s/iter. ETA=0:31:13\n",
            "\u001b[32m[04/30 13:32:37 d2.evaluation.evaluator]: \u001b[0mInference done 38/5000. Dataloading: 0.0019 s/iter. Inference: 0.3611 s/iter. Eval: 0.0195 s/iter. Total: 0.3825 s/iter. ETA=0:31:38\n",
            "\u001b[32m[04/30 13:32:42 d2.evaluation.evaluator]: \u001b[0mInference done 51/5000. Dataloading: 0.0019 s/iter. Inference: 0.3627 s/iter. Eval: 0.0201 s/iter. Total: 0.3849 s/iter. ETA=0:31:44\n",
            "\u001b[32m[04/30 13:32:48 d2.evaluation.evaluator]: \u001b[0mInference done 65/5000. Dataloading: 0.0019 s/iter. Inference: 0.3640 s/iter. Eval: 0.0183 s/iter. Total: 0.3844 s/iter. ETA=0:31:36\n",
            "\u001b[32m[04/30 13:32:53 d2.evaluation.evaluator]: \u001b[0mInference done 79/5000. Dataloading: 0.0019 s/iter. Inference: 0.3644 s/iter. Eval: 0.0181 s/iter. Total: 0.3846 s/iter. ETA=0:31:32\n",
            "\u001b[32m[04/30 13:32:58 d2.evaluation.evaluator]: \u001b[0mInference done 92/5000. Dataloading: 0.0019 s/iter. Inference: 0.3642 s/iter. Eval: 0.0187 s/iter. Total: 0.3850 s/iter. ETA=0:31:29\n",
            "\u001b[32m[04/30 13:33:03 d2.evaluation.evaluator]: \u001b[0mInference done 105/5000. Dataloading: 0.0020 s/iter. Inference: 0.3649 s/iter. Eval: 0.0203 s/iter. Total: 0.3873 s/iter. ETA=0:31:35\n",
            "\u001b[32m[04/30 13:33:09 d2.evaluation.evaluator]: \u001b[0mInference done 119/5000. Dataloading: 0.0020 s/iter. Inference: 0.3655 s/iter. Eval: 0.0197 s/iter. Total: 0.3872 s/iter. ETA=0:31:29\n",
            "\u001b[32m[04/30 13:33:14 d2.evaluation.evaluator]: \u001b[0mInference done 132/5000. Dataloading: 0.0020 s/iter. Inference: 0.3663 s/iter. Eval: 0.0197 s/iter. Total: 0.3882 s/iter. ETA=0:31:29\n",
            "\u001b[32m[04/30 13:33:19 d2.evaluation.evaluator]: \u001b[0mInference done 145/5000. Dataloading: 0.0020 s/iter. Inference: 0.3675 s/iter. Eval: 0.0203 s/iter. Total: 0.3899 s/iter. ETA=0:31:32\n",
            "\u001b[32m[04/30 13:33:24 d2.evaluation.evaluator]: \u001b[0mInference done 158/5000. Dataloading: 0.0020 s/iter. Inference: 0.3682 s/iter. Eval: 0.0201 s/iter. Total: 0.3904 s/iter. ETA=0:31:30\n",
            "\u001b[32m[04/30 13:33:29 d2.evaluation.evaluator]: \u001b[0mInference done 171/5000. Dataloading: 0.0020 s/iter. Inference: 0.3684 s/iter. Eval: 0.0198 s/iter. Total: 0.3903 s/iter. ETA=0:31:24\n",
            "\u001b[32m[04/30 13:33:35 d2.evaluation.evaluator]: \u001b[0mInference done 184/5000. Dataloading: 0.0020 s/iter. Inference: 0.3690 s/iter. Eval: 0.0205 s/iter. Total: 0.3916 s/iter. ETA=0:31:25\n",
            "\u001b[32m[04/30 13:33:40 d2.evaluation.evaluator]: \u001b[0mInference done 197/5000. Dataloading: 0.0020 s/iter. Inference: 0.3696 s/iter. Eval: 0.0201 s/iter. Total: 0.3918 s/iter. ETA=0:31:21\n",
            "\u001b[32m[04/30 13:33:45 d2.evaluation.evaluator]: \u001b[0mInference done 210/5000. Dataloading: 0.0020 s/iter. Inference: 0.3702 s/iter. Eval: 0.0197 s/iter. Total: 0.3919 s/iter. ETA=0:31:17\n",
            "\u001b[32m[04/30 13:33:50 d2.evaluation.evaluator]: \u001b[0mInference done 224/5000. Dataloading: 0.0020 s/iter. Inference: 0.3703 s/iter. Eval: 0.0191 s/iter. Total: 0.3915 s/iter. ETA=0:31:09\n",
            "\u001b[32m[04/30 13:33:56 d2.evaluation.evaluator]: \u001b[0mInference done 237/5000. Dataloading: 0.0020 s/iter. Inference: 0.3712 s/iter. Eval: 0.0192 s/iter. Total: 0.3924 s/iter. ETA=0:31:08\n",
            "\u001b[32m[04/30 13:34:01 d2.evaluation.evaluator]: \u001b[0mInference done 250/5000. Dataloading: 0.0020 s/iter. Inference: 0.3718 s/iter. Eval: 0.0194 s/iter. Total: 0.3932 s/iter. ETA=0:31:07\n",
            "\u001b[32m[04/30 13:34:06 d2.evaluation.evaluator]: \u001b[0mInference done 262/5000. Dataloading: 0.0020 s/iter. Inference: 0.3726 s/iter. Eval: 0.0197 s/iter. Total: 0.3944 s/iter. ETA=0:31:08\n",
            "\u001b[32m[04/30 13:34:11 d2.evaluation.evaluator]: \u001b[0mInference done 275/5000. Dataloading: 0.0020 s/iter. Inference: 0.3727 s/iter. Eval: 0.0194 s/iter. Total: 0.3941 s/iter. ETA=0:31:02\n",
            "\u001b[32m[04/30 13:34:16 d2.evaluation.evaluator]: \u001b[0mInference done 288/5000. Dataloading: 0.0020 s/iter. Inference: 0.3733 s/iter. Eval: 0.0194 s/iter. Total: 0.3947 s/iter. ETA=0:30:59\n",
            "\u001b[32m[04/30 13:34:22 d2.evaluation.evaluator]: \u001b[0mInference done 301/5000. Dataloading: 0.0020 s/iter. Inference: 0.3739 s/iter. Eval: 0.0195 s/iter. Total: 0.3955 s/iter. ETA=0:30:58\n",
            "\u001b[32m[04/30 13:34:27 d2.evaluation.evaluator]: \u001b[0mInference done 314/5000. Dataloading: 0.0020 s/iter. Inference: 0.3744 s/iter. Eval: 0.0196 s/iter. Total: 0.3960 s/iter. ETA=0:30:55\n",
            "\u001b[32m[04/30 13:34:32 d2.evaluation.evaluator]: \u001b[0mInference done 327/5000. Dataloading: 0.0020 s/iter. Inference: 0.3750 s/iter. Eval: 0.0195 s/iter. Total: 0.3966 s/iter. ETA=0:30:53\n",
            "\u001b[32m[04/30 13:34:37 d2.evaluation.evaluator]: \u001b[0mInference done 339/5000. Dataloading: 0.0020 s/iter. Inference: 0.3756 s/iter. Eval: 0.0197 s/iter. Total: 0.3974 s/iter. ETA=0:30:52\n",
            "\u001b[32m[04/30 13:34:43 d2.evaluation.evaluator]: \u001b[0mInference done 352/5000. Dataloading: 0.0020 s/iter. Inference: 0.3762 s/iter. Eval: 0.0196 s/iter. Total: 0.3979 s/iter. ETA=0:30:49\n",
            "\u001b[32m[04/30 13:34:48 d2.evaluation.evaluator]: \u001b[0mInference done 365/5000. Dataloading: 0.0020 s/iter. Inference: 0.3766 s/iter. Eval: 0.0197 s/iter. Total: 0.3984 s/iter. ETA=0:30:46\n",
            "\u001b[32m[04/30 13:34:53 d2.evaluation.evaluator]: \u001b[0mInference done 377/5000. Dataloading: 0.0020 s/iter. Inference: 0.3771 s/iter. Eval: 0.0199 s/iter. Total: 0.3991 s/iter. ETA=0:30:44\n",
            "\u001b[32m[04/30 13:34:58 d2.evaluation.evaluator]: \u001b[0mInference done 390/5000. Dataloading: 0.0020 s/iter. Inference: 0.3773 s/iter. Eval: 0.0196 s/iter. Total: 0.3990 s/iter. ETA=0:30:39\n",
            "\u001b[32m[04/30 13:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 403/5000. Dataloading: 0.0019 s/iter. Inference: 0.3778 s/iter. Eval: 0.0196 s/iter. Total: 0.3995 s/iter. ETA=0:30:36\n",
            "\u001b[32m[04/30 13:35:09 d2.evaluation.evaluator]: \u001b[0mInference done 416/5000. Dataloading: 0.0019 s/iter. Inference: 0.3783 s/iter. Eval: 0.0195 s/iter. Total: 0.3999 s/iter. ETA=0:30:32\n",
            "\u001b[32m[04/30 13:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 429/5000. Dataloading: 0.0019 s/iter. Inference: 0.3786 s/iter. Eval: 0.0194 s/iter. Total: 0.4001 s/iter. ETA=0:30:28\n",
            "\u001b[32m[04/30 13:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 441/5000. Dataloading: 0.0019 s/iter. Inference: 0.3792 s/iter. Eval: 0.0194 s/iter. Total: 0.4006 s/iter. ETA=0:30:26\n",
            "\u001b[32m[04/30 13:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 454/5000. Dataloading: 0.0019 s/iter. Inference: 0.3794 s/iter. Eval: 0.0192 s/iter. Total: 0.4007 s/iter. ETA=0:30:21\n",
            "\u001b[32m[04/30 13:35:30 d2.evaluation.evaluator]: \u001b[0mInference done 467/5000. Dataloading: 0.0019 s/iter. Inference: 0.3799 s/iter. Eval: 0.0191 s/iter. Total: 0.4011 s/iter. ETA=0:30:17\n",
            "\u001b[32m[04/30 13:35:35 d2.evaluation.evaluator]: \u001b[0mInference done 480/5000. Dataloading: 0.0019 s/iter. Inference: 0.3804 s/iter. Eval: 0.0189 s/iter. Total: 0.4013 s/iter. ETA=0:30:13\n",
            "\u001b[32m[04/30 13:35:40 d2.evaluation.evaluator]: \u001b[0mInference done 492/5000. Dataloading: 0.0019 s/iter. Inference: 0.3809 s/iter. Eval: 0.0191 s/iter. Total: 0.4020 s/iter. ETA=0:30:12\n",
            "\u001b[32m[04/30 13:35:46 d2.evaluation.evaluator]: \u001b[0mInference done 505/5000. Dataloading: 0.0020 s/iter. Inference: 0.3811 s/iter. Eval: 0.0191 s/iter. Total: 0.4022 s/iter. ETA=0:30:08\n",
            "\u001b[32m[04/30 13:35:51 d2.evaluation.evaluator]: \u001b[0mInference done 518/5000. Dataloading: 0.0019 s/iter. Inference: 0.3814 s/iter. Eval: 0.0191 s/iter. Total: 0.4025 s/iter. ETA=0:30:04\n",
            "\u001b[32m[04/30 13:35:56 d2.evaluation.evaluator]: \u001b[0mInference done 530/5000. Dataloading: 0.0019 s/iter. Inference: 0.3818 s/iter. Eval: 0.0192 s/iter. Total: 0.4031 s/iter. ETA=0:30:01\n",
            "\u001b[32m[04/30 13:36:02 d2.evaluation.evaluator]: \u001b[0mInference done 542/5000. Dataloading: 0.0019 s/iter. Inference: 0.3823 s/iter. Eval: 0.0195 s/iter. Total: 0.4038 s/iter. ETA=0:29:59\n",
            "\u001b[32m[04/30 13:36:07 d2.evaluation.evaluator]: \u001b[0mInference done 554/5000. Dataloading: 0.0019 s/iter. Inference: 0.3826 s/iter. Eval: 0.0195 s/iter. Total: 0.4041 s/iter. ETA=0:29:56\n",
            "\u001b[32m[04/30 13:36:12 d2.evaluation.evaluator]: \u001b[0mInference done 567/5000. Dataloading: 0.0019 s/iter. Inference: 0.3829 s/iter. Eval: 0.0194 s/iter. Total: 0.4044 s/iter. ETA=0:29:52\n",
            "\u001b[32m[04/30 13:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 579/5000. Dataloading: 0.0019 s/iter. Inference: 0.3833 s/iter. Eval: 0.0195 s/iter. Total: 0.4049 s/iter. ETA=0:29:50\n",
            "\u001b[32m[04/30 13:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 591/5000. Dataloading: 0.0019 s/iter. Inference: 0.3836 s/iter. Eval: 0.0196 s/iter. Total: 0.4053 s/iter. ETA=0:29:46\n",
            "\u001b[32m[04/30 13:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 604/5000. Dataloading: 0.0019 s/iter. Inference: 0.3839 s/iter. Eval: 0.0195 s/iter. Total: 0.4054 s/iter. ETA=0:29:42\n",
            "\u001b[32m[04/30 13:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 616/5000. Dataloading: 0.0019 s/iter. Inference: 0.3843 s/iter. Eval: 0.0195 s/iter. Total: 0.4058 s/iter. ETA=0:29:39\n",
            "\u001b[32m[04/30 13:36:38 d2.evaluation.evaluator]: \u001b[0mInference done 628/5000. Dataloading: 0.0019 s/iter. Inference: 0.3846 s/iter. Eval: 0.0195 s/iter. Total: 0.4061 s/iter. ETA=0:29:35\n",
            "\u001b[32m[04/30 13:36:43 d2.evaluation.evaluator]: \u001b[0mInference done 640/5000. Dataloading: 0.0019 s/iter. Inference: 0.3849 s/iter. Eval: 0.0197 s/iter. Total: 0.4066 s/iter. ETA=0:29:32\n",
            "\u001b[32m[04/30 13:36:48 d2.evaluation.evaluator]: \u001b[0mInference done 652/5000. Dataloading: 0.0019 s/iter. Inference: 0.3852 s/iter. Eval: 0.0198 s/iter. Total: 0.4070 s/iter. ETA=0:29:29\n",
            "\u001b[32m[04/30 13:36:53 d2.evaluation.evaluator]: \u001b[0mInference done 664/5000. Dataloading: 0.0019 s/iter. Inference: 0.3855 s/iter. Eval: 0.0199 s/iter. Total: 0.4074 s/iter. ETA=0:29:26\n",
            "\u001b[32m[04/30 13:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 677/5000. Dataloading: 0.0019 s/iter. Inference: 0.3858 s/iter. Eval: 0.0197 s/iter. Total: 0.4075 s/iter. ETA=0:29:21\n",
            "\u001b[32m[04/30 13:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 689/5000. Dataloading: 0.0019 s/iter. Inference: 0.3861 s/iter. Eval: 0.0197 s/iter. Total: 0.4078 s/iter. ETA=0:29:18\n",
            "\u001b[32m[04/30 13:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 701/5000. Dataloading: 0.0019 s/iter. Inference: 0.3863 s/iter. Eval: 0.0197 s/iter. Total: 0.4080 s/iter. ETA=0:29:14\n",
            "\u001b[32m[04/30 13:37:14 d2.evaluation.evaluator]: \u001b[0mInference done 713/5000. Dataloading: 0.0019 s/iter. Inference: 0.3867 s/iter. Eval: 0.0197 s/iter. Total: 0.4084 s/iter. ETA=0:29:10\n",
            "\u001b[32m[04/30 13:37:19 d2.evaluation.evaluator]: \u001b[0mInference done 725/5000. Dataloading: 0.0019 s/iter. Inference: 0.3870 s/iter. Eval: 0.0199 s/iter. Total: 0.4089 s/iter. ETA=0:29:08\n",
            "\u001b[32m[04/30 13:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 737/5000. Dataloading: 0.0019 s/iter. Inference: 0.3872 s/iter. Eval: 0.0199 s/iter. Total: 0.4092 s/iter. ETA=0:29:04\n",
            "\u001b[32m[04/30 13:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 749/5000. Dataloading: 0.0019 s/iter. Inference: 0.3875 s/iter. Eval: 0.0200 s/iter. Total: 0.4095 s/iter. ETA=0:29:00\n",
            "\u001b[32m[04/30 13:37:35 d2.evaluation.evaluator]: \u001b[0mInference done 762/5000. Dataloading: 0.0019 s/iter. Inference: 0.3877 s/iter. Eval: 0.0198 s/iter. Total: 0.4096 s/iter. ETA=0:28:55\n",
            "\u001b[32m[04/30 13:37:40 d2.evaluation.evaluator]: \u001b[0mInference done 774/5000. Dataloading: 0.0019 s/iter. Inference: 0.3880 s/iter. Eval: 0.0198 s/iter. Total: 0.4098 s/iter. ETA=0:28:51\n",
            "\u001b[32m[04/30 13:37:45 d2.evaluation.evaluator]: \u001b[0mInference done 786/5000. Dataloading: 0.0019 s/iter. Inference: 0.3882 s/iter. Eval: 0.0198 s/iter. Total: 0.4101 s/iter. ETA=0:28:48\n",
            "\u001b[32m[04/30 13:37:50 d2.evaluation.evaluator]: \u001b[0mInference done 798/5000. Dataloading: 0.0020 s/iter. Inference: 0.3885 s/iter. Eval: 0.0199 s/iter. Total: 0.4104 s/iter. ETA=0:28:44\n",
            "\u001b[32m[04/30 13:37:55 d2.evaluation.evaluator]: \u001b[0mInference done 810/5000. Dataloading: 0.0019 s/iter. Inference: 0.3887 s/iter. Eval: 0.0199 s/iter. Total: 0.4106 s/iter. ETA=0:28:40\n",
            "\u001b[32m[04/30 13:38:00 d2.evaluation.evaluator]: \u001b[0mInference done 822/5000. Dataloading: 0.0019 s/iter. Inference: 0.3890 s/iter. Eval: 0.0197 s/iter. Total: 0.4107 s/iter. ETA=0:28:36\n",
            "\u001b[32m[04/30 13:38:05 d2.evaluation.evaluator]: \u001b[0mInference done 834/5000. Dataloading: 0.0019 s/iter. Inference: 0.3891 s/iter. Eval: 0.0197 s/iter. Total: 0.4109 s/iter. ETA=0:28:31\n",
            "\u001b[32m[04/30 13:38:10 d2.evaluation.evaluator]: \u001b[0mInference done 846/5000. Dataloading: 0.0020 s/iter. Inference: 0.3893 s/iter. Eval: 0.0198 s/iter. Total: 0.4111 s/iter. ETA=0:28:27\n",
            "\u001b[32m[04/30 13:38:15 d2.evaluation.evaluator]: \u001b[0mInference done 858/5000. Dataloading: 0.0019 s/iter. Inference: 0.3895 s/iter. Eval: 0.0197 s/iter. Total: 0.4112 s/iter. ETA=0:28:23\n",
            "\u001b[32m[04/30 13:38:20 d2.evaluation.evaluator]: \u001b[0mInference done 870/5000. Dataloading: 0.0020 s/iter. Inference: 0.3897 s/iter. Eval: 0.0196 s/iter. Total: 0.4113 s/iter. ETA=0:28:18\n",
            "\u001b[32m[04/30 13:38:26 d2.evaluation.evaluator]: \u001b[0mInference done 882/5000. Dataloading: 0.0019 s/iter. Inference: 0.3899 s/iter. Eval: 0.0195 s/iter. Total: 0.4114 s/iter. ETA=0:28:14\n",
            "\u001b[32m[04/30 13:38:31 d2.evaluation.evaluator]: \u001b[0mInference done 894/5000. Dataloading: 0.0019 s/iter. Inference: 0.3901 s/iter. Eval: 0.0195 s/iter. Total: 0.4116 s/iter. ETA=0:28:10\n",
            "\u001b[32m[04/30 13:38:36 d2.evaluation.evaluator]: \u001b[0mInference done 906/5000. Dataloading: 0.0020 s/iter. Inference: 0.3902 s/iter. Eval: 0.0195 s/iter. Total: 0.4118 s/iter. ETA=0:28:05\n",
            "\u001b[32m[04/30 13:38:41 d2.evaluation.evaluator]: \u001b[0mInference done 918/5000. Dataloading: 0.0020 s/iter. Inference: 0.3904 s/iter. Eval: 0.0195 s/iter. Total: 0.4119 s/iter. ETA=0:28:01\n",
            "\u001b[32m[04/30 13:38:46 d2.evaluation.evaluator]: \u001b[0mInference done 930/5000. Dataloading: 0.0019 s/iter. Inference: 0.3905 s/iter. Eval: 0.0195 s/iter. Total: 0.4120 s/iter. ETA=0:27:57\n",
            "\u001b[32m[04/30 13:38:51 d2.evaluation.evaluator]: \u001b[0mInference done 942/5000. Dataloading: 0.0019 s/iter. Inference: 0.3907 s/iter. Eval: 0.0194 s/iter. Total: 0.4121 s/iter. ETA=0:27:52\n",
            "\u001b[32m[04/30 13:38:56 d2.evaluation.evaluator]: \u001b[0mInference done 954/5000. Dataloading: 0.0019 s/iter. Inference: 0.3909 s/iter. Eval: 0.0193 s/iter. Total: 0.4123 s/iter. ETA=0:27:48\n",
            "\u001b[32m[04/30 13:39:01 d2.evaluation.evaluator]: \u001b[0mInference done 966/5000. Dataloading: 0.0019 s/iter. Inference: 0.3911 s/iter. Eval: 0.0193 s/iter. Total: 0.4125 s/iter. ETA=0:27:43\n",
            "\u001b[32m[04/30 13:39:06 d2.evaluation.evaluator]: \u001b[0mInference done 978/5000. Dataloading: 0.0019 s/iter. Inference: 0.3912 s/iter. Eval: 0.0194 s/iter. Total: 0.4127 s/iter. ETA=0:27:39\n",
            "\u001b[32m[04/30 13:39:11 d2.evaluation.evaluator]: \u001b[0mInference done 990/5000. Dataloading: 0.0019 s/iter. Inference: 0.3914 s/iter. Eval: 0.0194 s/iter. Total: 0.4129 s/iter. ETA=0:27:35\n",
            "\u001b[32m[04/30 13:39:17 d2.evaluation.evaluator]: \u001b[0mInference done 1003/5000. Dataloading: 0.0019 s/iter. Inference: 0.3916 s/iter. Eval: 0.0193 s/iter. Total: 0.4129 s/iter. ETA=0:27:30\n",
            "\u001b[32m[04/30 13:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 1015/5000. Dataloading: 0.0019 s/iter. Inference: 0.3917 s/iter. Eval: 0.0192 s/iter. Total: 0.4130 s/iter. ETA=0:27:25\n",
            "\u001b[32m[04/30 13:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 1027/5000. Dataloading: 0.0019 s/iter. Inference: 0.3919 s/iter. Eval: 0.0194 s/iter. Total: 0.4133 s/iter. ETA=0:27:22\n",
            "\u001b[32m[04/30 13:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 1039/5000. Dataloading: 0.0020 s/iter. Inference: 0.3920 s/iter. Eval: 0.0194 s/iter. Total: 0.4135 s/iter. ETA=0:27:17\n",
            "\u001b[32m[04/30 13:39:37 d2.evaluation.evaluator]: \u001b[0mInference done 1051/5000. Dataloading: 0.0020 s/iter. Inference: 0.3922 s/iter. Eval: 0.0194 s/iter. Total: 0.4136 s/iter. ETA=0:27:13\n",
            "\u001b[32m[04/30 13:39:43 d2.evaluation.evaluator]: \u001b[0mInference done 1063/5000. Dataloading: 0.0020 s/iter. Inference: 0.3924 s/iter. Eval: 0.0194 s/iter. Total: 0.4138 s/iter. ETA=0:27:09\n",
            "\u001b[32m[04/30 13:39:48 d2.evaluation.evaluator]: \u001b[0mInference done 1075/5000. Dataloading: 0.0020 s/iter. Inference: 0.3926 s/iter. Eval: 0.0194 s/iter. Total: 0.4140 s/iter. ETA=0:27:05\n",
            "\u001b[32m[04/30 13:39:53 d2.evaluation.evaluator]: \u001b[0mInference done 1087/5000. Dataloading: 0.0020 s/iter. Inference: 0.3927 s/iter. Eval: 0.0194 s/iter. Total: 0.4142 s/iter. ETA=0:27:00\n",
            "\u001b[32m[04/30 13:39:58 d2.evaluation.evaluator]: \u001b[0mInference done 1099/5000. Dataloading: 0.0020 s/iter. Inference: 0.3928 s/iter. Eval: 0.0194 s/iter. Total: 0.4143 s/iter. ETA=0:26:56\n",
            "\u001b[32m[04/30 13:40:03 d2.evaluation.evaluator]: \u001b[0mInference done 1111/5000. Dataloading: 0.0020 s/iter. Inference: 0.3930 s/iter. Eval: 0.0194 s/iter. Total: 0.4144 s/iter. ETA=0:26:51\n",
            "\u001b[32m[04/30 13:40:08 d2.evaluation.evaluator]: \u001b[0mInference done 1123/5000. Dataloading: 0.0020 s/iter. Inference: 0.3931 s/iter. Eval: 0.0193 s/iter. Total: 0.4147 s/iter. ETA=0:26:47\n",
            "\u001b[32m[04/30 13:40:14 d2.evaluation.evaluator]: \u001b[0mInference done 1135/5000. Dataloading: 0.0020 s/iter. Inference: 0.3933 s/iter. Eval: 0.0193 s/iter. Total: 0.4149 s/iter. ETA=0:26:43\n",
            "\u001b[32m[04/30 13:40:19 d2.evaluation.evaluator]: \u001b[0mInference done 1147/5000. Dataloading: 0.0020 s/iter. Inference: 0.3934 s/iter. Eval: 0.0193 s/iter. Total: 0.4150 s/iter. ETA=0:26:38\n",
            "\u001b[32m[04/30 13:40:24 d2.evaluation.evaluator]: \u001b[0mInference done 1159/5000. Dataloading: 0.0020 s/iter. Inference: 0.3935 s/iter. Eval: 0.0194 s/iter. Total: 0.4152 s/iter. ETA=0:26:34\n",
            "\u001b[32m[04/30 13:40:29 d2.evaluation.evaluator]: \u001b[0mInference done 1171/5000. Dataloading: 0.0020 s/iter. Inference: 0.3937 s/iter. Eval: 0.0195 s/iter. Total: 0.4155 s/iter. ETA=0:26:30\n",
            "\u001b[32m[04/30 13:40:34 d2.evaluation.evaluator]: \u001b[0mInference done 1183/5000. Dataloading: 0.0020 s/iter. Inference: 0.3938 s/iter. Eval: 0.0195 s/iter. Total: 0.4156 s/iter. ETA=0:26:26\n",
            "\u001b[32m[04/30 13:40:39 d2.evaluation.evaluator]: \u001b[0mInference done 1195/5000. Dataloading: 0.0020 s/iter. Inference: 0.3939 s/iter. Eval: 0.0195 s/iter. Total: 0.4157 s/iter. ETA=0:26:21\n",
            "\u001b[32m[04/30 13:40:45 d2.evaluation.evaluator]: \u001b[0mInference done 1207/5000. Dataloading: 0.0020 s/iter. Inference: 0.3941 s/iter. Eval: 0.0197 s/iter. Total: 0.4161 s/iter. ETA=0:26:18\n",
            "\u001b[32m[04/30 13:40:50 d2.evaluation.evaluator]: \u001b[0mInference done 1219/5000. Dataloading: 0.0020 s/iter. Inference: 0.3942 s/iter. Eval: 0.0198 s/iter. Total: 0.4162 s/iter. ETA=0:26:13\n",
            "\u001b[32m[04/30 13:40:55 d2.evaluation.evaluator]: \u001b[0mInference done 1231/5000. Dataloading: 0.0020 s/iter. Inference: 0.3943 s/iter. Eval: 0.0198 s/iter. Total: 0.4164 s/iter. ETA=0:26:09\n",
            "\u001b[32m[04/30 13:41:00 d2.evaluation.evaluator]: \u001b[0mInference done 1243/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0198 s/iter. Total: 0.4165 s/iter. ETA=0:26:04\n",
            "\u001b[32m[04/30 13:41:06 d2.evaluation.evaluator]: \u001b[0mInference done 1255/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0199 s/iter. Total: 0.4167 s/iter. ETA=0:26:00\n",
            "\u001b[32m[04/30 13:41:11 d2.evaluation.evaluator]: \u001b[0mInference done 1268/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0199 s/iter. Total: 0.4167 s/iter. ETA=0:25:54\n",
            "\u001b[32m[04/30 13:41:16 d2.evaluation.evaluator]: \u001b[0mInference done 1280/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0199 s/iter. Total: 0.4168 s/iter. ETA=0:25:50\n",
            "\u001b[32m[04/30 13:41:21 d2.evaluation.evaluator]: \u001b[0mInference done 1292/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0198 s/iter. Total: 0.4169 s/iter. ETA=0:25:45\n",
            "\u001b[32m[04/30 13:41:26 d2.evaluation.evaluator]: \u001b[0mInference done 1304/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0198 s/iter. Total: 0.4169 s/iter. ETA=0:25:40\n",
            "\u001b[32m[04/30 13:41:31 d2.evaluation.evaluator]: \u001b[0mInference done 1316/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0198 s/iter. Total: 0.4169 s/iter. ETA=0:25:36\n",
            "\u001b[32m[04/30 13:41:37 d2.evaluation.evaluator]: \u001b[0mInference done 1329/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0198 s/iter. Total: 0.4170 s/iter. ETA=0:25:30\n",
            "\u001b[32m[04/30 13:41:42 d2.evaluation.evaluator]: \u001b[0mInference done 1341/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0199 s/iter. Total: 0.4172 s/iter. ETA=0:25:26\n",
            "\u001b[32m[04/30 13:41:47 d2.evaluation.evaluator]: \u001b[0mInference done 1353/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0200 s/iter. Total: 0.4174 s/iter. ETA=0:25:22\n",
            "\u001b[32m[04/30 13:41:52 d2.evaluation.evaluator]: \u001b[0mInference done 1365/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0199 s/iter. Total: 0.4174 s/iter. ETA=0:25:17\n",
            "\u001b[32m[04/30 13:41:57 d2.evaluation.evaluator]: \u001b[0mInference done 1377/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0199 s/iter. Total: 0.4174 s/iter. ETA=0:25:12\n",
            "\u001b[32m[04/30 13:42:02 d2.evaluation.evaluator]: \u001b[0mInference done 1389/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0199 s/iter. Total: 0.4175 s/iter. ETA=0:25:07\n",
            "\u001b[32m[04/30 13:42:08 d2.evaluation.evaluator]: \u001b[0mInference done 1401/5000. Dataloading: 0.0020 s/iter. Inference: 0.3954 s/iter. Eval: 0.0199 s/iter. Total: 0.4175 s/iter. ETA=0:25:02\n",
            "\u001b[32m[04/30 13:42:13 d2.evaluation.evaluator]: \u001b[0mInference done 1414/5000. Dataloading: 0.0020 s/iter. Inference: 0.3954 s/iter. Eval: 0.0198 s/iter. Total: 0.4175 s/iter. ETA=0:24:57\n",
            "\u001b[32m[04/30 13:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 1426/5000. Dataloading: 0.0020 s/iter. Inference: 0.3955 s/iter. Eval: 0.0199 s/iter. Total: 0.4176 s/iter. ETA=0:24:52\n",
            "\u001b[32m[04/30 13:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 1438/5000. Dataloading: 0.0020 s/iter. Inference: 0.3956 s/iter. Eval: 0.0199 s/iter. Total: 0.4177 s/iter. ETA=0:24:47\n",
            "\u001b[32m[04/30 13:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 1450/5000. Dataloading: 0.0020 s/iter. Inference: 0.3957 s/iter. Eval: 0.0198 s/iter. Total: 0.4178 s/iter. ETA=0:24:43\n",
            "\u001b[32m[04/30 13:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 1462/5000. Dataloading: 0.0020 s/iter. Inference: 0.3957 s/iter. Eval: 0.0198 s/iter. Total: 0.4178 s/iter. ETA=0:24:38\n",
            "\u001b[32m[04/30 13:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 1474/5000. Dataloading: 0.0020 s/iter. Inference: 0.3957 s/iter. Eval: 0.0198 s/iter. Total: 0.4178 s/iter. ETA=0:24:33\n",
            "\u001b[32m[04/30 13:42:44 d2.evaluation.evaluator]: \u001b[0mInference done 1486/5000. Dataloading: 0.0020 s/iter. Inference: 0.3958 s/iter. Eval: 0.0199 s/iter. Total: 0.4180 s/iter. ETA=0:24:28\n",
            "\u001b[32m[04/30 13:42:49 d2.evaluation.evaluator]: \u001b[0mInference done 1498/5000. Dataloading: 0.0020 s/iter. Inference: 0.3959 s/iter. Eval: 0.0199 s/iter. Total: 0.4180 s/iter. ETA=0:24:23\n",
            "\u001b[32m[04/30 13:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 1510/5000. Dataloading: 0.0020 s/iter. Inference: 0.3959 s/iter. Eval: 0.0199 s/iter. Total: 0.4181 s/iter. ETA=0:24:19\n",
            "\u001b[32m[04/30 13:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 1522/5000. Dataloading: 0.0020 s/iter. Inference: 0.3960 s/iter. Eval: 0.0199 s/iter. Total: 0.4181 s/iter. ETA=0:24:14\n",
            "\u001b[32m[04/30 13:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 1534/5000. Dataloading: 0.0020 s/iter. Inference: 0.3960 s/iter. Eval: 0.0199 s/iter. Total: 0.4181 s/iter. ETA=0:24:09\n",
            "\u001b[32m[04/30 13:43:09 d2.evaluation.evaluator]: \u001b[0mInference done 1546/5000. Dataloading: 0.0020 s/iter. Inference: 0.3961 s/iter. Eval: 0.0199 s/iter. Total: 0.4183 s/iter. ETA=0:24:04\n",
            "\u001b[32m[04/30 13:43:14 d2.evaluation.evaluator]: \u001b[0mInference done 1558/5000. Dataloading: 0.0020 s/iter. Inference: 0.3962 s/iter. Eval: 0.0199 s/iter. Total: 0.4184 s/iter. ETA=0:24:00\n",
            "\u001b[32m[04/30 13:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 1570/5000. Dataloading: 0.0020 s/iter. Inference: 0.3963 s/iter. Eval: 0.0199 s/iter. Total: 0.4185 s/iter. ETA=0:23:55\n",
            "\u001b[32m[04/30 13:43:25 d2.evaluation.evaluator]: \u001b[0mInference done 1582/5000. Dataloading: 0.0020 s/iter. Inference: 0.3963 s/iter. Eval: 0.0199 s/iter. Total: 0.4185 s/iter. ETA=0:23:50\n",
            "\u001b[32m[04/30 13:43:30 d2.evaluation.evaluator]: \u001b[0mInference done 1594/5000. Dataloading: 0.0020 s/iter. Inference: 0.3965 s/iter. Eval: 0.0200 s/iter. Total: 0.4187 s/iter. ETA=0:23:46\n",
            "\u001b[32m[04/30 13:43:35 d2.evaluation.evaluator]: \u001b[0mInference done 1606/5000. Dataloading: 0.0020 s/iter. Inference: 0.3965 s/iter. Eval: 0.0201 s/iter. Total: 0.4188 s/iter. ETA=0:23:41\n",
            "\u001b[32m[04/30 13:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 1619/5000. Dataloading: 0.0020 s/iter. Inference: 0.3966 s/iter. Eval: 0.0200 s/iter. Total: 0.4188 s/iter. ETA=0:23:36\n",
            "\u001b[32m[04/30 13:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 1631/5000. Dataloading: 0.0020 s/iter. Inference: 0.3966 s/iter. Eval: 0.0200 s/iter. Total: 0.4188 s/iter. ETA=0:23:31\n",
            "\u001b[32m[04/30 13:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 1643/5000. Dataloading: 0.0020 s/iter. Inference: 0.3967 s/iter. Eval: 0.0200 s/iter. Total: 0.4189 s/iter. ETA=0:23:26\n",
            "\u001b[32m[04/30 13:43:56 d2.evaluation.evaluator]: \u001b[0mInference done 1655/5000. Dataloading: 0.0020 s/iter. Inference: 0.3967 s/iter. Eval: 0.0200 s/iter. Total: 0.4189 s/iter. ETA=0:23:21\n",
            "\u001b[32m[04/30 13:44:01 d2.evaluation.evaluator]: \u001b[0mInference done 1667/5000. Dataloading: 0.0020 s/iter. Inference: 0.3968 s/iter. Eval: 0.0200 s/iter. Total: 0.4190 s/iter. ETA=0:23:16\n",
            "\u001b[32m[04/30 13:44:06 d2.evaluation.evaluator]: \u001b[0mInference done 1679/5000. Dataloading: 0.0020 s/iter. Inference: 0.3969 s/iter. Eval: 0.0200 s/iter. Total: 0.4191 s/iter. ETA=0:23:11\n",
            "\u001b[32m[04/30 13:44:11 d2.evaluation.evaluator]: \u001b[0mInference done 1691/5000. Dataloading: 0.0020 s/iter. Inference: 0.3969 s/iter. Eval: 0.0200 s/iter. Total: 0.4191 s/iter. ETA=0:23:06\n",
            "\u001b[32m[04/30 13:44:16 d2.evaluation.evaluator]: \u001b[0mInference done 1703/5000. Dataloading: 0.0020 s/iter. Inference: 0.3970 s/iter. Eval: 0.0199 s/iter. Total: 0.4192 s/iter. ETA=0:23:01\n",
            "\u001b[32m[04/30 13:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 1715/5000. Dataloading: 0.0020 s/iter. Inference: 0.3970 s/iter. Eval: 0.0200 s/iter. Total: 0.4192 s/iter. ETA=0:22:57\n",
            "\u001b[32m[04/30 13:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 1727/5000. Dataloading: 0.0020 s/iter. Inference: 0.3971 s/iter. Eval: 0.0200 s/iter. Total: 0.4193 s/iter. ETA=0:22:52\n",
            "\u001b[32m[04/30 13:44:32 d2.evaluation.evaluator]: \u001b[0mInference done 1740/5000. Dataloading: 0.0020 s/iter. Inference: 0.3971 s/iter. Eval: 0.0199 s/iter. Total: 0.4193 s/iter. ETA=0:22:46\n",
            "\u001b[32m[04/30 13:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 1752/5000. Dataloading: 0.0020 s/iter. Inference: 0.3972 s/iter. Eval: 0.0199 s/iter. Total: 0.4193 s/iter. ETA=0:22:41\n",
            "\u001b[32m[04/30 13:44:42 d2.evaluation.evaluator]: \u001b[0mInference done 1764/5000. Dataloading: 0.0020 s/iter. Inference: 0.3973 s/iter. Eval: 0.0198 s/iter. Total: 0.4193 s/iter. ETA=0:22:36\n",
            "\u001b[32m[04/30 13:44:48 d2.evaluation.evaluator]: \u001b[0mInference done 1777/5000. Dataloading: 0.0020 s/iter. Inference: 0.3973 s/iter. Eval: 0.0198 s/iter. Total: 0.4193 s/iter. ETA=0:22:31\n",
            "\u001b[32m[04/30 13:44:53 d2.evaluation.evaluator]: \u001b[0mInference done 1789/5000. Dataloading: 0.0020 s/iter. Inference: 0.3973 s/iter. Eval: 0.0198 s/iter. Total: 0.4193 s/iter. ETA=0:22:26\n",
            "\u001b[32m[04/30 13:44:58 d2.evaluation.evaluator]: \u001b[0mInference done 1801/5000. Dataloading: 0.0020 s/iter. Inference: 0.3973 s/iter. Eval: 0.0198 s/iter. Total: 0.4193 s/iter. ETA=0:22:21\n",
            "\u001b[32m[04/30 13:45:03 d2.evaluation.evaluator]: \u001b[0mInference done 1813/5000. Dataloading: 0.0020 s/iter. Inference: 0.3974 s/iter. Eval: 0.0198 s/iter. Total: 0.4194 s/iter. ETA=0:22:16\n",
            "\u001b[32m[04/30 13:45:08 d2.evaluation.evaluator]: \u001b[0mInference done 1825/5000. Dataloading: 0.0020 s/iter. Inference: 0.3975 s/iter. Eval: 0.0198 s/iter. Total: 0.4195 s/iter. ETA=0:22:12\n",
            "\u001b[32m[04/30 13:45:13 d2.evaluation.evaluator]: \u001b[0mInference done 1837/5000. Dataloading: 0.0020 s/iter. Inference: 0.3975 s/iter. Eval: 0.0198 s/iter. Total: 0.4196 s/iter. ETA=0:22:07\n",
            "\u001b[32m[04/30 13:45:18 d2.evaluation.evaluator]: \u001b[0mInference done 1849/5000. Dataloading: 0.0020 s/iter. Inference: 0.3975 s/iter. Eval: 0.0199 s/iter. Total: 0.4196 s/iter. ETA=0:22:02\n",
            "\u001b[32m[04/30 13:45:24 d2.evaluation.evaluator]: \u001b[0mInference done 1861/5000. Dataloading: 0.0020 s/iter. Inference: 0.3976 s/iter. Eval: 0.0199 s/iter. Total: 0.4197 s/iter. ETA=0:21:57\n",
            "\u001b[32m[04/30 13:45:29 d2.evaluation.evaluator]: \u001b[0mInference done 1873/5000. Dataloading: 0.0020 s/iter. Inference: 0.3976 s/iter. Eval: 0.0199 s/iter. Total: 0.4197 s/iter. ETA=0:21:52\n",
            "\u001b[32m[04/30 13:45:34 d2.evaluation.evaluator]: \u001b[0mInference done 1885/5000. Dataloading: 0.0020 s/iter. Inference: 0.3977 s/iter. Eval: 0.0199 s/iter. Total: 0.4197 s/iter. ETA=0:21:47\n",
            "\u001b[32m[04/30 13:45:39 d2.evaluation.evaluator]: \u001b[0mInference done 1897/5000. Dataloading: 0.0020 s/iter. Inference: 0.3977 s/iter. Eval: 0.0198 s/iter. Total: 0.4198 s/iter. ETA=0:21:42\n",
            "\u001b[32m[04/30 13:45:44 d2.evaluation.evaluator]: \u001b[0mInference done 1909/5000. Dataloading: 0.0020 s/iter. Inference: 0.3978 s/iter. Eval: 0.0198 s/iter. Total: 0.4198 s/iter. ETA=0:21:37\n",
            "\u001b[32m[04/30 13:45:49 d2.evaluation.evaluator]: \u001b[0mInference done 1922/5000. Dataloading: 0.0020 s/iter. Inference: 0.3978 s/iter. Eval: 0.0198 s/iter. Total: 0.4198 s/iter. ETA=0:21:32\n",
            "\u001b[32m[04/30 13:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 1934/5000. Dataloading: 0.0020 s/iter. Inference: 0.3978 s/iter. Eval: 0.0198 s/iter. Total: 0.4198 s/iter. ETA=0:21:27\n",
            "\u001b[32m[04/30 13:46:00 d2.evaluation.evaluator]: \u001b[0mInference done 1947/5000. Dataloading: 0.0020 s/iter. Inference: 0.3978 s/iter. Eval: 0.0197 s/iter. Total: 0.4198 s/iter. ETA=0:21:21\n",
            "\u001b[32m[04/30 13:46:05 d2.evaluation.evaluator]: \u001b[0mInference done 1959/5000. Dataloading: 0.0020 s/iter. Inference: 0.3979 s/iter. Eval: 0.0197 s/iter. Total: 0.4198 s/iter. ETA=0:21:16\n",
            "\u001b[32m[04/30 13:46:10 d2.evaluation.evaluator]: \u001b[0mInference done 1971/5000. Dataloading: 0.0020 s/iter. Inference: 0.3979 s/iter. Eval: 0.0197 s/iter. Total: 0.4198 s/iter. ETA=0:21:11\n",
            "\u001b[32m[04/30 13:46:15 d2.evaluation.evaluator]: \u001b[0mInference done 1983/5000. Dataloading: 0.0020 s/iter. Inference: 0.3979 s/iter. Eval: 0.0198 s/iter. Total: 0.4199 s/iter. ETA=0:21:06\n",
            "\u001b[32m[04/30 13:46:20 d2.evaluation.evaluator]: \u001b[0mInference done 1995/5000. Dataloading: 0.0020 s/iter. Inference: 0.3980 s/iter. Eval: 0.0198 s/iter. Total: 0.4200 s/iter. ETA=0:21:01\n",
            "\u001b[32m[04/30 13:46:26 d2.evaluation.evaluator]: \u001b[0mInference done 2007/5000. Dataloading: 0.0020 s/iter. Inference: 0.3980 s/iter. Eval: 0.0198 s/iter. Total: 0.4200 s/iter. ETA=0:20:57\n",
            "\u001b[32m[04/30 13:46:31 d2.evaluation.evaluator]: \u001b[0mInference done 2019/5000. Dataloading: 0.0020 s/iter. Inference: 0.3981 s/iter. Eval: 0.0198 s/iter. Total: 0.4201 s/iter. ETA=0:20:52\n",
            "\u001b[32m[04/30 13:46:36 d2.evaluation.evaluator]: \u001b[0mInference done 2031/5000. Dataloading: 0.0020 s/iter. Inference: 0.3981 s/iter. Eval: 0.0198 s/iter. Total: 0.4201 s/iter. ETA=0:20:47\n",
            "\u001b[32m[04/30 13:46:41 d2.evaluation.evaluator]: \u001b[0mInference done 2043/5000. Dataloading: 0.0020 s/iter. Inference: 0.3981 s/iter. Eval: 0.0198 s/iter. Total: 0.4202 s/iter. ETA=0:20:42\n",
            "\u001b[32m[04/30 13:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 2055/5000. Dataloading: 0.0020 s/iter. Inference: 0.3982 s/iter. Eval: 0.0198 s/iter. Total: 0.4202 s/iter. ETA=0:20:37\n",
            "\u001b[32m[04/30 13:46:51 d2.evaluation.evaluator]: \u001b[0mInference done 2067/5000. Dataloading: 0.0020 s/iter. Inference: 0.3982 s/iter. Eval: 0.0198 s/iter. Total: 0.4202 s/iter. ETA=0:20:32\n",
            "\u001b[32m[04/30 13:46:57 d2.evaluation.evaluator]: \u001b[0mInference done 2080/5000. Dataloading: 0.0020 s/iter. Inference: 0.3982 s/iter. Eval: 0.0197 s/iter. Total: 0.4202 s/iter. ETA=0:20:26\n",
            "\u001b[32m[04/30 13:47:02 d2.evaluation.evaluator]: \u001b[0mInference done 2092/5000. Dataloading: 0.0020 s/iter. Inference: 0.3983 s/iter. Eval: 0.0197 s/iter. Total: 0.4202 s/iter. ETA=0:20:21\n",
            "\u001b[32m[04/30 13:47:07 d2.evaluation.evaluator]: \u001b[0mInference done 2104/5000. Dataloading: 0.0020 s/iter. Inference: 0.3983 s/iter. Eval: 0.0197 s/iter. Total: 0.4202 s/iter. ETA=0:20:17\n",
            "\u001b[32m[04/30 13:47:12 d2.evaluation.evaluator]: \u001b[0mInference done 2116/5000. Dataloading: 0.0020 s/iter. Inference: 0.3984 s/iter. Eval: 0.0198 s/iter. Total: 0.4203 s/iter. ETA=0:20:12\n",
            "\u001b[32m[04/30 13:47:17 d2.evaluation.evaluator]: \u001b[0mInference done 2129/5000. Dataloading: 0.0020 s/iter. Inference: 0.3984 s/iter. Eval: 0.0197 s/iter. Total: 0.4203 s/iter. ETA=0:20:06\n",
            "\u001b[32m[04/30 13:47:22 d2.evaluation.evaluator]: \u001b[0mInference done 2141/5000. Dataloading: 0.0020 s/iter. Inference: 0.3984 s/iter. Eval: 0.0197 s/iter. Total: 0.4203 s/iter. ETA=0:20:01\n",
            "\u001b[32m[04/30 13:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 2153/5000. Dataloading: 0.0020 s/iter. Inference: 0.3984 s/iter. Eval: 0.0197 s/iter. Total: 0.4203 s/iter. ETA=0:19:56\n",
            "\u001b[32m[04/30 13:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 2165/5000. Dataloading: 0.0020 s/iter. Inference: 0.3984 s/iter. Eval: 0.0197 s/iter. Total: 0.4203 s/iter. ETA=0:19:51\n",
            "\u001b[32m[04/30 13:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 2177/5000. Dataloading: 0.0020 s/iter. Inference: 0.3984 s/iter. Eval: 0.0197 s/iter. Total: 0.4204 s/iter. ETA=0:19:46\n",
            "\u001b[32m[04/30 13:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 2190/5000. Dataloading: 0.0020 s/iter. Inference: 0.3984 s/iter. Eval: 0.0197 s/iter. Total: 0.4203 s/iter. ETA=0:19:41\n",
            "\u001b[32m[04/30 13:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 2202/5000. Dataloading: 0.0020 s/iter. Inference: 0.3985 s/iter. Eval: 0.0197 s/iter. Total: 0.4204 s/iter. ETA=0:19:36\n",
            "\u001b[32m[04/30 13:47:53 d2.evaluation.evaluator]: \u001b[0mInference done 2214/5000. Dataloading: 0.0020 s/iter. Inference: 0.3985 s/iter. Eval: 0.0197 s/iter. Total: 0.4204 s/iter. ETA=0:19:31\n",
            "\u001b[32m[04/30 13:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 2226/5000. Dataloading: 0.0020 s/iter. Inference: 0.3986 s/iter. Eval: 0.0197 s/iter. Total: 0.4205 s/iter. ETA=0:19:26\n",
            "\u001b[32m[04/30 13:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 2238/5000. Dataloading: 0.0020 s/iter. Inference: 0.3986 s/iter. Eval: 0.0197 s/iter. Total: 0.4205 s/iter. ETA=0:19:21\n",
            "\u001b[32m[04/30 13:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 2250/5000. Dataloading: 0.0020 s/iter. Inference: 0.3987 s/iter. Eval: 0.0197 s/iter. Total: 0.4206 s/iter. ETA=0:19:16\n",
            "\u001b[32m[04/30 13:48:14 d2.evaluation.evaluator]: \u001b[0mInference done 2262/5000. Dataloading: 0.0020 s/iter. Inference: 0.3988 s/iter. Eval: 0.0197 s/iter. Total: 0.4207 s/iter. ETA=0:19:11\n",
            "\u001b[32m[04/30 13:48:20 d2.evaluation.evaluator]: \u001b[0mInference done 2275/5000. Dataloading: 0.0020 s/iter. Inference: 0.3988 s/iter. Eval: 0.0197 s/iter. Total: 0.4207 s/iter. ETA=0:19:06\n",
            "\u001b[32m[04/30 13:48:25 d2.evaluation.evaluator]: \u001b[0mInference done 2288/5000. Dataloading: 0.0020 s/iter. Inference: 0.3989 s/iter. Eval: 0.0196 s/iter. Total: 0.4207 s/iter. ETA=0:19:00\n",
            "\u001b[32m[04/30 13:48:30 d2.evaluation.evaluator]: \u001b[0mInference done 2301/5000. Dataloading: 0.0020 s/iter. Inference: 0.3988 s/iter. Eval: 0.0196 s/iter. Total: 0.4206 s/iter. ETA=0:18:55\n",
            "\u001b[32m[04/30 13:48:36 d2.evaluation.evaluator]: \u001b[0mInference done 2313/5000. Dataloading: 0.0020 s/iter. Inference: 0.3989 s/iter. Eval: 0.0196 s/iter. Total: 0.4206 s/iter. ETA=0:18:50\n",
            "\u001b[32m[04/30 13:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 2325/5000. Dataloading: 0.0020 s/iter. Inference: 0.3989 s/iter. Eval: 0.0196 s/iter. Total: 0.4207 s/iter. ETA=0:18:45\n",
            "\u001b[32m[04/30 13:48:46 d2.evaluation.evaluator]: \u001b[0mInference done 2338/5000. Dataloading: 0.0020 s/iter. Inference: 0.3989 s/iter. Eval: 0.0195 s/iter. Total: 0.4206 s/iter. ETA=0:18:39\n",
            "\u001b[32m[04/30 13:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 2350/5000. Dataloading: 0.0020 s/iter. Inference: 0.3990 s/iter. Eval: 0.0195 s/iter. Total: 0.4206 s/iter. ETA=0:18:34\n",
            "\u001b[32m[04/30 13:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 2362/5000. Dataloading: 0.0020 s/iter. Inference: 0.3990 s/iter. Eval: 0.0195 s/iter. Total: 0.4207 s/iter. ETA=0:18:29\n",
            "\u001b[32m[04/30 13:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 2374/5000. Dataloading: 0.0020 s/iter. Inference: 0.3990 s/iter. Eval: 0.0195 s/iter. Total: 0.4207 s/iter. ETA=0:18:24\n",
            "\u001b[32m[04/30 13:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 2386/5000. Dataloading: 0.0020 s/iter. Inference: 0.3991 s/iter. Eval: 0.0195 s/iter. Total: 0.4207 s/iter. ETA=0:18:19\n",
            "\u001b[32m[04/30 13:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 2398/5000. Dataloading: 0.0020 s/iter. Inference: 0.3991 s/iter. Eval: 0.0195 s/iter. Total: 0.4208 s/iter. ETA=0:18:14\n",
            "\u001b[32m[04/30 13:49:17 d2.evaluation.evaluator]: \u001b[0mInference done 2410/5000. Dataloading: 0.0020 s/iter. Inference: 0.3991 s/iter. Eval: 0.0195 s/iter. Total: 0.4208 s/iter. ETA=0:18:09\n",
            "\u001b[32m[04/30 13:49:22 d2.evaluation.evaluator]: \u001b[0mInference done 2422/5000. Dataloading: 0.0020 s/iter. Inference: 0.3992 s/iter. Eval: 0.0195 s/iter. Total: 0.4209 s/iter. ETA=0:18:05\n",
            "\u001b[32m[04/30 13:49:27 d2.evaluation.evaluator]: \u001b[0mInference done 2434/5000. Dataloading: 0.0020 s/iter. Inference: 0.3992 s/iter. Eval: 0.0196 s/iter. Total: 0.4209 s/iter. ETA=0:18:00\n",
            "\u001b[32m[04/30 13:49:32 d2.evaluation.evaluator]: \u001b[0mInference done 2446/5000. Dataloading: 0.0020 s/iter. Inference: 0.3992 s/iter. Eval: 0.0195 s/iter. Total: 0.4210 s/iter. ETA=0:17:55\n",
            "\u001b[32m[04/30 13:49:37 d2.evaluation.evaluator]: \u001b[0mInference done 2458/5000. Dataloading: 0.0020 s/iter. Inference: 0.3993 s/iter. Eval: 0.0195 s/iter. Total: 0.4210 s/iter. ETA=0:17:50\n",
            "\u001b[32m[04/30 13:49:42 d2.evaluation.evaluator]: \u001b[0mInference done 2470/5000. Dataloading: 0.0020 s/iter. Inference: 0.3993 s/iter. Eval: 0.0195 s/iter. Total: 0.4210 s/iter. ETA=0:17:45\n",
            "\u001b[32m[04/30 13:49:48 d2.evaluation.evaluator]: \u001b[0mInference done 2482/5000. Dataloading: 0.0020 s/iter. Inference: 0.3993 s/iter. Eval: 0.0195 s/iter. Total: 0.4210 s/iter. ETA=0:17:40\n",
            "\u001b[32m[04/30 13:49:53 d2.evaluation.evaluator]: \u001b[0mInference done 2494/5000. Dataloading: 0.0020 s/iter. Inference: 0.3993 s/iter. Eval: 0.0195 s/iter. Total: 0.4210 s/iter. ETA=0:17:35\n",
            "\u001b[32m[04/30 13:49:58 d2.evaluation.evaluator]: \u001b[0mInference done 2506/5000. Dataloading: 0.0020 s/iter. Inference: 0.3993 s/iter. Eval: 0.0195 s/iter. Total: 0.4210 s/iter. ETA=0:17:30\n",
            "\u001b[32m[04/30 13:50:03 d2.evaluation.evaluator]: \u001b[0mInference done 2518/5000. Dataloading: 0.0020 s/iter. Inference: 0.3993 s/iter. Eval: 0.0196 s/iter. Total: 0.4211 s/iter. ETA=0:17:25\n",
            "\u001b[32m[04/30 13:50:08 d2.evaluation.evaluator]: \u001b[0mInference done 2530/5000. Dataloading: 0.0020 s/iter. Inference: 0.3993 s/iter. Eval: 0.0196 s/iter. Total: 0.4211 s/iter. ETA=0:17:20\n",
            "\u001b[32m[04/30 13:50:13 d2.evaluation.evaluator]: \u001b[0mInference done 2542/5000. Dataloading: 0.0020 s/iter. Inference: 0.3994 s/iter. Eval: 0.0196 s/iter. Total: 0.4211 s/iter. ETA=0:17:15\n",
            "\u001b[32m[04/30 13:50:18 d2.evaluation.evaluator]: \u001b[0mInference done 2554/5000. Dataloading: 0.0020 s/iter. Inference: 0.3994 s/iter. Eval: 0.0196 s/iter. Total: 0.4212 s/iter. ETA=0:17:10\n",
            "\u001b[32m[04/30 13:50:24 d2.evaluation.evaluator]: \u001b[0mInference done 2566/5000. Dataloading: 0.0020 s/iter. Inference: 0.3995 s/iter. Eval: 0.0196 s/iter. Total: 0.4212 s/iter. ETA=0:17:05\n",
            "\u001b[32m[04/30 13:50:29 d2.evaluation.evaluator]: \u001b[0mInference done 2578/5000. Dataloading: 0.0020 s/iter. Inference: 0.3995 s/iter. Eval: 0.0197 s/iter. Total: 0.4213 s/iter. ETA=0:17:00\n",
            "\u001b[32m[04/30 13:50:34 d2.evaluation.evaluator]: \u001b[0mInference done 2591/5000. Dataloading: 0.0020 s/iter. Inference: 0.3995 s/iter. Eval: 0.0197 s/iter. Total: 0.4213 s/iter. ETA=0:16:54\n",
            "\u001b[32m[04/30 13:50:39 d2.evaluation.evaluator]: \u001b[0mInference done 2603/5000. Dataloading: 0.0020 s/iter. Inference: 0.3995 s/iter. Eval: 0.0196 s/iter. Total: 0.4213 s/iter. ETA=0:16:49\n",
            "\u001b[32m[04/30 13:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 2615/5000. Dataloading: 0.0020 s/iter. Inference: 0.3995 s/iter. Eval: 0.0197 s/iter. Total: 0.4214 s/iter. ETA=0:16:44\n",
            "\u001b[32m[04/30 13:50:50 d2.evaluation.evaluator]: \u001b[0mInference done 2627/5000. Dataloading: 0.0020 s/iter. Inference: 0.3995 s/iter. Eval: 0.0197 s/iter. Total: 0.4214 s/iter. ETA=0:16:39\n",
            "\u001b[32m[04/30 13:50:55 d2.evaluation.evaluator]: \u001b[0mInference done 2639/5000. Dataloading: 0.0020 s/iter. Inference: 0.3996 s/iter. Eval: 0.0197 s/iter. Total: 0.4215 s/iter. ETA=0:16:35\n",
            "\u001b[32m[04/30 13:51:00 d2.evaluation.evaluator]: \u001b[0mInference done 2651/5000. Dataloading: 0.0020 s/iter. Inference: 0.3996 s/iter. Eval: 0.0197 s/iter. Total: 0.4215 s/iter. ETA=0:16:30\n",
            "\u001b[32m[04/30 13:51:05 d2.evaluation.evaluator]: \u001b[0mInference done 2663/5000. Dataloading: 0.0020 s/iter. Inference: 0.3996 s/iter. Eval: 0.0197 s/iter. Total: 0.4215 s/iter. ETA=0:16:25\n",
            "\u001b[32m[04/30 13:51:10 d2.evaluation.evaluator]: \u001b[0mInference done 2675/5000. Dataloading: 0.0020 s/iter. Inference: 0.3997 s/iter. Eval: 0.0197 s/iter. Total: 0.4215 s/iter. ETA=0:16:20\n",
            "\u001b[32m[04/30 13:51:15 d2.evaluation.evaluator]: \u001b[0mInference done 2687/5000. Dataloading: 0.0020 s/iter. Inference: 0.3997 s/iter. Eval: 0.0197 s/iter. Total: 0.4216 s/iter. ETA=0:16:15\n",
            "\u001b[32m[04/30 13:51:21 d2.evaluation.evaluator]: \u001b[0mInference done 2700/5000. Dataloading: 0.0020 s/iter. Inference: 0.3997 s/iter. Eval: 0.0196 s/iter. Total: 0.4215 s/iter. ETA=0:16:09\n",
            "\u001b[32m[04/30 13:51:26 d2.evaluation.evaluator]: \u001b[0mInference done 2712/5000. Dataloading: 0.0020 s/iter. Inference: 0.3998 s/iter. Eval: 0.0196 s/iter. Total: 0.4215 s/iter. ETA=0:16:04\n",
            "\u001b[32m[04/30 13:51:31 d2.evaluation.evaluator]: \u001b[0mInference done 2724/5000. Dataloading: 0.0020 s/iter. Inference: 0.3998 s/iter. Eval: 0.0196 s/iter. Total: 0.4216 s/iter. ETA=0:15:59\n",
            "\u001b[32m[04/30 13:51:36 d2.evaluation.evaluator]: \u001b[0mInference done 2736/5000. Dataloading: 0.0020 s/iter. Inference: 0.3998 s/iter. Eval: 0.0196 s/iter. Total: 0.4216 s/iter. ETA=0:15:54\n",
            "\u001b[32m[04/30 13:51:41 d2.evaluation.evaluator]: \u001b[0mInference done 2748/5000. Dataloading: 0.0020 s/iter. Inference: 0.3998 s/iter. Eval: 0.0196 s/iter. Total: 0.4215 s/iter. ETA=0:15:49\n",
            "\u001b[32m[04/30 13:51:46 d2.evaluation.evaluator]: \u001b[0mInference done 2760/5000. Dataloading: 0.0020 s/iter. Inference: 0.3998 s/iter. Eval: 0.0196 s/iter. Total: 0.4216 s/iter. ETA=0:15:44\n",
            "\u001b[32m[04/30 13:51:51 d2.evaluation.evaluator]: \u001b[0mInference done 2772/5000. Dataloading: 0.0020 s/iter. Inference: 0.3999 s/iter. Eval: 0.0196 s/iter. Total: 0.4216 s/iter. ETA=0:15:39\n",
            "\u001b[32m[04/30 13:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 2784/5000. Dataloading: 0.0020 s/iter. Inference: 0.3999 s/iter. Eval: 0.0196 s/iter. Total: 0.4216 s/iter. ETA=0:15:34\n",
            "\u001b[32m[04/30 13:52:01 d2.evaluation.evaluator]: \u001b[0mInference done 2796/5000. Dataloading: 0.0020 s/iter. Inference: 0.3999 s/iter. Eval: 0.0196 s/iter. Total: 0.4216 s/iter. ETA=0:15:29\n",
            "\u001b[32m[04/30 13:52:07 d2.evaluation.evaluator]: \u001b[0mInference done 2808/5000. Dataloading: 0.0020 s/iter. Inference: 0.3999 s/iter. Eval: 0.0196 s/iter. Total: 0.4216 s/iter. ETA=0:15:24\n",
            "\u001b[32m[04/30 13:52:12 d2.evaluation.evaluator]: \u001b[0mInference done 2820/5000. Dataloading: 0.0020 s/iter. Inference: 0.3999 s/iter. Eval: 0.0196 s/iter. Total: 0.4217 s/iter. ETA=0:15:19\n",
            "\u001b[32m[04/30 13:52:17 d2.evaluation.evaluator]: \u001b[0mInference done 2832/5000. Dataloading: 0.0020 s/iter. Inference: 0.3999 s/iter. Eval: 0.0196 s/iter. Total: 0.4217 s/iter. ETA=0:15:14\n",
            "\u001b[32m[04/30 13:52:22 d2.evaluation.evaluator]: \u001b[0mInference done 2844/5000. Dataloading: 0.0020 s/iter. Inference: 0.4000 s/iter. Eval: 0.0196 s/iter. Total: 0.4217 s/iter. ETA=0:15:09\n",
            "\u001b[32m[04/30 13:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 2856/5000. Dataloading: 0.0020 s/iter. Inference: 0.4000 s/iter. Eval: 0.0196 s/iter. Total: 0.4217 s/iter. ETA=0:15:04\n",
            "\u001b[32m[04/30 13:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 2868/5000. Dataloading: 0.0020 s/iter. Inference: 0.4000 s/iter. Eval: 0.0196 s/iter. Total: 0.4218 s/iter. ETA=0:14:59\n",
            "\u001b[32m[04/30 13:52:37 d2.evaluation.evaluator]: \u001b[0mInference done 2880/5000. Dataloading: 0.0020 s/iter. Inference: 0.4000 s/iter. Eval: 0.0196 s/iter. Total: 0.4218 s/iter. ETA=0:14:54\n",
            "\u001b[32m[04/30 13:52:42 d2.evaluation.evaluator]: \u001b[0mInference done 2892/5000. Dataloading: 0.0020 s/iter. Inference: 0.4001 s/iter. Eval: 0.0196 s/iter. Total: 0.4218 s/iter. ETA=0:14:49\n",
            "\u001b[32m[04/30 13:52:48 d2.evaluation.evaluator]: \u001b[0mInference done 2904/5000. Dataloading: 0.0020 s/iter. Inference: 0.4001 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:44\n",
            "\u001b[32m[04/30 13:52:53 d2.evaluation.evaluator]: \u001b[0mInference done 2916/5000. Dataloading: 0.0020 s/iter. Inference: 0.4001 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:39\n",
            "\u001b[32m[04/30 13:52:58 d2.evaluation.evaluator]: \u001b[0mInference done 2928/5000. Dataloading: 0.0020 s/iter. Inference: 0.4001 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:34\n",
            "\u001b[32m[04/30 13:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 2940/5000. Dataloading: 0.0020 s/iter. Inference: 0.4001 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:29\n",
            "\u001b[32m[04/30 13:53:08 d2.evaluation.evaluator]: \u001b[0mInference done 2952/5000. Dataloading: 0.0020 s/iter. Inference: 0.4001 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:24\n",
            "\u001b[32m[04/30 13:53:13 d2.evaluation.evaluator]: \u001b[0mInference done 2964/5000. Dataloading: 0.0020 s/iter. Inference: 0.4001 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:19\n",
            "\u001b[32m[04/30 13:53:19 d2.evaluation.evaluator]: \u001b[0mInference done 2977/5000. Dataloading: 0.0020 s/iter. Inference: 0.4002 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:13\n",
            "\u001b[32m[04/30 13:53:24 d2.evaluation.evaluator]: \u001b[0mInference done 2989/5000. Dataloading: 0.0020 s/iter. Inference: 0.4002 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:08\n",
            "\u001b[32m[04/30 13:53:29 d2.evaluation.evaluator]: \u001b[0mInference done 3001/5000. Dataloading: 0.0020 s/iter. Inference: 0.4002 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:14:03\n",
            "\u001b[32m[04/30 13:53:34 d2.evaluation.evaluator]: \u001b[0mInference done 3014/5000. Dataloading: 0.0020 s/iter. Inference: 0.4002 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:13:57\n",
            "\u001b[32m[04/30 13:53:39 d2.evaluation.evaluator]: \u001b[0mInference done 3026/5000. Dataloading: 0.0020 s/iter. Inference: 0.4002 s/iter. Eval: 0.0196 s/iter. Total: 0.4219 s/iter. ETA=0:13:52\n",
            "\u001b[32m[04/30 13:53:45 d2.evaluation.evaluator]: \u001b[0mInference done 3038/5000. Dataloading: 0.0020 s/iter. Inference: 0.4002 s/iter. Eval: 0.0196 s/iter. Total: 0.4220 s/iter. ETA=0:13:47\n",
            "\u001b[32m[04/30 13:53:50 d2.evaluation.evaluator]: \u001b[0mInference done 3050/5000. Dataloading: 0.0020 s/iter. Inference: 0.4003 s/iter. Eval: 0.0195 s/iter. Total: 0.4220 s/iter. ETA=0:13:42\n",
            "\u001b[32m[04/30 13:53:55 d2.evaluation.evaluator]: \u001b[0mInference done 3062/5000. Dataloading: 0.0020 s/iter. Inference: 0.4003 s/iter. Eval: 0.0195 s/iter. Total: 0.4220 s/iter. ETA=0:13:37\n",
            "\u001b[32m[04/30 13:54:00 d2.evaluation.evaluator]: \u001b[0mInference done 3074/5000. Dataloading: 0.0020 s/iter. Inference: 0.4003 s/iter. Eval: 0.0195 s/iter. Total: 0.4220 s/iter. ETA=0:13:32\n",
            "\u001b[32m[04/30 13:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 3086/5000. Dataloading: 0.0020 s/iter. Inference: 0.4004 s/iter. Eval: 0.0195 s/iter. Total: 0.4220 s/iter. ETA=0:13:27\n",
            "\u001b[32m[04/30 13:54:10 d2.evaluation.evaluator]: \u001b[0mInference done 3098/5000. Dataloading: 0.0020 s/iter. Inference: 0.4004 s/iter. Eval: 0.0195 s/iter. Total: 0.4220 s/iter. ETA=0:13:22\n",
            "\u001b[32m[04/30 13:54:15 d2.evaluation.evaluator]: \u001b[0mInference done 3110/5000. Dataloading: 0.0020 s/iter. Inference: 0.4004 s/iter. Eval: 0.0195 s/iter. Total: 0.4220 s/iter. ETA=0:13:17\n",
            "\u001b[32m[04/30 13:54:20 d2.evaluation.evaluator]: \u001b[0mInference done 3122/5000. Dataloading: 0.0020 s/iter. Inference: 0.4004 s/iter. Eval: 0.0195 s/iter. Total: 0.4220 s/iter. ETA=0:13:12\n",
            "\u001b[32m[04/30 13:54:25 d2.evaluation.evaluator]: \u001b[0mInference done 3134/5000. Dataloading: 0.0020 s/iter. Inference: 0.4004 s/iter. Eval: 0.0195 s/iter. Total: 0.4221 s/iter. ETA=0:13:07\n",
            "\u001b[32m[04/30 13:54:31 d2.evaluation.evaluator]: \u001b[0mInference done 3146/5000. Dataloading: 0.0020 s/iter. Inference: 0.4004 s/iter. Eval: 0.0195 s/iter. Total: 0.4221 s/iter. ETA=0:13:02\n",
            "\u001b[32m[04/30 13:54:36 d2.evaluation.evaluator]: \u001b[0mInference done 3159/5000. Dataloading: 0.0020 s/iter. Inference: 0.4004 s/iter. Eval: 0.0195 s/iter. Total: 0.4221 s/iter. ETA=0:12:57\n",
            "\u001b[32m[04/30 13:54:41 d2.evaluation.evaluator]: \u001b[0mInference done 3172/5000. Dataloading: 0.0020 s/iter. Inference: 0.4005 s/iter. Eval: 0.0194 s/iter. Total: 0.4220 s/iter. ETA=0:12:51\n",
            "\u001b[32m[04/30 13:54:46 d2.evaluation.evaluator]: \u001b[0mInference done 3184/5000. Dataloading: 0.0020 s/iter. Inference: 0.4005 s/iter. Eval: 0.0194 s/iter. Total: 0.4221 s/iter. ETA=0:12:46\n",
            "\u001b[32m[04/30 13:54:52 d2.evaluation.evaluator]: \u001b[0mInference done 3196/5000. Dataloading: 0.0020 s/iter. Inference: 0.4005 s/iter. Eval: 0.0194 s/iter. Total: 0.4221 s/iter. ETA=0:12:41\n",
            "\u001b[32m[04/30 13:54:57 d2.evaluation.evaluator]: \u001b[0mInference done 3208/5000. Dataloading: 0.0020 s/iter. Inference: 0.4005 s/iter. Eval: 0.0195 s/iter. Total: 0.4221 s/iter. ETA=0:12:36\n",
            "\u001b[32m[04/30 13:55:02 d2.evaluation.evaluator]: \u001b[0mInference done 3220/5000. Dataloading: 0.0020 s/iter. Inference: 0.4005 s/iter. Eval: 0.0195 s/iter. Total: 0.4222 s/iter. ETA=0:12:31\n",
            "\u001b[32m[04/30 13:55:07 d2.evaluation.evaluator]: \u001b[0mInference done 3232/5000. Dataloading: 0.0020 s/iter. Inference: 0.4005 s/iter. Eval: 0.0195 s/iter. Total: 0.4222 s/iter. ETA=0:12:26\n",
            "\u001b[32m[04/30 13:55:12 d2.evaluation.evaluator]: \u001b[0mInference done 3244/5000. Dataloading: 0.0020 s/iter. Inference: 0.4006 s/iter. Eval: 0.0195 s/iter. Total: 0.4222 s/iter. ETA=0:12:21\n",
            "\u001b[32m[04/30 13:55:17 d2.evaluation.evaluator]: \u001b[0mInference done 3256/5000. Dataloading: 0.0020 s/iter. Inference: 0.4006 s/iter. Eval: 0.0195 s/iter. Total: 0.4222 s/iter. ETA=0:12:16\n",
            "\u001b[32m[04/30 13:55:23 d2.evaluation.evaluator]: \u001b[0mInference done 3268/5000. Dataloading: 0.0020 s/iter. Inference: 0.4006 s/iter. Eval: 0.0195 s/iter. Total: 0.4223 s/iter. ETA=0:12:11\n",
            "\u001b[32m[04/30 13:55:28 d2.evaluation.evaluator]: \u001b[0mInference done 3280/5000. Dataloading: 0.0020 s/iter. Inference: 0.4006 s/iter. Eval: 0.0195 s/iter. Total: 0.4223 s/iter. ETA=0:12:06\n",
            "\u001b[32m[04/30 13:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 3292/5000. Dataloading: 0.0020 s/iter. Inference: 0.4007 s/iter. Eval: 0.0196 s/iter. Total: 0.4224 s/iter. ETA=0:12:01\n",
            "\u001b[32m[04/30 13:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 3304/5000. Dataloading: 0.0020 s/iter. Inference: 0.4007 s/iter. Eval: 0.0196 s/iter. Total: 0.4224 s/iter. ETA=0:11:56\n",
            "\u001b[32m[04/30 13:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 3316/5000. Dataloading: 0.0020 s/iter. Inference: 0.4007 s/iter. Eval: 0.0196 s/iter. Total: 0.4225 s/iter. ETA=0:11:51\n",
            "\u001b[32m[04/30 13:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 3328/5000. Dataloading: 0.0020 s/iter. Inference: 0.4007 s/iter. Eval: 0.0196 s/iter. Total: 0.4225 s/iter. ETA=0:11:46\n",
            "\u001b[32m[04/30 13:55:54 d2.evaluation.evaluator]: \u001b[0mInference done 3341/5000. Dataloading: 0.0020 s/iter. Inference: 0.4007 s/iter. Eval: 0.0196 s/iter. Total: 0.4225 s/iter. ETA=0:11:40\n",
            "\u001b[32m[04/30 13:55:59 d2.evaluation.evaluator]: \u001b[0mInference done 3353/5000. Dataloading: 0.0020 s/iter. Inference: 0.4007 s/iter. Eval: 0.0196 s/iter. Total: 0.4225 s/iter. ETA=0:11:35\n",
            "\u001b[32m[04/30 13:56:05 d2.evaluation.evaluator]: \u001b[0mInference done 3365/5000. Dataloading: 0.0020 s/iter. Inference: 0.4008 s/iter. Eval: 0.0197 s/iter. Total: 0.4226 s/iter. ETA=0:11:30\n",
            "\u001b[32m[04/30 13:56:10 d2.evaluation.evaluator]: \u001b[0mInference done 3377/5000. Dataloading: 0.0020 s/iter. Inference: 0.4008 s/iter. Eval: 0.0197 s/iter. Total: 0.4226 s/iter. ETA=0:11:25\n",
            "\u001b[32m[04/30 13:56:15 d2.evaluation.evaluator]: \u001b[0mInference done 3390/5000. Dataloading: 0.0020 s/iter. Inference: 0.4008 s/iter. Eval: 0.0197 s/iter. Total: 0.4226 s/iter. ETA=0:11:20\n",
            "\u001b[32m[04/30 13:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 3403/5000. Dataloading: 0.0020 s/iter. Inference: 0.4008 s/iter. Eval: 0.0196 s/iter. Total: 0.4226 s/iter. ETA=0:11:14\n",
            "\u001b[32m[04/30 13:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 3415/5000. Dataloading: 0.0020 s/iter. Inference: 0.4008 s/iter. Eval: 0.0196 s/iter. Total: 0.4226 s/iter. ETA=0:11:09\n",
            "\u001b[32m[04/30 13:56:31 d2.evaluation.evaluator]: \u001b[0mInference done 3427/5000. Dataloading: 0.0020 s/iter. Inference: 0.4008 s/iter. Eval: 0.0196 s/iter. Total: 0.4226 s/iter. ETA=0:11:04\n",
            "\u001b[32m[04/30 13:56:36 d2.evaluation.evaluator]: \u001b[0mInference done 3439/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4227 s/iter. ETA=0:10:59\n",
            "\u001b[32m[04/30 13:56:41 d2.evaluation.evaluator]: \u001b[0mInference done 3451/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4227 s/iter. ETA=0:10:54\n",
            "\u001b[32m[04/30 13:56:47 d2.evaluation.evaluator]: \u001b[0mInference done 3463/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4227 s/iter. ETA=0:10:49\n",
            "\u001b[32m[04/30 13:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 3475/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4227 s/iter. ETA=0:10:44\n",
            "\u001b[32m[04/30 13:56:57 d2.evaluation.evaluator]: \u001b[0mInference done 3488/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4227 s/iter. ETA=0:10:39\n",
            "\u001b[32m[04/30 13:57:02 d2.evaluation.evaluator]: \u001b[0mInference done 3500/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:10:34\n",
            "\u001b[32m[04/30 13:57:07 d2.evaluation.evaluator]: \u001b[0mInference done 3512/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:10:29\n",
            "\u001b[32m[04/30 13:57:13 d2.evaluation.evaluator]: \u001b[0mInference done 3525/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:10:23\n",
            "\u001b[32m[04/30 13:57:18 d2.evaluation.evaluator]: \u001b[0mInference done 3537/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4227 s/iter. ETA=0:10:18\n",
            "\u001b[32m[04/30 13:57:23 d2.evaluation.evaluator]: \u001b[0mInference done 3549/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:10:13\n",
            "\u001b[32m[04/30 13:57:28 d2.evaluation.evaluator]: \u001b[0mInference done 3561/5000. Dataloading: 0.0020 s/iter. Inference: 0.4009 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:10:08\n",
            "\u001b[32m[04/30 13:57:33 d2.evaluation.evaluator]: \u001b[0mInference done 3573/5000. Dataloading: 0.0020 s/iter. Inference: 0.4010 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:10:03\n",
            "\u001b[32m[04/30 13:57:38 d2.evaluation.evaluator]: \u001b[0mInference done 3585/5000. Dataloading: 0.0020 s/iter. Inference: 0.4010 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:09:58\n",
            "\u001b[32m[04/30 13:57:44 d2.evaluation.evaluator]: \u001b[0mInference done 3597/5000. Dataloading: 0.0020 s/iter. Inference: 0.4010 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:09:53\n",
            "\u001b[32m[04/30 13:57:49 d2.evaluation.evaluator]: \u001b[0mInference done 3609/5000. Dataloading: 0.0020 s/iter. Inference: 0.4010 s/iter. Eval: 0.0197 s/iter. Total: 0.4229 s/iter. ETA=0:09:48\n",
            "\u001b[32m[04/30 13:57:54 d2.evaluation.evaluator]: \u001b[0mInference done 3622/5000. Dataloading: 0.0020 s/iter. Inference: 0.4010 s/iter. Eval: 0.0197 s/iter. Total: 0.4228 s/iter. ETA=0:09:42\n",
            "\u001b[32m[04/30 13:57:59 d2.evaluation.evaluator]: \u001b[0mInference done 3634/5000. Dataloading: 0.0020 s/iter. Inference: 0.4010 s/iter. Eval: 0.0197 s/iter. Total: 0.4229 s/iter. ETA=0:09:37\n",
            "\u001b[32m[04/30 13:58:04 d2.evaluation.evaluator]: \u001b[0mInference done 3646/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0197 s/iter. Total: 0.4229 s/iter. ETA=0:09:32\n",
            "\u001b[32m[04/30 13:58:10 d2.evaluation.evaluator]: \u001b[0mInference done 3658/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0197 s/iter. Total: 0.4229 s/iter. ETA=0:09:27\n",
            "\u001b[32m[04/30 13:58:15 d2.evaluation.evaluator]: \u001b[0mInference done 3670/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0197 s/iter. Total: 0.4229 s/iter. ETA=0:09:22\n",
            "\u001b[32m[04/30 13:58:20 d2.evaluation.evaluator]: \u001b[0mInference done 3682/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0196 s/iter. Total: 0.4229 s/iter. ETA=0:09:17\n",
            "\u001b[32m[04/30 13:58:25 d2.evaluation.evaluator]: \u001b[0mInference done 3694/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0197 s/iter. Total: 0.4229 s/iter. ETA=0:09:12\n",
            "\u001b[32m[04/30 13:58:30 d2.evaluation.evaluator]: \u001b[0mInference done 3706/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0197 s/iter. Total: 0.4229 s/iter. ETA=0:09:07\n",
            "\u001b[32m[04/30 13:58:35 d2.evaluation.evaluator]: \u001b[0mInference done 3719/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0196 s/iter. Total: 0.4229 s/iter. ETA=0:09:01\n",
            "\u001b[32m[04/30 13:58:41 d2.evaluation.evaluator]: \u001b[0mInference done 3731/5000. Dataloading: 0.0020 s/iter. Inference: 0.4011 s/iter. Eval: 0.0196 s/iter. Total: 0.4229 s/iter. ETA=0:08:56\n",
            "\u001b[32m[04/30 13:58:46 d2.evaluation.evaluator]: \u001b[0mInference done 3743/5000. Dataloading: 0.0020 s/iter. Inference: 0.4012 s/iter. Eval: 0.0196 s/iter. Total: 0.4230 s/iter. ETA=0:08:51\n",
            "\u001b[32m[04/30 13:58:51 d2.evaluation.evaluator]: \u001b[0mInference done 3755/5000. Dataloading: 0.0020 s/iter. Inference: 0.4012 s/iter. Eval: 0.0196 s/iter. Total: 0.4230 s/iter. ETA=0:08:46\n",
            "\u001b[32m[04/30 13:58:56 d2.evaluation.evaluator]: \u001b[0mInference done 3767/5000. Dataloading: 0.0020 s/iter. Inference: 0.4012 s/iter. Eval: 0.0196 s/iter. Total: 0.4230 s/iter. ETA=0:08:41\n",
            "\u001b[32m[04/30 13:59:01 d2.evaluation.evaluator]: \u001b[0mInference done 3779/5000. Dataloading: 0.0020 s/iter. Inference: 0.4012 s/iter. Eval: 0.0197 s/iter. Total: 0.4230 s/iter. ETA=0:08:36\n",
            "\u001b[32m[04/30 13:59:06 d2.evaluation.evaluator]: \u001b[0mInference done 3791/5000. Dataloading: 0.0020 s/iter. Inference: 0.4012 s/iter. Eval: 0.0197 s/iter. Total: 0.4230 s/iter. ETA=0:08:31\n",
            "\u001b[32m[04/30 13:59:12 d2.evaluation.evaluator]: \u001b[0mInference done 3803/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0197 s/iter. Total: 0.4231 s/iter. ETA=0:08:26\n",
            "\u001b[32m[04/30 13:59:17 d2.evaluation.evaluator]: \u001b[0mInference done 3816/5000. Dataloading: 0.0020 s/iter. Inference: 0.4012 s/iter. Eval: 0.0197 s/iter. Total: 0.4230 s/iter. ETA=0:08:20\n",
            "\u001b[32m[04/30 13:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 3828/5000. Dataloading: 0.0020 s/iter. Inference: 0.4012 s/iter. Eval: 0.0196 s/iter. Total: 0.4230 s/iter. ETA=0:08:15\n",
            "\u001b[32m[04/30 13:59:27 d2.evaluation.evaluator]: \u001b[0mInference done 3840/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4230 s/iter. ETA=0:08:10\n",
            "\u001b[32m[04/30 13:59:32 d2.evaluation.evaluator]: \u001b[0mInference done 3852/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4230 s/iter. ETA=0:08:05\n",
            "\u001b[32m[04/30 13:59:37 d2.evaluation.evaluator]: \u001b[0mInference done 3864/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:08:00\n",
            "\u001b[32m[04/30 13:59:42 d2.evaluation.evaluator]: \u001b[0mInference done 3876/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:55\n",
            "\u001b[32m[04/30 13:59:48 d2.evaluation.evaluator]: \u001b[0mInference done 3889/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:50\n",
            "\u001b[32m[04/30 13:59:53 d2.evaluation.evaluator]: \u001b[0mInference done 3902/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4230 s/iter. ETA=0:07:44\n",
            "\u001b[32m[04/30 13:59:58 d2.evaluation.evaluator]: \u001b[0mInference done 3914/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:39\n",
            "\u001b[32m[04/30 14:00:04 d2.evaluation.evaluator]: \u001b[0mInference done 3926/5000. Dataloading: 0.0020 s/iter. Inference: 0.4013 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:34\n",
            "\u001b[32m[04/30 14:00:09 d2.evaluation.evaluator]: \u001b[0mInference done 3938/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:29\n",
            "\u001b[32m[04/30 14:00:14 d2.evaluation.evaluator]: \u001b[0mInference done 3950/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:24\n",
            "\u001b[32m[04/30 14:00:19 d2.evaluation.evaluator]: \u001b[0mInference done 3962/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:19\n",
            "\u001b[32m[04/30 14:00:24 d2.evaluation.evaluator]: \u001b[0mInference done 3974/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:14\n",
            "\u001b[32m[04/30 14:00:29 d2.evaluation.evaluator]: \u001b[0mInference done 3987/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:08\n",
            "\u001b[32m[04/30 14:00:35 d2.evaluation.evaluator]: \u001b[0mInference done 3999/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:07:03\n",
            "\u001b[32m[04/30 14:00:40 d2.evaluation.evaluator]: \u001b[0mInference done 4011/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:06:58\n",
            "\u001b[32m[04/30 14:00:45 d2.evaluation.evaluator]: \u001b[0mInference done 4023/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4231 s/iter. ETA=0:06:53\n",
            "\u001b[32m[04/30 14:00:50 d2.evaluation.evaluator]: \u001b[0mInference done 4035/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4232 s/iter. ETA=0:06:48\n",
            "\u001b[32m[04/30 14:00:55 d2.evaluation.evaluator]: \u001b[0mInference done 4047/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4232 s/iter. ETA=0:06:43\n",
            "\u001b[32m[04/30 14:01:00 d2.evaluation.evaluator]: \u001b[0mInference done 4059/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0196 s/iter. Total: 0.4232 s/iter. ETA=0:06:38\n",
            "\u001b[32m[04/30 14:01:06 d2.evaluation.evaluator]: \u001b[0mInference done 4071/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0197 s/iter. Total: 0.4232 s/iter. ETA=0:06:33\n",
            "\u001b[32m[04/30 14:01:11 d2.evaluation.evaluator]: \u001b[0mInference done 4083/5000. Dataloading: 0.0020 s/iter. Inference: 0.4014 s/iter. Eval: 0.0197 s/iter. Total: 0.4233 s/iter. ETA=0:06:28\n",
            "\u001b[32m[04/30 14:01:16 d2.evaluation.evaluator]: \u001b[0mInference done 4095/5000. Dataloading: 0.0020 s/iter. Inference: 0.4015 s/iter. Eval: 0.0197 s/iter. Total: 0.4233 s/iter. ETA=0:06:23\n",
            "\u001b[32m[04/30 14:01:21 d2.evaluation.evaluator]: \u001b[0mInference done 4107/5000. Dataloading: 0.0020 s/iter. Inference: 0.4015 s/iter. Eval: 0.0197 s/iter. Total: 0.4233 s/iter. ETA=0:06:17\n",
            "\u001b[32m[04/30 14:01:26 d2.evaluation.evaluator]: \u001b[0mInference done 4119/5000. Dataloading: 0.0020 s/iter. Inference: 0.4015 s/iter. Eval: 0.0196 s/iter. Total: 0.4233 s/iter. ETA=0:06:12\n",
            "\u001b[32m[04/30 14:01:31 d2.evaluation.evaluator]: \u001b[0mInference done 4131/5000. Dataloading: 0.0020 s/iter. Inference: 0.4015 s/iter. Eval: 0.0196 s/iter. Total: 0.4233 s/iter. ETA=0:06:07\n",
            "\u001b[32m[04/30 14:01:36 d2.evaluation.evaluator]: \u001b[0mInference done 4143/5000. Dataloading: 0.0020 s/iter. Inference: 0.4015 s/iter. Eval: 0.0196 s/iter. Total: 0.4233 s/iter. ETA=0:06:02\n",
            "\u001b[32m[04/30 14:01:42 d2.evaluation.evaluator]: \u001b[0mInference done 4155/5000. Dataloading: 0.0020 s/iter. Inference: 0.4015 s/iter. Eval: 0.0197 s/iter. Total: 0.4233 s/iter. ETA=0:05:57\n",
            "\u001b[32m[04/30 14:01:47 d2.evaluation.evaluator]: \u001b[0mInference done 4167/5000. Dataloading: 0.0020 s/iter. Inference: 0.4015 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:05:52\n",
            "\u001b[32m[04/30 14:01:52 d2.evaluation.evaluator]: \u001b[0mInference done 4179/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:05:47\n",
            "\u001b[32m[04/30 14:01:58 d2.evaluation.evaluator]: \u001b[0mInference done 4192/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:05:42\n",
            "\u001b[32m[04/30 14:02:03 d2.evaluation.evaluator]: \u001b[0mInference done 4204/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:05:37\n",
            "\u001b[32m[04/30 14:02:08 d2.evaluation.evaluator]: \u001b[0mInference done 4216/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:05:31\n",
            "\u001b[32m[04/30 14:02:13 d2.evaluation.evaluator]: \u001b[0mInference done 4228/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:05:26\n",
            "\u001b[32m[04/30 14:02:18 d2.evaluation.evaluator]: \u001b[0mInference done 4241/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:05:21\n",
            "\u001b[32m[04/30 14:02:24 d2.evaluation.evaluator]: \u001b[0mInference done 4253/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:05:16\n",
            "\u001b[32m[04/30 14:02:29 d2.evaluation.evaluator]: \u001b[0mInference done 4265/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0198 s/iter. Total: 0.4235 s/iter. ETA=0:05:11\n",
            "\u001b[32m[04/30 14:02:34 d2.evaluation.evaluator]: \u001b[0mInference done 4278/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:05:05\n",
            "\u001b[32m[04/30 14:02:39 d2.evaluation.evaluator]: \u001b[0mInference done 4290/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0198 s/iter. Total: 0.4235 s/iter. ETA=0:05:00\n",
            "\u001b[32m[04/30 14:02:45 d2.evaluation.evaluator]: \u001b[0mInference done 4302/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0198 s/iter. Total: 0.4235 s/iter. ETA=0:04:55\n",
            "\u001b[32m[04/30 14:02:50 d2.evaluation.evaluator]: \u001b[0mInference done 4314/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:04:50\n",
            "\u001b[32m[04/30 14:02:55 d2.evaluation.evaluator]: \u001b[0mInference done 4326/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:04:45\n",
            "\u001b[32m[04/30 14:03:00 d2.evaluation.evaluator]: \u001b[0mInference done 4339/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:04:39\n",
            "\u001b[32m[04/30 14:03:05 d2.evaluation.evaluator]: \u001b[0mInference done 4351/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:04:34\n",
            "\u001b[32m[04/30 14:03:10 d2.evaluation.evaluator]: \u001b[0mInference done 4364/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:04:29\n",
            "\u001b[32m[04/30 14:03:16 d2.evaluation.evaluator]: \u001b[0mInference done 4376/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:04:24\n",
            "\u001b[32m[04/30 14:03:21 d2.evaluation.evaluator]: \u001b[0mInference done 4388/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:04:19\n",
            "\u001b[32m[04/30 14:03:26 d2.evaluation.evaluator]: \u001b[0mInference done 4400/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:04:14\n",
            "\u001b[32m[04/30 14:03:31 d2.evaluation.evaluator]: \u001b[0mInference done 4412/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:04:08\n",
            "\u001b[32m[04/30 14:03:36 d2.evaluation.evaluator]: \u001b[0mInference done 4424/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:04:03\n",
            "\u001b[32m[04/30 14:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 4436/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:03:58\n",
            "\u001b[32m[04/30 14:03:46 d2.evaluation.evaluator]: \u001b[0mInference done 4448/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:03:53\n",
            "\u001b[32m[04/30 14:03:51 d2.evaluation.evaluator]: \u001b[0mInference done 4460/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:03:48\n",
            "\u001b[32m[04/30 14:03:56 d2.evaluation.evaluator]: \u001b[0mInference done 4472/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0197 s/iter. Total: 0.4234 s/iter. ETA=0:03:43\n",
            "\u001b[32m[04/30 14:04:01 d2.evaluation.evaluator]: \u001b[0mInference done 4484/5000. Dataloading: 0.0020 s/iter. Inference: 0.4016 s/iter. Eval: 0.0196 s/iter. Total: 0.4234 s/iter. ETA=0:03:38\n",
            "\u001b[32m[04/30 14:04:06 d2.evaluation.evaluator]: \u001b[0mInference done 4496/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:03:33\n",
            "\u001b[32m[04/30 14:04:12 d2.evaluation.evaluator]: \u001b[0mInference done 4508/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:03:28\n",
            "\u001b[32m[04/30 14:04:17 d2.evaluation.evaluator]: \u001b[0mInference done 4520/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:03:23\n",
            "\u001b[32m[04/30 14:04:22 d2.evaluation.evaluator]: \u001b[0mInference done 4532/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:03:18\n",
            "\u001b[32m[04/30 14:04:27 d2.evaluation.evaluator]: \u001b[0mInference done 4544/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:03:13\n",
            "\u001b[32m[04/30 14:04:32 d2.evaluation.evaluator]: \u001b[0mInference done 4556/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:03:08\n",
            "\u001b[32m[04/30 14:04:37 d2.evaluation.evaluator]: \u001b[0mInference done 4568/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:03:02\n",
            "\u001b[32m[04/30 14:04:42 d2.evaluation.evaluator]: \u001b[0mInference done 4580/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:02:57\n",
            "\u001b[32m[04/30 14:04:48 d2.evaluation.evaluator]: \u001b[0mInference done 4592/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:02:52\n",
            "\u001b[32m[04/30 14:04:53 d2.evaluation.evaluator]: \u001b[0mInference done 4604/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:02:47\n",
            "\u001b[32m[04/30 14:04:58 d2.evaluation.evaluator]: \u001b[0mInference done 4616/5000. Dataloading: 0.0020 s/iter. Inference: 0.4017 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:02:42\n",
            "\u001b[32m[04/30 14:05:03 d2.evaluation.evaluator]: \u001b[0mInference done 4628/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:02:37\n",
            "\u001b[32m[04/30 14:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 4640/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4235 s/iter. ETA=0:02:32\n",
            "\u001b[32m[04/30 14:05:13 d2.evaluation.evaluator]: \u001b[0mInference done 4652/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:02:27\n",
            "\u001b[32m[04/30 14:05:18 d2.evaluation.evaluator]: \u001b[0mInference done 4664/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:02:22\n",
            "\u001b[32m[04/30 14:05:23 d2.evaluation.evaluator]: \u001b[0mInference done 4676/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:02:17\n",
            "\u001b[32m[04/30 14:05:28 d2.evaluation.evaluator]: \u001b[0mInference done 4688/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:02:12\n",
            "\u001b[32m[04/30 14:05:34 d2.evaluation.evaluator]: \u001b[0mInference done 4700/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:02:07\n",
            "\u001b[32m[04/30 14:05:39 d2.evaluation.evaluator]: \u001b[0mInference done 4712/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:02:02\n",
            "\u001b[32m[04/30 14:05:44 d2.evaluation.evaluator]: \u001b[0mInference done 4724/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:56\n",
            "\u001b[32m[04/30 14:05:49 d2.evaluation.evaluator]: \u001b[0mInference done 4736/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:51\n",
            "\u001b[32m[04/30 14:05:54 d2.evaluation.evaluator]: \u001b[0mInference done 4748/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:46\n",
            "\u001b[32m[04/30 14:05:59 d2.evaluation.evaluator]: \u001b[0mInference done 4760/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4237 s/iter. ETA=0:01:41\n",
            "\u001b[32m[04/30 14:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 4772/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:36\n",
            "\u001b[32m[04/30 14:06:09 d2.evaluation.evaluator]: \u001b[0mInference done 4784/5000. Dataloading: 0.0020 s/iter. Inference: 0.4018 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:31\n",
            "\u001b[32m[04/30 14:06:14 d2.evaluation.evaluator]: \u001b[0mInference done 4796/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:26\n",
            "\u001b[32m[04/30 14:06:20 d2.evaluation.evaluator]: \u001b[0mInference done 4808/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0197 s/iter. Total: 0.4237 s/iter. ETA=0:01:21\n",
            "\u001b[32m[04/30 14:06:25 d2.evaluation.evaluator]: \u001b[0mInference done 4820/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:16\n",
            "\u001b[32m[04/30 14:06:30 d2.evaluation.evaluator]: \u001b[0mInference done 4833/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:10\n",
            "\u001b[32m[04/30 14:06:35 d2.evaluation.evaluator]: \u001b[0mInference done 4845/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0197 s/iter. Total: 0.4236 s/iter. ETA=0:01:05\n",
            "\u001b[32m[04/30 14:06:40 d2.evaluation.evaluator]: \u001b[0mInference done 4857/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0196 s/iter. Total: 0.4236 s/iter. ETA=0:01:00\n",
            "\u001b[32m[04/30 14:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 4869/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0196 s/iter. Total: 0.4236 s/iter. ETA=0:00:55\n",
            "\u001b[32m[04/30 14:06:50 d2.evaluation.evaluator]: \u001b[0mInference done 4881/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0196 s/iter. Total: 0.4236 s/iter. ETA=0:00:50\n",
            "\u001b[32m[04/30 14:06:55 d2.evaluation.evaluator]: \u001b[0mInference done 4893/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0196 s/iter. Total: 0.4236 s/iter. ETA=0:00:45\n",
            "\u001b[32m[04/30 14:07:01 d2.evaluation.evaluator]: \u001b[0mInference done 4905/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0196 s/iter. Total: 0.4236 s/iter. ETA=0:00:40\n",
            "\u001b[32m[04/30 14:07:06 d2.evaluation.evaluator]: \u001b[0mInference done 4917/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0197 s/iter. Total: 0.4237 s/iter. ETA=0:00:35\n",
            "\u001b[32m[04/30 14:07:11 d2.evaluation.evaluator]: \u001b[0mInference done 4929/5000. Dataloading: 0.0020 s/iter. Inference: 0.4019 s/iter. Eval: 0.0197 s/iter. Total: 0.4237 s/iter. ETA=0:00:30\n",
            "\u001b[32m[04/30 14:07:16 d2.evaluation.evaluator]: \u001b[0mInference done 4941/5000. Dataloading: 0.0020 s/iter. Inference: 0.4020 s/iter. Eval: 0.0197 s/iter. Total: 0.4237 s/iter. ETA=0:00:24\n",
            "\u001b[32m[04/30 14:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 4953/5000. Dataloading: 0.0020 s/iter. Inference: 0.4020 s/iter. Eval: 0.0197 s/iter. Total: 0.4237 s/iter. ETA=0:00:19\n",
            "\u001b[32m[04/30 14:07:26 d2.evaluation.evaluator]: \u001b[0mInference done 4965/5000. Dataloading: 0.0020 s/iter. Inference: 0.4020 s/iter. Eval: 0.0196 s/iter. Total: 0.4237 s/iter. ETA=0:00:14\n",
            "\u001b[32m[04/30 14:07:32 d2.evaluation.evaluator]: \u001b[0mInference done 4977/5000. Dataloading: 0.0020 s/iter. Inference: 0.4020 s/iter. Eval: 0.0196 s/iter. Total: 0.4237 s/iter. ETA=0:00:09\n",
            "\u001b[32m[04/30 14:07:37 d2.evaluation.evaluator]: \u001b[0mInference done 4989/5000. Dataloading: 0.0020 s/iter. Inference: 0.4020 s/iter. Eval: 0.0196 s/iter. Total: 0.4237 s/iter. ETA=0:00:04\n",
            "\u001b[32m[04/30 14:07:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:35:16.835977 (0.423791 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 14:07:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:33:27 (0.401987 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 14:07:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/30 14:07:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/30 14:07:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.19s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 14:07:46 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/30 14:07:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 8.28 seconds.\n",
            "\u001b[32m[04/30 14:07:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 14:07:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.90 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.646\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.501\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.289\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.498\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.573\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.602\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.422\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.636\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.737\n",
            "\u001b[32m[04/30 14:07:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 46.237 | 64.623 | 50.149 | 28.857 | 49.831 | 58.906 |\n",
            "\u001b[32m[04/30 14:07:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 59.770 | bicycle      | 33.646 | car            | 48.854 |\n",
            "| motorcycle    | 50.276 | airplane     | 71.318 | bus            | 69.074 |\n",
            "| train         | 67.608 | truck        | 40.494 | boat           | 30.846 |\n",
            "| traffic light | 30.997 | fire hydrant | 71.796 | stop sign      | 70.176 |\n",
            "| parking meter | 46.549 | bench        | 27.715 | bird           | 41.201 |\n",
            "| cat           | 73.339 | dog          | 68.959 | horse          | 63.672 |\n",
            "| sheep         | 56.762 | cow          | 61.638 | elephant       | 71.102 |\n",
            "| bear          | 71.154 | zebra        | 70.774 | giraffe        | 72.649 |\n",
            "| backpack      | 17.172 | umbrella     | 45.330 | handbag        | 17.464 |\n",
            "| tie           | 39.678 | suitcase     | 48.401 | frisbee        | 72.504 |\n",
            "| skis          | 30.603 | snowboard    | 44.802 | sports ball    | 51.808 |\n",
            "| kite          | 48.597 | baseball bat | 35.864 | baseball glove | 39.938 |\n",
            "| skateboard    | 59.873 | surfboard    | 44.559 | tennis racket  | 55.082 |\n",
            "| bottle        | 43.663 | wine glass   | 41.368 | cup            | 47.203 |\n",
            "| fork          | 42.446 | knife        | 25.125 | spoon          | 20.559 |\n",
            "| bowl          | 45.020 | banana       | 26.792 | apple          | 24.283 |\n",
            "| sandwich      | 39.009 | orange       | 32.839 | broccoli       | 25.089 |\n",
            "| carrot        | 26.337 | hot dog      | 39.991 | pizza          | 55.685 |\n",
            "| donut         | 54.052 | cake         | 40.592 | chair          | 31.909 |\n",
            "| couch         | 45.792 | potted plant | 28.816 | bed            | 47.121 |\n",
            "| dining table  | 30.966 | toilet       | 66.743 | tv             | 61.085 |\n",
            "| laptop        | 63.619 | mouse        | 64.320 | remote         | 42.078 |\n",
            "| keyboard      | 54.690 | cell phone   | 40.131 | microwave      | 57.373 |\n",
            "| oven          | 35.588 | toaster      | 34.159 | sink           | 39.207 |\n",
            "| refrigerator  | 64.114 | book         | 18.703 | clock          | 53.611 |\n",
            "| vase          | 41.691 | scissors     | 34.158 | teddy bear     | 52.536 |\n",
            "| hair drier    | 6.535  | toothbrush   | 31.924 |                |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=1.26s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 14:07:59 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
            "\u001b[32m[04/30 14:08:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 9.83 seconds.\n",
            "\u001b[32m[04/30 14:08:09 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 14:08:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.93 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.619\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.429\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.551\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.662\n",
            "\u001b[32m[04/30 14:08:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 39.640 | 61.864 | 42.880 | 20.836 | 42.424 | 55.520 |\n",
            "\u001b[32m[04/30 14:08:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 49.000 | bicycle      | 18.976 | car            | 43.559 |\n",
            "| motorcycle    | 36.316 | airplane     | 51.045 | bus            | 64.739 |\n",
            "| train         | 63.662 | truck        | 38.456 | boat           | 24.537 |\n",
            "| traffic light | 29.475 | fire hydrant | 65.524 | stop sign      | 67.308 |\n",
            "| parking meter | 46.539 | bench        | 18.931 | bird           | 33.201 |\n",
            "| cat           | 69.405 | dog          | 61.807 | horse          | 44.022 |\n",
            "| sheep         | 46.791 | cow          | 51.020 | elephant       | 61.154 |\n",
            "| bear          | 66.336 | zebra        | 58.699 | giraffe        | 53.112 |\n",
            "| backpack      | 16.062 | umbrella     | 48.724 | handbag        | 15.252 |\n",
            "| tie           | 34.845 | suitcase     | 47.285 | frisbee        | 66.643 |\n",
            "| skis          | 4.145  | snowboard    | 26.592 | sports ball    | 50.427 |\n",
            "| kite          | 34.849 | baseball bat | 26.633 | baseball glove | 40.004 |\n",
            "| skateboard    | 34.874 | surfboard    | 35.052 | tennis racket  | 58.314 |\n",
            "| bottle        | 39.822 | wine glass   | 34.686 | cup            | 46.155 |\n",
            "| fork          | 19.232 | knife        | 15.385 | spoon          | 13.585 |\n",
            "| bowl          | 40.994 | banana       | 19.844 | apple          | 22.703 |\n",
            "| sandwich      | 41.406 | orange       | 31.671 | broccoli       | 23.017 |\n",
            "| carrot        | 21.660 | hot dog      | 29.421 | pizza          | 51.781 |\n",
            "| donut         | 52.486 | cake         | 40.142 | chair          | 21.244 |\n",
            "| couch         | 36.603 | potted plant | 23.162 | bed            | 35.300 |\n",
            "| dining table  | 16.838 | toilet       | 61.205 | tv             | 61.869 |\n",
            "| laptop        | 59.761 | mouse        | 62.516 | remote         | 36.042 |\n",
            "| keyboard      | 51.605 | cell phone   | 37.641 | microwave      | 58.015 |\n",
            "| oven          | 31.262 | toaster      | 36.148 | sink           | 35.127 |\n",
            "| refrigerator  | 60.299 | book         | 12.884 | clock          | 52.577 |\n",
            "| vase          | 39.579 | scissors     | 22.637 | teddy bear     | 47.533 |\n",
            "| hair drier    | 2.624  | toothbrush   | 21.460 |                |        |\n",
            "\u001b[32m[04/30 14:08:15 d2.engine.defaults]: \u001b[0mEvaluation results for coco_2017_val in csv format:\n",
            "\u001b[32m[04/30 14:08:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/30 14:08:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 14:08:15 d2.evaluation.testing]: \u001b[0mcopypaste: 46.2371,64.6233,50.1493,28.8566,49.8315,58.9055\n",
            "\u001b[32m[04/30 14:08:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[04/30 14:08:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 14:08:15 d2.evaluation.testing]: \u001b[0mcopypaste: 39.6405,61.8638,42.8804,20.8359,42.4238,55.5196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mask_cascade_rcnn_ResNeSt_50 - evaluation results for coco_2017_val in csv format:\n",
        "\n",
        "Task\\metrics  | AP | AP50 | AP75 | APs | APm | APl |\n",
        "--------------|----|------|------|-----|-----|-----|\n",
        "**bbox**    | 46.2371 | 64.6233 | 50.1493 | 28.8566 | 49.8315 | 58.9055 \n",
        "**segm**   | 39.6405 | 61.8638 | 42.8804 | 20.8359 | 42.4238 | 55.5196 \n"
      ],
      "metadata": {
        "id": "uDfdbBFU2E67"
      },
      "id": "uDfdbBFU2E67"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x-62448b9c.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yso-wdzlguq8",
        "outputId": "a6523488-cc2e-4950-e2a2-74171b34a791"
      },
      "id": "Yso-wdzlguq8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command Line Args: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x-62448b9c.pth'], resume=False)\n",
            "\u001b[32m[04/30 14:34:35 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[04/30 14:34:35 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ----------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "numpy                   1.21.6\n",
            "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.5\n",
            "CUDA compiler           CUDA 11.1\n",
            "detectron2 arch flags   7.5\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.11.0+cu113 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           Yes\n",
            "GPU 0                   Tesla T4 (arch=7.5)\n",
            "Driver version          460.32.03\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.12.0+cu113 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
            "fvcore                  0.1.5.post20220414\n",
            "iopath                  0.1.9\n",
            "cv2                     4.1.2\n",
            "----------------------  ----------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.3\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.2\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "\u001b[32m[04/30 14:34:35 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x-62448b9c.pth'], resume=False)\n",
            "\u001b[32m[04/30 14:34:35 detectron2]: \u001b[0mContents of args.config_file=./configs/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x.yaml:\n",
            "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186m../ResNest-Base-RCNN-FPN.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mhttps://s3.us-west-1.wasabisys.com/resnest/detectron/resnest101_detectron-486f69a8.pth\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m101\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mFastRCNNConvFCHead\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m123.68\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m116.779\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m103.939\u001b[39m]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m58.393\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.12\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.375\u001b[39m]\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\u001b[38;5;15m    \u001b[39m\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mRGB\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\n",
            "\u001b[32m[04/30 14:34:35 detectron2]: \u001b[0mRunning with full config:\n",
            "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRGB\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mpolygon\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m672\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m704\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m736\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m768\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mchoice\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnest_fpn_backbone\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGeneralizedRCNN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.68\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.779\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.939\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m58.393\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.12\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.375\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRPN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVG_DOWN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOTTLENECK_WIDTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEEP_STEM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m101\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_NUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFastRCNNConvFCHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_FED_LOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_SIGMOID_CE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x-62448b9c.pth\n",
            "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./output\n",
            "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR_END\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m90000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m60000\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m80000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\n",
            "\u001b[32m[04/30 14:34:36 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[04/30 14:34:36 d2.utils.env]: \u001b[0mUsing a generated random seed 36178936\n",
            "\u001b[32m[04/30 14:34:41 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(\n",
            "      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output2): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral3): Conv2d(\n",
            "      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output3): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral4): Conv2d(\n",
            "      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output4): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral5): Conv2d(\n",
            "      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output5): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNeSt(\n",
            "      (stem): BasicStem(\n",
            "        (conv1_1): Conv2d(\n",
            "          3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv1_2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv1_3): Conv2d(\n",
            "          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): CascadeROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): ModuleList(\n",
            "      (0): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (1): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (2): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): ModuleList(\n",
            "      (0): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (1): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (2): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/30 14:34:41 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from ./checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x-62448b9c.pth ...\n",
            "Traceback (most recent call last):\n",
            "  File \"train_net.py\", line 169, in <module>\n",
            "    args=(args,),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/detectron2/engine/launch.py\", line 82, in launch\n",
            "    main_func(*args)\n",
            "  File \"train_net.py\", line 137, in main\n",
            "    cfg.MODEL.WEIGHTS, resume=args.resume\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fvcore-0.1.5.post20220414-py3.7.egg/fvcore/common/checkpoint.py\", line 227, in resume_or_load\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/detectron2/checkpoint/detection_checkpoint.py\", line 52, in load\n",
            "    ret = super().load(path, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fvcore-0.1.5.post20220414-py3.7.egg/fvcore/common/checkpoint.py\", line 153, in load\n",
            "AssertionError: Checkpoint ./checkpoints/COCO-InstanceSegmentation/mask_cascade_rcnn_ResNeSt_101_FPN_syncBN_1x-62448b9c.pth not found!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mask_cascade_rcnn_ResNeSt_101 - evaluation results for coco_2017_val in csv format:\n",
        "\n",
        "Task\\metrics  | AP | AP50 | AP75 | APs | APm | APl |\n",
        "--------------|----|------|------|-----|-----|-----|\n",
        "**bbox**    | 46.2371 | 64.6233 | 50.1493 | 28.8566 | 49.8315 | 58.9055 \n",
        "**segm**   | 39.6405 | 61.8638 | 42.8804 | 20.8359 | 42.4238 | 55.5196 "
      ],
      "metadata": {
        "id": "3qtFUxrAF4MC"
      },
      "id": "3qtFUxrAF4MC"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/mask_rcnn_ResNeSt_50_FPN_syncBN_1x-f442d863.pth"
      ],
      "metadata": {
        "id": "gD8MnapUX1uK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "901dcebb-3468-4cb4-fa9d-d24dbc7789bc"
      },
      "id": "gD8MnapUX1uK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command Line Args: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/mask_rcnn_ResNeSt_50_FPN_syncBN_1x-f442d863.pth'], resume=False)\n",
            "\u001b[32m[04/30 14:41:08 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[04/30 14:41:09 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ----------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "numpy                   1.21.6\n",
            "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.5\n",
            "CUDA compiler           CUDA 11.1\n",
            "detectron2 arch flags   7.5\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.11.0+cu113 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           Yes\n",
            "GPU 0                   Tesla T4 (arch=7.5)\n",
            "Driver version          460.32.03\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.12.0+cu113 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
            "fvcore                  0.1.5.post20220414\n",
            "iopath                  0.1.9\n",
            "cv2                     4.1.2\n",
            "----------------------  ----------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.3\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.2\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "\u001b[32m[04/30 14:41:09 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/mask_rcnn_ResNeSt_50_FPN_syncBN_1x-f442d863.pth'], resume=False)\n",
            "\u001b[32m[04/30 14:41:09 detectron2]: \u001b[0mContents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_50_FPN_syncBN_1x.yaml:\n",
            "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186m../ResNest-Base-RCNN-FPN.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mhttps://s3.us-west-1.wasabisys.com/resnest/detectron/resnest50_detectron-255b5649.pth\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\u001b[38;5;15m        \u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mFastRCNNConvFCHead\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m123.68\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m116.779\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m103.939\u001b[39m]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m58.393\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.12\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.375\u001b[39m]\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\u001b[38;5;15m    \u001b[39m\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mRGB\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\n",
            "\u001b[32m[04/30 14:41:09 detectron2]: \u001b[0mRunning with full config:\n",
            "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRGB\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mpolygon\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m672\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m704\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m736\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m768\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mchoice\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnest_fpn_backbone\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGeneralizedRCNN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.68\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.779\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.939\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m58.393\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.12\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.375\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRPN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVG_DOWN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOTTLENECK_WIDTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEEP_STEM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_NUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFastRCNNConvFCHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_FED_LOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_SIGMOID_CE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardROIHeads\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./checkpoints/mask_rcnn_ResNeSt_50_FPN_syncBN_1x-f442d863.pth\n",
            "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./output\n",
            "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR_END\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m90000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m60000\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m80000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\n",
            "\u001b[32m[04/30 14:41:09 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[04/30 14:41:09 d2.utils.env]: \u001b[0mUsing a generated random seed 9831620\n",
            "\u001b[32m[04/30 14:41:14 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(\n",
            "      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output2): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral3): Conv2d(\n",
            "      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output3): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral4): Conv2d(\n",
            "      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output4): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral5): Conv2d(\n",
            "      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output5): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNeSt(\n",
            "      (stem): BasicStem(\n",
            "        (conv1_1): Conv2d(\n",
            "          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "        )\n",
            "        (conv1_2): Conv2d(\n",
            "          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "        )\n",
            "        (conv1_3): Conv2d(\n",
            "          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (conv1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (conv4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/30 14:41:14 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from ./checkpoints/mask_rcnn_ResNeSt_50_FPN_syncBN_1x-f442d863.pth ...\n",
            "Traceback (most recent call last):\n",
            "  File \"train_net.py\", line 169, in <module>\n",
            "    args=(args,),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/detectron2/engine/launch.py\", line 82, in launch\n",
            "    main_func(*args)\n",
            "  File \"train_net.py\", line 137, in main\n",
            "    cfg.MODEL.WEIGHTS, resume=args.resume\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fvcore-0.1.5.post20220414-py3.7.egg/fvcore/common/checkpoint.py\", line 227, in resume_or_load\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/detectron2/checkpoint/detection_checkpoint.py\", line 52, in load\n",
            "    ret = super().load(path, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fvcore-0.1.5.post20220414-py3.7.egg/fvcore/common/checkpoint.py\", line 153, in load\n",
            "AssertionError: Checkpoint ./checkpoints/mask_rcnn_ResNeSt_50_FPN_syncBN_1x-f442d863.pth not found!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mask_rcnn_ResNeSt_50 - evaluation results for coco_2017_val in csv format:\n",
        "\n",
        "Task\\metrics  | AP | AP50 | AP75 | APs | APm | APl |\n",
        "--------------|----|------|------|-----|-----|-----|\n",
        "**bbox**    | 46.2371 | 64.6233 | 50.1493 | 28.8566 | 49.8315 | 58.9055 \n",
        "**segm**   | 39.6405 | 61.8638 | 42.8804 | 20.8359 | 42.4238 | 55.5196 "
      ],
      "metadata": {
        "id": "8sBwb_9nF7X3"
      },
      "id": "8sBwb_9nF7X3"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-InstanceSegmentation/mask_rcnn_ResNeSt_101_FPN_syncBN_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/mask_rcnn_ResNeSt_101_FPN_syncBN_1x-528502c6.pth"
      ],
      "metadata": {
        "id": "nIisTojAhX7v"
      },
      "id": "nIisTojAhX7v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "mask_rcnn_ResNeSt_101 - evaluation results for coco_2017_val in csv format:\n",
        "\n",
        "Task\\metrics  | AP | AP50 | AP75 | APs | APm | APl |\n",
        "--------------|----|------|------|-----|-----|-----|\n",
        "**bbox**    | 46.2371 | 64.6233 | 50.1493 | 28.8566 | 49.8315 | 58.9055 \n",
        "**segm**   | 39.6405 | 61.8638 | 42.8804 | 20.8359 | 42.4238 | 55.5196 \n",
        "\n",
        "Overral, the final results match those found in the original paper, the pretrained models thus perform as expected.\n",
        "\n",
        "Method | Backbone  | box mAP% | mask mAP% |\n",
        "------------------|--------------|------------------|------------------|\n",
        "**Mask-RCNN**    | ResNeSt50 | 42.81 |  38.14\n",
        "**Mask-RCNN**   | ResNeSt101 | 45.75 |  40.65\n",
        "**Cascade-RCNN**   | ResNeSt50 | 46.19 |  39.55\n",
        "**Cascade-RCNN** | ResNeSt101 | 48.30 | 41.56 \n",
        "\n",
        "Please consult the final report for additional comments."
      ],
      "metadata": {
        "id": "U_uyv1XbF9Fl"
      },
      "id": "U_uyv1XbF9Fl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Object Detection\n",
        "\n",
        "The object detection task closely ressembles the instance segmentation task, in both cases the dataset evaluated on is COCO and the models are based on a Detectron2 wrapper\n",
        "\n",
        "Like before we will access the necessary file from the drive and run the experiments with Colab and the ResNeSt repository has to be loaded in the drive. We assume that the dataset has already been prepared in the above section and the repository and detectron2 were successfully installed.\n",
        "\n",
        "In the wrapper subsection you will also find both the configuration files as and the weights, for this experiment. Once again the weights need to be downloaded manually and added to the repository, the path should be the following:\n",
        "* ResNeSt-master/d2/checkpoints/COCO-ObjectDetection/someweights.pth\n",
        "\n",
        "The configuration files are available by default when cloning the repository, it is not needed to download them."
      ],
      "metadata": {
        "id": "ZjJ8NEdL5bWJ"
      },
      "id": "ZjJ8NEdL5bWJ"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2/checkpoints/COCO-ObjectDetection/ && ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnQw-ENr_Jj6",
        "outputId": "55908d1a-01e2-4925-92de-a9bc9bfd5f3c"
      },
      "id": "OnQw-ENr_Jj6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x-e9955232.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-ObjectDetection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x-e9955232.pth"
      ],
      "metadata": {
        "id": "B3Mw2iv07qEc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421d6a33-cd38-4fd6-fadb-a5a72c2e15d6"
      },
      "id": "B3Mw2iv07qEc",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command Line Args: Namespace(config_file='./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-ObjectDetection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x-e9955232.pth'], resume=False)\n",
            "\u001b[32m[04/30 15:22:38 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[04/30 15:22:38 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ----------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "numpy                   1.21.6\n",
            "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.5\n",
            "CUDA compiler           CUDA 11.1\n",
            "detectron2 arch flags   7.5\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.11.0+cu113 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           Yes\n",
            "GPU 0                   Tesla T4 (arch=7.5)\n",
            "Driver version          460.32.03\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.12.0+cu113 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
            "fvcore                  0.1.5.post20220414\n",
            "iopath                  0.1.9\n",
            "cv2                     4.1.2\n",
            "----------------------  ----------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.3\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.2\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "\u001b[32m[04/30 15:22:38 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', './checkpoints/COCO-ObjectDetection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x-e9955232.pth'], resume=False)\n",
            "\u001b[32m[04/30 15:22:38 detectron2]: \u001b[0mContents of args.config_file=./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x.yaml:\n",
            "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186m../ResNest-Base-RCNN-FPN.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mhttps://s3.us-west-1.wasabisys.com/resnest/detectron/resnest50_detectron-255b5649.pth\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mFastRCNNConvFCHead\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mSyncBN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m123.68\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m116.779\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m103.939\u001b[39m]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[\u001b[38;5;15m58.393\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.12\u001b[39m,\u001b[38;5;15m \u001b[39m\u001b[38;5;15m57.375\u001b[39m]\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\u001b[38;5;15m    \u001b[39m\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m(640, 800)\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mrange\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mRGB\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrue\n",
            "\n",
            "\u001b[32m[04/30 15:22:39 detectron2]: \u001b[0mRunning with full config:\n",
            "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRGB\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mpolygon\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrange\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnest_fpn_backbone\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGeneralizedRCNN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.68\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.779\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.939\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m58.393\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.12\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m57.375\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mRPN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mAVG_DOWN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOTTLENECK_WIDTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEEP_STEM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRADIX\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFED_LOSS_NUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFastRCNNConvFCHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSyncBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_FED_LOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUSE_SIGMOID_CE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCascadeROIHeads\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./checkpoints/COCO-ObjectDetection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x-e9955232.pth\n",
            "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./output\n",
            "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.02\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR_END\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m90000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m60000\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m80000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\n",
            "\u001b[32m[04/30 15:22:39 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[04/30 15:22:39 d2.utils.env]: \u001b[0mUsing a generated random seed 39170675\n",
            "\u001b[32m[04/30 15:22:44 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(\n",
            "      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output2): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral3): Conv2d(\n",
            "      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output3): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral4): Conv2d(\n",
            "      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output4): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_lateral5): Conv2d(\n",
            "      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fpn_output5): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNeSt(\n",
            "      (stem): BasicStem(\n",
            "        (conv1_1): Conv2d(\n",
            "          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "        )\n",
            "        (conv1_2): Conv2d(\n",
            "          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "        )\n",
            "        (conv1_3): Conv2d(\n",
            "          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): FrozenBatchNorm2d(num_features=32, eps=1e-05)\n",
            "            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut_avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv2): SplAtConv2d(\n",
            "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "            (bn0): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (rsoftmax): rSoftMax()\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): CascadeROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): ModuleList(\n",
            "      (0): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (1): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "      (2): FastRCNNConvFCHead(\n",
            "        (conv1): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (conv4): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "        (fc_relu1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): ModuleList(\n",
            "      (0): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (1): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "      (2): FastRCNNOutputLayers(\n",
            "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/30 15:22:44 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from ./checkpoints/COCO-ObjectDetection/faster_cascade_rcnn_ResNeSt_50_FPN_syncbn_range-scale-1x-e9955232.pth ...\n",
            "\u001b[32m[04/30 15:22:46 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
            "| Names in Model                                  | Names in Checkpoint                                                                                                           | Shapes                                             |\n",
            "|:------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------|\n",
            "| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,1,1)                |\n",
            "| backbone.bottom_up.res2.0.conv2.bn0.*           | backbone.bottom_up.res2.0.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.0.conv2.bn1.*           | backbone.bottom_up.res2.0.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.0.conv2.conv.weight     | backbone.bottom_up.res2.0.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.0.conv2.fc1.*           | backbone.bottom_up.res2.0.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.0.conv2.fc2.*           | backbone.bottom_up.res2.0.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.1.conv2.bn0.*           | backbone.bottom_up.res2.1.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.1.conv2.bn1.*           | backbone.bottom_up.res2.1.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.1.conv2.conv.weight     | backbone.bottom_up.res2.1.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.1.conv2.fc1.*           | backbone.bottom_up.res2.1.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.1.conv2.fc2.*           | backbone.bottom_up.res2.1.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |\n",
            "| backbone.bottom_up.res2.2.conv2.bn0.*           | backbone.bottom_up.res2.2.conv2.bn0.{bias,running_mean,running_var,weight}                                                    | (128,) (128,) (128,) (128,)                        |\n",
            "| backbone.bottom_up.res2.2.conv2.bn1.*           | backbone.bottom_up.res2.2.conv2.bn1.{bias,running_mean,running_var,weight}                                                    | (32,) (32,) (32,) (32,)                            |\n",
            "| backbone.bottom_up.res2.2.conv2.conv.weight     | backbone.bottom_up.res2.2.conv2.conv.weight                                                                                   | (128, 32, 3, 3)                                    |\n",
            "| backbone.bottom_up.res2.2.conv2.fc1.*           | backbone.bottom_up.res2.2.conv2.fc1.{bias,weight}                                                                             | (32,) (32,64,1,1)                                  |\n",
            "| backbone.bottom_up.res2.2.conv2.fc2.*           | backbone.bottom_up.res2.2.conv2.fc2.{bias,weight}                                                                             | (128,) (128,32,1,1)                                |\n",
            "| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |\n",
            "| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv2.bn0.*           | backbone.bottom_up.res3.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.0.conv2.bn1.*           | backbone.bottom_up.res3.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.0.conv2.conv.weight     | backbone.bottom_up.res3.0.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.0.conv2.fc1.*           | backbone.bottom_up.res3.0.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.0.conv2.fc2.*           | backbone.bottom_up.res3.0.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv2.bn0.*           | backbone.bottom_up.res3.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.1.conv2.bn1.*           | backbone.bottom_up.res3.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.1.conv2.conv.weight     | backbone.bottom_up.res3.1.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.1.conv2.fc1.*           | backbone.bottom_up.res3.1.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.1.conv2.fc2.*           | backbone.bottom_up.res3.1.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv2.bn0.*           | backbone.bottom_up.res3.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.2.conv2.bn1.*           | backbone.bottom_up.res3.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.2.conv2.conv.weight     | backbone.bottom_up.res3.2.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.2.conv2.fc1.*           | backbone.bottom_up.res3.2.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.2.conv2.fc2.*           | backbone.bottom_up.res3.2.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv2.bn0.*           | backbone.bottom_up.res3.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res3.3.conv2.bn1.*           | backbone.bottom_up.res3.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (64,) () (64,) (64,) (64,)                         |\n",
            "| backbone.bottom_up.res3.3.conv2.conv.weight     | backbone.bottom_up.res3.3.conv2.conv.weight                                                                                   | (256, 64, 3, 3)                                    |\n",
            "| backbone.bottom_up.res3.3.conv2.fc1.*           | backbone.bottom_up.res3.3.conv2.fc1.{bias,weight}                                                                             | (64,) (64,128,1,1)                                 |\n",
            "| backbone.bottom_up.res3.3.conv2.fc2.*           | backbone.bottom_up.res3.3.conv2.fc2.{bias,weight}                                                                             | (256,) (256,64,1,1)                                |\n",
            "| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv2.bn0.*           | backbone.bottom_up.res4.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.bn1.*           | backbone.bottom_up.res4.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.0.conv2.conv.weight     | backbone.bottom_up.res4.0.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.0.conv2.fc1.*           | backbone.bottom_up.res4.0.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv2.fc2.*           | backbone.bottom_up.res4.0.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.1.conv2.bn0.*           | backbone.bottom_up.res4.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.bn1.*           | backbone.bottom_up.res4.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.1.conv2.conv.weight     | backbone.bottom_up.res4.1.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.1.conv2.fc1.*           | backbone.bottom_up.res4.1.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv2.fc2.*           | backbone.bottom_up.res4.1.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.2.conv2.bn0.*           | backbone.bottom_up.res4.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.bn1.*           | backbone.bottom_up.res4.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.2.conv2.conv.weight     | backbone.bottom_up.res4.2.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.2.conv2.fc1.*           | backbone.bottom_up.res4.2.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv2.fc2.*           | backbone.bottom_up.res4.2.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.3.conv2.bn0.*           | backbone.bottom_up.res4.3.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.bn1.*           | backbone.bottom_up.res4.3.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.3.conv2.conv.weight     | backbone.bottom_up.res4.3.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.3.conv2.fc1.*           | backbone.bottom_up.res4.3.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv2.fc2.*           | backbone.bottom_up.res4.3.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.4.conv2.bn0.*           | backbone.bottom_up.res4.4.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.bn1.*           | backbone.bottom_up.res4.4.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.4.conv2.conv.weight     | backbone.bottom_up.res4.4.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.4.conv2.fc1.*           | backbone.bottom_up.res4.4.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv2.fc2.*           | backbone.bottom_up.res4.4.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.5.conv2.bn0.*           | backbone.bottom_up.res4.5.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (512,) () (512,) (512,) (512,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.bn1.*           | backbone.bottom_up.res4.5.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (128,) () (128,) (128,) (128,)                     |\n",
            "| backbone.bottom_up.res4.5.conv2.conv.weight     | backbone.bottom_up.res4.5.conv2.conv.weight                                                                                   | (512, 128, 3, 3)                                   |\n",
            "| backbone.bottom_up.res4.5.conv2.fc1.*           | backbone.bottom_up.res4.5.conv2.fc1.{bias,weight}                                                                             | (128,) (128,256,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv2.fc2.*           | backbone.bottom_up.res4.5.conv2.fc2.{bias,weight}                                                                             | (512,) (512,128,1,1)                               |\n",
            "| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| backbone.bottom_up.res5.0.conv2.bn0.*           | backbone.bottom_up.res5.0.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.0.conv2.bn1.*           | backbone.bottom_up.res5.0.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.0.conv2.conv.weight     | backbone.bottom_up.res5.0.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.0.conv2.fc1.*           | backbone.bottom_up.res5.0.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.0.conv2.fc2.*           | backbone.bottom_up.res5.0.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.1.conv2.bn0.*           | backbone.bottom_up.res5.1.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.1.conv2.bn1.*           | backbone.bottom_up.res5.1.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.1.conv2.conv.weight     | backbone.bottom_up.res5.1.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.1.conv2.fc1.*           | backbone.bottom_up.res5.1.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.1.conv2.fc2.*           | backbone.bottom_up.res5.1.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.2.conv2.bn0.*           | backbone.bottom_up.res5.2.conv2.bn0.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (1024,) () (1024,) (1024,) (1024,)                 |\n",
            "| backbone.bottom_up.res5.2.conv2.bn1.*           | backbone.bottom_up.res5.2.conv2.bn1.{bias,num_batches_tracked,running_mean,running_var,weight}                                | (256,) () (256,) (256,) (256,)                     |\n",
            "| backbone.bottom_up.res5.2.conv2.conv.weight     | backbone.bottom_up.res5.2.conv2.conv.weight                                                                                   | (1024, 256, 3, 3)                                  |\n",
            "| backbone.bottom_up.res5.2.conv2.fc1.*           | backbone.bottom_up.res5.2.conv2.fc1.{bias,weight}                                                                             | (256,) (256,512,1,1)                               |\n",
            "| backbone.bottom_up.res5.2.conv2.fc2.*           | backbone.bottom_up.res5.2.conv2.fc2.{bias,weight}                                                                             | (1024,) (1024,256,1,1)                             |\n",
            "| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.stem.conv1_1.*               | backbone.bottom_up.stem.conv1_1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (32,) (32,) (32,) (32,) (32,3,3,3)                 |\n",
            "| backbone.bottom_up.stem.conv1_2.*               | backbone.bottom_up.stem.conv1_2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (32,) (32,) (32,) (32,) (32,32,3,3)                |\n",
            "| backbone.bottom_up.stem.conv1_3.*               | backbone.bottom_up.stem.conv1_3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,32,3,3)                |\n",
            "| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}              | (256,) () (256,) (256,) (256,) (256,2048,1,1)      |\n",
            "| backbone.fpn_output2.*                          | backbone.fpn_output2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output3.*                          | backbone.fpn_output3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output4.*                          | backbone.fpn_output4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.fpn_output5.*                          | backbone.fpn_output5.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}               | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                                                       | (12,) (12,256,1,1)                                 |\n",
            "| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                                                | (256,) (256,256,3,3)                               |\n",
            "| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                                                   | (3,) (3,256,1,1)                                   |\n",
            "| roi_heads.box_head.0.conv1.*                    | roi_heads.box_head.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv2.*                    | roi_heads.box_head.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv3.*                    | roi_heads.box_head.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.conv4.*                    | roi_heads.box_head.0.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.0.fc1.*                      | roi_heads.box_head.0.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_head.1.conv1.*                    | roi_heads.box_head.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv2.*                    | roi_heads.box_head.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv3.*                    | roi_heads.box_head.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.conv4.*                    | roi_heads.box_head.1.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.1.fc1.*                      | roi_heads.box_head.1.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_head.2.conv1.*                    | roi_heads.box_head.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv2.*                    | roi_heads.box_head.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv3.*                    | roi_heads.box_head.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.conv4.*                    | roi_heads.box_head.2.conv4.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}         | (256,) () (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| roi_heads.box_head.2.fc1.*                      | roi_heads.box_head.2.fc1.{bias,weight}                                                                                        | (1024,) (1024,12544)                               |\n",
            "| roi_heads.box_predictor.0.bbox_pred.*           | roi_heads.box_predictor.0.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.0.cls_score.*           | roi_heads.box_predictor.0.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.box_predictor.1.bbox_pred.*           | roi_heads.box_predictor.1.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.1.cls_score.*           | roi_heads.box_predictor.1.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "| roi_heads.box_predictor.2.bbox_pred.*           | roi_heads.box_predictor.2.bbox_pred.{bias,weight}                                                                             | (4,) (4,1024)                                      |\n",
            "| roi_heads.box_predictor.2.cls_score.*           | roi_heads.box_predictor.2.cls_score.{bias,weight}                                                                             | (81,) (81,1024)                                    |\n",
            "\u001b[32m[04/30 15:22:47 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json\n",
            "\u001b[32m[04/30 15:22:48 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n",
            "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
            "|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\n",
            "|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\n",
            "|     train     | 190          |    truck     | 414          |     boat      | 424          |\n",
            "| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\n",
            "| parking meter | 60           |    bench     | 411          |     bird      | 427          |\n",
            "|      cat      | 202          |     dog      | 218          |     horse     | 272          |\n",
            "|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\n",
            "|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\n",
            "|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\n",
            "|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\n",
            "|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\n",
            "|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\n",
            "|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\n",
            "|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\n",
            "|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\n",
            "|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\n",
            "|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\n",
            "|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\n",
            "|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\n",
            "|     couch     | 261          | potted plant | 342          |      bed      | 163          |\n",
            "| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\n",
            "|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\n",
            "|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\n",
            "|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\n",
            "| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\n",
            "|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\n",
            "|  hair drier   | 11           |  toothbrush  | 57           |               |              |\n",
            "|     total     | 36335        |              |              |               |              |\u001b[0m\n",
            "\u001b[32m[04/30 15:22:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/30 15:22:48 d2.data.common]: \u001b[0mSerializing 5000 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/30 15:22:48 d2.data.common]: \u001b[0mSerialized dataset takes 19.10 MiB\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[32m[04/30 15:22:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 5000 batches\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m[04/30 15:22:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/5000. Dataloading: 0.0030 s/iter. Inference: 0.3551 s/iter. Eval: 0.0003 s/iter. Total: 0.3583 s/iter. ETA=0:29:47\n",
            "\u001b[32m[04/30 15:22:59 d2.evaluation.evaluator]: \u001b[0mInference done 26/5000. Dataloading: 0.0021 s/iter. Inference: 0.3519 s/iter. Eval: 0.0006 s/iter. Total: 0.3547 s/iter. ETA=0:29:24\n",
            "\u001b[32m[04/30 15:23:04 d2.evaluation.evaluator]: \u001b[0mInference done 40/5000. Dataloading: 0.0020 s/iter. Inference: 0.3534 s/iter. Eval: 0.0005 s/iter. Total: 0.3560 s/iter. ETA=0:29:25\n",
            "\u001b[32m[04/30 15:23:09 d2.evaluation.evaluator]: \u001b[0mInference done 54/5000. Dataloading: 0.0020 s/iter. Inference: 0.3540 s/iter. Eval: 0.0004 s/iter. Total: 0.3565 s/iter. ETA=0:29:23\n",
            "\u001b[32m[04/30 15:23:14 d2.evaluation.evaluator]: \u001b[0mInference done 68/5000. Dataloading: 0.0020 s/iter. Inference: 0.3552 s/iter. Eval: 0.0004 s/iter. Total: 0.3576 s/iter. ETA=0:29:23\n",
            "\u001b[32m[04/30 15:23:19 d2.evaluation.evaluator]: \u001b[0mInference done 82/5000. Dataloading: 0.0020 s/iter. Inference: 0.3556 s/iter. Eval: 0.0003 s/iter. Total: 0.3580 s/iter. ETA=0:29:20\n",
            "\u001b[32m[04/30 15:23:24 d2.evaluation.evaluator]: \u001b[0mInference done 97/5000. Dataloading: 0.0020 s/iter. Inference: 0.3555 s/iter. Eval: 0.0003 s/iter. Total: 0.3579 s/iter. ETA=0:29:14\n",
            "\u001b[32m[04/30 15:23:29 d2.evaluation.evaluator]: \u001b[0mInference done 112/5000. Dataloading: 0.0020 s/iter. Inference: 0.3554 s/iter. Eval: 0.0003 s/iter. Total: 0.3578 s/iter. ETA=0:29:08\n",
            "\u001b[32m[04/30 15:23:35 d2.evaluation.evaluator]: \u001b[0mInference done 126/5000. Dataloading: 0.0020 s/iter. Inference: 0.3561 s/iter. Eval: 0.0003 s/iter. Total: 0.3585 s/iter. ETA=0:29:07\n",
            "\u001b[32m[04/30 15:23:40 d2.evaluation.evaluator]: \u001b[0mInference done 140/5000. Dataloading: 0.0020 s/iter. Inference: 0.3570 s/iter. Eval: 0.0003 s/iter. Total: 0.3594 s/iter. ETA=0:29:06\n",
            "\u001b[32m[04/30 15:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 154/5000. Dataloading: 0.0020 s/iter. Inference: 0.3580 s/iter. Eval: 0.0003 s/iter. Total: 0.3604 s/iter. ETA=0:29:06\n",
            "\u001b[32m[04/30 15:23:50 d2.evaluation.evaluator]: \u001b[0mInference done 168/5000. Dataloading: 0.0020 s/iter. Inference: 0.3584 s/iter. Eval: 0.0003 s/iter. Total: 0.3608 s/iter. ETA=0:29:03\n",
            "\u001b[32m[04/30 15:23:55 d2.evaluation.evaluator]: \u001b[0mInference done 182/5000. Dataloading: 0.0020 s/iter. Inference: 0.3590 s/iter. Eval: 0.0003 s/iter. Total: 0.3614 s/iter. ETA=0:29:01\n",
            "\u001b[32m[04/30 15:24:00 d2.evaluation.evaluator]: \u001b[0mInference done 196/5000. Dataloading: 0.0020 s/iter. Inference: 0.3598 s/iter. Eval: 0.0003 s/iter. Total: 0.3622 s/iter. ETA=0:29:00\n",
            "\u001b[32m[04/30 15:24:06 d2.evaluation.evaluator]: \u001b[0mInference done 210/5000. Dataloading: 0.0020 s/iter. Inference: 0.3605 s/iter. Eval: 0.0003 s/iter. Total: 0.3629 s/iter. ETA=0:28:58\n",
            "\u001b[32m[04/30 15:24:11 d2.evaluation.evaluator]: \u001b[0mInference done 224/5000. Dataloading: 0.0020 s/iter. Inference: 0.3608 s/iter. Eval: 0.0003 s/iter. Total: 0.3632 s/iter. ETA=0:28:54\n",
            "\u001b[32m[04/30 15:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 238/5000. Dataloading: 0.0020 s/iter. Inference: 0.3617 s/iter. Eval: 0.0003 s/iter. Total: 0.3641 s/iter. ETA=0:28:53\n",
            "\u001b[32m[04/30 15:24:21 d2.evaluation.evaluator]: \u001b[0mInference done 252/5000. Dataloading: 0.0020 s/iter. Inference: 0.3624 s/iter. Eval: 0.0003 s/iter. Total: 0.3647 s/iter. ETA=0:28:51\n",
            "\u001b[32m[04/30 15:24:27 d2.evaluation.evaluator]: \u001b[0mInference done 266/5000. Dataloading: 0.0020 s/iter. Inference: 0.3630 s/iter. Eval: 0.0003 s/iter. Total: 0.3654 s/iter. ETA=0:28:49\n",
            "\u001b[32m[04/30 15:24:32 d2.evaluation.evaluator]: \u001b[0mInference done 280/5000. Dataloading: 0.0020 s/iter. Inference: 0.3634 s/iter. Eval: 0.0003 s/iter. Total: 0.3658 s/iter. ETA=0:28:46\n",
            "\u001b[32m[04/30 15:24:37 d2.evaluation.evaluator]: \u001b[0mInference done 294/5000. Dataloading: 0.0020 s/iter. Inference: 0.3642 s/iter. Eval: 0.0003 s/iter. Total: 0.3665 s/iter. ETA=0:28:44\n",
            "\u001b[32m[04/30 15:24:42 d2.evaluation.evaluator]: \u001b[0mInference done 308/5000. Dataloading: 0.0020 s/iter. Inference: 0.3647 s/iter. Eval: 0.0003 s/iter. Total: 0.3671 s/iter. ETA=0:28:42\n",
            "\u001b[32m[04/30 15:24:48 d2.evaluation.evaluator]: \u001b[0mInference done 322/5000. Dataloading: 0.0020 s/iter. Inference: 0.3653 s/iter. Eval: 0.0003 s/iter. Total: 0.3676 s/iter. ETA=0:28:39\n",
            "\u001b[32m[04/30 15:24:53 d2.evaluation.evaluator]: \u001b[0mInference done 336/5000. Dataloading: 0.0020 s/iter. Inference: 0.3660 s/iter. Eval: 0.0003 s/iter. Total: 0.3683 s/iter. ETA=0:28:37\n",
            "\u001b[32m[04/30 15:24:58 d2.evaluation.evaluator]: \u001b[0mInference done 350/5000. Dataloading: 0.0020 s/iter. Inference: 0.3666 s/iter. Eval: 0.0003 s/iter. Total: 0.3690 s/iter. ETA=0:28:35\n",
            "\u001b[32m[04/30 15:25:04 d2.evaluation.evaluator]: \u001b[0mInference done 364/5000. Dataloading: 0.0020 s/iter. Inference: 0.3672 s/iter. Eval: 0.0003 s/iter. Total: 0.3695 s/iter. ETA=0:28:33\n",
            "\u001b[32m[04/30 15:25:09 d2.evaluation.evaluator]: \u001b[0mInference done 377/5000. Dataloading: 0.0020 s/iter. Inference: 0.3678 s/iter. Eval: 0.0003 s/iter. Total: 0.3702 s/iter. ETA=0:28:31\n",
            "\u001b[32m[04/30 15:25:14 d2.evaluation.evaluator]: \u001b[0mInference done 391/5000. Dataloading: 0.0020 s/iter. Inference: 0.3682 s/iter. Eval: 0.0003 s/iter. Total: 0.3705 s/iter. ETA=0:28:27\n",
            "\u001b[32m[04/30 15:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 404/5000. Dataloading: 0.0020 s/iter. Inference: 0.3686 s/iter. Eval: 0.0003 s/iter. Total: 0.3710 s/iter. ETA=0:28:24\n",
            "\u001b[32m[04/30 15:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 417/5000. Dataloading: 0.0020 s/iter. Inference: 0.3692 s/iter. Eval: 0.0003 s/iter. Total: 0.3715 s/iter. ETA=0:28:22\n",
            "\u001b[32m[04/30 15:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 430/5000. Dataloading: 0.0020 s/iter. Inference: 0.3697 s/iter. Eval: 0.0003 s/iter. Total: 0.3720 s/iter. ETA=0:28:19\n",
            "\u001b[32m[04/30 15:25:34 d2.evaluation.evaluator]: \u001b[0mInference done 443/5000. Dataloading: 0.0020 s/iter. Inference: 0.3703 s/iter. Eval: 0.0003 s/iter. Total: 0.3726 s/iter. ETA=0:28:17\n",
            "\u001b[32m[04/30 15:25:39 d2.evaluation.evaluator]: \u001b[0mInference done 456/5000. Dataloading: 0.0020 s/iter. Inference: 0.3708 s/iter. Eval: 0.0003 s/iter. Total: 0.3731 s/iter. ETA=0:28:15\n",
            "\u001b[32m[04/30 15:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 469/5000. Dataloading: 0.0020 s/iter. Inference: 0.3713 s/iter. Eval: 0.0003 s/iter. Total: 0.3737 s/iter. ETA=0:28:13\n",
            "\u001b[32m[04/30 15:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 482/5000. Dataloading: 0.0020 s/iter. Inference: 0.3719 s/iter. Eval: 0.0003 s/iter. Total: 0.3743 s/iter. ETA=0:28:10\n",
            "\u001b[32m[04/30 15:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 495/5000. Dataloading: 0.0020 s/iter. Inference: 0.3724 s/iter. Eval: 0.0003 s/iter. Total: 0.3747 s/iter. ETA=0:28:08\n",
            "\u001b[32m[04/30 15:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 508/5000. Dataloading: 0.0020 s/iter. Inference: 0.3727 s/iter. Eval: 0.0003 s/iter. Total: 0.3750 s/iter. ETA=0:28:04\n",
            "\u001b[32m[04/30 15:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 521/5000. Dataloading: 0.0020 s/iter. Inference: 0.3730 s/iter. Eval: 0.0003 s/iter. Total: 0.3753 s/iter. ETA=0:28:01\n",
            "\u001b[32m[04/30 15:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 534/5000. Dataloading: 0.0020 s/iter. Inference: 0.3734 s/iter. Eval: 0.0003 s/iter. Total: 0.3758 s/iter. ETA=0:27:58\n",
            "\u001b[32m[04/30 15:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 547/5000. Dataloading: 0.0020 s/iter. Inference: 0.3738 s/iter. Eval: 0.0003 s/iter. Total: 0.3761 s/iter. ETA=0:27:54\n",
            "\u001b[32m[04/30 15:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 560/5000. Dataloading: 0.0020 s/iter. Inference: 0.3742 s/iter. Eval: 0.0003 s/iter. Total: 0.3765 s/iter. ETA=0:27:51\n",
            "\u001b[32m[04/30 15:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 573/5000. Dataloading: 0.0020 s/iter. Inference: 0.3746 s/iter. Eval: 0.0003 s/iter. Total: 0.3770 s/iter. ETA=0:27:48\n",
            "\u001b[32m[04/30 15:26:30 d2.evaluation.evaluator]: \u001b[0mInference done 586/5000. Dataloading: 0.0020 s/iter. Inference: 0.3749 s/iter. Eval: 0.0003 s/iter. Total: 0.3772 s/iter. ETA=0:27:45\n",
            "\u001b[32m[04/30 15:26:35 d2.evaluation.evaluator]: \u001b[0mInference done 599/5000. Dataloading: 0.0020 s/iter. Inference: 0.3752 s/iter. Eval: 0.0003 s/iter. Total: 0.3776 s/iter. ETA=0:27:41\n",
            "\u001b[32m[04/30 15:26:41 d2.evaluation.evaluator]: \u001b[0mInference done 612/5000. Dataloading: 0.0020 s/iter. Inference: 0.3756 s/iter. Eval: 0.0003 s/iter. Total: 0.3780 s/iter. ETA=0:27:38\n",
            "\u001b[32m[04/30 15:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 625/5000. Dataloading: 0.0020 s/iter. Inference: 0.3761 s/iter. Eval: 0.0003 s/iter. Total: 0.3784 s/iter. ETA=0:27:35\n",
            "\u001b[32m[04/30 15:26:51 d2.evaluation.evaluator]: \u001b[0mInference done 638/5000. Dataloading: 0.0020 s/iter. Inference: 0.3764 s/iter. Eval: 0.0003 s/iter. Total: 0.3788 s/iter. ETA=0:27:32\n",
            "\u001b[32m[04/30 15:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 651/5000. Dataloading: 0.0020 s/iter. Inference: 0.3767 s/iter. Eval: 0.0003 s/iter. Total: 0.3790 s/iter. ETA=0:27:28\n",
            "\u001b[32m[04/30 15:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 664/5000. Dataloading: 0.0020 s/iter. Inference: 0.3770 s/iter. Eval: 0.0003 s/iter. Total: 0.3794 s/iter. ETA=0:27:24\n",
            "\u001b[32m[04/30 15:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 677/5000. Dataloading: 0.0020 s/iter. Inference: 0.3774 s/iter. Eval: 0.0003 s/iter. Total: 0.3797 s/iter. ETA=0:27:21\n",
            "\u001b[32m[04/30 15:27:11 d2.evaluation.evaluator]: \u001b[0mInference done 690/5000. Dataloading: 0.0020 s/iter. Inference: 0.3777 s/iter. Eval: 0.0003 s/iter. Total: 0.3801 s/iter. ETA=0:27:18\n",
            "\u001b[32m[04/30 15:27:17 d2.evaluation.evaluator]: \u001b[0mInference done 703/5000. Dataloading: 0.0020 s/iter. Inference: 0.3781 s/iter. Eval: 0.0003 s/iter. Total: 0.3804 s/iter. ETA=0:27:14\n",
            "\u001b[32m[04/30 15:27:22 d2.evaluation.evaluator]: \u001b[0mInference done 716/5000. Dataloading: 0.0020 s/iter. Inference: 0.3785 s/iter. Eval: 0.0002 s/iter. Total: 0.3808 s/iter. ETA=0:27:11\n",
            "\u001b[32m[04/30 15:27:27 d2.evaluation.evaluator]: \u001b[0mInference done 729/5000. Dataloading: 0.0020 s/iter. Inference: 0.3788 s/iter. Eval: 0.0002 s/iter. Total: 0.3811 s/iter. ETA=0:27:07\n",
            "\u001b[32m[04/30 15:27:32 d2.evaluation.evaluator]: \u001b[0mInference done 742/5000. Dataloading: 0.0020 s/iter. Inference: 0.3793 s/iter. Eval: 0.0002 s/iter. Total: 0.3816 s/iter. ETA=0:27:05\n",
            "\u001b[32m[04/30 15:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 755/5000. Dataloading: 0.0020 s/iter. Inference: 0.3796 s/iter. Eval: 0.0003 s/iter. Total: 0.3819 s/iter. ETA=0:27:01\n",
            "\u001b[32m[04/30 15:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 768/5000. Dataloading: 0.0020 s/iter. Inference: 0.3798 s/iter. Eval: 0.0003 s/iter. Total: 0.3822 s/iter. ETA=0:26:57\n",
            "\u001b[32m[04/30 15:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 781/5000. Dataloading: 0.0020 s/iter. Inference: 0.3802 s/iter. Eval: 0.0003 s/iter. Total: 0.3825 s/iter. ETA=0:26:53\n",
            "\u001b[32m[04/30 15:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 794/5000. Dataloading: 0.0020 s/iter. Inference: 0.3805 s/iter. Eval: 0.0003 s/iter. Total: 0.3828 s/iter. ETA=0:26:50\n",
            "\u001b[32m[04/30 15:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 807/5000. Dataloading: 0.0020 s/iter. Inference: 0.3808 s/iter. Eval: 0.0003 s/iter. Total: 0.3832 s/iter. ETA=0:26:46\n",
            "\u001b[32m[04/30 15:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 820/5000. Dataloading: 0.0020 s/iter. Inference: 0.3811 s/iter. Eval: 0.0003 s/iter. Total: 0.3835 s/iter. ETA=0:26:42\n",
            "\u001b[32m[04/30 15:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 833/5000. Dataloading: 0.0020 s/iter. Inference: 0.3812 s/iter. Eval: 0.0003 s/iter. Total: 0.3836 s/iter. ETA=0:26:38\n",
            "\u001b[32m[04/30 15:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 846/5000. Dataloading: 0.0020 s/iter. Inference: 0.3815 s/iter. Eval: 0.0003 s/iter. Total: 0.3839 s/iter. ETA=0:26:34\n",
            "\u001b[32m[04/30 15:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 859/5000. Dataloading: 0.0020 s/iter. Inference: 0.3818 s/iter. Eval: 0.0003 s/iter. Total: 0.3842 s/iter. ETA=0:26:30\n",
            "\u001b[32m[04/30 15:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 872/5000. Dataloading: 0.0020 s/iter. Inference: 0.3821 s/iter. Eval: 0.0003 s/iter. Total: 0.3845 s/iter. ETA=0:26:27\n",
            "\u001b[32m[04/30 15:28:30 d2.evaluation.evaluator]: \u001b[0mInference done 885/5000. Dataloading: 0.0020 s/iter. Inference: 0.3823 s/iter. Eval: 0.0003 s/iter. Total: 0.3847 s/iter. ETA=0:26:23\n",
            "\u001b[32m[04/30 15:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 898/5000. Dataloading: 0.0020 s/iter. Inference: 0.3826 s/iter. Eval: 0.0003 s/iter. Total: 0.3849 s/iter. ETA=0:26:19\n",
            "\u001b[32m[04/30 15:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 911/5000. Dataloading: 0.0020 s/iter. Inference: 0.3827 s/iter. Eval: 0.0003 s/iter. Total: 0.3851 s/iter. ETA=0:26:14\n",
            "\u001b[32m[04/30 15:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 924/5000. Dataloading: 0.0020 s/iter. Inference: 0.3830 s/iter. Eval: 0.0003 s/iter. Total: 0.3853 s/iter. ETA=0:26:10\n",
            "\u001b[32m[04/30 15:28:51 d2.evaluation.evaluator]: \u001b[0mInference done 937/5000. Dataloading: 0.0020 s/iter. Inference: 0.3832 s/iter. Eval: 0.0003 s/iter. Total: 0.3856 s/iter. ETA=0:26:06\n",
            "\u001b[32m[04/30 15:28:56 d2.evaluation.evaluator]: \u001b[0mInference done 950/5000. Dataloading: 0.0020 s/iter. Inference: 0.3835 s/iter. Eval: 0.0003 s/iter. Total: 0.3858 s/iter. ETA=0:26:02\n",
            "\u001b[32m[04/30 15:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 963/5000. Dataloading: 0.0020 s/iter. Inference: 0.3837 s/iter. Eval: 0.0003 s/iter. Total: 0.3860 s/iter. ETA=0:25:58\n",
            "\u001b[32m[04/30 15:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 976/5000. Dataloading: 0.0020 s/iter. Inference: 0.3838 s/iter. Eval: 0.0003 s/iter. Total: 0.3862 s/iter. ETA=0:25:54\n",
            "\u001b[32m[04/30 15:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 989/5000. Dataloading: 0.0020 s/iter. Inference: 0.3841 s/iter. Eval: 0.0003 s/iter. Total: 0.3864 s/iter. ETA=0:25:49\n",
            "\u001b[32m[04/30 15:29:17 d2.evaluation.evaluator]: \u001b[0mInference done 1002/5000. Dataloading: 0.0020 s/iter. Inference: 0.3842 s/iter. Eval: 0.0003 s/iter. Total: 0.3866 s/iter. ETA=0:25:45\n",
            "\u001b[32m[04/30 15:29:22 d2.evaluation.evaluator]: \u001b[0mInference done 1015/5000. Dataloading: 0.0020 s/iter. Inference: 0.3844 s/iter. Eval: 0.0003 s/iter. Total: 0.3868 s/iter. ETA=0:25:41\n",
            "\u001b[32m[04/30 15:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 1028/5000. Dataloading: 0.0020 s/iter. Inference: 0.3845 s/iter. Eval: 0.0003 s/iter. Total: 0.3869 s/iter. ETA=0:25:36\n",
            "\u001b[32m[04/30 15:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 1041/5000. Dataloading: 0.0020 s/iter. Inference: 0.3847 s/iter. Eval: 0.0003 s/iter. Total: 0.3870 s/iter. ETA=0:25:32\n",
            "\u001b[32m[04/30 15:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 1054/5000. Dataloading: 0.0020 s/iter. Inference: 0.3849 s/iter. Eval: 0.0003 s/iter. Total: 0.3872 s/iter. ETA=0:25:28\n",
            "\u001b[32m[04/30 15:29:43 d2.evaluation.evaluator]: \u001b[0mInference done 1067/5000. Dataloading: 0.0020 s/iter. Inference: 0.3851 s/iter. Eval: 0.0003 s/iter. Total: 0.3874 s/iter. ETA=0:25:23\n",
            "\u001b[32m[04/30 15:29:48 d2.evaluation.evaluator]: \u001b[0mInference done 1080/5000. Dataloading: 0.0020 s/iter. Inference: 0.3853 s/iter. Eval: 0.0003 s/iter. Total: 0.3876 s/iter. ETA=0:25:19\n",
            "\u001b[32m[04/30 15:29:53 d2.evaluation.evaluator]: \u001b[0mInference done 1093/5000. Dataloading: 0.0020 s/iter. Inference: 0.3854 s/iter. Eval: 0.0003 s/iter. Total: 0.3878 s/iter. ETA=0:25:15\n",
            "\u001b[32m[04/30 15:29:58 d2.evaluation.evaluator]: \u001b[0mInference done 1106/5000. Dataloading: 0.0020 s/iter. Inference: 0.3856 s/iter. Eval: 0.0003 s/iter. Total: 0.3879 s/iter. ETA=0:25:10\n",
            "\u001b[32m[04/30 15:30:03 d2.evaluation.evaluator]: \u001b[0mInference done 1119/5000. Dataloading: 0.0020 s/iter. Inference: 0.3857 s/iter. Eval: 0.0003 s/iter. Total: 0.3881 s/iter. ETA=0:25:06\n",
            "\u001b[32m[04/30 15:30:09 d2.evaluation.evaluator]: \u001b[0mInference done 1132/5000. Dataloading: 0.0020 s/iter. Inference: 0.3859 s/iter. Eval: 0.0003 s/iter. Total: 0.3883 s/iter. ETA=0:25:01\n",
            "\u001b[32m[04/30 15:30:14 d2.evaluation.evaluator]: \u001b[0mInference done 1145/5000. Dataloading: 0.0020 s/iter. Inference: 0.3861 s/iter. Eval: 0.0003 s/iter. Total: 0.3884 s/iter. ETA=0:24:57\n",
            "\u001b[32m[04/30 15:30:19 d2.evaluation.evaluator]: \u001b[0mInference done 1158/5000. Dataloading: 0.0020 s/iter. Inference: 0.3862 s/iter. Eval: 0.0003 s/iter. Total: 0.3885 s/iter. ETA=0:24:52\n",
            "\u001b[32m[04/30 15:30:24 d2.evaluation.evaluator]: \u001b[0mInference done 1171/5000. Dataloading: 0.0020 s/iter. Inference: 0.3864 s/iter. Eval: 0.0003 s/iter. Total: 0.3887 s/iter. ETA=0:24:48\n",
            "\u001b[32m[04/30 15:30:30 d2.evaluation.evaluator]: \u001b[0mInference done 1184/5000. Dataloading: 0.0020 s/iter. Inference: 0.3865 s/iter. Eval: 0.0003 s/iter. Total: 0.3888 s/iter. ETA=0:24:43\n",
            "\u001b[32m[04/30 15:30:35 d2.evaluation.evaluator]: \u001b[0mInference done 1197/5000. Dataloading: 0.0020 s/iter. Inference: 0.3866 s/iter. Eval: 0.0003 s/iter. Total: 0.3889 s/iter. ETA=0:24:39\n",
            "\u001b[32m[04/30 15:30:40 d2.evaluation.evaluator]: \u001b[0mInference done 1210/5000. Dataloading: 0.0020 s/iter. Inference: 0.3868 s/iter. Eval: 0.0003 s/iter. Total: 0.3891 s/iter. ETA=0:24:34\n",
            "\u001b[32m[04/30 15:30:45 d2.evaluation.evaluator]: \u001b[0mInference done 1223/5000. Dataloading: 0.0020 s/iter. Inference: 0.3869 s/iter. Eval: 0.0003 s/iter. Total: 0.3892 s/iter. ETA=0:24:29\n",
            "\u001b[32m[04/30 15:30:50 d2.evaluation.evaluator]: \u001b[0mInference done 1236/5000. Dataloading: 0.0020 s/iter. Inference: 0.3870 s/iter. Eval: 0.0003 s/iter. Total: 0.3893 s/iter. ETA=0:24:25\n",
            "\u001b[32m[04/30 15:30:56 d2.evaluation.evaluator]: \u001b[0mInference done 1249/5000. Dataloading: 0.0020 s/iter. Inference: 0.3871 s/iter. Eval: 0.0003 s/iter. Total: 0.3894 s/iter. ETA=0:24:20\n",
            "\u001b[32m[04/30 15:31:01 d2.evaluation.evaluator]: \u001b[0mInference done 1262/5000. Dataloading: 0.0020 s/iter. Inference: 0.3872 s/iter. Eval: 0.0003 s/iter. Total: 0.3895 s/iter. ETA=0:24:15\n",
            "\u001b[32m[04/30 15:31:06 d2.evaluation.evaluator]: \u001b[0mInference done 1275/5000. Dataloading: 0.0020 s/iter. Inference: 0.3873 s/iter. Eval: 0.0003 s/iter. Total: 0.3896 s/iter. ETA=0:24:11\n",
            "\u001b[32m[04/30 15:31:11 d2.evaluation.evaluator]: \u001b[0mInference done 1288/5000. Dataloading: 0.0020 s/iter. Inference: 0.3874 s/iter. Eval: 0.0003 s/iter. Total: 0.3897 s/iter. ETA=0:24:06\n",
            "\u001b[32m[04/30 15:31:16 d2.evaluation.evaluator]: \u001b[0mInference done 1301/5000. Dataloading: 0.0020 s/iter. Inference: 0.3875 s/iter. Eval: 0.0003 s/iter. Total: 0.3898 s/iter. ETA=0:24:01\n",
            "\u001b[32m[04/30 15:31:22 d2.evaluation.evaluator]: \u001b[0mInference done 1314/5000. Dataloading: 0.0020 s/iter. Inference: 0.3876 s/iter. Eval: 0.0003 s/iter. Total: 0.3899 s/iter. ETA=0:23:57\n",
            "\u001b[32m[04/30 15:31:27 d2.evaluation.evaluator]: \u001b[0mInference done 1327/5000. Dataloading: 0.0020 s/iter. Inference: 0.3876 s/iter. Eval: 0.0003 s/iter. Total: 0.3900 s/iter. ETA=0:23:52\n",
            "\u001b[32m[04/30 15:31:32 d2.evaluation.evaluator]: \u001b[0mInference done 1340/5000. Dataloading: 0.0020 s/iter. Inference: 0.3878 s/iter. Eval: 0.0003 s/iter. Total: 0.3901 s/iter. ETA=0:23:47\n",
            "\u001b[32m[04/30 15:31:37 d2.evaluation.evaluator]: \u001b[0mInference done 1353/5000. Dataloading: 0.0020 s/iter. Inference: 0.3879 s/iter. Eval: 0.0003 s/iter. Total: 0.3902 s/iter. ETA=0:23:43\n",
            "\u001b[32m[04/30 15:31:42 d2.evaluation.evaluator]: \u001b[0mInference done 1366/5000. Dataloading: 0.0020 s/iter. Inference: 0.3880 s/iter. Eval: 0.0003 s/iter. Total: 0.3903 s/iter. ETA=0:23:38\n",
            "\u001b[32m[04/30 15:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 1379/5000. Dataloading: 0.0020 s/iter. Inference: 0.3881 s/iter. Eval: 0.0003 s/iter. Total: 0.3904 s/iter. ETA=0:23:33\n",
            "\u001b[32m[04/30 15:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 1392/5000. Dataloading: 0.0020 s/iter. Inference: 0.3882 s/iter. Eval: 0.0003 s/iter. Total: 0.3905 s/iter. ETA=0:23:28\n",
            "\u001b[32m[04/30 15:31:58 d2.evaluation.evaluator]: \u001b[0mInference done 1405/5000. Dataloading: 0.0020 s/iter. Inference: 0.3883 s/iter. Eval: 0.0003 s/iter. Total: 0.3906 s/iter. ETA=0:23:24\n",
            "\u001b[32m[04/30 15:32:03 d2.evaluation.evaluator]: \u001b[0mInference done 1418/5000. Dataloading: 0.0020 s/iter. Inference: 0.3883 s/iter. Eval: 0.0003 s/iter. Total: 0.3906 s/iter. ETA=0:23:19\n",
            "\u001b[32m[04/30 15:32:08 d2.evaluation.evaluator]: \u001b[0mInference done 1431/5000. Dataloading: 0.0020 s/iter. Inference: 0.3884 s/iter. Eval: 0.0003 s/iter. Total: 0.3907 s/iter. ETA=0:23:14\n",
            "\u001b[32m[04/30 15:32:14 d2.evaluation.evaluator]: \u001b[0mInference done 1444/5000. Dataloading: 0.0020 s/iter. Inference: 0.3885 s/iter. Eval: 0.0003 s/iter. Total: 0.3908 s/iter. ETA=0:23:09\n",
            "\u001b[32m[04/30 15:32:19 d2.evaluation.evaluator]: \u001b[0mInference done 1457/5000. Dataloading: 0.0020 s/iter. Inference: 0.3886 s/iter. Eval: 0.0003 s/iter. Total: 0.3909 s/iter. ETA=0:23:05\n",
            "\u001b[32m[04/30 15:32:24 d2.evaluation.evaluator]: \u001b[0mInference done 1470/5000. Dataloading: 0.0020 s/iter. Inference: 0.3886 s/iter. Eval: 0.0003 s/iter. Total: 0.3909 s/iter. ETA=0:23:00\n",
            "\u001b[32m[04/30 15:32:29 d2.evaluation.evaluator]: \u001b[0mInference done 1483/5000. Dataloading: 0.0020 s/iter. Inference: 0.3887 s/iter. Eval: 0.0003 s/iter. Total: 0.3910 s/iter. ETA=0:22:55\n",
            "\u001b[32m[04/30 15:32:34 d2.evaluation.evaluator]: \u001b[0mInference done 1496/5000. Dataloading: 0.0020 s/iter. Inference: 0.3888 s/iter. Eval: 0.0003 s/iter. Total: 0.3911 s/iter. ETA=0:22:50\n",
            "\u001b[32m[04/30 15:32:39 d2.evaluation.evaluator]: \u001b[0mInference done 1509/5000. Dataloading: 0.0020 s/iter. Inference: 0.3889 s/iter. Eval: 0.0003 s/iter. Total: 0.3912 s/iter. ETA=0:22:45\n",
            "\u001b[32m[04/30 15:32:45 d2.evaluation.evaluator]: \u001b[0mInference done 1522/5000. Dataloading: 0.0020 s/iter. Inference: 0.3889 s/iter. Eval: 0.0003 s/iter. Total: 0.3912 s/iter. ETA=0:22:40\n",
            "\u001b[32m[04/30 15:32:50 d2.evaluation.evaluator]: \u001b[0mInference done 1535/5000. Dataloading: 0.0020 s/iter. Inference: 0.3890 s/iter. Eval: 0.0003 s/iter. Total: 0.3913 s/iter. ETA=0:22:35\n",
            "\u001b[32m[04/30 15:32:55 d2.evaluation.evaluator]: \u001b[0mInference done 1548/5000. Dataloading: 0.0020 s/iter. Inference: 0.3891 s/iter. Eval: 0.0003 s/iter. Total: 0.3914 s/iter. ETA=0:22:31\n",
            "\u001b[32m[04/30 15:33:00 d2.evaluation.evaluator]: \u001b[0mInference done 1561/5000. Dataloading: 0.0020 s/iter. Inference: 0.3892 s/iter. Eval: 0.0003 s/iter. Total: 0.3915 s/iter. ETA=0:22:26\n",
            "\u001b[32m[04/30 15:33:06 d2.evaluation.evaluator]: \u001b[0mInference done 1574/5000. Dataloading: 0.0020 s/iter. Inference: 0.3893 s/iter. Eval: 0.0003 s/iter. Total: 0.3916 s/iter. ETA=0:22:21\n",
            "\u001b[32m[04/30 15:33:11 d2.evaluation.evaluator]: \u001b[0mInference done 1587/5000. Dataloading: 0.0020 s/iter. Inference: 0.3894 s/iter. Eval: 0.0003 s/iter. Total: 0.3917 s/iter. ETA=0:22:16\n",
            "\u001b[32m[04/30 15:33:16 d2.evaluation.evaluator]: \u001b[0mInference done 1600/5000. Dataloading: 0.0020 s/iter. Inference: 0.3895 s/iter. Eval: 0.0003 s/iter. Total: 0.3918 s/iter. ETA=0:22:12\n",
            "\u001b[32m[04/30 15:33:21 d2.evaluation.evaluator]: \u001b[0mInference done 1613/5000. Dataloading: 0.0020 s/iter. Inference: 0.3896 s/iter. Eval: 0.0003 s/iter. Total: 0.3919 s/iter. ETA=0:22:07\n",
            "\u001b[32m[04/30 15:33:27 d2.evaluation.evaluator]: \u001b[0mInference done 1626/5000. Dataloading: 0.0020 s/iter. Inference: 0.3896 s/iter. Eval: 0.0003 s/iter. Total: 0.3920 s/iter. ETA=0:22:02\n",
            "\u001b[32m[04/30 15:33:32 d2.evaluation.evaluator]: \u001b[0mInference done 1639/5000. Dataloading: 0.0020 s/iter. Inference: 0.3897 s/iter. Eval: 0.0003 s/iter. Total: 0.3920 s/iter. ETA=0:21:57\n",
            "\u001b[32m[04/30 15:33:37 d2.evaluation.evaluator]: \u001b[0mInference done 1652/5000. Dataloading: 0.0020 s/iter. Inference: 0.3898 s/iter. Eval: 0.0003 s/iter. Total: 0.3921 s/iter. ETA=0:21:52\n",
            "\u001b[32m[04/30 15:33:42 d2.evaluation.evaluator]: \u001b[0mInference done 1665/5000. Dataloading: 0.0020 s/iter. Inference: 0.3898 s/iter. Eval: 0.0003 s/iter. Total: 0.3921 s/iter. ETA=0:21:47\n",
            "\u001b[32m[04/30 15:33:47 d2.evaluation.evaluator]: \u001b[0mInference done 1678/5000. Dataloading: 0.0020 s/iter. Inference: 0.3899 s/iter. Eval: 0.0003 s/iter. Total: 0.3922 s/iter. ETA=0:21:43\n",
            "\u001b[32m[04/30 15:33:53 d2.evaluation.evaluator]: \u001b[0mInference done 1691/5000. Dataloading: 0.0020 s/iter. Inference: 0.3900 s/iter. Eval: 0.0003 s/iter. Total: 0.3923 s/iter. ETA=0:21:38\n",
            "\u001b[32m[04/30 15:33:58 d2.evaluation.evaluator]: \u001b[0mInference done 1704/5000. Dataloading: 0.0020 s/iter. Inference: 0.3901 s/iter. Eval: 0.0003 s/iter. Total: 0.3924 s/iter. ETA=0:21:33\n",
            "\u001b[32m[04/30 15:34:03 d2.evaluation.evaluator]: \u001b[0mInference done 1717/5000. Dataloading: 0.0020 s/iter. Inference: 0.3901 s/iter. Eval: 0.0003 s/iter. Total: 0.3925 s/iter. ETA=0:21:28\n",
            "\u001b[32m[04/30 15:34:08 d2.evaluation.evaluator]: \u001b[0mInference done 1730/5000. Dataloading: 0.0020 s/iter. Inference: 0.3902 s/iter. Eval: 0.0002 s/iter. Total: 0.3925 s/iter. ETA=0:21:23\n",
            "\u001b[32m[04/30 15:34:13 d2.evaluation.evaluator]: \u001b[0mInference done 1743/5000. Dataloading: 0.0020 s/iter. Inference: 0.3903 s/iter. Eval: 0.0002 s/iter. Total: 0.3926 s/iter. ETA=0:21:18\n",
            "\u001b[32m[04/30 15:34:19 d2.evaluation.evaluator]: \u001b[0mInference done 1756/5000. Dataloading: 0.0020 s/iter. Inference: 0.3903 s/iter. Eval: 0.0002 s/iter. Total: 0.3927 s/iter. ETA=0:21:13\n",
            "\u001b[32m[04/30 15:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 1769/5000. Dataloading: 0.0020 s/iter. Inference: 0.3904 s/iter. Eval: 0.0002 s/iter. Total: 0.3927 s/iter. ETA=0:21:08\n",
            "\u001b[32m[04/30 15:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 1782/5000. Dataloading: 0.0020 s/iter. Inference: 0.3904 s/iter. Eval: 0.0002 s/iter. Total: 0.3927 s/iter. ETA=0:21:03\n",
            "\u001b[32m[04/30 15:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 1795/5000. Dataloading: 0.0020 s/iter. Inference: 0.3905 s/iter. Eval: 0.0002 s/iter. Total: 0.3928 s/iter. ETA=0:20:58\n",
            "\u001b[32m[04/30 15:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 1808/5000. Dataloading: 0.0020 s/iter. Inference: 0.3905 s/iter. Eval: 0.0002 s/iter. Total: 0.3928 s/iter. ETA=0:20:53\n",
            "\u001b[32m[04/30 15:34:45 d2.evaluation.evaluator]: \u001b[0mInference done 1821/5000. Dataloading: 0.0020 s/iter. Inference: 0.3906 s/iter. Eval: 0.0002 s/iter. Total: 0.3929 s/iter. ETA=0:20:49\n",
            "\u001b[32m[04/30 15:34:50 d2.evaluation.evaluator]: \u001b[0mInference done 1834/5000. Dataloading: 0.0020 s/iter. Inference: 0.3906 s/iter. Eval: 0.0002 s/iter. Total: 0.3930 s/iter. ETA=0:20:44\n",
            "\u001b[32m[04/30 15:34:55 d2.evaluation.evaluator]: \u001b[0mInference done 1847/5000. Dataloading: 0.0020 s/iter. Inference: 0.3907 s/iter. Eval: 0.0002 s/iter. Total: 0.3930 s/iter. ETA=0:20:39\n",
            "\u001b[32m[04/30 15:35:00 d2.evaluation.evaluator]: \u001b[0mInference done 1860/5000. Dataloading: 0.0020 s/iter. Inference: 0.3907 s/iter. Eval: 0.0002 s/iter. Total: 0.3931 s/iter. ETA=0:20:34\n",
            "\u001b[32m[04/30 15:35:06 d2.evaluation.evaluator]: \u001b[0mInference done 1873/5000. Dataloading: 0.0020 s/iter. Inference: 0.3908 s/iter. Eval: 0.0002 s/iter. Total: 0.3931 s/iter. ETA=0:20:29\n",
            "\u001b[32m[04/30 15:35:11 d2.evaluation.evaluator]: \u001b[0mInference done 1886/5000. Dataloading: 0.0020 s/iter. Inference: 0.3909 s/iter. Eval: 0.0002 s/iter. Total: 0.3932 s/iter. ETA=0:20:24\n",
            "\u001b[32m[04/30 15:35:16 d2.evaluation.evaluator]: \u001b[0mInference done 1899/5000. Dataloading: 0.0020 s/iter. Inference: 0.3909 s/iter. Eval: 0.0002 s/iter. Total: 0.3933 s/iter. ETA=0:20:19\n",
            "\u001b[32m[04/30 15:35:21 d2.evaluation.evaluator]: \u001b[0mInference done 1912/5000. Dataloading: 0.0020 s/iter. Inference: 0.3910 s/iter. Eval: 0.0002 s/iter. Total: 0.3933 s/iter. ETA=0:20:14\n",
            "\u001b[32m[04/30 15:35:26 d2.evaluation.evaluator]: \u001b[0mInference done 1925/5000. Dataloading: 0.0020 s/iter. Inference: 0.3910 s/iter. Eval: 0.0002 s/iter. Total: 0.3934 s/iter. ETA=0:20:09\n",
            "\u001b[32m[04/30 15:35:32 d2.evaluation.evaluator]: \u001b[0mInference done 1938/5000. Dataloading: 0.0020 s/iter. Inference: 0.3911 s/iter. Eval: 0.0002 s/iter. Total: 0.3934 s/iter. ETA=0:20:04\n",
            "\u001b[32m[04/30 15:35:37 d2.evaluation.evaluator]: \u001b[0mInference done 1951/5000. Dataloading: 0.0020 s/iter. Inference: 0.3911 s/iter. Eval: 0.0002 s/iter. Total: 0.3934 s/iter. ETA=0:19:59\n",
            "\u001b[32m[04/30 15:35:42 d2.evaluation.evaluator]: \u001b[0mInference done 1964/5000. Dataloading: 0.0020 s/iter. Inference: 0.3912 s/iter. Eval: 0.0002 s/iter. Total: 0.3935 s/iter. ETA=0:19:54\n",
            "\u001b[32m[04/30 15:35:47 d2.evaluation.evaluator]: \u001b[0mInference done 1977/5000. Dataloading: 0.0020 s/iter. Inference: 0.3912 s/iter. Eval: 0.0002 s/iter. Total: 0.3935 s/iter. ETA=0:19:49\n",
            "\u001b[32m[04/30 15:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 1990/5000. Dataloading: 0.0020 s/iter. Inference: 0.3913 s/iter. Eval: 0.0002 s/iter. Total: 0.3936 s/iter. ETA=0:19:44\n",
            "\u001b[32m[04/30 15:35:58 d2.evaluation.evaluator]: \u001b[0mInference done 2003/5000. Dataloading: 0.0020 s/iter. Inference: 0.3913 s/iter. Eval: 0.0002 s/iter. Total: 0.3936 s/iter. ETA=0:19:39\n",
            "\u001b[32m[04/30 15:36:03 d2.evaluation.evaluator]: \u001b[0mInference done 2016/5000. Dataloading: 0.0020 s/iter. Inference: 0.3914 s/iter. Eval: 0.0002 s/iter. Total: 0.3937 s/iter. ETA=0:19:34\n",
            "\u001b[32m[04/30 15:36:08 d2.evaluation.evaluator]: \u001b[0mInference done 2029/5000. Dataloading: 0.0020 s/iter. Inference: 0.3914 s/iter. Eval: 0.0002 s/iter. Total: 0.3937 s/iter. ETA=0:19:29\n",
            "\u001b[32m[04/30 15:36:13 d2.evaluation.evaluator]: \u001b[0mInference done 2042/5000. Dataloading: 0.0020 s/iter. Inference: 0.3914 s/iter. Eval: 0.0002 s/iter. Total: 0.3938 s/iter. ETA=0:19:24\n",
            "\u001b[32m[04/30 15:36:18 d2.evaluation.evaluator]: \u001b[0mInference done 2055/5000. Dataloading: 0.0020 s/iter. Inference: 0.3914 s/iter. Eval: 0.0002 s/iter. Total: 0.3938 s/iter. ETA=0:19:19\n",
            "\u001b[32m[04/30 15:36:24 d2.evaluation.evaluator]: \u001b[0mInference done 2068/5000. Dataloading: 0.0020 s/iter. Inference: 0.3915 s/iter. Eval: 0.0002 s/iter. Total: 0.3939 s/iter. ETA=0:19:14\n",
            "\u001b[32m[04/30 15:36:29 d2.evaluation.evaluator]: \u001b[0mInference done 2081/5000. Dataloading: 0.0020 s/iter. Inference: 0.3916 s/iter. Eval: 0.0002 s/iter. Total: 0.3939 s/iter. ETA=0:19:09\n",
            "\u001b[32m[04/30 15:36:34 d2.evaluation.evaluator]: \u001b[0mInference done 2094/5000. Dataloading: 0.0020 s/iter. Inference: 0.3916 s/iter. Eval: 0.0002 s/iter. Total: 0.3939 s/iter. ETA=0:19:04\n",
            "\u001b[32m[04/30 15:36:39 d2.evaluation.evaluator]: \u001b[0mInference done 2107/5000. Dataloading: 0.0020 s/iter. Inference: 0.3916 s/iter. Eval: 0.0002 s/iter. Total: 0.3940 s/iter. ETA=0:18:59\n",
            "\u001b[32m[04/30 15:36:44 d2.evaluation.evaluator]: \u001b[0mInference done 2120/5000. Dataloading: 0.0020 s/iter. Inference: 0.3917 s/iter. Eval: 0.0002 s/iter. Total: 0.3940 s/iter. ETA=0:18:54\n",
            "\u001b[32m[04/30 15:36:50 d2.evaluation.evaluator]: \u001b[0mInference done 2133/5000. Dataloading: 0.0020 s/iter. Inference: 0.3917 s/iter. Eval: 0.0002 s/iter. Total: 0.3940 s/iter. ETA=0:18:49\n",
            "\u001b[32m[04/30 15:36:55 d2.evaluation.evaluator]: \u001b[0mInference done 2146/5000. Dataloading: 0.0020 s/iter. Inference: 0.3917 s/iter. Eval: 0.0002 s/iter. Total: 0.3940 s/iter. ETA=0:18:44\n",
            "\u001b[32m[04/30 15:37:00 d2.evaluation.evaluator]: \u001b[0mInference done 2159/5000. Dataloading: 0.0020 s/iter. Inference: 0.3917 s/iter. Eval: 0.0002 s/iter. Total: 0.3941 s/iter. ETA=0:18:39\n",
            "\u001b[32m[04/30 15:37:05 d2.evaluation.evaluator]: \u001b[0mInference done 2172/5000. Dataloading: 0.0020 s/iter. Inference: 0.3917 s/iter. Eval: 0.0002 s/iter. Total: 0.3941 s/iter. ETA=0:18:34\n",
            "\u001b[32m[04/30 15:37:10 d2.evaluation.evaluator]: \u001b[0mInference done 2185/5000. Dataloading: 0.0020 s/iter. Inference: 0.3918 s/iter. Eval: 0.0002 s/iter. Total: 0.3941 s/iter. ETA=0:18:29\n",
            "\u001b[32m[04/30 15:37:16 d2.evaluation.evaluator]: \u001b[0mInference done 2198/5000. Dataloading: 0.0020 s/iter. Inference: 0.3918 s/iter. Eval: 0.0002 s/iter. Total: 0.3941 s/iter. ETA=0:18:24\n",
            "\u001b[32m[04/30 15:37:21 d2.evaluation.evaluator]: \u001b[0mInference done 2211/5000. Dataloading: 0.0020 s/iter. Inference: 0.3918 s/iter. Eval: 0.0002 s/iter. Total: 0.3942 s/iter. ETA=0:18:19\n",
            "\u001b[32m[04/30 15:37:26 d2.evaluation.evaluator]: \u001b[0mInference done 2224/5000. Dataloading: 0.0020 s/iter. Inference: 0.3919 s/iter. Eval: 0.0002 s/iter. Total: 0.3942 s/iter. ETA=0:18:14\n",
            "\u001b[32m[04/30 15:37:31 d2.evaluation.evaluator]: \u001b[0mInference done 2237/5000. Dataloading: 0.0020 s/iter. Inference: 0.3919 s/iter. Eval: 0.0002 s/iter. Total: 0.3942 s/iter. ETA=0:18:09\n",
            "\u001b[32m[04/30 15:37:36 d2.evaluation.evaluator]: \u001b[0mInference done 2250/5000. Dataloading: 0.0020 s/iter. Inference: 0.3919 s/iter. Eval: 0.0002 s/iter. Total: 0.3943 s/iter. ETA=0:18:04\n",
            "\u001b[32m[04/30 15:37:42 d2.evaluation.evaluator]: \u001b[0mInference done 2263/5000. Dataloading: 0.0020 s/iter. Inference: 0.3920 s/iter. Eval: 0.0002 s/iter. Total: 0.3943 s/iter. ETA=0:17:59\n",
            "\u001b[32m[04/30 15:37:47 d2.evaluation.evaluator]: \u001b[0mInference done 2276/5000. Dataloading: 0.0020 s/iter. Inference: 0.3920 s/iter. Eval: 0.0002 s/iter. Total: 0.3943 s/iter. ETA=0:17:54\n",
            "\u001b[32m[04/30 15:37:52 d2.evaluation.evaluator]: \u001b[0mInference done 2289/5000. Dataloading: 0.0020 s/iter. Inference: 0.3921 s/iter. Eval: 0.0002 s/iter. Total: 0.3944 s/iter. ETA=0:17:49\n",
            "\u001b[32m[04/30 15:37:57 d2.evaluation.evaluator]: \u001b[0mInference done 2302/5000. Dataloading: 0.0020 s/iter. Inference: 0.3921 s/iter. Eval: 0.0002 s/iter. Total: 0.3944 s/iter. ETA=0:17:44\n",
            "\u001b[32m[04/30 15:38:02 d2.evaluation.evaluator]: \u001b[0mInference done 2315/5000. Dataloading: 0.0020 s/iter. Inference: 0.3921 s/iter. Eval: 0.0002 s/iter. Total: 0.3944 s/iter. ETA=0:17:39\n",
            "\u001b[32m[04/30 15:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 2328/5000. Dataloading: 0.0020 s/iter. Inference: 0.3921 s/iter. Eval: 0.0002 s/iter. Total: 0.3945 s/iter. ETA=0:17:33\n",
            "\u001b[32m[04/30 15:38:13 d2.evaluation.evaluator]: \u001b[0mInference done 2341/5000. Dataloading: 0.0020 s/iter. Inference: 0.3921 s/iter. Eval: 0.0002 s/iter. Total: 0.3945 s/iter. ETA=0:17:28\n",
            "\u001b[32m[04/30 15:38:18 d2.evaluation.evaluator]: \u001b[0mInference done 2354/5000. Dataloading: 0.0020 s/iter. Inference: 0.3922 s/iter. Eval: 0.0002 s/iter. Total: 0.3946 s/iter. ETA=0:17:23\n",
            "\u001b[32m[04/30 15:38:23 d2.evaluation.evaluator]: \u001b[0mInference done 2367/5000. Dataloading: 0.0020 s/iter. Inference: 0.3923 s/iter. Eval: 0.0002 s/iter. Total: 0.3946 s/iter. ETA=0:17:19\n",
            "\u001b[32m[04/30 15:38:28 d2.evaluation.evaluator]: \u001b[0mInference done 2380/5000. Dataloading: 0.0020 s/iter. Inference: 0.3923 s/iter. Eval: 0.0002 s/iter. Total: 0.3946 s/iter. ETA=0:17:13\n",
            "\u001b[32m[04/30 15:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 2393/5000. Dataloading: 0.0020 s/iter. Inference: 0.3924 s/iter. Eval: 0.0002 s/iter. Total: 0.3947 s/iter. ETA=0:17:08\n",
            "\u001b[32m[04/30 15:38:39 d2.evaluation.evaluator]: \u001b[0mInference done 2406/5000. Dataloading: 0.0020 s/iter. Inference: 0.3924 s/iter. Eval: 0.0002 s/iter. Total: 0.3947 s/iter. ETA=0:17:03\n",
            "\u001b[32m[04/30 15:38:44 d2.evaluation.evaluator]: \u001b[0mInference done 2419/5000. Dataloading: 0.0020 s/iter. Inference: 0.3924 s/iter. Eval: 0.0002 s/iter. Total: 0.3947 s/iter. ETA=0:16:58\n",
            "\u001b[32m[04/30 15:38:49 d2.evaluation.evaluator]: \u001b[0mInference done 2432/5000. Dataloading: 0.0020 s/iter. Inference: 0.3925 s/iter. Eval: 0.0002 s/iter. Total: 0.3948 s/iter. ETA=0:16:53\n",
            "\u001b[32m[04/30 15:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 2445/5000. Dataloading: 0.0020 s/iter. Inference: 0.3925 s/iter. Eval: 0.0002 s/iter. Total: 0.3948 s/iter. ETA=0:16:48\n",
            "\u001b[32m[04/30 15:39:00 d2.evaluation.evaluator]: \u001b[0mInference done 2458/5000. Dataloading: 0.0020 s/iter. Inference: 0.3925 s/iter. Eval: 0.0002 s/iter. Total: 0.3949 s/iter. ETA=0:16:43\n",
            "\u001b[32m[04/30 15:39:05 d2.evaluation.evaluator]: \u001b[0mInference done 2471/5000. Dataloading: 0.0020 s/iter. Inference: 0.3926 s/iter. Eval: 0.0002 s/iter. Total: 0.3949 s/iter. ETA=0:16:38\n",
            "\u001b[32m[04/30 15:39:10 d2.evaluation.evaluator]: \u001b[0mInference done 2484/5000. Dataloading: 0.0020 s/iter. Inference: 0.3926 s/iter. Eval: 0.0002 s/iter. Total: 0.3949 s/iter. ETA=0:16:33\n",
            "\u001b[32m[04/30 15:39:15 d2.evaluation.evaluator]: \u001b[0mInference done 2497/5000. Dataloading: 0.0020 s/iter. Inference: 0.3926 s/iter. Eval: 0.0002 s/iter. Total: 0.3949 s/iter. ETA=0:16:28\n",
            "\u001b[32m[04/30 15:39:20 d2.evaluation.evaluator]: \u001b[0mInference done 2510/5000. Dataloading: 0.0020 s/iter. Inference: 0.3926 s/iter. Eval: 0.0002 s/iter. Total: 0.3950 s/iter. ETA=0:16:23\n",
            "\u001b[32m[04/30 15:39:26 d2.evaluation.evaluator]: \u001b[0mInference done 2523/5000. Dataloading: 0.0020 s/iter. Inference: 0.3926 s/iter. Eval: 0.0002 s/iter. Total: 0.3950 s/iter. ETA=0:16:18\n",
            "\u001b[32m[04/30 15:39:31 d2.evaluation.evaluator]: \u001b[0mInference done 2536/5000. Dataloading: 0.0020 s/iter. Inference: 0.3926 s/iter. Eval: 0.0002 s/iter. Total: 0.3950 s/iter. ETA=0:16:13\n",
            "\u001b[32m[04/30 15:39:36 d2.evaluation.evaluator]: \u001b[0mInference done 2549/5000. Dataloading: 0.0020 s/iter. Inference: 0.3927 s/iter. Eval: 0.0002 s/iter. Total: 0.3950 s/iter. ETA=0:16:08\n",
            "\u001b[32m[04/30 15:39:41 d2.evaluation.evaluator]: \u001b[0mInference done 2562/5000. Dataloading: 0.0020 s/iter. Inference: 0.3927 s/iter. Eval: 0.0002 s/iter. Total: 0.3951 s/iter. ETA=0:16:03\n",
            "\u001b[32m[04/30 15:39:47 d2.evaluation.evaluator]: \u001b[0mInference done 2575/5000. Dataloading: 0.0020 s/iter. Inference: 0.3928 s/iter. Eval: 0.0002 s/iter. Total: 0.3951 s/iter. ETA=0:15:58\n",
            "\u001b[32m[04/30 15:39:52 d2.evaluation.evaluator]: \u001b[0mInference done 2588/5000. Dataloading: 0.0020 s/iter. Inference: 0.3927 s/iter. Eval: 0.0002 s/iter. Total: 0.3951 s/iter. ETA=0:15:52\n",
            "\u001b[32m[04/30 15:39:57 d2.evaluation.evaluator]: \u001b[0mInference done 2601/5000. Dataloading: 0.0020 s/iter. Inference: 0.3928 s/iter. Eval: 0.0002 s/iter. Total: 0.3951 s/iter. ETA=0:15:47\n",
            "\u001b[32m[04/30 15:40:02 d2.evaluation.evaluator]: \u001b[0mInference done 2614/5000. Dataloading: 0.0020 s/iter. Inference: 0.3928 s/iter. Eval: 0.0002 s/iter. Total: 0.3951 s/iter. ETA=0:15:42\n",
            "\u001b[32m[04/30 15:40:07 d2.evaluation.evaluator]: \u001b[0mInference done 2627/5000. Dataloading: 0.0020 s/iter. Inference: 0.3928 s/iter. Eval: 0.0002 s/iter. Total: 0.3952 s/iter. ETA=0:15:37\n",
            "\u001b[32m[04/30 15:40:13 d2.evaluation.evaluator]: \u001b[0mInference done 2640/5000. Dataloading: 0.0020 s/iter. Inference: 0.3929 s/iter. Eval: 0.0002 s/iter. Total: 0.3952 s/iter. ETA=0:15:32\n",
            "\u001b[32m[04/30 15:40:18 d2.evaluation.evaluator]: \u001b[0mInference done 2653/5000. Dataloading: 0.0020 s/iter. Inference: 0.3929 s/iter. Eval: 0.0002 s/iter. Total: 0.3952 s/iter. ETA=0:15:27\n",
            "\u001b[32m[04/30 15:40:23 d2.evaluation.evaluator]: \u001b[0mInference done 2666/5000. Dataloading: 0.0020 s/iter. Inference: 0.3929 s/iter. Eval: 0.0002 s/iter. Total: 0.3953 s/iter. ETA=0:15:22\n",
            "\u001b[32m[04/30 15:40:28 d2.evaluation.evaluator]: \u001b[0mInference done 2679/5000. Dataloading: 0.0020 s/iter. Inference: 0.3930 s/iter. Eval: 0.0002 s/iter. Total: 0.3953 s/iter. ETA=0:15:17\n",
            "\u001b[32m[04/30 15:40:33 d2.evaluation.evaluator]: \u001b[0mInference done 2692/5000. Dataloading: 0.0020 s/iter. Inference: 0.3930 s/iter. Eval: 0.0002 s/iter. Total: 0.3954 s/iter. ETA=0:15:12\n",
            "\u001b[32m[04/30 15:40:39 d2.evaluation.evaluator]: \u001b[0mInference done 2705/5000. Dataloading: 0.0020 s/iter. Inference: 0.3931 s/iter. Eval: 0.0002 s/iter. Total: 0.3954 s/iter. ETA=0:15:07\n",
            "\u001b[32m[04/30 15:40:44 d2.evaluation.evaluator]: \u001b[0mInference done 2718/5000. Dataloading: 0.0020 s/iter. Inference: 0.3931 s/iter. Eval: 0.0002 s/iter. Total: 0.3954 s/iter. ETA=0:15:02\n",
            "\u001b[32m[04/30 15:40:49 d2.evaluation.evaluator]: \u001b[0mInference done 2731/5000. Dataloading: 0.0020 s/iter. Inference: 0.3931 s/iter. Eval: 0.0002 s/iter. Total: 0.3955 s/iter. ETA=0:14:57\n",
            "\u001b[32m[04/30 15:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 2744/5000. Dataloading: 0.0020 s/iter. Inference: 0.3931 s/iter. Eval: 0.0002 s/iter. Total: 0.3955 s/iter. ETA=0:14:52\n",
            "\u001b[32m[04/30 15:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 2757/5000. Dataloading: 0.0020 s/iter. Inference: 0.3931 s/iter. Eval: 0.0002 s/iter. Total: 0.3955 s/iter. ETA=0:14:47\n",
            "\u001b[32m[04/30 15:41:05 d2.evaluation.evaluator]: \u001b[0mInference done 2770/5000. Dataloading: 0.0020 s/iter. Inference: 0.3932 s/iter. Eval: 0.0002 s/iter. Total: 0.3955 s/iter. ETA=0:14:41\n",
            "\u001b[32m[04/30 15:41:10 d2.evaluation.evaluator]: \u001b[0mInference done 2783/5000. Dataloading: 0.0020 s/iter. Inference: 0.3932 s/iter. Eval: 0.0002 s/iter. Total: 0.3955 s/iter. ETA=0:14:36\n",
            "\u001b[32m[04/30 15:41:15 d2.evaluation.evaluator]: \u001b[0mInference done 2796/5000. Dataloading: 0.0020 s/iter. Inference: 0.3932 s/iter. Eval: 0.0002 s/iter. Total: 0.3955 s/iter. ETA=0:14:31\n",
            "\u001b[32m[04/30 15:41:20 d2.evaluation.evaluator]: \u001b[0mInference done 2809/5000. Dataloading: 0.0020 s/iter. Inference: 0.3932 s/iter. Eval: 0.0002 s/iter. Total: 0.3956 s/iter. ETA=0:14:26\n",
            "\u001b[32m[04/30 15:41:25 d2.evaluation.evaluator]: \u001b[0mInference done 2822/5000. Dataloading: 0.0020 s/iter. Inference: 0.3932 s/iter. Eval: 0.0002 s/iter. Total: 0.3956 s/iter. ETA=0:14:21\n",
            "\u001b[32m[04/30 15:41:31 d2.evaluation.evaluator]: \u001b[0mInference done 2835/5000. Dataloading: 0.0020 s/iter. Inference: 0.3933 s/iter. Eval: 0.0002 s/iter. Total: 0.3956 s/iter. ETA=0:14:16\n",
            "\u001b[32m[04/30 15:41:36 d2.evaluation.evaluator]: \u001b[0mInference done 2848/5000. Dataloading: 0.0020 s/iter. Inference: 0.3933 s/iter. Eval: 0.0002 s/iter. Total: 0.3957 s/iter. ETA=0:14:11\n",
            "\u001b[32m[04/30 15:41:41 d2.evaluation.evaluator]: \u001b[0mInference done 2861/5000. Dataloading: 0.0020 s/iter. Inference: 0.3933 s/iter. Eval: 0.0002 s/iter. Total: 0.3957 s/iter. ETA=0:14:06\n",
            "\u001b[32m[04/30 15:41:46 d2.evaluation.evaluator]: \u001b[0mInference done 2874/5000. Dataloading: 0.0020 s/iter. Inference: 0.3934 s/iter. Eval: 0.0002 s/iter. Total: 0.3957 s/iter. ETA=0:14:01\n",
            "\u001b[32m[04/30 15:41:52 d2.evaluation.evaluator]: \u001b[0mInference done 2887/5000. Dataloading: 0.0020 s/iter. Inference: 0.3934 s/iter. Eval: 0.0002 s/iter. Total: 0.3957 s/iter. ETA=0:13:56\n",
            "\u001b[32m[04/30 15:41:57 d2.evaluation.evaluator]: \u001b[0mInference done 2900/5000. Dataloading: 0.0020 s/iter. Inference: 0.3934 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:51\n",
            "\u001b[32m[04/30 15:42:02 d2.evaluation.evaluator]: \u001b[0mInference done 2913/5000. Dataloading: 0.0020 s/iter. Inference: 0.3934 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:45\n",
            "\u001b[32m[04/30 15:42:07 d2.evaluation.evaluator]: \u001b[0mInference done 2926/5000. Dataloading: 0.0020 s/iter. Inference: 0.3934 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:40\n",
            "\u001b[32m[04/30 15:42:12 d2.evaluation.evaluator]: \u001b[0mInference done 2939/5000. Dataloading: 0.0020 s/iter. Inference: 0.3935 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:35\n",
            "\u001b[32m[04/30 15:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 2952/5000. Dataloading: 0.0020 s/iter. Inference: 0.3935 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:30\n",
            "\u001b[32m[04/30 15:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 2965/5000. Dataloading: 0.0020 s/iter. Inference: 0.3935 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:25\n",
            "\u001b[32m[04/30 15:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 2978/5000. Dataloading: 0.0020 s/iter. Inference: 0.3935 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:20\n",
            "\u001b[32m[04/30 15:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 2991/5000. Dataloading: 0.0020 s/iter. Inference: 0.3935 s/iter. Eval: 0.0002 s/iter. Total: 0.3958 s/iter. ETA=0:13:15\n",
            "\u001b[32m[04/30 15:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 3004/5000. Dataloading: 0.0020 s/iter. Inference: 0.3935 s/iter. Eval: 0.0002 s/iter. Total: 0.3959 s/iter. ETA=0:13:10\n",
            "\u001b[32m[04/30 15:42:44 d2.evaluation.evaluator]: \u001b[0mInference done 3017/5000. Dataloading: 0.0020 s/iter. Inference: 0.3936 s/iter. Eval: 0.0002 s/iter. Total: 0.3959 s/iter. ETA=0:13:05\n",
            "\u001b[32m[04/30 15:42:49 d2.evaluation.evaluator]: \u001b[0mInference done 3030/5000. Dataloading: 0.0020 s/iter. Inference: 0.3936 s/iter. Eval: 0.0002 s/iter. Total: 0.3959 s/iter. ETA=0:12:59\n",
            "\u001b[32m[04/30 15:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 3043/5000. Dataloading: 0.0020 s/iter. Inference: 0.3936 s/iter. Eval: 0.0002 s/iter. Total: 0.3960 s/iter. ETA=0:12:54\n",
            "\u001b[32m[04/30 15:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 3056/5000. Dataloading: 0.0020 s/iter. Inference: 0.3937 s/iter. Eval: 0.0002 s/iter. Total: 0.3960 s/iter. ETA=0:12:49\n",
            "\u001b[32m[04/30 15:43:05 d2.evaluation.evaluator]: \u001b[0mInference done 3069/5000. Dataloading: 0.0020 s/iter. Inference: 0.3937 s/iter. Eval: 0.0002 s/iter. Total: 0.3960 s/iter. ETA=0:12:44\n",
            "\u001b[32m[04/30 15:43:10 d2.evaluation.evaluator]: \u001b[0mInference done 3082/5000. Dataloading: 0.0020 s/iter. Inference: 0.3937 s/iter. Eval: 0.0002 s/iter. Total: 0.3961 s/iter. ETA=0:12:39\n",
            "\u001b[32m[04/30 15:43:15 d2.evaluation.evaluator]: \u001b[0mInference done 3095/5000. Dataloading: 0.0020 s/iter. Inference: 0.3937 s/iter. Eval: 0.0002 s/iter. Total: 0.3961 s/iter. ETA=0:12:34\n",
            "\u001b[32m[04/30 15:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 3108/5000. Dataloading: 0.0020 s/iter. Inference: 0.3938 s/iter. Eval: 0.0002 s/iter. Total: 0.3961 s/iter. ETA=0:12:29\n",
            "\u001b[32m[04/30 15:43:25 d2.evaluation.evaluator]: \u001b[0mInference done 3121/5000. Dataloading: 0.0020 s/iter. Inference: 0.3938 s/iter. Eval: 0.0002 s/iter. Total: 0.3961 s/iter. ETA=0:12:24\n",
            "\u001b[32m[04/30 15:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 3134/5000. Dataloading: 0.0020 s/iter. Inference: 0.3938 s/iter. Eval: 0.0002 s/iter. Total: 0.3961 s/iter. ETA=0:12:19\n",
            "\u001b[32m[04/30 15:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 3147/5000. Dataloading: 0.0020 s/iter. Inference: 0.3938 s/iter. Eval: 0.0002 s/iter. Total: 0.3962 s/iter. ETA=0:12:14\n",
            "\u001b[32m[04/30 15:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 3160/5000. Dataloading: 0.0020 s/iter. Inference: 0.3938 s/iter. Eval: 0.0002 s/iter. Total: 0.3962 s/iter. ETA=0:12:08\n",
            "\u001b[32m[04/30 15:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 3173/5000. Dataloading: 0.0020 s/iter. Inference: 0.3939 s/iter. Eval: 0.0002 s/iter. Total: 0.3962 s/iter. ETA=0:12:03\n",
            "\u001b[32m[04/30 15:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 3186/5000. Dataloading: 0.0020 s/iter. Inference: 0.3939 s/iter. Eval: 0.0002 s/iter. Total: 0.3962 s/iter. ETA=0:11:58\n",
            "\u001b[32m[04/30 15:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 3199/5000. Dataloading: 0.0020 s/iter. Inference: 0.3939 s/iter. Eval: 0.0002 s/iter. Total: 0.3962 s/iter. ETA=0:11:53\n",
            "\u001b[32m[04/30 15:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 3212/5000. Dataloading: 0.0020 s/iter. Inference: 0.3939 s/iter. Eval: 0.0002 s/iter. Total: 0.3963 s/iter. ETA=0:11:48\n",
            "\u001b[32m[04/30 15:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 3225/5000. Dataloading: 0.0020 s/iter. Inference: 0.3939 s/iter. Eval: 0.0002 s/iter. Total: 0.3963 s/iter. ETA=0:11:43\n",
            "\u001b[32m[04/30 15:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 3238/5000. Dataloading: 0.0020 s/iter. Inference: 0.3940 s/iter. Eval: 0.0002 s/iter. Total: 0.3963 s/iter. ETA=0:11:38\n",
            "\u001b[32m[04/30 15:44:18 d2.evaluation.evaluator]: \u001b[0mInference done 3251/5000. Dataloading: 0.0020 s/iter. Inference: 0.3940 s/iter. Eval: 0.0002 s/iter. Total: 0.3963 s/iter. ETA=0:11:33\n",
            "\u001b[32m[04/30 15:44:23 d2.evaluation.evaluator]: \u001b[0mInference done 3264/5000. Dataloading: 0.0020 s/iter. Inference: 0.3940 s/iter. Eval: 0.0002 s/iter. Total: 0.3963 s/iter. ETA=0:11:28\n",
            "\u001b[32m[04/30 15:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 3277/5000. Dataloading: 0.0020 s/iter. Inference: 0.3940 s/iter. Eval: 0.0002 s/iter. Total: 0.3964 s/iter. ETA=0:11:22\n",
            "\u001b[32m[04/30 15:44:33 d2.evaluation.evaluator]: \u001b[0mInference done 3290/5000. Dataloading: 0.0020 s/iter. Inference: 0.3941 s/iter. Eval: 0.0002 s/iter. Total: 0.3964 s/iter. ETA=0:11:17\n",
            "\u001b[32m[04/30 15:44:39 d2.evaluation.evaluator]: \u001b[0mInference done 3303/5000. Dataloading: 0.0020 s/iter. Inference: 0.3941 s/iter. Eval: 0.0002 s/iter. Total: 0.3964 s/iter. ETA=0:11:12\n",
            "\u001b[32m[04/30 15:44:44 d2.evaluation.evaluator]: \u001b[0mInference done 3316/5000. Dataloading: 0.0020 s/iter. Inference: 0.3941 s/iter. Eval: 0.0002 s/iter. Total: 0.3964 s/iter. ETA=0:11:07\n",
            "\u001b[32m[04/30 15:44:49 d2.evaluation.evaluator]: \u001b[0mInference done 3329/5000. Dataloading: 0.0020 s/iter. Inference: 0.3941 s/iter. Eval: 0.0002 s/iter. Total: 0.3965 s/iter. ETA=0:11:02\n",
            "\u001b[32m[04/30 15:44:54 d2.evaluation.evaluator]: \u001b[0mInference done 3342/5000. Dataloading: 0.0020 s/iter. Inference: 0.3941 s/iter. Eval: 0.0002 s/iter. Total: 0.3965 s/iter. ETA=0:10:57\n",
            "\u001b[32m[04/30 15:44:59 d2.evaluation.evaluator]: \u001b[0mInference done 3355/5000. Dataloading: 0.0020 s/iter. Inference: 0.3941 s/iter. Eval: 0.0002 s/iter. Total: 0.3965 s/iter. ETA=0:10:52\n",
            "\u001b[32m[04/30 15:45:05 d2.evaluation.evaluator]: \u001b[0mInference done 3368/5000. Dataloading: 0.0020 s/iter. Inference: 0.3942 s/iter. Eval: 0.0002 s/iter. Total: 0.3965 s/iter. ETA=0:10:47\n",
            "\u001b[32m[04/30 15:45:10 d2.evaluation.evaluator]: \u001b[0mInference done 3381/5000. Dataloading: 0.0020 s/iter. Inference: 0.3942 s/iter. Eval: 0.0002 s/iter. Total: 0.3965 s/iter. ETA=0:10:42\n",
            "\u001b[32m[04/30 15:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 3394/5000. Dataloading: 0.0020 s/iter. Inference: 0.3942 s/iter. Eval: 0.0002 s/iter. Total: 0.3966 s/iter. ETA=0:10:36\n",
            "\u001b[32m[04/30 15:45:20 d2.evaluation.evaluator]: \u001b[0mInference done 3407/5000. Dataloading: 0.0020 s/iter. Inference: 0.3942 s/iter. Eval: 0.0002 s/iter. Total: 0.3966 s/iter. ETA=0:10:31\n",
            "\u001b[32m[04/30 15:45:25 d2.evaluation.evaluator]: \u001b[0mInference done 3420/5000. Dataloading: 0.0020 s/iter. Inference: 0.3942 s/iter. Eval: 0.0002 s/iter. Total: 0.3966 s/iter. ETA=0:10:26\n",
            "\u001b[32m[04/30 15:45:31 d2.evaluation.evaluator]: \u001b[0mInference done 3433/5000. Dataloading: 0.0020 s/iter. Inference: 0.3943 s/iter. Eval: 0.0002 s/iter. Total: 0.3966 s/iter. ETA=0:10:21\n",
            "\u001b[32m[04/30 15:45:36 d2.evaluation.evaluator]: \u001b[0mInference done 3446/5000. Dataloading: 0.0020 s/iter. Inference: 0.3943 s/iter. Eval: 0.0002 s/iter. Total: 0.3966 s/iter. ETA=0:10:16\n",
            "\u001b[32m[04/30 15:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 3459/5000. Dataloading: 0.0020 s/iter. Inference: 0.3943 s/iter. Eval: 0.0002 s/iter. Total: 0.3966 s/iter. ETA=0:10:11\n",
            "\u001b[32m[04/30 15:45:46 d2.evaluation.evaluator]: \u001b[0mInference done 3472/5000. Dataloading: 0.0020 s/iter. Inference: 0.3943 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:10:06\n",
            "\u001b[32m[04/30 15:45:52 d2.evaluation.evaluator]: \u001b[0mInference done 3485/5000. Dataloading: 0.0020 s/iter. Inference: 0.3943 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:10:00\n",
            "\u001b[32m[04/30 15:45:57 d2.evaluation.evaluator]: \u001b[0mInference done 3498/5000. Dataloading: 0.0020 s/iter. Inference: 0.3943 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:09:55\n",
            "\u001b[32m[04/30 15:46:02 d2.evaluation.evaluator]: \u001b[0mInference done 3511/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:09:50\n",
            "\u001b[32m[04/30 15:46:07 d2.evaluation.evaluator]: \u001b[0mInference done 3524/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:09:45\n",
            "\u001b[32m[04/30 15:46:12 d2.evaluation.evaluator]: \u001b[0mInference done 3537/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:09:40\n",
            "\u001b[32m[04/30 15:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 3550/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:09:35\n",
            "\u001b[32m[04/30 15:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 3563/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3967 s/iter. ETA=0:09:30\n",
            "\u001b[32m[04/30 15:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 3576/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:09:24\n",
            "\u001b[32m[04/30 15:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 3589/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:09:19\n",
            "\u001b[32m[04/30 15:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 3602/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:09:14\n",
            "\u001b[32m[04/30 15:46:44 d2.evaluation.evaluator]: \u001b[0mInference done 3615/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:09:09\n",
            "\u001b[32m[04/30 15:46:49 d2.evaluation.evaluator]: \u001b[0mInference done 3628/5000. Dataloading: 0.0020 s/iter. Inference: 0.3944 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:09:04\n",
            "\u001b[32m[04/30 15:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 3641/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:08:59\n",
            "\u001b[32m[04/30 15:46:59 d2.evaluation.evaluator]: \u001b[0mInference done 3654/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:08:54\n",
            "\u001b[32m[04/30 15:47:04 d2.evaluation.evaluator]: \u001b[0mInference done 3667/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:08:48\n",
            "\u001b[32m[04/30 15:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 3680/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:08:43\n",
            "\u001b[32m[04/30 15:47:15 d2.evaluation.evaluator]: \u001b[0mInference done 3693/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3968 s/iter. ETA=0:08:38\n",
            "\u001b[32m[04/30 15:47:20 d2.evaluation.evaluator]: \u001b[0mInference done 3706/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:08:33\n",
            "\u001b[32m[04/30 15:47:25 d2.evaluation.evaluator]: \u001b[0mInference done 3719/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:08:28\n",
            "\u001b[32m[04/30 15:47:30 d2.evaluation.evaluator]: \u001b[0mInference done 3732/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:08:23\n",
            "\u001b[32m[04/30 15:47:36 d2.evaluation.evaluator]: \u001b[0mInference done 3745/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:08:18\n",
            "\u001b[32m[04/30 15:47:41 d2.evaluation.evaluator]: \u001b[0mInference done 3758/5000. Dataloading: 0.0020 s/iter. Inference: 0.3945 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:08:12\n",
            "\u001b[32m[04/30 15:47:46 d2.evaluation.evaluator]: \u001b[0mInference done 3771/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:08:07\n",
            "\u001b[32m[04/30 15:47:51 d2.evaluation.evaluator]: \u001b[0mInference done 3784/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:08:02\n",
            "\u001b[32m[04/30 15:47:56 d2.evaluation.evaluator]: \u001b[0mInference done 3797/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:07:57\n",
            "\u001b[32m[04/30 15:48:01 d2.evaluation.evaluator]: \u001b[0mInference done 3810/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:07:52\n",
            "\u001b[32m[04/30 15:48:07 d2.evaluation.evaluator]: \u001b[0mInference done 3823/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3969 s/iter. ETA=0:07:47\n",
            "\u001b[32m[04/30 15:48:12 d2.evaluation.evaluator]: \u001b[0mInference done 3836/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:42\n",
            "\u001b[32m[04/30 15:48:17 d2.evaluation.evaluator]: \u001b[0mInference done 3849/5000. Dataloading: 0.0020 s/iter. Inference: 0.3946 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:36\n",
            "\u001b[32m[04/30 15:48:22 d2.evaluation.evaluator]: \u001b[0mInference done 3862/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:31\n",
            "\u001b[32m[04/30 15:48:28 d2.evaluation.evaluator]: \u001b[0mInference done 3875/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:26\n",
            "\u001b[32m[04/30 15:48:33 d2.evaluation.evaluator]: \u001b[0mInference done 3888/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:21\n",
            "\u001b[32m[04/30 15:48:38 d2.evaluation.evaluator]: \u001b[0mInference done 3901/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:16\n",
            "\u001b[32m[04/30 15:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 3914/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:11\n",
            "\u001b[32m[04/30 15:48:48 d2.evaluation.evaluator]: \u001b[0mInference done 3927/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:06\n",
            "\u001b[32m[04/30 15:48:53 d2.evaluation.evaluator]: \u001b[0mInference done 3940/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:07:00\n",
            "\u001b[32m[04/30 15:48:59 d2.evaluation.evaluator]: \u001b[0mInference done 3953/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:06:55\n",
            "\u001b[32m[04/30 15:49:04 d2.evaluation.evaluator]: \u001b[0mInference done 3966/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3970 s/iter. ETA=0:06:50\n",
            "\u001b[32m[04/30 15:49:09 d2.evaluation.evaluator]: \u001b[0mInference done 3979/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:45\n",
            "\u001b[32m[04/30 15:49:14 d2.evaluation.evaluator]: \u001b[0mInference done 3992/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:40\n",
            "\u001b[32m[04/30 15:49:19 d2.evaluation.evaluator]: \u001b[0mInference done 4005/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:35\n",
            "\u001b[32m[04/30 15:49:25 d2.evaluation.evaluator]: \u001b[0mInference done 4018/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:29\n",
            "\u001b[32m[04/30 15:49:30 d2.evaluation.evaluator]: \u001b[0mInference done 4031/5000. Dataloading: 0.0020 s/iter. Inference: 0.3947 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:24\n",
            "\u001b[32m[04/30 15:49:35 d2.evaluation.evaluator]: \u001b[0mInference done 4044/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:19\n",
            "\u001b[32m[04/30 15:49:40 d2.evaluation.evaluator]: \u001b[0mInference done 4057/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:14\n",
            "\u001b[32m[04/30 15:49:45 d2.evaluation.evaluator]: \u001b[0mInference done 4070/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:09\n",
            "\u001b[32m[04/30 15:49:51 d2.evaluation.evaluator]: \u001b[0mInference done 4083/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:06:04\n",
            "\u001b[32m[04/30 15:49:56 d2.evaluation.evaluator]: \u001b[0mInference done 4096/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:05:59\n",
            "\u001b[32m[04/30 15:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 4109/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0002 s/iter. Total: 0.3971 s/iter. ETA=0:05:53\n",
            "\u001b[32m[04/30 15:50:06 d2.evaluation.evaluator]: \u001b[0mInference done 4122/5000. Dataloading: 0.0020 s/iter. Inference: 0.3948 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:48\n",
            "\u001b[32m[04/30 15:50:12 d2.evaluation.evaluator]: \u001b[0mInference done 4135/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:43\n",
            "\u001b[32m[04/30 15:50:17 d2.evaluation.evaluator]: \u001b[0mInference done 4148/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:38\n",
            "\u001b[32m[04/30 15:50:22 d2.evaluation.evaluator]: \u001b[0mInference done 4161/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:33\n",
            "\u001b[32m[04/30 15:50:27 d2.evaluation.evaluator]: \u001b[0mInference done 4174/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:28\n",
            "\u001b[32m[04/30 15:50:32 d2.evaluation.evaluator]: \u001b[0mInference done 4187/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:22\n",
            "\u001b[32m[04/30 15:50:38 d2.evaluation.evaluator]: \u001b[0mInference done 4200/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:17\n",
            "\u001b[32m[04/30 15:50:43 d2.evaluation.evaluator]: \u001b[0mInference done 4213/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:12\n",
            "\u001b[32m[04/30 15:50:48 d2.evaluation.evaluator]: \u001b[0mInference done 4226/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:05:07\n",
            "\u001b[32m[04/30 15:50:53 d2.evaluation.evaluator]: \u001b[0mInference done 4239/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:05:02\n",
            "\u001b[32m[04/30 15:50:58 d2.evaluation.evaluator]: \u001b[0mInference done 4252/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:04:57\n",
            "\u001b[32m[04/30 15:51:03 d2.evaluation.evaluator]: \u001b[0mInference done 4265/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3972 s/iter. ETA=0:04:51\n",
            "\u001b[32m[04/30 15:51:09 d2.evaluation.evaluator]: \u001b[0mInference done 4278/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:46\n",
            "\u001b[32m[04/30 15:51:14 d2.evaluation.evaluator]: \u001b[0mInference done 4291/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:41\n",
            "\u001b[32m[04/30 15:51:19 d2.evaluation.evaluator]: \u001b[0mInference done 4304/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:36\n",
            "\u001b[32m[04/30 15:51:24 d2.evaluation.evaluator]: \u001b[0mInference done 4317/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:31\n",
            "\u001b[32m[04/30 15:51:29 d2.evaluation.evaluator]: \u001b[0mInference done 4330/5000. Dataloading: 0.0020 s/iter. Inference: 0.3949 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:26\n",
            "\u001b[32m[04/30 15:51:35 d2.evaluation.evaluator]: \u001b[0mInference done 4343/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:21\n",
            "\u001b[32m[04/30 15:51:40 d2.evaluation.evaluator]: \u001b[0mInference done 4356/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:15\n",
            "\u001b[32m[04/30 15:51:45 d2.evaluation.evaluator]: \u001b[0mInference done 4369/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:04:10\n",
            "\u001b[32m[04/30 15:51:50 d2.evaluation.evaluator]: \u001b[0mInference done 4382/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3973 s/iter. ETA=0:04:05\n",
            "\u001b[32m[04/30 15:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 4395/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:04:00\n",
            "\u001b[32m[04/30 15:52:01 d2.evaluation.evaluator]: \u001b[0mInference done 4408/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:55\n",
            "\u001b[32m[04/30 15:52:06 d2.evaluation.evaluator]: \u001b[0mInference done 4421/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:50\n",
            "\u001b[32m[04/30 15:52:11 d2.evaluation.evaluator]: \u001b[0mInference done 4434/5000. Dataloading: 0.0020 s/iter. Inference: 0.3950 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:44\n",
            "\u001b[32m[04/30 15:52:16 d2.evaluation.evaluator]: \u001b[0mInference done 4447/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:39\n",
            "\u001b[32m[04/30 15:52:22 d2.evaluation.evaluator]: \u001b[0mInference done 4460/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:34\n",
            "\u001b[32m[04/30 15:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 4473/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:29\n",
            "\u001b[32m[04/30 15:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 4486/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:24\n",
            "\u001b[32m[04/30 15:52:37 d2.evaluation.evaluator]: \u001b[0mInference done 4499/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:19\n",
            "\u001b[32m[04/30 15:52:42 d2.evaluation.evaluator]: \u001b[0mInference done 4512/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:13\n",
            "\u001b[32m[04/30 15:52:48 d2.evaluation.evaluator]: \u001b[0mInference done 4525/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:08\n",
            "\u001b[32m[04/30 15:52:53 d2.evaluation.evaluator]: \u001b[0mInference done 4538/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:03:03\n",
            "\u001b[32m[04/30 15:52:58 d2.evaluation.evaluator]: \u001b[0mInference done 4551/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3974 s/iter. ETA=0:02:58\n",
            "\u001b[32m[04/30 15:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 4564/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:53\n",
            "\u001b[32m[04/30 15:53:08 d2.evaluation.evaluator]: \u001b[0mInference done 4577/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:48\n",
            "\u001b[32m[04/30 15:53:14 d2.evaluation.evaluator]: \u001b[0mInference done 4590/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:42\n",
            "\u001b[32m[04/30 15:53:19 d2.evaluation.evaluator]: \u001b[0mInference done 4603/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:37\n",
            "\u001b[32m[04/30 15:53:24 d2.evaluation.evaluator]: \u001b[0mInference done 4616/5000. Dataloading: 0.0020 s/iter. Inference: 0.3951 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:32\n",
            "\u001b[32m[04/30 15:53:29 d2.evaluation.evaluator]: \u001b[0mInference done 4629/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:27\n",
            "\u001b[32m[04/30 15:53:34 d2.evaluation.evaluator]: \u001b[0mInference done 4642/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:22\n",
            "\u001b[32m[04/30 15:53:40 d2.evaluation.evaluator]: \u001b[0mInference done 4655/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:17\n",
            "\u001b[32m[04/30 15:53:45 d2.evaluation.evaluator]: \u001b[0mInference done 4668/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:11\n",
            "\u001b[32m[04/30 15:53:50 d2.evaluation.evaluator]: \u001b[0mInference done 4681/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:06\n",
            "\u001b[32m[04/30 15:53:55 d2.evaluation.evaluator]: \u001b[0mInference done 4694/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:02:01\n",
            "\u001b[32m[04/30 15:54:00 d2.evaluation.evaluator]: \u001b[0mInference done 4707/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:01:56\n",
            "\u001b[32m[04/30 15:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 4720/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:01:51\n",
            "\u001b[32m[04/30 15:54:11 d2.evaluation.evaluator]: \u001b[0mInference done 4733/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:01:46\n",
            "\u001b[32m[04/30 15:54:16 d2.evaluation.evaluator]: \u001b[0mInference done 4746/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:01:40\n",
            "\u001b[32m[04/30 15:54:21 d2.evaluation.evaluator]: \u001b[0mInference done 4759/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:01:35\n",
            "\u001b[32m[04/30 15:54:26 d2.evaluation.evaluator]: \u001b[0mInference done 4772/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:01:30\n",
            "\u001b[32m[04/30 15:54:31 d2.evaluation.evaluator]: \u001b[0mInference done 4785/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:01:25\n",
            "\u001b[32m[04/30 15:54:37 d2.evaluation.evaluator]: \u001b[0mInference done 4798/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:01:20\n",
            "\u001b[32m[04/30 15:54:42 d2.evaluation.evaluator]: \u001b[0mInference done 4811/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:01:15\n",
            "\u001b[32m[04/30 15:54:47 d2.evaluation.evaluator]: \u001b[0mInference done 4824/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:01:09\n",
            "\u001b[32m[04/30 15:54:52 d2.evaluation.evaluator]: \u001b[0mInference done 4837/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3975 s/iter. ETA=0:01:04\n",
            "\u001b[32m[04/30 15:54:57 d2.evaluation.evaluator]: \u001b[0mInference done 4850/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:59\n",
            "\u001b[32m[04/30 15:55:03 d2.evaluation.evaluator]: \u001b[0mInference done 4863/5000. Dataloading: 0.0020 s/iter. Inference: 0.3952 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:54\n",
            "\u001b[32m[04/30 15:55:08 d2.evaluation.evaluator]: \u001b[0mInference done 4876/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:49\n",
            "\u001b[32m[04/30 15:55:13 d2.evaluation.evaluator]: \u001b[0mInference done 4889/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:44\n",
            "\u001b[32m[04/30 15:55:18 d2.evaluation.evaluator]: \u001b[0mInference done 4902/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:38\n",
            "\u001b[32m[04/30 15:55:23 d2.evaluation.evaluator]: \u001b[0mInference done 4915/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:33\n",
            "\u001b[32m[04/30 15:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 4928/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:28\n",
            "\u001b[32m[04/30 15:55:34 d2.evaluation.evaluator]: \u001b[0mInference done 4941/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:23\n",
            "\u001b[32m[04/30 15:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 4954/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3976 s/iter. ETA=0:00:18\n",
            "\u001b[32m[04/30 15:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 4967/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3977 s/iter. ETA=0:00:13\n",
            "\u001b[32m[04/30 15:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 4980/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3977 s/iter. ETA=0:00:07\n",
            "\u001b[32m[04/30 15:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 4993/5000. Dataloading: 0.0020 s/iter. Inference: 0.3953 s/iter. Eval: 0.0002 s/iter. Total: 0.3977 s/iter. ETA=0:00:02\n",
            "\u001b[32m[04/30 15:55:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:33:06.530207 (0.397704 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 15:55:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:32:54 (0.395342 s / iter per device, on 1 devices)\n",
            "\u001b[32m[04/30 15:55:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/30 15:55:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/30 15:55:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.44s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/30 15:56:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/30 15:56:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 8.06 seconds.\n",
            "\u001b[32m[04/30 15:56:08 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/30 15:56:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.95 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.639\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.487\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.487\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.566\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.594\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738\n",
            "\u001b[32m[04/30 15:56:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 45.408 | 63.923 | 48.701 | 28.767 | 48.693 | 58.429 |\n",
            "\u001b[32m[04/30 15:56:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 58.624 | bicycle      | 32.908 | car            | 48.271 |\n",
            "| motorcycle    | 46.440 | airplane     | 68.067 | bus            | 68.425 |\n",
            "| train         | 66.699 | truck        | 38.693 | boat           | 30.799 |\n",
            "| traffic light | 31.221 | fire hydrant | 71.224 | stop sign      | 70.503 |\n",
            "| parking meter | 49.486 | bench        | 27.713 | bird           | 38.792 |\n",
            "| cat           | 74.579 | dog          | 67.272 | horse          | 60.823 |\n",
            "| sheep         | 55.491 | cow          | 61.081 | elephant       | 67.356 |\n",
            "| bear          | 73.520 | zebra        | 69.968 | giraffe        | 71.867 |\n",
            "| backpack      | 15.444 | umbrella     | 42.920 | handbag        | 17.071 |\n",
            "| tie           | 38.259 | suitcase     | 44.097 | frisbee        | 70.688 |\n",
            "| skis          | 28.861 | snowboard    | 41.994 | sports ball    | 51.488 |\n",
            "| kite          | 48.666 | baseball bat | 38.565 | baseball glove | 40.780 |\n",
            "| skateboard    | 58.474 | surfboard    | 43.512 | tennis racket  | 52.613 |\n",
            "| bottle        | 44.289 | wine glass   | 39.766 | cup            | 47.769 |\n",
            "| fork          | 41.927 | knife        | 26.748 | spoon          | 21.343 |\n",
            "| bowl          | 44.505 | banana       | 27.732 | apple          | 21.735 |\n",
            "| sandwich      | 36.654 | orange       | 30.908 | broccoli       | 24.763 |\n",
            "| carrot        | 25.473 | hot dog      | 34.539 | pizza          | 54.644 |\n",
            "| donut         | 51.431 | cake         | 40.581 | chair          | 30.304 |\n",
            "| couch         | 42.850 | potted plant | 28.514 | bed            | 47.883 |\n",
            "| dining table  | 31.143 | toilet       | 65.346 | tv             | 60.449 |\n",
            "| laptop        | 63.218 | mouse        | 63.567 | remote         | 40.392 |\n",
            "| keyboard      | 52.342 | cell phone   | 39.867 | microwave      | 61.073 |\n",
            "| oven          | 36.082 | toaster      | 34.250 | sink           | 40.465 |\n",
            "| refrigerator  | 59.283 | book         | 16.998 | clock          | 54.235 |\n",
            "| vase          | 41.118 | scissors     | 35.154 | teddy bear     | 52.487 |\n",
            "| hair drier    | 4.950  | toothbrush   | 32.600 |                |        |\n",
            "\u001b[32m[04/30 15:56:11 d2.engine.defaults]: \u001b[0mEvaluation results for coco_2017_val in csv format:\n",
            "\u001b[32m[04/30 15:56:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/30 15:56:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/30 15:56:11 d2.evaluation.testing]: \u001b[0mcopypaste: 45.4079,63.9231,48.7010,28.7674,48.6927,58.4289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[04/30 15:56:11 d2.engine.defaults]: Evaluation results for coco_2017_val in csv format:\n",
        "[04/30 15:56:11 d2.evaluation.testing]: copypaste: Task: bbox\n",
        "[04/30 15:56:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
        "[04/30 15:56:11 d2.evaluation.testing]: copypaste: 45.4079,63.9231,48.7010,28.7674,48.6927,58.4289"
      ],
      "metadata": {
        "id": "9FWvXdAsL_y4"
      },
      "id": "9FWvXdAsL_y4"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-ObjectDetection/faster_cascade_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x-3627ef78.pth"
      ],
      "metadata": {
        "id": "aYoEROmw9GYl"
      },
      "id": "aYoEROmw9GYl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-Detection/faster_cascade_rcnn_ResNeSt_200_FPN_syncbn_range-scale_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-ObjectDetection/faster_cascade_rcnn_ResNeSt_200_FPN_syncbn_range-scale_1x-1be2a87e.pth"
      ],
      "metadata": {
        "id": "36W3Ai_J9MLw"
      },
      "id": "36W3Ai_J9MLw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-Detection/faster_rcnn_ResNeSt_50_FPN_syncbn_range-scale_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-ObjectDetection/faster_rcnn_ResNeSt_50_FPN_syncbn_range-scale_1x-ad123c0b.pth"
      ],
      "metadata": {
        "id": "IFLGp30O9Pb1"
      },
      "id": "IFLGp30O9Pb1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/'Colab Notebooks'/ResNeSt-master/d2 && python train_net.py  \\\n",
        " --config-file ./configs/COCO-Detection/faster_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x.yaml \\\n",
        " --eval-only MODEL.WEIGHTS ./checkpoints/COCO-ObjectDetection/faster_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x-d8f284b6.pth"
      ],
      "metadata": {
        "id": "7ZqaE4aq9Xis"
      },
      "id": "7ZqaE4aq9Xis",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "We were ultimately able to reproduce all the experiments conducted on the pretrained models for the transfer learning tasks. ResNeSts indeed constitute an improvement to ResNets as backbone models for downstream tasks, at the same computational cost.\n",
        "\n",
        "The replications were conducted on semantic segmentation, instance segmentation and objet detection, with different level of ease. Semantic segmentation was easy to reproduce on ADE20k but the pretrained models are missing for CityScapes on both the GluonCV platform and the original article first author's website. Furthermore, we encountered several difficulties on instance segmentation and object detection because the documentation was not as clear, in particular concerning the match between the configurations files and the weight files. The task would have been made easier if it was possible to download the pretrained models from the net with pip, like in the other cases. Yet, we were still able to reproduce the experiments successfully.\n",
        "\n",
        "We chose to conduct the experiments on Colab. All things considered, opting immediatly for an AWS instance could have simplified the ordeal, for we have experienced many memory errors using Colab Pro.\n",
        "\n",
        "For further comments and analyses please consult our final report."
      ],
      "metadata": {
        "id": "wD6N-UR4i5k7"
      },
      "id": "wD6N-UR4i5k7"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qQtiLem0gzFq"
      },
      "id": "qQtiLem0gzFq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "ResNeSt-TransferLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
